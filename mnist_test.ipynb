{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82dc6d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2998166309626122\n",
      "=== epoch:1, train acc:0.183, test acc:0.187 ===\n",
      "train loss:2.2966422248973\n",
      "train loss:2.2950768683797733\n",
      "train loss:2.2889545877804207\n",
      "train loss:2.2836303264558504\n",
      "train loss:2.275257691662823\n",
      "train loss:2.259594953843099\n",
      "train loss:2.2473446065262075\n",
      "train loss:2.229762677755931\n",
      "train loss:2.213209430267651\n",
      "train loss:2.17926023046891\n",
      "train loss:2.1363436386286736\n",
      "train loss:2.081710113515117\n",
      "train loss:2.09837971800852\n",
      "train loss:2.0071977649189816\n",
      "train loss:1.9644921430399578\n",
      "train loss:1.8958366674232265\n",
      "train loss:1.7720676329109026\n",
      "train loss:1.8226363883818617\n",
      "train loss:1.6929681875751867\n",
      "train loss:1.5790621596996155\n",
      "train loss:1.5053439779182078\n",
      "train loss:1.4975330027454559\n",
      "train loss:1.3597414947637796\n",
      "train loss:1.2566156014615464\n",
      "train loss:1.2160356471396507\n",
      "train loss:1.065554269037058\n",
      "train loss:0.9645756498276316\n",
      "train loss:0.9403017422977215\n",
      "train loss:0.9245096256657298\n",
      "train loss:0.8966168650031902\n",
      "train loss:0.8592419060275704\n",
      "train loss:0.8216821709897535\n",
      "train loss:0.7528424440390571\n",
      "train loss:0.7047208647556947\n",
      "train loss:0.7118292962841207\n",
      "train loss:0.6434098795994682\n",
      "train loss:0.7443609747012608\n",
      "train loss:0.8766650179061188\n",
      "train loss:0.6503104325153332\n",
      "train loss:0.6566846339049716\n",
      "train loss:0.5747088041382296\n",
      "train loss:0.6262839712284475\n",
      "train loss:0.42082719247498274\n",
      "train loss:0.569606201170563\n",
      "train loss:0.5368887840188749\n",
      "train loss:0.6146269547296723\n",
      "train loss:0.6462223874524184\n",
      "train loss:0.7879167926757447\n",
      "train loss:0.7631951540401407\n",
      "train loss:0.40789954979928067\n",
      "train loss:0.5213418994041163\n",
      "train loss:0.35890405034104816\n",
      "train loss:0.753404496998527\n",
      "train loss:0.7028903068556602\n",
      "train loss:0.47631179732591966\n",
      "train loss:0.43951269056182174\n",
      "train loss:0.5012125984974124\n",
      "train loss:0.4870331679729215\n",
      "train loss:0.4255593076823839\n",
      "train loss:0.5126181681992837\n",
      "train loss:0.4808492474303225\n",
      "train loss:0.5754636487343792\n",
      "train loss:0.577819778334953\n",
      "train loss:0.35171267779787735\n",
      "train loss:0.3945506610431187\n",
      "train loss:0.52133272881825\n",
      "train loss:0.5617619012743361\n",
      "train loss:0.46886793158338924\n",
      "train loss:0.37637033658338404\n",
      "train loss:0.5276314752635768\n",
      "train loss:0.5807882036171909\n",
      "train loss:0.24744009001512376\n",
      "train loss:0.5763411810958525\n",
      "train loss:0.2592761703858023\n",
      "train loss:0.4591751259245201\n",
      "train loss:0.6449704725833076\n",
      "train loss:0.4332629487946862\n",
      "train loss:0.468579805616292\n",
      "train loss:0.4668947417770814\n",
      "train loss:0.47238095546759845\n",
      "train loss:0.36387519208007274\n",
      "train loss:0.4459825165812112\n",
      "train loss:0.4032830525379746\n",
      "train loss:0.47312694661549626\n",
      "train loss:0.37063028854392305\n",
      "train loss:0.3271295473198901\n",
      "train loss:0.3956250146990573\n",
      "train loss:0.36389275158362866\n",
      "train loss:0.4907616660829179\n",
      "train loss:0.38340749670420643\n",
      "train loss:0.39844828639777796\n",
      "train loss:0.4575221562419298\n",
      "train loss:0.2111441779701805\n",
      "train loss:0.3555766391824523\n",
      "train loss:0.31925781628543765\n",
      "train loss:0.3556589237300682\n",
      "train loss:0.33153306123255366\n",
      "train loss:0.30407390820917063\n",
      "train loss:0.3417404621155023\n",
      "train loss:0.5701187043782815\n",
      "train loss:0.19168321326240184\n",
      "train loss:0.369058161317576\n",
      "train loss:0.296517168834646\n",
      "train loss:0.4364628971325236\n",
      "train loss:0.2300210711473921\n",
      "train loss:0.3584884992919592\n",
      "train loss:0.2937664271029989\n",
      "train loss:0.3401800069799205\n",
      "train loss:0.4516838568895439\n",
      "train loss:0.33727282006570786\n",
      "train loss:0.3997862909781683\n",
      "train loss:0.3278683496190609\n",
      "train loss:0.31041561465800027\n",
      "train loss:0.2172973166643553\n",
      "train loss:0.27242424804600646\n",
      "train loss:0.3634851962365413\n",
      "train loss:0.2909041512415559\n",
      "train loss:0.2945748745275761\n",
      "train loss:0.3946613231333695\n",
      "train loss:0.3513813472730082\n",
      "train loss:0.3663502241675923\n",
      "train loss:0.4883901126661711\n",
      "train loss:0.3815308306762282\n",
      "train loss:0.36215585213618273\n",
      "train loss:0.38083091667755087\n",
      "train loss:0.4046672995176781\n",
      "train loss:0.24564136412789203\n",
      "train loss:0.4144551180152357\n",
      "train loss:0.3101328057559664\n",
      "train loss:0.30464000571649413\n",
      "train loss:0.2755855174197888\n",
      "train loss:0.26343234681828753\n",
      "train loss:0.30094879401769303\n",
      "train loss:0.45404241415279206\n",
      "train loss:0.2900256182911519\n",
      "train loss:0.2901771203733979\n",
      "train loss:0.3601669337611757\n",
      "train loss:0.41348808878234045\n",
      "train loss:0.27880483823570124\n",
      "train loss:0.21586899143988106\n",
      "train loss:0.17601973771864596\n",
      "train loss:0.33463269704029214\n",
      "train loss:0.2385587474795615\n",
      "train loss:0.29340357391375316\n",
      "train loss:0.23766000898927755\n",
      "train loss:0.23533117479170512\n",
      "train loss:0.15968192821997457\n",
      "train loss:0.311799300143041\n",
      "train loss:0.27243111465142333\n",
      "train loss:0.22102143173613106\n",
      "train loss:0.40275658230956585\n",
      "train loss:0.2721479769552264\n",
      "train loss:0.29176780847016703\n",
      "train loss:0.1667750686824308\n",
      "train loss:0.2711637423266107\n",
      "train loss:0.2464039150844472\n",
      "train loss:0.2124222979893511\n",
      "train loss:0.41143235668118355\n",
      "train loss:0.3324129257207485\n",
      "train loss:0.2573668756426545\n",
      "train loss:0.20925041821967094\n",
      "train loss:0.23192024503145922\n",
      "train loss:0.253826431480942\n",
      "train loss:0.28015460408405807\n",
      "train loss:0.28896611152709145\n",
      "train loss:0.3692800656670832\n",
      "train loss:0.36589225522167224\n",
      "train loss:0.4116443294870706\n",
      "train loss:0.2945853983197158\n",
      "train loss:0.2970951646593592\n",
      "train loss:0.300303543223411\n",
      "train loss:0.3952248070253687\n",
      "train loss:0.4205042981138381\n",
      "train loss:0.3316311379405856\n",
      "train loss:0.26179930004373897\n",
      "train loss:0.20946489636905766\n",
      "train loss:0.34379329157894634\n",
      "train loss:0.41441548004891077\n",
      "train loss:0.3744368869825808\n",
      "train loss:0.20095069244110303\n",
      "train loss:0.2617285228879439\n",
      "train loss:0.16613556047820505\n",
      "train loss:0.24502095743668056\n",
      "train loss:0.18867717839638262\n",
      "train loss:0.25489304289690223\n",
      "train loss:0.25490409342387993\n",
      "train loss:0.21639381425940646\n",
      "train loss:0.2842643876310922\n",
      "train loss:0.2507600934968211\n",
      "train loss:0.41939159323717473\n",
      "train loss:0.20171901721969165\n",
      "train loss:0.30038745146313545\n",
      "train loss:0.25606929197431966\n",
      "train loss:0.30145499487163935\n",
      "train loss:0.15337759416994132\n",
      "train loss:0.22334705671081018\n",
      "train loss:0.2813628053184086\n",
      "train loss:0.22268548253204112\n",
      "train loss:0.43453473041813545\n",
      "train loss:0.2098674358970038\n",
      "train loss:0.36483407739493917\n",
      "train loss:0.2158491806186403\n",
      "train loss:0.30974613554348923\n",
      "train loss:0.2597093047408594\n",
      "train loss:0.20569305111291591\n",
      "train loss:0.17374056111202668\n",
      "train loss:0.32314265056036845\n",
      "train loss:0.24276382667191923\n",
      "train loss:0.15306978013005246\n",
      "train loss:0.3291100346020524\n",
      "train loss:0.224368932813697\n",
      "train loss:0.40070999865444273\n",
      "train loss:0.4862991980792195\n",
      "train loss:0.1640557005877003\n",
      "train loss:0.29933643029934986\n",
      "train loss:0.23336625377820971\n",
      "train loss:0.16632619605207896\n",
      "train loss:0.2390898997661108\n",
      "train loss:0.28741481258339036\n",
      "train loss:0.31273470226349775\n",
      "train loss:0.2851300009007866\n",
      "train loss:0.19166428708487157\n",
      "train loss:0.23686538907580826\n",
      "train loss:0.15206979094807144\n",
      "train loss:0.28545129157648363\n",
      "train loss:0.20987446529209444\n",
      "train loss:0.3229393979858723\n",
      "train loss:0.1865146788969104\n",
      "train loss:0.21336619559269854\n",
      "train loss:0.24125636144186455\n",
      "train loss:0.1621794564841463\n",
      "train loss:0.2303006193480905\n",
      "train loss:0.3295569983612337\n",
      "train loss:0.2006266652049914\n",
      "train loss:0.21452104367048322\n",
      "train loss:0.25002243538345964\n",
      "train loss:0.22913297520216658\n",
      "train loss:0.17913271974179937\n",
      "train loss:0.1735471813593273\n",
      "train loss:0.20354566098989432\n",
      "train loss:0.34887299795034654\n",
      "train loss:0.3408978312961415\n",
      "train loss:0.20396857854698333\n",
      "train loss:0.15288711408449504\n",
      "train loss:0.16738757588999523\n",
      "train loss:0.23360777179252995\n",
      "train loss:0.36602645937607814\n",
      "train loss:0.16981269754547662\n",
      "train loss:0.22161569802506248\n",
      "train loss:0.2651176127761129\n",
      "train loss:0.15253733424807128\n",
      "train loss:0.23010910475114715\n",
      "train loss:0.19295173468328622\n",
      "train loss:0.1849343317314474\n",
      "train loss:0.1800073224749494\n",
      "train loss:0.23162886540912112\n",
      "train loss:0.24222428050944658\n",
      "train loss:0.2673658018217749\n",
      "train loss:0.3447828164215745\n",
      "train loss:0.39940835397007385\n",
      "train loss:0.3612582595083261\n",
      "train loss:0.13471157639303719\n",
      "train loss:0.24218239514048398\n",
      "train loss:0.241413081902567\n",
      "train loss:0.24235548631351736\n",
      "train loss:0.2388459917089386\n",
      "train loss:0.20227148978823392\n",
      "train loss:0.2377472351793039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1807881104761269\n",
      "train loss:0.2203021465153267\n",
      "train loss:0.14749214725750537\n",
      "train loss:0.2289562368683439\n",
      "train loss:0.21568278220622433\n",
      "train loss:0.14486771276727126\n",
      "train loss:0.20159508414478236\n",
      "train loss:0.24936455944384986\n",
      "train loss:0.13510530980304852\n",
      "train loss:0.247320993910061\n",
      "train loss:0.1815632617943366\n",
      "train loss:0.31485758595541263\n",
      "train loss:0.1577569187984503\n",
      "train loss:0.25714270015979396\n",
      "train loss:0.1634320584081633\n",
      "train loss:0.27653570206025513\n",
      "train loss:0.29096778599760653\n",
      "train loss:0.19795170592476058\n",
      "train loss:0.21040182607043273\n",
      "train loss:0.06639971497069205\n",
      "train loss:0.22578451959404877\n",
      "train loss:0.28349695363557087\n",
      "train loss:0.19524062295695638\n",
      "train loss:0.17110001556062876\n",
      "train loss:0.18305644758323647\n",
      "train loss:0.15738805555293348\n",
      "train loss:0.2299929727917423\n",
      "train loss:0.1926397893195049\n",
      "train loss:0.17673863027309875\n",
      "train loss:0.1256920520502097\n",
      "train loss:0.25887160764452755\n",
      "train loss:0.20009096585537217\n",
      "train loss:0.2638457435111872\n",
      "train loss:0.1404435362049969\n",
      "train loss:0.20536698884512053\n",
      "train loss:0.254951351388822\n",
      "train loss:0.13799710175055774\n",
      "train loss:0.22814373595439358\n",
      "train loss:0.11020439344521217\n",
      "train loss:0.12448075694038468\n",
      "train loss:0.23345528755557302\n",
      "train loss:0.10882684060114307\n",
      "train loss:0.23472776040653529\n",
      "train loss:0.2418128339008979\n",
      "train loss:0.21724887642555318\n",
      "train loss:0.1641750235154395\n",
      "train loss:0.20785266225418528\n",
      "train loss:0.15727167658864571\n",
      "train loss:0.15629732827698842\n",
      "train loss:0.1631261123370659\n",
      "train loss:0.13070388774981026\n",
      "train loss:0.2570383967973593\n",
      "train loss:0.14615974016679634\n",
      "train loss:0.178145769191755\n",
      "train loss:0.17013522385371235\n",
      "train loss:0.21477295889521217\n",
      "train loss:0.11517552926481382\n",
      "train loss:0.14766907148862327\n",
      "train loss:0.21950420301047896\n",
      "train loss:0.27403111585884454\n",
      "train loss:0.13507805491395025\n",
      "train loss:0.19069562499634943\n",
      "train loss:0.20657799664857718\n",
      "train loss:0.20551822492702967\n",
      "train loss:0.12243756128789177\n",
      "train loss:0.230321477498055\n",
      "train loss:0.13149885215413654\n",
      "train loss:0.11875343970466402\n",
      "train loss:0.1349304903168456\n",
      "train loss:0.15438660754941577\n",
      "train loss:0.17043491402567804\n",
      "train loss:0.11149351475898127\n",
      "train loss:0.19211839657524338\n",
      "train loss:0.1557497968534066\n",
      "train loss:0.16123416806369192\n",
      "train loss:0.23766005186609937\n",
      "train loss:0.116272792733951\n",
      "train loss:0.25018521368183044\n",
      "train loss:0.14314158053918288\n",
      "train loss:0.10283754261963211\n",
      "train loss:0.25155467981903923\n",
      "train loss:0.22180769966346012\n",
      "train loss:0.16456089592284134\n",
      "train loss:0.13124650246553388\n",
      "train loss:0.2867610469013243\n",
      "train loss:0.17883402830830372\n",
      "train loss:0.17792207014890146\n",
      "train loss:0.16452051260744793\n",
      "train loss:0.28461671385369747\n",
      "train loss:0.15129664016907032\n",
      "train loss:0.14199112664386426\n",
      "train loss:0.14599516522963304\n",
      "train loss:0.18466360084704653\n",
      "train loss:0.15842745250435447\n",
      "train loss:0.19076236475406297\n",
      "train loss:0.14313934862459846\n",
      "train loss:0.15441321236418112\n",
      "train loss:0.2160062025071616\n",
      "train loss:0.16110809403599197\n",
      "train loss:0.24652504527954572\n",
      "train loss:0.16472720680444974\n",
      "train loss:0.17764714409383026\n",
      "train loss:0.17870690807866782\n",
      "train loss:0.1760998404175644\n",
      "train loss:0.1561319980029949\n",
      "train loss:0.14370606354232912\n",
      "train loss:0.14040372331966727\n",
      "train loss:0.25547394182479344\n",
      "train loss:0.2137297485075373\n",
      "train loss:0.1426716409519891\n",
      "train loss:0.11765683953249578\n",
      "train loss:0.21975830392514356\n",
      "train loss:0.08697555651123015\n",
      "train loss:0.09672234398426023\n",
      "train loss:0.12144735079299881\n",
      "train loss:0.16230033117530807\n",
      "train loss:0.10904587000655035\n",
      "train loss:0.09171579262543242\n",
      "train loss:0.10523319406627701\n",
      "train loss:0.1426036657338871\n",
      "train loss:0.13852886910471943\n",
      "train loss:0.16567813816671276\n",
      "train loss:0.20189631999148336\n",
      "train loss:0.1178360469683682\n",
      "train loss:0.14548394464495437\n",
      "train loss:0.24836662739717025\n",
      "train loss:0.1649312574386949\n",
      "train loss:0.14773601460916683\n",
      "train loss:0.17442633470045385\n",
      "train loss:0.14054038694318383\n",
      "train loss:0.13430779390462125\n",
      "train loss:0.11169861214203579\n",
      "train loss:0.1057929304374265\n",
      "train loss:0.04720123643781715\n",
      "train loss:0.1811378935182544\n",
      "train loss:0.10954533783705542\n",
      "train loss:0.09946537307986339\n",
      "train loss:0.060131668613837445\n",
      "train loss:0.16439554494812145\n",
      "train loss:0.19985387660740125\n",
      "train loss:0.1326803022250096\n",
      "train loss:0.06760763781255369\n",
      "train loss:0.12519241420223348\n",
      "train loss:0.0761567120868573\n",
      "train loss:0.1877665398109107\n",
      "train loss:0.33834651970983654\n",
      "train loss:0.12366965331675542\n",
      "train loss:0.16223091116018606\n",
      "train loss:0.17128887464144232\n",
      "train loss:0.1440656703158473\n",
      "train loss:0.19285712485046236\n",
      "train loss:0.2061252254541061\n",
      "train loss:0.22583943800530587\n",
      "train loss:0.2237086107814216\n",
      "train loss:0.1277304102407594\n",
      "train loss:0.20813965267622273\n",
      "train loss:0.13700137385650235\n",
      "train loss:0.13000104582308583\n",
      "train loss:0.09971774966420162\n",
      "train loss:0.21751820424771087\n",
      "train loss:0.12094658767861874\n",
      "train loss:0.13626243651864398\n",
      "train loss:0.12471808183386335\n",
      "train loss:0.20408520200655947\n",
      "train loss:0.11987153019807083\n",
      "train loss:0.08073581694605815\n",
      "train loss:0.13896177175602953\n",
      "train loss:0.12057262993446649\n",
      "train loss:0.06197387371120114\n",
      "train loss:0.14621256984959255\n",
      "train loss:0.09947080077534466\n",
      "train loss:0.11995409486107231\n",
      "train loss:0.07939199251910414\n",
      "train loss:0.11042940121227061\n",
      "train loss:0.12405703814996369\n",
      "train loss:0.1065736734488815\n",
      "train loss:0.1900195750674395\n",
      "train loss:0.14020751059460881\n",
      "train loss:0.2206936391217968\n",
      "train loss:0.23173415257230293\n",
      "train loss:0.1121955928217795\n",
      "train loss:0.15623034735459088\n",
      "train loss:0.06976141371603878\n",
      "train loss:0.09853952441414314\n",
      "train loss:0.14438590446813396\n",
      "train loss:0.12999670561994967\n",
      "train loss:0.11520942619631235\n",
      "train loss:0.10257381929622765\n",
      "train loss:0.10930213802384901\n",
      "train loss:0.08912412954881638\n",
      "train loss:0.10006028450909876\n",
      "train loss:0.2037133553538851\n",
      "train loss:0.23264206231273182\n",
      "train loss:0.09891924670239055\n",
      "train loss:0.1261318012592909\n",
      "train loss:0.1359978782665441\n",
      "train loss:0.17168322097227248\n",
      "train loss:0.18768823407080132\n",
      "train loss:0.16314468631843565\n",
      "train loss:0.08243719993624242\n",
      "train loss:0.1156676891159233\n",
      "train loss:0.1408144352966313\n",
      "train loss:0.043087775034946735\n",
      "train loss:0.09186652656756984\n",
      "train loss:0.16635029684215077\n",
      "train loss:0.13995460526866238\n",
      "train loss:0.19206390038944093\n",
      "train loss:0.0719746006037309\n",
      "train loss:0.2365077915404761\n",
      "train loss:0.08412449972453451\n",
      "train loss:0.08075885061124052\n",
      "train loss:0.22882902849476808\n",
      "train loss:0.13062114817585005\n",
      "train loss:0.13555246784299044\n",
      "train loss:0.15091099435548203\n",
      "train loss:0.05177473435660307\n",
      "train loss:0.22188558491632854\n",
      "train loss:0.06904635861810983\n",
      "train loss:0.16950203309663633\n",
      "train loss:0.18656853402176596\n",
      "train loss:0.16173393271160988\n",
      "train loss:0.08991941283552746\n",
      "train loss:0.16086371801176175\n",
      "train loss:0.05896055834682205\n",
      "train loss:0.12333744375069569\n",
      "train loss:0.051120755154826905\n",
      "train loss:0.11423618590212833\n",
      "train loss:0.16760584805536702\n",
      "train loss:0.11351470886616012\n",
      "train loss:0.1678728501048176\n",
      "train loss:0.18465604440633598\n",
      "train loss:0.10571187598363399\n",
      "=== epoch:2, train acc:0.96, test acc:0.958 ===\n",
      "train loss:0.07160507435488027\n",
      "train loss:0.16671130443762086\n",
      "train loss:0.15185677297040417\n",
      "train loss:0.11597239602382436\n",
      "train loss:0.1842318113826846\n",
      "train loss:0.11637185647851808\n",
      "train loss:0.15285903646415114\n",
      "train loss:0.15277880818327863\n",
      "train loss:0.11833505908151261\n",
      "train loss:0.10151886571205686\n",
      "train loss:0.08030006059097873\n",
      "train loss:0.07285954703514193\n",
      "train loss:0.15354668408085312\n",
      "train loss:0.21249808500480075\n",
      "train loss:0.09578886798630618\n",
      "train loss:0.1610949582690603\n",
      "train loss:0.1892371530450065\n",
      "train loss:0.12378822803174057\n",
      "train loss:0.13985795391443812\n",
      "train loss:0.08909158353281721\n",
      "train loss:0.08935168541233418\n",
      "train loss:0.18259453635169862\n",
      "train loss:0.13316468968453954\n",
      "train loss:0.10367720025054658\n",
      "train loss:0.09412630856406592\n",
      "train loss:0.1633406290755711\n",
      "train loss:0.1531655165649987\n",
      "train loss:0.15167072247803243\n",
      "train loss:0.13588001666221852\n",
      "train loss:0.06913374535948699\n",
      "train loss:0.09254332549570655\n",
      "train loss:0.12944760670688743\n",
      "train loss:0.11194379924282333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1212605925990169\n",
      "train loss:0.17145694667380793\n",
      "train loss:0.07315668994553111\n",
      "train loss:0.10407064700462713\n",
      "train loss:0.043534384435236065\n",
      "train loss:0.15110222269025306\n",
      "train loss:0.17907755645690682\n",
      "train loss:0.1853572669446562\n",
      "train loss:0.12084442452649863\n",
      "train loss:0.12696914331851575\n",
      "train loss:0.07067237763098004\n",
      "train loss:0.2479429821963444\n",
      "train loss:0.08599736350229455\n",
      "train loss:0.10022905511167922\n",
      "train loss:0.09263210457439645\n",
      "train loss:0.1129960297040301\n",
      "train loss:0.19549779409488127\n",
      "train loss:0.16911189721345185\n",
      "train loss:0.08947470722984859\n",
      "train loss:0.12127651493735478\n",
      "train loss:0.1008633777193063\n",
      "train loss:0.06236858751463143\n",
      "train loss:0.09359861323281957\n",
      "train loss:0.10058454778204576\n",
      "train loss:0.07733169005523563\n",
      "train loss:0.09356181941407685\n",
      "train loss:0.11828108013665031\n",
      "train loss:0.08182590189328423\n",
      "train loss:0.11088176151517391\n",
      "train loss:0.1079549493927206\n",
      "train loss:0.15651079273553314\n",
      "train loss:0.08089476828045593\n",
      "train loss:0.04097039399885141\n",
      "train loss:0.071872625107791\n",
      "train loss:0.06935004653627187\n",
      "train loss:0.11828928120289821\n",
      "train loss:0.06749580583005864\n",
      "train loss:0.08076475625081003\n",
      "train loss:0.09219723680289828\n",
      "train loss:0.05317421001378639\n",
      "train loss:0.06206295797888507\n",
      "train loss:0.08260085929002832\n",
      "train loss:0.13702130926182515\n",
      "train loss:0.07834495802855085\n",
      "train loss:0.047477258714212135\n",
      "train loss:0.0747038439919443\n",
      "train loss:0.13666904100426447\n",
      "train loss:0.136099628084425\n",
      "train loss:0.07542237725613796\n",
      "train loss:0.07412599232961012\n",
      "train loss:0.05000349405610223\n",
      "train loss:0.13949413640811828\n",
      "train loss:0.08122566545346183\n",
      "train loss:0.1470274098309651\n",
      "train loss:0.1220383103284399\n",
      "train loss:0.0897997972861427\n",
      "train loss:0.1258692120577169\n",
      "train loss:0.11235336773546087\n",
      "train loss:0.13779998217674602\n",
      "train loss:0.0729568676770101\n",
      "train loss:0.05957178208897939\n",
      "train loss:0.02843912482603966\n",
      "train loss:0.10374850217939503\n",
      "train loss:0.171555966589775\n",
      "train loss:0.06853542645494949\n",
      "train loss:0.11386264528087944\n",
      "train loss:0.16909371283385954\n",
      "train loss:0.1949823101451336\n",
      "train loss:0.052056816596784156\n",
      "train loss:0.2243161762757304\n",
      "train loss:0.08892696011521917\n",
      "train loss:0.06984805019785731\n",
      "train loss:0.20179713238238467\n",
      "train loss:0.08428970037431262\n",
      "train loss:0.08334909821256739\n",
      "train loss:0.14937859649658428\n",
      "train loss:0.0446428392425676\n",
      "train loss:0.09302862153493517\n",
      "train loss:0.037557863147954\n",
      "train loss:0.09676536017302013\n",
      "train loss:0.08028935711998136\n",
      "train loss:0.18517633810181638\n",
      "train loss:0.033272204105700746\n",
      "train loss:0.07679753764154154\n",
      "train loss:0.05539418094450591\n",
      "train loss:0.0882497660766212\n",
      "train loss:0.11509222647416349\n",
      "train loss:0.105567839489233\n",
      "train loss:0.12203128908755036\n",
      "train loss:0.1479345235699128\n",
      "train loss:0.044891753478149984\n",
      "train loss:0.14474224243013692\n",
      "train loss:0.07333035103604797\n",
      "train loss:0.09285573862882407\n",
      "train loss:0.13298625603739914\n",
      "train loss:0.14329015898439745\n",
      "train loss:0.07729881271639248\n",
      "train loss:0.11887010775218758\n",
      "train loss:0.1362104946993515\n",
      "train loss:0.099905755222552\n",
      "train loss:0.17847803986758773\n",
      "train loss:0.09085101367306224\n",
      "train loss:0.0549823494553184\n",
      "train loss:0.07457194748523091\n",
      "train loss:0.18334699136645144\n",
      "train loss:0.07456735659208524\n",
      "train loss:0.05285673728520154\n",
      "train loss:0.08004126826050738\n",
      "train loss:0.046203909509837625\n",
      "train loss:0.20527546874339833\n",
      "train loss:0.06890807729405266\n",
      "train loss:0.06710382206154089\n",
      "train loss:0.10989140452969502\n",
      "train loss:0.06845585378298692\n",
      "train loss:0.10968080661003111\n",
      "train loss:0.12894948593772457\n",
      "train loss:0.03995857597545064\n",
      "train loss:0.10990963460505082\n",
      "train loss:0.07818279351135242\n",
      "train loss:0.10697613970161383\n",
      "train loss:0.05250378644067215\n",
      "train loss:0.1308763448029457\n",
      "train loss:0.10805340934652176\n",
      "train loss:0.1101115724715888\n",
      "train loss:0.11531334557988814\n",
      "train loss:0.12170900281672843\n",
      "train loss:0.034118883762124845\n",
      "train loss:0.1853777878815193\n",
      "train loss:0.0546270685517303\n",
      "train loss:0.06260928485922658\n",
      "train loss:0.10870365243694581\n",
      "train loss:0.16264484782864547\n",
      "train loss:0.07246784407949798\n",
      "train loss:0.044528396229108175\n",
      "train loss:0.13673611638459818\n",
      "train loss:0.07525624114755083\n",
      "train loss:0.05350666748872333\n",
      "train loss:0.08499820587156262\n",
      "train loss:0.14034100891343007\n",
      "train loss:0.11543042297981006\n",
      "train loss:0.145130026073405\n",
      "train loss:0.07480525492850862\n",
      "train loss:0.04538108661901784\n",
      "train loss:0.08491030111050961\n",
      "train loss:0.13963768185993797\n",
      "train loss:0.07243310995575003\n",
      "train loss:0.08602503201430323\n",
      "train loss:0.10479301648167996\n",
      "train loss:0.15187938708366613\n",
      "train loss:0.04847671943414231\n",
      "train loss:0.1997324205042936\n",
      "train loss:0.04545268841957701\n",
      "train loss:0.08194920434939505\n",
      "train loss:0.08523545491237915\n",
      "train loss:0.13522591086651747\n",
      "train loss:0.07482229743597663\n",
      "train loss:0.11431548316898024\n",
      "train loss:0.08521076574931082\n",
      "train loss:0.03955998961266109\n",
      "train loss:0.11941200921733384\n",
      "train loss:0.11939729303590586\n",
      "train loss:0.16125193063610915\n",
      "train loss:0.06810167166986357\n",
      "train loss:0.11762068066725512\n",
      "train loss:0.08491323184821242\n",
      "train loss:0.12244999236247635\n",
      "train loss:0.041784574780778204\n",
      "train loss:0.04613941650010408\n",
      "train loss:0.09595533674310298\n",
      "train loss:0.09211309034542525\n",
      "train loss:0.08058908249336033\n",
      "train loss:0.04629434944387592\n",
      "train loss:0.05896456465077153\n",
      "train loss:0.09640187227775639\n",
      "train loss:0.14232637704499804\n",
      "train loss:0.04847858636768532\n",
      "train loss:0.0704482972243936\n",
      "train loss:0.09784357836102492\n",
      "train loss:0.12161591583452416\n",
      "train loss:0.06700086736080994\n",
      "train loss:0.03557651228014317\n",
      "train loss:0.040865405289483285\n",
      "train loss:0.05796374808819229\n",
      "train loss:0.06524332460300968\n",
      "train loss:0.06906622747028572\n",
      "train loss:0.03616681686606579\n",
      "train loss:0.10953610782143913\n",
      "train loss:0.029228167208208547\n",
      "train loss:0.21276228227100624\n",
      "train loss:0.0452794674101652\n",
      "train loss:0.10488121091739491\n",
      "train loss:0.09708897578580396\n",
      "train loss:0.12550693002632166\n",
      "train loss:0.12631299846899938\n",
      "train loss:0.06672913286856441\n",
      "train loss:0.06697660479026815\n",
      "train loss:0.21032311836760129\n",
      "train loss:0.06681901389180413\n",
      "train loss:0.11612467070099267\n",
      "train loss:0.12676353798872764\n",
      "train loss:0.08189295128545895\n",
      "train loss:0.10319790082698582\n",
      "train loss:0.16911614190002833\n",
      "train loss:0.12924588374743698\n",
      "train loss:0.09987360714177583\n",
      "train loss:0.04146683879162617\n",
      "train loss:0.08843179235539246\n",
      "train loss:0.0772129580886953\n",
      "train loss:0.10253254400581624\n",
      "train loss:0.13496696915957454\n",
      "train loss:0.06940287440509998\n",
      "train loss:0.03238927434293903\n",
      "train loss:0.02215021920784695\n",
      "train loss:0.1516239643597916\n",
      "train loss:0.11556730273829206\n",
      "train loss:0.059229670226991514\n",
      "train loss:0.0892094810480814\n",
      "train loss:0.03229775755883822\n",
      "train loss:0.10680421987952067\n",
      "train loss:0.0728498779684673\n",
      "train loss:0.04976031456355604\n",
      "train loss:0.06863627627476535\n",
      "train loss:0.20563509416075226\n",
      "train loss:0.09309305515240501\n",
      "train loss:0.0786522725642865\n",
      "train loss:0.07868238859765543\n",
      "train loss:0.08601777637207178\n",
      "train loss:0.0579077535652168\n",
      "train loss:0.17449103447504033\n",
      "train loss:0.1423919024554336\n",
      "train loss:0.0678441892518997\n",
      "train loss:0.05787175884508003\n",
      "train loss:0.11595023313741087\n",
      "train loss:0.024359560759122274\n",
      "train loss:0.11894921940368842\n",
      "train loss:0.16651506157611032\n",
      "train loss:0.10194719576932562\n",
      "train loss:0.08435375383837848\n",
      "train loss:0.055622964956986515\n",
      "train loss:0.05136959304545648\n",
      "train loss:0.06858508030531743\n",
      "train loss:0.06635471297972792\n",
      "train loss:0.2169046704252556\n",
      "train loss:0.07599266832643922\n",
      "train loss:0.10455822719088902\n",
      "train loss:0.0683400323718954\n",
      "train loss:0.04024144226328201\n",
      "train loss:0.20449683126872922\n",
      "train loss:0.048401080160479414\n",
      "train loss:0.04375504967238825\n",
      "train loss:0.10912367200189976\n",
      "train loss:0.08593957464053387\n",
      "train loss:0.04175245079924512\n",
      "train loss:0.06252509061698659\n",
      "train loss:0.11105504599516962\n",
      "train loss:0.09327129996437039\n",
      "train loss:0.061845985732056796\n",
      "train loss:0.05582535391037906\n",
      "train loss:0.11473161205515597\n",
      "train loss:0.05341531959919436\n",
      "train loss:0.07341098533066744\n",
      "train loss:0.12664081968283145\n",
      "train loss:0.1024347084723843\n",
      "train loss:0.04013549039209128\n",
      "train loss:0.08777570582801589\n",
      "train loss:0.06463911926217535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08144371724151628\n",
      "train loss:0.04563351948337208\n",
      "train loss:0.0854731594709568\n",
      "train loss:0.15320281741844768\n",
      "train loss:0.06770754204309665\n",
      "train loss:0.036901392584924135\n",
      "train loss:0.09776767672249521\n",
      "train loss:0.11493847614119374\n",
      "train loss:0.10575830278740943\n",
      "train loss:0.04041905246864463\n",
      "train loss:0.06538029670177262\n",
      "train loss:0.04879025994418716\n",
      "train loss:0.08210792018497085\n",
      "train loss:0.12765956780643403\n",
      "train loss:0.06632330184505757\n",
      "train loss:0.09504895735923605\n",
      "train loss:0.12550143136829142\n",
      "train loss:0.12481284310582552\n",
      "train loss:0.0786628743285753\n",
      "train loss:0.3286992991388129\n",
      "train loss:0.12235427756876358\n",
      "train loss:0.06327038222507285\n",
      "train loss:0.032908198645215554\n",
      "train loss:0.032129520332219844\n",
      "train loss:0.0927218076469005\n",
      "train loss:0.07836568943061396\n",
      "train loss:0.04593786155459967\n",
      "train loss:0.0709719513517328\n",
      "train loss:0.1444544409246463\n",
      "train loss:0.07489054544969839\n",
      "train loss:0.056432129944166\n",
      "train loss:0.07531995511726179\n",
      "train loss:0.10535219362472815\n",
      "train loss:0.049465367405159374\n",
      "train loss:0.06319895628569012\n",
      "train loss:0.025826070464620487\n",
      "train loss:0.05712890443950336\n",
      "train loss:0.05914994262657318\n",
      "train loss:0.09724161262497127\n",
      "train loss:0.05125052733522984\n",
      "train loss:0.1790106037929341\n",
      "train loss:0.0703770393073159\n",
      "train loss:0.07921791688049555\n",
      "train loss:0.12637089605305\n",
      "train loss:0.11546173461354516\n",
      "train loss:0.11916160790360339\n",
      "train loss:0.11117591312223433\n",
      "train loss:0.10091164232742764\n",
      "train loss:0.041056223321519654\n",
      "train loss:0.20506387165819218\n",
      "train loss:0.04978285148951793\n",
      "train loss:0.0647938081002117\n",
      "train loss:0.07221725714542213\n",
      "train loss:0.09184031323464922\n",
      "train loss:0.02809253012557046\n",
      "train loss:0.13170006966589723\n",
      "train loss:0.08232534203009356\n",
      "train loss:0.07664283778192506\n",
      "train loss:0.023297653061731118\n",
      "train loss:0.05059992273007211\n",
      "train loss:0.05823888991447013\n",
      "train loss:0.046401241472638806\n",
      "train loss:0.114926953051682\n",
      "train loss:0.12998193042338407\n",
      "train loss:0.0339386991091671\n",
      "train loss:0.04906718251686106\n",
      "train loss:0.15296905346952805\n",
      "train loss:0.08439392499762534\n",
      "train loss:0.0679872146714913\n",
      "train loss:0.08856649858755529\n",
      "train loss:0.09366087830235485\n",
      "train loss:0.13038666121361359\n",
      "train loss:0.060973435777719645\n",
      "train loss:0.10668390266370327\n",
      "train loss:0.0657483608846139\n",
      "train loss:0.03208676632405869\n",
      "train loss:0.05311062892104244\n",
      "train loss:0.11341097371195337\n",
      "train loss:0.05556835900180909\n",
      "train loss:0.03911454477383871\n",
      "train loss:0.04640707796661685\n",
      "train loss:0.06000464076540584\n",
      "train loss:0.12150827879904891\n",
      "train loss:0.07984838182943568\n",
      "train loss:0.11286775408160968\n",
      "train loss:0.12092471895741162\n",
      "train loss:0.08637773797607616\n",
      "train loss:0.07958771533007875\n",
      "train loss:0.0624333101450641\n",
      "train loss:0.06349181090346148\n",
      "train loss:0.07272758870368391\n",
      "train loss:0.11410389606294431\n",
      "train loss:0.0930267289971287\n",
      "train loss:0.034825945534887555\n",
      "train loss:0.1883399672906926\n",
      "train loss:0.05981400478178123\n",
      "train loss:0.058914515389168635\n",
      "train loss:0.07111410005930367\n",
      "train loss:0.11583577332961936\n",
      "train loss:0.10752469902385557\n",
      "train loss:0.07957854887089862\n",
      "train loss:0.0677010547404191\n",
      "train loss:0.09317248733645975\n",
      "train loss:0.11466448442736388\n",
      "train loss:0.06936792128748455\n",
      "train loss:0.0470680460702663\n",
      "train loss:0.048222045848858294\n",
      "train loss:0.1083678805947699\n",
      "train loss:0.11103458658683257\n",
      "train loss:0.07847253616303583\n",
      "train loss:0.10812377497632628\n",
      "train loss:0.12042905917092178\n",
      "train loss:0.033870455035305926\n",
      "train loss:0.07214759107694893\n",
      "train loss:0.09812942102682509\n",
      "train loss:0.12709288186421755\n",
      "train loss:0.03783986708699454\n",
      "train loss:0.03607954677873033\n",
      "train loss:0.03819237111839078\n",
      "train loss:0.11561235331333544\n",
      "train loss:0.08952996161118405\n",
      "train loss:0.10008158743856335\n",
      "train loss:0.1059226473276724\n",
      "train loss:0.042806582814722355\n",
      "train loss:0.09290797471454368\n",
      "train loss:0.06605194168754136\n",
      "train loss:0.055657941980274295\n",
      "train loss:0.11152497087215937\n",
      "train loss:0.06400548927532443\n",
      "train loss:0.09537589907498259\n",
      "train loss:0.09234771527198891\n",
      "train loss:0.07529560021742232\n",
      "train loss:0.05286882312055561\n",
      "train loss:0.09542422856304951\n",
      "train loss:0.08981731510354765\n",
      "train loss:0.06562661803860134\n",
      "train loss:0.09095397681146948\n",
      "train loss:0.13106407129096673\n",
      "train loss:0.05269047242307946\n",
      "train loss:0.08712516162899518\n",
      "train loss:0.0998685952860789\n",
      "train loss:0.04521325357546965\n",
      "train loss:0.047229365524066945\n",
      "train loss:0.0482329675155801\n",
      "train loss:0.07973226116549288\n",
      "train loss:0.048786801254793545\n",
      "train loss:0.04079805391841166\n",
      "train loss:0.09326603752052329\n",
      "train loss:0.04101387244891095\n",
      "train loss:0.08079284002745817\n",
      "train loss:0.08073765411791906\n",
      "train loss:0.04938534622461277\n",
      "train loss:0.04100238332712203\n",
      "train loss:0.07083872445888278\n",
      "train loss:0.09033616495214435\n",
      "train loss:0.045304415498501706\n",
      "train loss:0.13468529608872848\n",
      "train loss:0.13936163147191705\n",
      "train loss:0.037030674535678404\n",
      "train loss:0.09342886949866666\n",
      "train loss:0.039360162673336516\n",
      "train loss:0.1282856529336218\n",
      "train loss:0.11164969778761218\n",
      "train loss:0.0902328356401731\n",
      "train loss:0.05275246537231162\n",
      "train loss:0.04237857907984955\n",
      "train loss:0.06980106662429847\n",
      "train loss:0.0798382218108947\n",
      "train loss:0.13310356238288876\n",
      "train loss:0.07896069262506304\n",
      "train loss:0.09074252129861422\n",
      "train loss:0.07273691730126935\n",
      "train loss:0.15008659180621536\n",
      "train loss:0.047169124390251144\n",
      "train loss:0.10588395968609692\n",
      "train loss:0.10709350415127948\n",
      "train loss:0.11431115861168335\n",
      "train loss:0.08865104886089516\n",
      "train loss:0.022492201034446126\n",
      "train loss:0.053381414648149175\n",
      "train loss:0.052208967906103985\n",
      "train loss:0.08418238906247964\n",
      "train loss:0.11887799411099544\n",
      "train loss:0.07114708591952643\n",
      "train loss:0.10073738540698242\n",
      "train loss:0.08316982839336219\n",
      "train loss:0.08219619440545557\n",
      "train loss:0.08768833349164518\n",
      "train loss:0.11425481364694426\n",
      "train loss:0.05770223529078831\n",
      "train loss:0.05884244345605336\n",
      "train loss:0.09848125266993356\n",
      "train loss:0.034100832363496786\n",
      "train loss:0.10003132330005356\n",
      "train loss:0.04802977952593933\n",
      "train loss:0.054346697759386164\n",
      "train loss:0.06873777577225644\n",
      "train loss:0.06280280568258324\n",
      "train loss:0.07801742403755234\n",
      "train loss:0.12329190999464418\n",
      "train loss:0.13816262175881894\n",
      "=== epoch:3, train acc:0.975, test acc:0.975 ===\n",
      "train loss:0.15073147548784263\n",
      "train loss:0.02816151493197624\n",
      "train loss:0.06787698679795956\n",
      "train loss:0.0865176700968387\n",
      "train loss:0.04762248473898049\n",
      "train loss:0.06268052020551639\n",
      "train loss:0.03151076494281634\n",
      "train loss:0.16127157094213446\n",
      "train loss:0.06767324744081585\n",
      "train loss:0.03770907843942572\n",
      "train loss:0.042824818654949005\n",
      "train loss:0.10579164730691047\n",
      "train loss:0.05599229220159234\n",
      "train loss:0.07200526407252011\n",
      "train loss:0.06038401594073265\n",
      "train loss:0.10341200221564292\n",
      "train loss:0.04697910285258094\n",
      "train loss:0.08509373930275126\n",
      "train loss:0.04221395250111284\n",
      "train loss:0.06869485386222975\n",
      "train loss:0.06503587283358507\n",
      "train loss:0.03420176656206217\n",
      "train loss:0.031910714237735734\n",
      "train loss:0.06901932674685751\n",
      "train loss:0.05349254487244288\n",
      "train loss:0.09207989193658929\n",
      "train loss:0.13824033455923876\n",
      "train loss:0.1075899952609626\n",
      "train loss:0.06447039045299761\n",
      "train loss:0.14135184403545678\n",
      "train loss:0.03614900949088378\n",
      "train loss:0.09486834810894368\n",
      "train loss:0.05805543769983705\n",
      "train loss:0.06579280611667317\n",
      "train loss:0.02725880863692023\n",
      "train loss:0.16408613231058133\n",
      "train loss:0.10077005688354837\n",
      "train loss:0.04000130624792793\n",
      "train loss:0.04426156592648564\n",
      "train loss:0.13304080098695154\n",
      "train loss:0.03997100059571968\n",
      "train loss:0.14031674221938525\n",
      "train loss:0.09389819194195073\n",
      "train loss:0.02193787186183927\n",
      "train loss:0.061318745935498284\n",
      "train loss:0.04456713757188968\n",
      "train loss:0.13755182768502117\n",
      "train loss:0.07518467228082475\n",
      "train loss:0.10248799886038072\n",
      "train loss:0.1372039367119976\n",
      "train loss:0.1979656608770067\n",
      "train loss:0.12464744702611755\n",
      "train loss:0.08175993199841444\n",
      "train loss:0.06502763661716728\n",
      "train loss:0.03558187848328749\n",
      "train loss:0.036185034191446384\n",
      "train loss:0.039880961507798615\n",
      "train loss:0.04558318723278611\n",
      "train loss:0.09953204918924673\n",
      "train loss:0.12065562143954074\n",
      "train loss:0.07833928777375734\n",
      "train loss:0.029745083634343566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06739570667001811\n",
      "train loss:0.07346769891197909\n",
      "train loss:0.06142238604473504\n",
      "train loss:0.061202070884606635\n",
      "train loss:0.01501573750336624\n",
      "train loss:0.04544226330514652\n",
      "train loss:0.044008713371870276\n",
      "train loss:0.02740032805714758\n",
      "train loss:0.032559001259954895\n",
      "train loss:0.1615259094519945\n",
      "train loss:0.06399948359778002\n",
      "train loss:0.04265467100575889\n",
      "train loss:0.04832525622891972\n",
      "train loss:0.055396125017352485\n",
      "train loss:0.10747495181586367\n",
      "train loss:0.06366055389630662\n",
      "train loss:0.09448693135269094\n",
      "train loss:0.06653011537513749\n",
      "train loss:0.08287229809128378\n",
      "train loss:0.15054377677812095\n",
      "train loss:0.185800744861391\n",
      "train loss:0.08515116313922547\n",
      "train loss:0.05653516663971778\n",
      "train loss:0.07080360804314853\n",
      "train loss:0.04582092815883436\n",
      "train loss:0.038614159462321565\n",
      "train loss:0.08732606258425527\n",
      "train loss:0.020073217189612434\n",
      "train loss:0.07418648283503247\n",
      "train loss:0.05395280102530204\n",
      "train loss:0.06975589644488832\n",
      "train loss:0.030351469964362977\n",
      "train loss:0.059950935574822686\n",
      "train loss:0.07526964535725793\n",
      "train loss:0.09149877954923501\n",
      "train loss:0.033178402269179\n",
      "train loss:0.08683725360255018\n",
      "train loss:0.09644267300200828\n",
      "train loss:0.049906306384869065\n",
      "train loss:0.10608446960692834\n",
      "train loss:0.07610972683089585\n",
      "train loss:0.10455443837913436\n",
      "train loss:0.10130056070397452\n",
      "train loss:0.06947499731138781\n",
      "train loss:0.08553569724614644\n",
      "train loss:0.13418142775143263\n",
      "train loss:0.08083471460227372\n",
      "train loss:0.04181384268259417\n",
      "train loss:0.04937939462556487\n",
      "train loss:0.1089803615550793\n",
      "train loss:0.05070229160165087\n",
      "train loss:0.03795953183593552\n",
      "train loss:0.044665619749748114\n",
      "train loss:0.07710495670533932\n",
      "train loss:0.09526206583026085\n",
      "train loss:0.0459921423135777\n",
      "train loss:0.10142042004995896\n",
      "train loss:0.05468108304627838\n",
      "train loss:0.04253265066983498\n",
      "train loss:0.08512150492205468\n",
      "train loss:0.12896679517088114\n",
      "train loss:0.15273213936017976\n",
      "train loss:0.06220695033649511\n",
      "train loss:0.06698086128829435\n",
      "train loss:0.06255614769500967\n",
      "train loss:0.23846929588942223\n",
      "train loss:0.018252674642164176\n",
      "train loss:0.06378959644787402\n",
      "train loss:0.04556678581632372\n",
      "train loss:0.022495499080892743\n",
      "train loss:0.06714459119889646\n",
      "train loss:0.050238153195695474\n",
      "train loss:0.09176652618718527\n",
      "train loss:0.06165203768030083\n",
      "train loss:0.05485754324303424\n",
      "train loss:0.07463929912612631\n",
      "train loss:0.0830974630588833\n",
      "train loss:0.03848320306036646\n",
      "train loss:0.06807375882594527\n",
      "train loss:0.03828218915287045\n",
      "train loss:0.03219482456180392\n",
      "train loss:0.14531893358623174\n",
      "train loss:0.11976473066195184\n",
      "train loss:0.05050884023414814\n",
      "train loss:0.1263267451545084\n",
      "train loss:0.03418589491012011\n",
      "train loss:0.042015477461031146\n",
      "train loss:0.04532139759387532\n",
      "train loss:0.06771043474589768\n",
      "train loss:0.04260832135890966\n",
      "train loss:0.07034604650884302\n",
      "train loss:0.07991843193508696\n",
      "train loss:0.12782615193935198\n",
      "train loss:0.05345681946234283\n",
      "train loss:0.02708148851976962\n",
      "train loss:0.0739228550472775\n",
      "train loss:0.09218895952002025\n",
      "train loss:0.06581052734282992\n",
      "train loss:0.03499650123768161\n",
      "train loss:0.11636516627966052\n",
      "train loss:0.05393961277444225\n",
      "train loss:0.08235410923034124\n",
      "train loss:0.06260601735436715\n",
      "train loss:0.11220864652687755\n",
      "train loss:0.019413978373644246\n",
      "train loss:0.02624550178326235\n",
      "train loss:0.022165583252789344\n",
      "train loss:0.076794924799161\n",
      "train loss:0.0941933457243754\n",
      "train loss:0.09203487280044167\n",
      "train loss:0.04838496270437103\n",
      "train loss:0.08667823359161536\n",
      "train loss:0.02657091239961636\n",
      "train loss:0.04182512314530706\n",
      "train loss:0.053306377491748054\n",
      "train loss:0.044185559337739586\n",
      "train loss:0.029243885832702654\n",
      "train loss:0.035298606441325306\n",
      "train loss:0.08876767845855517\n",
      "train loss:0.05560273282274987\n",
      "train loss:0.09701415863486842\n",
      "train loss:0.07356414932211351\n",
      "train loss:0.09583633461073916\n",
      "train loss:0.036004635804007125\n",
      "train loss:0.09802384688860909\n",
      "train loss:0.06864217118891078\n",
      "train loss:0.07264317730635744\n",
      "train loss:0.029377036957039828\n",
      "train loss:0.10712388429486162\n",
      "train loss:0.020451314396204377\n",
      "train loss:0.0684551482276245\n",
      "train loss:0.05779831770527879\n",
      "train loss:0.016155215567790523\n",
      "train loss:0.03601333256446983\n",
      "train loss:0.024292489597534557\n",
      "train loss:0.01895810111028228\n",
      "train loss:0.13084641517986773\n",
      "train loss:0.07903205329032476\n",
      "train loss:0.03685136043356616\n",
      "train loss:0.05089589862537796\n",
      "train loss:0.08415095844388605\n",
      "train loss:0.03580544593843301\n",
      "train loss:0.038106930538736775\n",
      "train loss:0.0643029560289698\n",
      "train loss:0.12526821685180325\n",
      "train loss:0.0761520957023009\n",
      "train loss:0.11886501208190567\n",
      "train loss:0.0442080977171557\n",
      "train loss:0.08207380661417968\n",
      "train loss:0.08171302950371175\n",
      "train loss:0.020636681681417485\n",
      "train loss:0.033986067554889275\n",
      "train loss:0.016572129641680897\n",
      "train loss:0.14220398327390332\n",
      "train loss:0.1036933071928987\n",
      "train loss:0.12461381050457003\n",
      "train loss:0.051577325673043184\n",
      "train loss:0.07953070011555148\n",
      "train loss:0.10395408340274855\n",
      "train loss:0.04356998156180805\n",
      "train loss:0.04961801799297561\n",
      "train loss:0.07162745789142926\n",
      "train loss:0.08801586349191594\n",
      "train loss:0.08122047257766224\n",
      "train loss:0.06229865949043304\n",
      "train loss:0.12587529993292332\n",
      "train loss:0.03636379181967821\n",
      "train loss:0.06395488133829029\n",
      "train loss:0.01917039700403146\n",
      "train loss:0.0895524648968494\n",
      "train loss:0.034817801031705814\n",
      "train loss:0.05342105610598122\n",
      "train loss:0.06125791772577907\n",
      "train loss:0.04658868186269131\n",
      "train loss:0.02952469832153731\n",
      "train loss:0.040857969290851885\n",
      "train loss:0.07203279206820201\n",
      "train loss:0.06587036334352599\n",
      "train loss:0.08752737149165232\n",
      "train loss:0.07324306902163388\n",
      "train loss:0.05412166978572444\n",
      "train loss:0.13603239859725935\n",
      "train loss:0.019685931609906334\n",
      "train loss:0.11592546605130048\n",
      "train loss:0.11279906948963947\n",
      "train loss:0.03195145788159941\n",
      "train loss:0.06697179161160323\n",
      "train loss:0.06158931482755757\n",
      "train loss:0.03317164840943342\n",
      "train loss:0.06118362438317854\n",
      "train loss:0.06081452875650986\n",
      "train loss:0.0544953276807236\n",
      "train loss:0.09621075029412536\n",
      "train loss:0.08603949880390623\n",
      "train loss:0.1269395396882478\n",
      "train loss:0.032197797988083046\n",
      "train loss:0.04627098113022722\n",
      "train loss:0.03167948560255681\n",
      "train loss:0.0996646598058944\n",
      "train loss:0.034521248911472686\n",
      "train loss:0.0475531325919287\n",
      "train loss:0.07165146777842388\n",
      "train loss:0.07903039851615111\n",
      "train loss:0.060538832268912546\n",
      "train loss:0.023477690115189433\n",
      "train loss:0.047486742489891834\n",
      "train loss:0.051553485706779305\n",
      "train loss:0.028476994864313283\n",
      "train loss:0.03746305444023654\n",
      "train loss:0.02552467040412506\n",
      "train loss:0.0595205180142231\n",
      "train loss:0.08465162109025423\n",
      "train loss:0.03224505896280334\n",
      "train loss:0.06380458751960963\n",
      "train loss:0.027024464846046703\n",
      "train loss:0.036676000370323356\n",
      "train loss:0.09296789196350626\n",
      "train loss:0.0548630620831079\n",
      "train loss:0.06081596546060388\n",
      "train loss:0.06585854214319767\n",
      "train loss:0.039122652344808447\n",
      "train loss:0.036277201629729056\n",
      "train loss:0.03990545949472858\n",
      "train loss:0.0156508379940399\n",
      "train loss:0.031066982529087885\n",
      "train loss:0.06992315415522578\n",
      "train loss:0.06266636178550426\n",
      "train loss:0.05605489282707194\n",
      "train loss:0.09120212754959314\n",
      "train loss:0.04451224561129843\n",
      "train loss:0.05586554879466169\n",
      "train loss:0.06720754221387906\n",
      "train loss:0.07171152947609787\n",
      "train loss:0.08011650355119496\n",
      "train loss:0.01635799724106069\n",
      "train loss:0.0828710703161248\n",
      "train loss:0.06905493927045608\n",
      "train loss:0.054506659575938005\n",
      "train loss:0.09625108878653423\n",
      "train loss:0.018970827789733646\n",
      "train loss:0.0331987213052172\n",
      "train loss:0.056173030792577926\n",
      "train loss:0.044115338614754515\n",
      "train loss:0.036534998022053206\n",
      "train loss:0.1186914021949108\n",
      "train loss:0.03291045572490108\n",
      "train loss:0.10670400449077677\n",
      "train loss:0.019248056757258263\n",
      "train loss:0.05001668915151146\n",
      "train loss:0.027929076995901924\n",
      "train loss:0.05466904807011837\n",
      "train loss:0.10172188642904385\n",
      "train loss:0.046204044339372044\n",
      "train loss:0.04700620666961255\n",
      "train loss:0.04250356502450701\n",
      "train loss:0.06464588088492242\n",
      "train loss:0.06016885782013756\n",
      "train loss:0.05123660454353792\n",
      "train loss:0.05039312704446179\n",
      "train loss:0.051638309179765564\n",
      "train loss:0.12057220541747564\n",
      "train loss:0.021463410671424966\n",
      "train loss:0.060059528017338784\n",
      "train loss:0.031926894986061674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0353157156500307\n",
      "train loss:0.07953370881887034\n",
      "train loss:0.05734887587593739\n",
      "train loss:0.03904725848130141\n",
      "train loss:0.1110635452601844\n",
      "train loss:0.04509794190548035\n",
      "train loss:0.08185777457637856\n",
      "train loss:0.026385780709447863\n",
      "train loss:0.06886033577294572\n",
      "train loss:0.07911069402037597\n",
      "train loss:0.05962406874967665\n",
      "train loss:0.040963040980401086\n",
      "train loss:0.1161874781759099\n",
      "train loss:0.05592817447838043\n",
      "train loss:0.052054838690951274\n",
      "train loss:0.053492130967882606\n",
      "train loss:0.08741273781722726\n",
      "train loss:0.0249594828068618\n",
      "train loss:0.03625072023137363\n",
      "train loss:0.04455593223269713\n",
      "train loss:0.06655854033057036\n",
      "train loss:0.06147503247190548\n",
      "train loss:0.049727905699081955\n",
      "train loss:0.04368459869835616\n",
      "train loss:0.06780678837067625\n",
      "train loss:0.0306604822058104\n",
      "train loss:0.08518733676852813\n",
      "train loss:0.020304945179317784\n",
      "train loss:0.10218156471766092\n",
      "train loss:0.04741494070912932\n",
      "train loss:0.04535398272545715\n",
      "train loss:0.07842919861696769\n",
      "train loss:0.0437220054821148\n",
      "train loss:0.014084269821719342\n",
      "train loss:0.061881014760769494\n",
      "train loss:0.06579197989565344\n",
      "train loss:0.07615096532665837\n",
      "train loss:0.025216899949092226\n",
      "train loss:0.03677258518877762\n",
      "train loss:0.034760091748502565\n",
      "train loss:0.09273373144333087\n",
      "train loss:0.0206236841290645\n",
      "train loss:0.038061144976580155\n",
      "train loss:0.020701614035867413\n",
      "train loss:0.030430200027957384\n",
      "train loss:0.028467384311644993\n",
      "train loss:0.02737975202585409\n",
      "train loss:0.024874980011756555\n",
      "train loss:0.04158374480433567\n",
      "train loss:0.04654152885080303\n",
      "train loss:0.08408905874799076\n",
      "train loss:0.03829211545083395\n",
      "train loss:0.027763777811659025\n",
      "train loss:0.0338052688664098\n",
      "train loss:0.03250655324144093\n",
      "train loss:0.05138285825627809\n",
      "train loss:0.06258177522532025\n",
      "train loss:0.027333787230597074\n",
      "train loss:0.04004505057635911\n",
      "train loss:0.15056575343355838\n",
      "train loss:0.07800231900751711\n",
      "train loss:0.018097395867303575\n",
      "train loss:0.07489944057514673\n",
      "train loss:0.032177474085571076\n",
      "train loss:0.04576300731320724\n",
      "train loss:0.05865739607929952\n",
      "train loss:0.029718276330816296\n",
      "train loss:0.02494590888394283\n",
      "train loss:0.07444826904586384\n",
      "train loss:0.050244618656066255\n",
      "train loss:0.04143936039686147\n",
      "train loss:0.02047302593095721\n",
      "train loss:0.03498441015657979\n",
      "train loss:0.0539855279916056\n",
      "train loss:0.014816051363010058\n",
      "train loss:0.06786522792551412\n",
      "train loss:0.03570409128187623\n",
      "train loss:0.04955006903569186\n",
      "train loss:0.07043826113418904\n",
      "train loss:0.02497030266608185\n",
      "train loss:0.0984098431376986\n",
      "train loss:0.058590751356334896\n",
      "train loss:0.019411469836241625\n",
      "train loss:0.044035160190328826\n",
      "train loss:0.04220802271889391\n",
      "train loss:0.03463948184280392\n",
      "train loss:0.038359547307433406\n",
      "train loss:0.0622448150941147\n",
      "train loss:0.01206141271766686\n",
      "train loss:0.07728118062980865\n",
      "train loss:0.07459052823393716\n",
      "train loss:0.1291020413335335\n",
      "train loss:0.039600420372761395\n",
      "train loss:0.03277204640453726\n",
      "train loss:0.04251894950366868\n",
      "train loss:0.029298675586611433\n",
      "train loss:0.04104531451841852\n",
      "train loss:0.021191467825047588\n",
      "train loss:0.039672137640119516\n",
      "train loss:0.02426318443367218\n",
      "train loss:0.022399462101302704\n",
      "train loss:0.03670888759383236\n",
      "train loss:0.06356585272337717\n",
      "train loss:0.034920143005566985\n",
      "train loss:0.17614684138859352\n",
      "train loss:0.08613899101944968\n",
      "train loss:0.012871107335642888\n",
      "train loss:0.05511845065806114\n",
      "train loss:0.08475405512503234\n",
      "train loss:0.13674003315232294\n",
      "train loss:0.01650113074434522\n",
      "train loss:0.08961937482865864\n",
      "train loss:0.19999361270766186\n",
      "train loss:0.04376813154427408\n",
      "train loss:0.07373213506948777\n",
      "train loss:0.05890343930499107\n",
      "train loss:0.03272724807091834\n",
      "train loss:0.040763033082566326\n",
      "train loss:0.07180594532222077\n",
      "train loss:0.08908872914621813\n",
      "train loss:0.09181976848740256\n",
      "train loss:0.05265263187053451\n",
      "train loss:0.08203143822640252\n",
      "train loss:0.04508450554261652\n",
      "train loss:0.0883678482837209\n",
      "train loss:0.06938437897853741\n",
      "train loss:0.009450419689351432\n",
      "train loss:0.019977395744501754\n",
      "train loss:0.07425655955903468\n",
      "train loss:0.05411639984511316\n",
      "train loss:0.058931509850013004\n",
      "train loss:0.0736658893024225\n",
      "train loss:0.029091593557029182\n",
      "train loss:0.05110176564954817\n",
      "train loss:0.04543532672620961\n",
      "train loss:0.10626104611643239\n",
      "train loss:0.07512598838304957\n",
      "train loss:0.02855955672919536\n",
      "train loss:0.03864309958297953\n",
      "train loss:0.04670764082341499\n",
      "train loss:0.08797543410727306\n",
      "train loss:0.11074198649572763\n",
      "train loss:0.06133271628690405\n",
      "train loss:0.03954204469797642\n",
      "train loss:0.018800199965715397\n",
      "train loss:0.021339780072271813\n",
      "train loss:0.0380631904483374\n",
      "train loss:0.08624118118710969\n",
      "train loss:0.030394232458594236\n",
      "train loss:0.05066567919953312\n",
      "train loss:0.048470620518883685\n",
      "train loss:0.04713061409370142\n",
      "train loss:0.07092657512706177\n",
      "train loss:0.04137890121616953\n",
      "train loss:0.06880999668436517\n",
      "train loss:0.05261691486750226\n",
      "train loss:0.025877973390055944\n",
      "train loss:0.06758907991010939\n",
      "train loss:0.02916100510100885\n",
      "train loss:0.05492521319116539\n",
      "train loss:0.033133612913704875\n",
      "train loss:0.028973922089552837\n",
      "train loss:0.032670618461710994\n",
      "train loss:0.04813756651105107\n",
      "train loss:0.06449617580472057\n",
      "train loss:0.016937425779977772\n",
      "train loss:0.03771825017604388\n",
      "train loss:0.025018521041299157\n",
      "train loss:0.0817939411467309\n",
      "train loss:0.025423421715265123\n",
      "train loss:0.03977319468663017\n",
      "train loss:0.03360450179373413\n",
      "train loss:0.025284364298071408\n",
      "train loss:0.04214307557445244\n",
      "=== epoch:4, train acc:0.981, test acc:0.978 ===\n",
      "train loss:0.07019878082082037\n",
      "train loss:0.03136319011756835\n",
      "train loss:0.017415800008470882\n",
      "train loss:0.0770633229168232\n",
      "train loss:0.08735965559723405\n",
      "train loss:0.07243824636688292\n",
      "train loss:0.03591488953923169\n",
      "train loss:0.020848047049376418\n",
      "train loss:0.09584851234891387\n",
      "train loss:0.029982971685769723\n",
      "train loss:0.01531974121436088\n",
      "train loss:0.025760312324523856\n",
      "train loss:0.032787765121131685\n",
      "train loss:0.014539982378702215\n",
      "train loss:0.02291853116597065\n",
      "train loss:0.047187796008679776\n",
      "train loss:0.01922072777858229\n",
      "train loss:0.057524061368654546\n",
      "train loss:0.035520412127839164\n",
      "train loss:0.06661178316427084\n",
      "train loss:0.096653394576939\n",
      "train loss:0.03204429686292913\n",
      "train loss:0.05841914644480665\n",
      "train loss:0.08038054521366993\n",
      "train loss:0.04608125680767869\n",
      "train loss:0.08710397917630636\n",
      "train loss:0.06817483541892931\n",
      "train loss:0.05435589120415497\n",
      "train loss:0.04108546657565682\n",
      "train loss:0.0964136213050185\n",
      "train loss:0.06624539865101112\n",
      "train loss:0.08524632440090425\n",
      "train loss:0.06585930398647259\n",
      "train loss:0.09792166210350602\n",
      "train loss:0.036331043481425254\n",
      "train loss:0.05444805130630532\n",
      "train loss:0.024700406082823326\n",
      "train loss:0.12875088138759241\n",
      "train loss:0.05401311200657366\n",
      "train loss:0.04350252165202238\n",
      "train loss:0.023550767359064872\n",
      "train loss:0.025756278634699183\n",
      "train loss:0.0577342172233055\n",
      "train loss:0.033582076504731107\n",
      "train loss:0.06950109707088913\n",
      "train loss:0.05381150148649049\n",
      "train loss:0.024323792398210038\n",
      "train loss:0.09780808043476244\n",
      "train loss:0.02677281273455599\n",
      "train loss:0.03784290084251739\n",
      "train loss:0.05710994605495268\n",
      "train loss:0.15305646426613978\n",
      "train loss:0.04223411339558206\n",
      "train loss:0.045398535142452755\n",
      "train loss:0.03475902196861558\n",
      "train loss:0.06259539611456992\n",
      "train loss:0.03859489395277253\n",
      "train loss:0.08129220743369643\n",
      "train loss:0.054272495965712625\n",
      "train loss:0.05848500576367203\n",
      "train loss:0.018276333537783195\n",
      "train loss:0.06034993310273885\n",
      "train loss:0.05855884730551854\n",
      "train loss:0.11177903027083973\n",
      "train loss:0.03527318938289007\n",
      "train loss:0.029972829599490783\n",
      "train loss:0.02508502366220121\n",
      "train loss:0.024484946284077373\n",
      "train loss:0.031928415924190615\n",
      "train loss:0.06974126951248977\n",
      "train loss:0.07021060189833593\n",
      "train loss:0.10761447418878833\n",
      "train loss:0.028409378541558773\n",
      "train loss:0.04745907374553002\n",
      "train loss:0.2038375986374165\n",
      "train loss:0.07002799447423631\n",
      "train loss:0.05970805061973608\n",
      "train loss:0.04022770021300368\n",
      "train loss:0.036194593085687385\n",
      "train loss:0.03437870482642844\n",
      "train loss:0.038862452217463414\n",
      "train loss:0.028321073560226714\n",
      "train loss:0.0625732547145669\n",
      "train loss:0.01975322640485894\n",
      "train loss:0.1055319423454126\n",
      "train loss:0.042553772361716515\n",
      "train loss:0.04950045583357081\n",
      "train loss:0.04024753856543482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06350419648033584\n",
      "train loss:0.06754711328129538\n",
      "train loss:0.0605707508982071\n",
      "train loss:0.05048587365327485\n",
      "train loss:0.0852039336563656\n",
      "train loss:0.06656166758136643\n",
      "train loss:0.03649692994199456\n",
      "train loss:0.02881255909523456\n",
      "train loss:0.02985026856470901\n",
      "train loss:0.028355538156509076\n",
      "train loss:0.05815176524221528\n",
      "train loss:0.08558200297744953\n",
      "train loss:0.0590325158866738\n",
      "train loss:0.061296748010375525\n",
      "train loss:0.057575045882012635\n",
      "train loss:0.051224092678686196\n",
      "train loss:0.07869452421229897\n",
      "train loss:0.030105825601655357\n",
      "train loss:0.042567404757179524\n",
      "train loss:0.03266410979223641\n",
      "train loss:0.0486559045584497\n",
      "train loss:0.03247174576836342\n",
      "train loss:0.01548339492877331\n",
      "train loss:0.19040965723045383\n",
      "train loss:0.031061552826415904\n",
      "train loss:0.020054536636919383\n",
      "train loss:0.04364221286545497\n",
      "train loss:0.0576015235933709\n",
      "train loss:0.031116045590540042\n",
      "train loss:0.04881918765637035\n",
      "train loss:0.09185719934969659\n",
      "train loss:0.013709718446017972\n",
      "train loss:0.04873535491804282\n",
      "train loss:0.0544856455529567\n",
      "train loss:0.0607482248839498\n",
      "train loss:0.07148871489553299\n",
      "train loss:0.09927271447871401\n",
      "train loss:0.1502766573579846\n",
      "train loss:0.03483957788939469\n",
      "train loss:0.050391122741025744\n",
      "train loss:0.02635455823191374\n",
      "train loss:0.11299710541099608\n",
      "train loss:0.010110659225111281\n",
      "train loss:0.027389538996883716\n",
      "train loss:0.04397603354230822\n",
      "train loss:0.06548916971929603\n",
      "train loss:0.11495149111934334\n",
      "train loss:0.06804336517172802\n",
      "train loss:0.03549701244720085\n",
      "train loss:0.028374184658717858\n",
      "train loss:0.06778781789394286\n",
      "train loss:0.04061028676889923\n",
      "train loss:0.12106999036424866\n",
      "train loss:0.023968197455838055\n",
      "train loss:0.0894953031537816\n",
      "train loss:0.009595908947353111\n",
      "train loss:0.047419548063971924\n",
      "train loss:0.0446948021150462\n",
      "train loss:0.025843165765884368\n",
      "train loss:0.027799445888270706\n",
      "train loss:0.07569152304625518\n",
      "train loss:0.035389731293868396\n",
      "train loss:0.0777118241632446\n",
      "train loss:0.019798252509352122\n",
      "train loss:0.05731315760359178\n",
      "train loss:0.06985313883777056\n",
      "train loss:0.07421897635086268\n",
      "train loss:0.026401901320126844\n",
      "train loss:0.049096558431304935\n",
      "train loss:0.016892236463083188\n",
      "train loss:0.028469796471843355\n",
      "train loss:0.08484035512788024\n",
      "train loss:0.06308970077785565\n",
      "train loss:0.08793666630387255\n",
      "train loss:0.01931541318631654\n",
      "train loss:0.03846111824547753\n",
      "train loss:0.03465357717389642\n",
      "train loss:0.040221200315074486\n",
      "train loss:0.04326750937405053\n",
      "train loss:0.04449071680527759\n",
      "train loss:0.07037303228336192\n",
      "train loss:0.08107813636511953\n",
      "train loss:0.05176665076380422\n",
      "train loss:0.009494235408621573\n",
      "train loss:0.005449576326385843\n",
      "train loss:0.08903039252349368\n",
      "train loss:0.03449159683006262\n",
      "train loss:0.02441612453863031\n",
      "train loss:0.03823125947609543\n",
      "train loss:0.033244487114046636\n",
      "train loss:0.0762270223657711\n",
      "train loss:0.06732454152165321\n",
      "train loss:0.09299746264674055\n",
      "train loss:0.04141105631317629\n",
      "train loss:0.09088379251607157\n",
      "train loss:0.07180108746692167\n",
      "train loss:0.029844228989874187\n",
      "train loss:0.029943554869864317\n",
      "train loss:0.036219362804177015\n",
      "train loss:0.11735954982062466\n",
      "train loss:0.011041839201503745\n",
      "train loss:0.03351520094899398\n",
      "train loss:0.07898729040241767\n",
      "train loss:0.06679196113451165\n",
      "train loss:0.028376427853556298\n",
      "train loss:0.037040565442632824\n",
      "train loss:0.014209511838187793\n",
      "train loss:0.030732434516886543\n",
      "train loss:0.010533821940789327\n",
      "train loss:0.09649152996153351\n",
      "train loss:0.018229661374155305\n",
      "train loss:0.01618534715483812\n",
      "train loss:0.02565208105930195\n",
      "train loss:0.040122288640468066\n",
      "train loss:0.04803389120161199\n",
      "train loss:0.048124983496883766\n",
      "train loss:0.009641406822896183\n",
      "train loss:0.045232604481119806\n",
      "train loss:0.04479511205377573\n",
      "train loss:0.038439464064095694\n",
      "train loss:0.010684906431407222\n",
      "train loss:0.04133341959759015\n",
      "train loss:0.03137636845668297\n",
      "train loss:0.06445835358522192\n",
      "train loss:0.06373894182601571\n",
      "train loss:0.07142193814950874\n",
      "train loss:0.024053412662090934\n",
      "train loss:0.031138358471040472\n",
      "train loss:0.08975503446144127\n",
      "train loss:0.05188844733461506\n",
      "train loss:0.019640118645047125\n",
      "train loss:0.024955078339495805\n",
      "train loss:0.0409030956361033\n",
      "train loss:0.03561965273375979\n",
      "train loss:0.09766434994361212\n",
      "train loss:0.010939748302614348\n",
      "train loss:0.014421578165467346\n",
      "train loss:0.09499115383904645\n",
      "train loss:0.02306660722996149\n",
      "train loss:0.13446007444741584\n",
      "train loss:0.022726665434980215\n",
      "train loss:0.05919789337971497\n",
      "train loss:0.018245121673597865\n",
      "train loss:0.015825461458811352\n",
      "train loss:0.06772095625904656\n",
      "train loss:0.027712731968737327\n",
      "train loss:0.03738336539893628\n",
      "train loss:0.02304822627068599\n",
      "train loss:0.042183306608094044\n",
      "train loss:0.07106481250606458\n",
      "train loss:0.01594502273714803\n",
      "train loss:0.028357257077093287\n",
      "train loss:0.07005827739272479\n",
      "train loss:0.05110469200315366\n",
      "train loss:0.039931815632284005\n",
      "train loss:0.05721020262422987\n",
      "train loss:0.09736431622755859\n",
      "train loss:0.09300070607370606\n",
      "train loss:0.027470579933647987\n",
      "train loss:0.0229461222371845\n",
      "train loss:0.039944359528912135\n",
      "train loss:0.039839374921358015\n",
      "train loss:0.036303578521586694\n",
      "train loss:0.09009463970375517\n",
      "train loss:0.06450955741110515\n",
      "train loss:0.03146794219154549\n",
      "train loss:0.13520475520965564\n",
      "train loss:0.07753492560405235\n",
      "train loss:0.05395436895849646\n",
      "train loss:0.07477713787602387\n",
      "train loss:0.02622223540978707\n",
      "train loss:0.10718786246724912\n",
      "train loss:0.10324232387616365\n",
      "train loss:0.09748510127820047\n",
      "train loss:0.10262884079535825\n",
      "train loss:0.04492304961382869\n",
      "train loss:0.049009206495626456\n",
      "train loss:0.11705601042038168\n",
      "train loss:0.059720854085741716\n",
      "train loss:0.047901045157460645\n",
      "train loss:0.08391784291966463\n",
      "train loss:0.08323132763584137\n",
      "train loss:0.04481543725940375\n",
      "train loss:0.03125436138373688\n",
      "train loss:0.022015479470104515\n",
      "train loss:0.02030025225595562\n",
      "train loss:0.04528123472946166\n",
      "train loss:0.04099278365336301\n",
      "train loss:0.0656041877255038\n",
      "train loss:0.088489200350873\n",
      "train loss:0.05552212262639064\n",
      "train loss:0.02053606022128879\n",
      "train loss:0.05672994324612138\n",
      "train loss:0.024146101263877413\n",
      "train loss:0.025198784255653126\n",
      "train loss:0.018251528994990187\n",
      "train loss:0.07450415322834877\n",
      "train loss:0.031703471843819886\n",
      "train loss:0.07352386882023675\n",
      "train loss:0.03445245617200705\n",
      "train loss:0.025133501371398397\n",
      "train loss:0.04798282671889176\n",
      "train loss:0.02821332537179022\n",
      "train loss:0.02773359108978736\n",
      "train loss:0.05481601472359118\n",
      "train loss:0.02511698397333743\n",
      "train loss:0.01810959044838425\n",
      "train loss:0.0679233596002571\n",
      "train loss:0.018638937086126905\n",
      "train loss:0.07721466750138396\n",
      "train loss:0.06737705610069188\n",
      "train loss:0.029278068506208215\n",
      "train loss:0.04394096618703314\n",
      "train loss:0.015028018843570327\n",
      "train loss:0.022598843150851824\n",
      "train loss:0.022858801731173287\n",
      "train loss:0.08098552495630812\n",
      "train loss:0.05086086162359956\n",
      "train loss:0.02259865060290062\n",
      "train loss:0.030592682842889806\n",
      "train loss:0.03202999396532819\n",
      "train loss:0.05312292309262228\n",
      "train loss:0.04318370543832197\n",
      "train loss:0.018272756277648555\n",
      "train loss:0.0664896212670431\n",
      "train loss:0.01770563565063944\n",
      "train loss:0.04035142625578151\n",
      "train loss:0.024847745232404014\n",
      "train loss:0.039098127606678475\n",
      "train loss:0.011892883348326406\n",
      "train loss:0.08577532007324576\n",
      "train loss:0.03780080686908615\n",
      "train loss:0.10818579114466416\n",
      "train loss:0.011502260777782729\n",
      "train loss:0.009528349693508261\n",
      "train loss:0.0363647812258654\n",
      "train loss:0.009838035198815107\n",
      "train loss:0.03128317215937585\n",
      "train loss:0.005243632408350927\n",
      "train loss:0.06986916519518127\n",
      "train loss:0.08465931317182097\n",
      "train loss:0.022315763480095504\n",
      "train loss:0.0175793568300955\n",
      "train loss:0.026122285036787856\n",
      "train loss:0.02418075440723666\n",
      "train loss:0.023129038076104096\n",
      "train loss:0.04387451815845249\n",
      "train loss:0.041144997321037456\n",
      "train loss:0.05071074202405416\n",
      "train loss:0.010986928183027427\n",
      "train loss:0.012883532119309484\n",
      "train loss:0.03415697589660497\n",
      "train loss:0.033098977250438345\n",
      "train loss:0.15550100271243414\n",
      "train loss:0.06373230119246522\n",
      "train loss:0.038279305631339716\n",
      "train loss:0.018045732530498463\n",
      "train loss:0.012792961424135739\n",
      "train loss:0.04585590502099309\n",
      "train loss:0.07437620678081741\n",
      "train loss:0.049493935283079334\n",
      "train loss:0.03214298580467243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014839175662155287\n",
      "train loss:0.03179483613085486\n",
      "train loss:0.02885367683354084\n",
      "train loss:0.006224572014751699\n",
      "train loss:0.018491736484794408\n",
      "train loss:0.03486676534579905\n",
      "train loss:0.02020851552891174\n",
      "train loss:0.09617156093496375\n",
      "train loss:0.03907033387079862\n",
      "train loss:0.02677844184435007\n",
      "train loss:0.015504896595115466\n",
      "train loss:0.05279930228943899\n",
      "train loss:0.06163032774056622\n",
      "train loss:0.023636556758991775\n",
      "train loss:0.018598040194318346\n",
      "train loss:0.04314933421277614\n",
      "train loss:0.04077031682531643\n",
      "train loss:0.036523427822123145\n",
      "train loss:0.04295253559834051\n",
      "train loss:0.016261629563021265\n",
      "train loss:0.02169972943380231\n",
      "train loss:0.017284161784437223\n",
      "train loss:0.08022661129554545\n",
      "train loss:0.02798393038639684\n",
      "train loss:0.02036183941640538\n",
      "train loss:0.15378269445954804\n",
      "train loss:0.023340338564327223\n",
      "train loss:0.031841521935805854\n",
      "train loss:0.021733970711525163\n",
      "train loss:0.09543343887241393\n",
      "train loss:0.03402241339362962\n",
      "train loss:0.028584401122962885\n",
      "train loss:0.03343304619556895\n",
      "train loss:0.08127535837658889\n",
      "train loss:0.0176221691210179\n",
      "train loss:0.04165496273811182\n",
      "train loss:0.034186656084983634\n",
      "train loss:0.05318298254471203\n",
      "train loss:0.044308983738322746\n",
      "train loss:0.027172464436267463\n",
      "train loss:0.03296576735141241\n",
      "train loss:0.042496490029357646\n",
      "train loss:0.05151646976141634\n",
      "train loss:0.01222396866661926\n",
      "train loss:0.016520971327299714\n",
      "train loss:0.038891173959388875\n",
      "train loss:0.034215036211491585\n",
      "train loss:0.03955075081404846\n",
      "train loss:0.08161100960580242\n",
      "train loss:0.057634327892927245\n",
      "train loss:0.08794712530423181\n",
      "train loss:0.021313801294958603\n",
      "train loss:0.045300928968054\n",
      "train loss:0.04481750133743733\n",
      "train loss:0.06113234105018055\n",
      "train loss:0.03983383705436686\n",
      "train loss:0.0989472440801715\n",
      "train loss:0.023223433680609477\n",
      "train loss:0.019024670636937\n",
      "train loss:0.02941421086556889\n",
      "train loss:0.03215316526962935\n",
      "train loss:0.027630291685256426\n",
      "train loss:0.04287099680505248\n",
      "train loss:0.024112951713529413\n",
      "train loss:0.05673448922115376\n",
      "train loss:0.01535209424356649\n",
      "train loss:0.024595600049146737\n",
      "train loss:0.015248731231397758\n",
      "train loss:0.04006717379367448\n",
      "train loss:0.013276801880780087\n",
      "train loss:0.07855686919808517\n",
      "train loss:0.04329479648006229\n",
      "train loss:0.10452908644295629\n",
      "train loss:0.025167025524714767\n",
      "train loss:0.10768570185361456\n",
      "train loss:0.046228693943234804\n",
      "train loss:0.03990140964915599\n",
      "train loss:0.06657050150051007\n",
      "train loss:0.019064639471374593\n",
      "train loss:0.018308778911470765\n",
      "train loss:0.024507785700242198\n",
      "train loss:0.021375655424530147\n",
      "train loss:0.04228006936836337\n",
      "train loss:0.007487303526664989\n",
      "train loss:0.053518537516261185\n",
      "train loss:0.03757686994222743\n",
      "train loss:0.04589007892066024\n",
      "train loss:0.05269001657727502\n",
      "train loss:0.04920192653214512\n",
      "train loss:0.08601336656816988\n",
      "train loss:0.07575739574353402\n",
      "train loss:0.03403183920159513\n",
      "train loss:0.030493732782918222\n",
      "train loss:0.03504605387091786\n",
      "train loss:0.06483649232558672\n",
      "train loss:0.02541650873418153\n",
      "train loss:0.02513105782746112\n",
      "train loss:0.0070586217189779876\n",
      "train loss:0.05723976384944791\n",
      "train loss:0.02282315808009499\n",
      "train loss:0.05845625468701355\n",
      "train loss:0.01767149347127639\n",
      "train loss:0.04735444464071285\n",
      "train loss:0.019025984251825886\n",
      "train loss:0.04754792105252064\n",
      "train loss:0.013509353216058022\n",
      "train loss:0.0762683762067108\n",
      "train loss:0.039018586475742335\n",
      "train loss:0.0495749010538636\n",
      "train loss:0.03262891094204121\n",
      "train loss:0.021987707913219173\n",
      "train loss:0.017464724513786015\n",
      "train loss:0.06098454272468719\n",
      "train loss:0.05898708390087515\n",
      "train loss:0.04645025929100314\n",
      "train loss:0.0231470335743082\n",
      "train loss:0.04707291858713863\n",
      "train loss:0.05166936653240886\n",
      "train loss:0.047645053276605356\n",
      "train loss:0.03172878554306818\n",
      "train loss:0.02300625176269914\n",
      "train loss:0.031363658569174016\n",
      "train loss:0.0679616967539899\n",
      "train loss:0.12136786222851913\n",
      "train loss:0.08031112468393897\n",
      "train loss:0.03192273644967578\n",
      "train loss:0.016245096142371147\n",
      "train loss:0.12876561815308152\n",
      "train loss:0.1287656907998752\n",
      "train loss:0.0092446870224298\n",
      "train loss:0.0771606472848978\n",
      "train loss:0.0109845746444558\n",
      "train loss:0.042752730874879526\n",
      "train loss:0.017051587746760636\n",
      "train loss:0.06144931031572034\n",
      "train loss:0.018079685526709022\n",
      "train loss:0.03339474028912896\n",
      "train loss:0.0319260464131955\n",
      "train loss:0.09986620896290094\n",
      "train loss:0.04414051841191478\n",
      "train loss:0.06473242016607533\n",
      "train loss:0.03535089029911228\n",
      "train loss:0.053550724080494584\n",
      "train loss:0.05255493238237111\n",
      "train loss:0.03575629711773187\n",
      "train loss:0.03767877221729233\n",
      "train loss:0.04963929022323989\n",
      "train loss:0.08137342158568987\n",
      "train loss:0.024883540012397218\n",
      "train loss:0.014161607841046198\n",
      "=== epoch:5, train acc:0.984, test acc:0.983 ===\n",
      "train loss:0.03475911115660487\n",
      "train loss:0.026626148536878124\n",
      "train loss:0.034177789969441645\n",
      "train loss:0.01493003407203442\n",
      "train loss:0.019411837516630514\n",
      "train loss:0.013499273329406489\n",
      "train loss:0.0786706821716391\n",
      "train loss:0.005931478172479101\n",
      "train loss:0.006300423364788689\n",
      "train loss:0.04080311656612907\n",
      "train loss:0.01776549179400873\n",
      "train loss:0.04654796614690622\n",
      "train loss:0.040206841096071706\n",
      "train loss:0.030497823679924627\n",
      "train loss:0.022319302911163387\n",
      "train loss:0.015525745183334933\n",
      "train loss:0.06647639768046515\n",
      "train loss:0.07801288099487597\n",
      "train loss:0.062309177198618705\n",
      "train loss:0.05130493892577692\n",
      "train loss:0.047307168128568965\n",
      "train loss:0.024950742659392337\n",
      "train loss:0.016034376977935336\n",
      "train loss:0.04096490940152964\n",
      "train loss:0.022284855300716687\n",
      "train loss:0.0639574985854387\n",
      "train loss:0.019137506262711063\n",
      "train loss:0.0055528665388125936\n",
      "train loss:0.0762319646410719\n",
      "train loss:0.023204920787347354\n",
      "train loss:0.028353882809396148\n",
      "train loss:0.019553071140781385\n",
      "train loss:0.023639138345764775\n",
      "train loss:0.05340629505383733\n",
      "train loss:0.021952643926414165\n",
      "train loss:0.10733589221479803\n",
      "train loss:0.009116077130200776\n",
      "train loss:0.017912727879028836\n",
      "train loss:0.043846348975409136\n",
      "train loss:0.025847318834554378\n",
      "train loss:0.039044226753934555\n",
      "train loss:0.013280279088041507\n",
      "train loss:0.13150575001353224\n",
      "train loss:0.02028537480202992\n",
      "train loss:0.03153278150529284\n",
      "train loss:0.050680692232832655\n",
      "train loss:0.034222232120932894\n",
      "train loss:0.027721162448660686\n",
      "train loss:0.020148428829714092\n",
      "train loss:0.057137327168739635\n",
      "train loss:0.013007405506666554\n",
      "train loss:0.03325590737303553\n",
      "train loss:0.024148647080352123\n",
      "train loss:0.06758903584329555\n",
      "train loss:0.029760330561640593\n",
      "train loss:0.04138191433564398\n",
      "train loss:0.02149090855811279\n",
      "train loss:0.03767100495091622\n",
      "train loss:0.04473692919018304\n",
      "train loss:0.05737204092811216\n",
      "train loss:0.051591316602601474\n",
      "train loss:0.028892252985831875\n",
      "train loss:0.07189385739454103\n",
      "train loss:0.03606368615035174\n",
      "train loss:0.02483264495237769\n",
      "train loss:0.033042691174515186\n",
      "train loss:0.048297386836254404\n",
      "train loss:0.0556129706282572\n",
      "train loss:0.03673103025368472\n",
      "train loss:0.044553823045049915\n",
      "train loss:0.03895275168964463\n",
      "train loss:0.008649866392996263\n",
      "train loss:0.015582130525203642\n",
      "train loss:0.02180247275550163\n",
      "train loss:0.015709587479656652\n",
      "train loss:0.04865474436791608\n",
      "train loss:0.006454734347706057\n",
      "train loss:0.036936523754463435\n",
      "train loss:0.04080861476800842\n",
      "train loss:0.05410287587364009\n",
      "train loss:0.07001254647721838\n",
      "train loss:0.050364182525681235\n",
      "train loss:0.02229656814571517\n",
      "train loss:0.09623396521463264\n",
      "train loss:0.0435974386769341\n",
      "train loss:0.01743957404692092\n",
      "train loss:0.03608127810377267\n",
      "train loss:0.02735216084188052\n",
      "train loss:0.04695236170810049\n",
      "train loss:0.12066435745906998\n",
      "train loss:0.014151936882977334\n",
      "train loss:0.059045178370653845\n",
      "train loss:0.048759573598291854\n",
      "train loss:0.0868687158177206\n",
      "train loss:0.06135533688599583\n",
      "train loss:0.021840002871812557\n",
      "train loss:0.010550415516596556\n",
      "train loss:0.026271392835006842\n",
      "train loss:0.09704278871581265\n",
      "train loss:0.023517254051393544\n",
      "train loss:0.01186467807323811\n",
      "train loss:0.028196142871593236\n",
      "train loss:0.09029959198990316\n",
      "train loss:0.04807388087380794\n",
      "train loss:0.018398023664660954\n",
      "train loss:0.034019599119354725\n",
      "train loss:0.026096705366607797\n",
      "train loss:0.04287853171597156\n",
      "train loss:0.016045030331209544\n",
      "train loss:0.026712788232395982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.033738293031643836\n",
      "train loss:0.08808317840602994\n",
      "train loss:0.010213216405507626\n",
      "train loss:0.007476188247839962\n",
      "train loss:0.04467384248087444\n",
      "train loss:0.011964743718968282\n",
      "train loss:0.013763636349081513\n",
      "train loss:0.010293459790062671\n",
      "train loss:0.05337281605916166\n",
      "train loss:0.00655259642680359\n",
      "train loss:0.029555011464454446\n",
      "train loss:0.053815391020647495\n",
      "train loss:0.09686127187677736\n",
      "train loss:0.0379135043805479\n",
      "train loss:0.01845880729895989\n",
      "train loss:0.01311427575218347\n",
      "train loss:0.023729079206554746\n",
      "train loss:0.017389201386060753\n",
      "train loss:0.040421950553750904\n",
      "train loss:0.026438362833378436\n",
      "train loss:0.01778851108542843\n",
      "train loss:0.02137835206610904\n",
      "train loss:0.10427253024413337\n",
      "train loss:0.027794025549389787\n",
      "train loss:0.028149260768424975\n",
      "train loss:0.04623830237079137\n",
      "train loss:0.0929585960086028\n",
      "train loss:0.055145095696471455\n",
      "train loss:0.021263052348865812\n",
      "train loss:0.02566443005512388\n",
      "train loss:0.016596305388992566\n",
      "train loss:0.011956859060232953\n",
      "train loss:0.017076003513441892\n",
      "train loss:0.032300904073816854\n",
      "train loss:0.024549306300917752\n",
      "train loss:0.01906070961099898\n",
      "train loss:0.07201423654419685\n",
      "train loss:0.036382739575722606\n",
      "train loss:0.03291497480525858\n",
      "train loss:0.01590666593988517\n",
      "train loss:0.05180130301033296\n",
      "train loss:0.07844775935697706\n",
      "train loss:0.027454828780320413\n",
      "train loss:0.017761070315879143\n",
      "train loss:0.04917546633267959\n",
      "train loss:0.05465385505259159\n",
      "train loss:0.01803309219163535\n",
      "train loss:0.029094915479612227\n",
      "train loss:0.051317427274187935\n",
      "train loss:0.061881060546896946\n",
      "train loss:0.031207137109012573\n",
      "train loss:0.02594046064317915\n",
      "train loss:0.11681909539827545\n",
      "train loss:0.036778249789786284\n",
      "train loss:0.038225930238356715\n",
      "train loss:0.024307931489751335\n",
      "train loss:0.07132653032623554\n",
      "train loss:0.01680447843223275\n",
      "train loss:0.024909924852698693\n",
      "train loss:0.030322887344294034\n",
      "train loss:0.04451366124734002\n",
      "train loss:0.03211706478096566\n",
      "train loss:0.04765661025301179\n",
      "train loss:0.04758524983706648\n",
      "train loss:0.08222134337655197\n",
      "train loss:0.010842745904814523\n",
      "train loss:0.03511302979930675\n",
      "train loss:0.125667279652205\n",
      "train loss:0.028679680860913676\n",
      "train loss:0.022785851205168895\n",
      "train loss:0.04982153922355461\n",
      "train loss:0.06229843550557221\n",
      "train loss:0.039760822327236996\n",
      "train loss:0.022807313937587576\n",
      "train loss:0.04987762774114892\n",
      "train loss:0.041313768894832376\n",
      "train loss:0.019913903232440414\n",
      "train loss:0.019522204667842793\n",
      "train loss:0.011721295325793638\n",
      "train loss:0.02623062283927697\n",
      "train loss:0.02616663904060233\n",
      "train loss:0.027886893822063486\n",
      "train loss:0.07511264842781308\n",
      "train loss:0.025454637700684755\n",
      "train loss:0.06264308988428742\n",
      "train loss:0.04672837539034129\n",
      "train loss:0.03518482866062513\n",
      "train loss:0.051422276433111924\n",
      "train loss:0.07588809844636463\n",
      "train loss:0.03799232635422437\n",
      "train loss:0.05033334965041106\n",
      "train loss:0.005508766376209906\n",
      "train loss:0.06374236288960787\n",
      "train loss:0.015885268056437977\n",
      "train loss:0.006069597936157376\n",
      "train loss:0.015558632523852508\n",
      "train loss:0.14374682436325456\n",
      "train loss:0.0761167893281026\n",
      "train loss:0.08653195541550343\n",
      "train loss:0.05249365861225835\n",
      "train loss:0.02644787361388936\n",
      "train loss:0.019646798920272626\n",
      "train loss:0.017593571517504618\n",
      "train loss:0.025104972230594592\n",
      "train loss:0.046320709866346434\n",
      "train loss:0.016908073985231944\n",
      "train loss:0.058954456182400555\n",
      "train loss:0.020215288081968055\n",
      "train loss:0.018500620199595464\n",
      "train loss:0.016187157013068713\n",
      "train loss:0.048903010647858514\n",
      "train loss:0.013839101222957525\n",
      "train loss:0.08262546608508943\n",
      "train loss:0.028525855277373127\n",
      "train loss:0.03621180377148035\n",
      "train loss:0.017853734133221135\n",
      "train loss:0.0819714643817329\n",
      "train loss:0.040077744356212246\n",
      "train loss:0.01236297367724624\n",
      "train loss:0.07717953919742117\n",
      "train loss:0.015573742956840534\n",
      "train loss:0.025404148291154095\n",
      "train loss:0.07202373384080693\n",
      "train loss:0.051116283668475544\n",
      "train loss:0.022730191144699274\n",
      "train loss:0.03418395010767296\n",
      "train loss:0.05575510932432515\n",
      "train loss:0.015437886966419699\n",
      "train loss:0.06077026600527903\n",
      "train loss:0.04986017589374833\n",
      "train loss:0.00983632159778666\n",
      "train loss:0.06403928141325449\n",
      "train loss:0.017951460272556605\n",
      "train loss:0.022223187379571917\n",
      "train loss:0.009496885296883585\n",
      "train loss:0.07434933969894453\n",
      "train loss:0.021227894904296794\n",
      "train loss:0.08255722840655313\n",
      "train loss:0.02935774861676498\n",
      "train loss:0.05857199523066054\n",
      "train loss:0.08534524419747762\n",
      "train loss:0.04108559522954282\n",
      "train loss:0.030888562659300785\n",
      "train loss:0.015955752029426586\n",
      "train loss:0.03207788583026402\n",
      "train loss:0.058877459864381934\n",
      "train loss:0.031435264627936214\n",
      "train loss:0.05319962761597796\n",
      "train loss:0.0374194614827509\n",
      "train loss:0.022298427369802143\n",
      "train loss:0.012835553404786626\n",
      "train loss:0.0733796094422475\n",
      "train loss:0.0411217031643896\n",
      "train loss:0.011852055135628687\n",
      "train loss:0.01973778931501408\n",
      "train loss:0.052362349025765406\n",
      "train loss:0.06400955442968052\n",
      "train loss:0.051553029572286656\n",
      "train loss:0.03583330268773234\n",
      "train loss:0.027308553466834754\n",
      "train loss:0.0502104163159232\n",
      "train loss:0.030020670074563445\n",
      "train loss:0.006624461427686303\n",
      "train loss:0.028551304789698907\n",
      "train loss:0.07842311905821824\n",
      "train loss:0.013050627822443362\n",
      "train loss:0.06987584292933514\n",
      "train loss:0.02132698335239546\n",
      "train loss:0.057641475947286885\n",
      "train loss:0.010227611740208361\n",
      "train loss:0.02632964348649462\n",
      "train loss:0.0435944275429799\n",
      "train loss:0.04073804359565605\n",
      "train loss:0.0258236496836881\n",
      "train loss:0.007980185313303205\n",
      "train loss:0.01254087878461717\n",
      "train loss:0.02268846267280607\n",
      "train loss:0.05189106957541199\n",
      "train loss:0.0171463570299586\n",
      "train loss:0.05951995141359637\n",
      "train loss:0.04031880200180964\n",
      "train loss:0.04894041591763459\n",
      "train loss:0.0225645993491823\n",
      "train loss:0.031014332444048255\n",
      "train loss:0.00559821807926808\n",
      "train loss:0.01829801970247254\n",
      "train loss:0.04528522379693742\n",
      "train loss:0.025096202226537766\n",
      "train loss:0.035272077985548496\n",
      "train loss:0.02087211578588198\n",
      "train loss:0.01136302019937792\n",
      "train loss:0.007235199850210297\n",
      "train loss:0.08594647926914009\n",
      "train loss:0.020914893156284548\n",
      "train loss:0.039825481330912\n",
      "train loss:0.07950071832930256\n",
      "train loss:0.07055712309555988\n",
      "train loss:0.031890537999513996\n",
      "train loss:0.0718415292912865\n",
      "train loss:0.07488265853188095\n",
      "train loss:0.022584349725674024\n",
      "train loss:0.04337965856020099\n",
      "train loss:0.02474120629238081\n",
      "train loss:0.01574462548529271\n",
      "train loss:0.007891173145133322\n",
      "train loss:0.007327731817791421\n",
      "train loss:0.028369252283553376\n",
      "train loss:0.017034623581460098\n",
      "train loss:0.005358125985056686\n",
      "train loss:0.008049571301243156\n",
      "train loss:0.02357258651846852\n",
      "train loss:0.0407036228127748\n",
      "train loss:0.04691163419876099\n",
      "train loss:0.06307459795809608\n",
      "train loss:0.025312253848467654\n",
      "train loss:0.021111729137537324\n",
      "train loss:0.03991194113455125\n",
      "train loss:0.007575723448304576\n",
      "train loss:0.036790449204104896\n",
      "train loss:0.019764311584808576\n",
      "train loss:0.019831435500863186\n",
      "train loss:0.024271870568732718\n",
      "train loss:0.03232121353189966\n",
      "train loss:0.044600869889193734\n",
      "train loss:0.02375729934748254\n",
      "train loss:0.03403516301792407\n",
      "train loss:0.0267943379486543\n",
      "train loss:0.05414038415830869\n",
      "train loss:0.036316955289671056\n",
      "train loss:0.05002968836036549\n",
      "train loss:0.015326829458065494\n",
      "train loss:0.02456288979313951\n",
      "train loss:0.04782153764666179\n",
      "train loss:0.04842955434275961\n",
      "train loss:0.07312375211227187\n",
      "train loss:0.06587950471540774\n",
      "train loss:0.04197012156668443\n",
      "train loss:0.03813534448652776\n",
      "train loss:0.06354131758099275\n",
      "train loss:0.013110304671446416\n",
      "train loss:0.035047643939560384\n",
      "train loss:0.05021260237248321\n",
      "train loss:0.027706580542829536\n",
      "train loss:0.021663185230669145\n",
      "train loss:0.016813254890237002\n",
      "train loss:0.009233152312958867\n",
      "train loss:0.11855589284809866\n",
      "train loss:0.06261261908633847\n",
      "train loss:0.02429522244325267\n",
      "train loss:0.015149383707178323\n",
      "train loss:0.030083337213647244\n",
      "train loss:0.01571157771997039\n",
      "train loss:0.05003190478980383\n",
      "train loss:0.02523953706809828\n",
      "train loss:0.1302524837417068\n",
      "train loss:0.02745149170682444\n",
      "train loss:0.04651399631441174\n",
      "train loss:0.05600883670350216\n",
      "train loss:0.02225327906361104\n",
      "train loss:0.01670742493451218\n",
      "train loss:0.013758279824930155\n",
      "train loss:0.06487384336751968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03715919113965385\n",
      "train loss:0.02775612762976491\n",
      "train loss:0.047388925164920034\n",
      "train loss:0.03975111766541457\n",
      "train loss:0.07764229141130477\n",
      "train loss:0.02144999580659398\n",
      "train loss:0.05503813320750953\n",
      "train loss:0.05122558230153363\n",
      "train loss:0.023031789646450744\n",
      "train loss:0.010025479994677282\n",
      "train loss:0.010700036696565331\n",
      "train loss:0.006993037205283145\n",
      "train loss:0.03493979208964134\n",
      "train loss:0.06683170510044313\n",
      "train loss:0.008774021129232213\n",
      "train loss:0.06938037791618931\n",
      "train loss:0.009095148528760998\n",
      "train loss:0.029908322112694362\n",
      "train loss:0.013407569044065452\n",
      "train loss:0.05026323396045063\n",
      "train loss:0.012809421811402278\n",
      "train loss:0.02220789930493163\n",
      "train loss:0.046463923342546905\n",
      "train loss:0.011696689872826483\n",
      "train loss:0.010832218911599793\n",
      "train loss:0.05078304032169567\n",
      "train loss:0.037290076727516296\n",
      "train loss:0.03029160482556914\n",
      "train loss:0.019371271678215583\n",
      "train loss:0.02670297654687835\n",
      "train loss:0.019301981007104178\n",
      "train loss:0.048756096728957865\n",
      "train loss:0.06079124495231627\n",
      "train loss:0.028021175349280544\n",
      "train loss:0.013122141277525274\n",
      "train loss:0.05199215232627089\n",
      "train loss:0.03911565037095948\n",
      "train loss:0.011410419670319404\n",
      "train loss:0.0210644821222088\n",
      "train loss:0.05807710175799539\n",
      "train loss:0.014373482453970875\n",
      "train loss:0.009691814567819949\n",
      "train loss:0.005584475569380441\n",
      "train loss:0.018830173503253732\n",
      "train loss:0.04845021849862046\n",
      "train loss:0.011478001645209145\n",
      "train loss:0.021611655489164366\n",
      "train loss:0.057388257960062326\n",
      "train loss:0.026636736824237024\n",
      "train loss:0.0420514041779565\n",
      "train loss:0.04126385035532516\n",
      "train loss:0.03391315835614644\n",
      "train loss:0.03002568056075679\n",
      "train loss:0.07413377969951616\n",
      "train loss:0.0450426682169821\n",
      "train loss:0.012289215487119698\n",
      "train loss:0.02036594797411135\n",
      "train loss:0.022228157065681448\n",
      "train loss:0.03210815321643702\n",
      "train loss:0.026187546219150055\n",
      "train loss:0.016987151088390804\n",
      "train loss:0.009406848636852634\n",
      "train loss:0.028721211967476123\n",
      "train loss:0.027171218390929966\n",
      "train loss:0.028842046064647065\n",
      "train loss:0.018902497084891303\n",
      "train loss:0.013455853538900536\n",
      "train loss:0.016293748241805083\n",
      "train loss:0.025566657357163205\n",
      "train loss:0.02620334387185424\n",
      "train loss:0.042262024042140925\n",
      "train loss:0.01344596775785114\n",
      "train loss:0.10841261708021056\n",
      "train loss:0.056917285002177166\n",
      "train loss:0.023706701646452687\n",
      "train loss:0.02143039702898698\n",
      "train loss:0.016478651651608348\n",
      "train loss:0.031528835677519976\n",
      "train loss:0.025314565544138686\n",
      "train loss:0.02624440651907994\n",
      "train loss:0.06287913849227597\n",
      "train loss:0.03325299016545277\n",
      "train loss:0.014295201070459557\n",
      "train loss:0.02228237018021957\n",
      "train loss:0.029830534720322634\n",
      "train loss:0.017246344621965563\n",
      "train loss:0.104916193748664\n",
      "train loss:0.048596500468511904\n",
      "train loss:0.019787731179885627\n",
      "train loss:0.044593590079300825\n",
      "train loss:0.011664168066370946\n",
      "train loss:0.008564682271994407\n",
      "train loss:0.03147234720912965\n",
      "train loss:0.0501110826997816\n",
      "train loss:0.019240399206021226\n",
      "train loss:0.026405829825480544\n",
      "train loss:0.04480082334620524\n",
      "train loss:0.036475070936335244\n",
      "train loss:0.04974392639598417\n",
      "train loss:0.010674661936176845\n",
      "train loss:0.02231187782676903\n",
      "train loss:0.020299726157772018\n",
      "train loss:0.013692577305926185\n",
      "train loss:0.014996836212893844\n",
      "train loss:0.0179148974259672\n",
      "train loss:0.046347769829133925\n",
      "train loss:0.033083758880353725\n",
      "train loss:0.0198560604417097\n",
      "train loss:0.026081887556777688\n",
      "train loss:0.057835206366401784\n",
      "train loss:0.022746204127775723\n",
      "train loss:0.015710376115997595\n",
      "train loss:0.019954432472381614\n",
      "train loss:0.05088207596950599\n",
      "train loss:0.06114157466050187\n",
      "train loss:0.013448105543187587\n",
      "train loss:0.0486913496892226\n",
      "train loss:0.02853588611695461\n",
      "train loss:0.017966924316529784\n",
      "train loss:0.02296392097922595\n",
      "train loss:0.03561565513605014\n",
      "train loss:0.025315020449092965\n",
      "train loss:0.008508453024038165\n",
      "train loss:0.01481966431203639\n",
      "train loss:0.03266722238340966\n",
      "train loss:0.021309575192988248\n",
      "train loss:0.021591131181521294\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9842\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnS0lEQVR4nO3de5wcZZ3v8c+ve3ruuU5ukCEkZENIRCQQIwi4oKsQVrkddZGDuqwaWJHFXUHBs97O63g2e3BdYReJLEbkLst9NQgiaBYBISEBkhBICMFMorlBMpnpme7pnt/5o2pCZ9IzU5lMTQ/T3/fr1a9Md1V1/6YY6tvPU1XPY+6OiIhId4lSFyAiIkOTAkJERIpSQIiISFEKCBERKUoBISIiRSkgRESkqNgCwswWm9k2M1vVw3Izs+vMbL2ZvWhmxxUsO8PMXgmXXRVXjSIi0rM4WxA3A2f0snw+MCN8LABuADCzJHB9uHw28Ckzmx1jnSIiUkRsAeHuS4E3e1nlbOAWDzwDjDazQ4B5wHp33+DuWeCucF0RERlEFSX87MnApoLnTeFrxV5/X09vYmYLCFog1NXVHX/UUUcNfKUiIsPU8uXLd7j7+GLLShkQVuQ17+X1otz9RuBGgLlz5/qyZcsGpjoRkTJgZm/0tKyUAdEEHFbwvBHYAlT28LqIiAyiUl7m+hDwmfBqphOA3e7+R+A5YIaZTTOzSuD8cF0RERlEsbUgzOxO4FRgnJk1Ad8CUgDuvghYApwJrAfSwEXhspyZfQl4BEgCi919dVx1iohIcbEFhLt/qo/lDlzaw7IlBAEiIiIlojupRUSkKAWEiIgUpYAQEZGiFBAiIlKUAkJERIpSQIiISFEKCBERKUoBISIiRSkgRESkKAWEiIgUpYAQEZGiFBAiIlKUAkJERIpSQIiISFEKCBERKUoBISIiRSkgRESkKAWEiIgUpYAQEZGiFBAiIlKUAkJERIpSQIiISFEKCBERKUoBISIiRSkgRESkKAWEiIgUVVHqAkREpH8eWLGZax55hS272jh0dA1Xnj6Tc+ZMHrD3V0CIiLwDPbBiM1ff9xJtHXkANu9q4+r7XgIYsJBQQIiIvAO0d+TZ2ZplZ0uGnS1ZTn7wRF5O7obkvuvtfHA0zHljQD5TASEiUgK5fCdvpTvY2Roc8HeEB/63n7/9886WDK3Z/D7bb6zeXfR9G9g1YDUqIEREBoC709yeC77hd33Tb83uPcDvKPj2v7M1y1vpLO77v08yYTTUVdJQX8W4+koOH1tLQ30VDfWVjKurYmxdJQ31lbA4/t9JASEi0oPu3To7Cg/+LdluB/0MHfkiR3xgVE1q7wH+zybU8776ShrqggBoqK/aJxBGVqdIJCwsoBnefA3efBl2boCm1+DNDbDztUH5/RUQIlI2DqRb583WLC2ZXNH3qU4lGFdfRUN9FZNGVvOuQ0fuPdCPC7/tN9QF/46praSyopc7CrpCYNsGeHlDGAhhCKR37LvuiEOhYTocdSY8f8sA7pniFBAi8o61f7fOvv32B9qtMzY8wE+ZUrv3AD+u4GDfdfCvrTzAQ+felsCGoCXwZhgEfYXA2OnBz2OPgDHToLL27fUUECJSbjrynWzbkyldt05/xRECvambAK3bir8+QGINCDM7A7iW4EKsm9x9YbflYwhOtUwH2oG/cfdV4bK/Bz4POPAScJG7t8dZr4gMns5OZ9NbaV750x7WbWvhlT/t4dWte3hte0vRg35v3ToN3b7l99mt0189hcCbG6B1+77rDkQI9ObKdQf/Hn2ILSDMLAlcD3wYaAKeM7OH3H1NwWpfB1a6+7lmdlS4/ofMbDLwd8Bsd28zs7uB84Gb46pXROLh7mxtzvDK1j28+qc9wb9b97Bua8vem7wAGsfUMHPiCE6dOYGpDbV7u3P63a3TX+3NBd/+I4bAzPlBCIw9Ing+UCFQYnHu8XnAenffAGBmdwFnA4UBMRv4JwB3X2tmU81sYkFtNWbWAdQCW2KsVUQGwJut2b0tga5AeHXrHprb3z7ZO35EFTMnjuBT86Ywc1I9R04cwYyJI6ivGsQeb4VAJHH+F5kMbCp43gS8r9s6LwDnAU+a2TzgcKDR3Zeb2feAPwBtwKPu/mixDzGzBcACgClTpgzsbyAiRe1p72DdtpZ9WgSv/KmFHS2ZveuMrK7gqEkjOevYQ5k5cQRHho8xdZWDU2RhCOztElIIHIg4A6LYGZ/uHYsLgWvNbCXBeYYVQC48N3E2MA3YBfynmV3o7rft94buNwI3AsydO7f42SoR6Zf2jjzrt7V0axG0sHlX2951aiuTzJhQz2kzxzNzUhACMyeNYMKIKswO8sRvnwUqBOIUZ0A0AYcVPG+kWzeRuzcDFwFY8Jf0evg4HXjd3beHy+4D3g/sFxAicvA68p1s3NEatgZa9nYNbdzZSmf4tasymeCI8XXMnTqGCyZOYWYYBJNH1xz8FUC9KRoC4XOFQKziDIjngBlmNg3YTHCS+YLCFcxsNJB29yzBFUtL3b3ZzP4AnGBmtQRdTB8ClsVYq0hZ6Ox0mt5qK+gW2v/KoYTB1HF1zJw0go+959CwRVDP4Q11pJIDeGVQZye0vRUc5Pc+dgT/7m5SCAwBsQWEu+fM7EvAIwSXuS5299Vmdkm4fBEwC7jFzPIEJ68/Fy77vZndAzwP5Ai6nm6Mq1aR4SbqlUOTR9cwc1Jw5VDXCePp4+upTiV7efcePxSyLfse6Lsf+Pf+vCO4N8A7938fS0D9JIXAEGBe7LbCd6i5c+f6smVqaEh5Kbxy6NWClkGxK4e6WgORrxzKZQoO7uG/6R09HPS3Q66HW5WqRkHdOKgb38u/4aNmDCT6EVDSL2a23N3nFlumO6lF3iGiXjnU1TXUdcL4yIkjGNt15dDebp2tsGVVH9/2d0Cm+JDSJKv2PbiPn7X/gb4wACqqBmEPyUBTQIgMMVGuHKpJJTlyYj2nHTmOo8cnmTUyw5/VtTHGd2PpV4MD/K4dsLnbQT+9s+dundqGtw/ohx6770G+ttu3/aoREPcVSlJyCgiRuFwzo+excq5ct/fKoVe3tuxzU9mWnbsY7c00WDMTk83MHpnl7BFtTBnfxsTkHsb6bqo73sRad8Cr22FNT906I98+oI89Ag6bV+Tbvbp1pGcKCJG4FAuH8PXr//mreMt2xvhuGqyZD9huPpFsocF2U1vVuu/66fCRrAzCpcdunXH7fuNPVcf9G8owp4AQKYFL236EJ41s5Ri8bhypkRNJ1h/dwzd8detIaSggRAbYy3/YyqsPX8/Zva10xXqsdixV6taRIUwBITIAcvlOHn9xA9se/yGnN9/DLOvh6p8u9eMHpzCRg6CAEDkIb7Vmue+pNeSfWcQncv/FGGuhaewJ7Dnjakbc2WsbQmTIU0CI9MOaLc3859KVjF+zmAvtl4y0NrYdehr5+f+LxinvDVYahBm/ROKkgBCJKJfv5FdrtnL/fz/P8Vtu54rkY9QksrQecSZ8+ComHHLMvhsMwoxfInFSQIj04a3WLHc9t4lHnlrG2el7+beKJ0hV5MjNPo/EqVcyYsJRpS5RJBYKCJEevPzHZn761EaeW/E8n+NB7qlYSiIFvOd8Eqf8A5UN00tdokisFBAiBXL5Th57eSs/+d1Gtm9cxWWph/huxe+wRJLE8X8NJ10OozVzoZQHBYQIb3cj3fr0RkY0v8qVNT/nQ1W/g4pqbO4l8P7LYOQhpS5TZFApIKSsdXUj3b9iMzPy67l21BLeW/UUXlGPzfsynHCp7lmQsqWAkLJT2I30+9ff5MTUOh4a8zAz9zwDjII/vwp738VQO7bUpYqUlAJCykZXN9Jtz7zB5l1pPjbiNX436SEm71oG+Qb40DfhvV+A6pGlLlVkSFBAyLBX2I2UyeX528mvs6DuXsbsXAG5SXD6/4Xj/xoq60pdqsiQooCQYal7N1JNCv5x+kY+kb6L6u0vwshGOPN7MOfTGhZbpAcKCBlW9u1GauOwUZXcdPwbnLbtVpJvrAkmvT/r3+CY86GistTligxpCggZFvbtRurk5GmjWPTuVzl6w03Y6nUwbiac9x/wrvMgqT97kSj0f4q8Y3V1I9381Eae2fAm1akEnzh2ApeOfZZDXrwBnnsDJr4bPvFTmHUWJBKlLlnkHUUBIe84b7Vm+dmyTdz6dNCNNHl0Df/4kalckPoNtc99BVZthkOPg/n/DEeeoVnYRPpJASHvGN27kU48ooHvzD+cD+75BYmnLw6G1p5yYnCOYfoHFQwiB0kBIUNasW6k845r5KLjx3Dkxjvhl9dD21twxKnwgZth6kmlLllk2FBAyJC0K901NtLb3UhXzz+K84+uY9QLN8EdN0Jmd9CFdMoVcNh7S12yyLCjgJAhpasb6YGVm2nvCLqRvvmx2fzFYZB85npY9GPoaA1OOn/gCjjkPaUuWWTYUkBIyRXrRjp3TiOfff/hHFWzB576V7j/Zshn4ej/Aad8BSbMKnXZIsOeAkJKpqdupL9672GMzmyBJ78JK28H7wxubDvlH0CT9IgMGgWEDLoeu5FmTST55mvwyOXw4s8gkQyGwjjpchhzeKnLFik7CggZFEE30jZufur1/buRJo2ErWvgvq/D6vshWQXvuzicpOfQUpcuUrYUEBKrXruRaithywq463uw9udQWQ/v/zs48UuapEdkCFBASCzW/untm9r260ZKGGx6Fu6/BtY9CtXBJD1okh6RIUUBIQOmeDfSZD77/qlBN5I7bHwSlv4/eH0p1HZN0vP5ICREZEiJNSDM7AzgWiAJ3OTuC7stHwMsBqYD7cDfuPuqcNlo4CbgaMDDZU/HWa/0T5/dSO6w7jFYeg1segbqJ8JHvgtzL9IkPSJDWGwBYWZJ4Hrgw0AT8JyZPeTuawpW+zqw0t3PNbOjwvU/FC67Fvilu3/czCqB2rhqlf4p1o30jY/O5i9mTaAimYDOTlj7iyAYtqzQJD0i7zBxtiDmAevdfQOAmd0FnA0UBsRs4J8A3H2tmU01s4lAG/AB4K/DZVkgG2OtcgCeWr+D6x5fV7wbCaAzD6vug//+F9i6CsZM1SQ9Iu9AcQbEZGBTwfMm4H3d1nkBOA940szmAYcDjUAe2A78xMzeAywHLnf31u4fYmYLgAUAU6ZMGejfQYq46r6XSGfz+3YjAeRzsOqeIBh2vArjjoRzbwzuftYkPSLvOHHOoFJsrGXv9nwhMMbMVgKXASuAHEFwHQfc4O5zgFbgqmIf4u43uvtcd587frwujRwMe9o7mH/0JC7+8+lBOOSysPxm+Pfj4f6LIVkJn7gZvvgMvOevFA4i71CR/s81s3sJTiY/7O6dEd+7CTis4HkjsKVwBXdvBi4KP8OA18NHLdDk7r8PV72HHgJCBl86m6e2MgkdbfD8rfC7H0BzOEnPGQs1SY/IMBH1q90NBAfy68zsP4Gb3X1tH9s8B8wws2nAZuB84ILCFcIrldLhOYbPA0vD0Gg2s01mNtPdXyE4cb0GKbl8p5PMpTlp211w7Z3QslWT9IgMU5ECwt0fAx4zs1HAp4Bfmdkm4D+A29y9o8g2OTP7EvAIwWWui919tZldEi5fBMwCbjGzPEEAfK7gLS4Dbg+vYNpA2NKQ0kpnc/wo9X1O2bgqmKTn44th6smlLktEYmDu3U8L9LCiWQNwIfBpgq6i24GTgXe7+6lxFXgg5s6d68uWLSt1GcPa1uZ2Ev9yJM2Nf870L9xa6nJE5CCZ2XJ3n1tsWdRzEPcBRwG3Ah9z9z+Gi35mZjoil5F0Ns94MuyuHlPqUkQkZlHPQfy7uz9ebEFPySPDU2t7B4eTwXQHtMiwF/Uy11nhCWUgGCLDzL4YT0kylGXaW0mYk6iqL3UpIhKzqAHxBXff1fXE3d8CvhBLRTKktbc2A5CsHlHiSkQkblEDIhHepwDsHWdJYyaUoY70HgAqatTFJDLcRT0H8Qhwt5ktIrgb+hLgl7FVJUNWtr0FgJRaECLDXtSA+BpwMfC3BENoPEowFLeUmXx70IKorFVAiAx3UW+U6yS4m/qGeMuRoS4ftiCqFBAiw17U+yBmEAzLPRvYO5C/ux8RU10yROUzwYC6lTUKCJHhLupJ6p8QtB5ywGnALQQ3zUmZ8UzQgtBlriLDX9SAqHH3XxMMzfGGu38b+GB8ZclQ5dlwSg7dKCcy7EU9Sd1uZglgXTgA32ZgQnxlyVBlCgiRshG1BfFlgjka/g44nmDQvs/GVJMMYYlcOvghpSnCRYa7PlsQ4U1xn3T3K4EWNOx2WUt0pMlQRVUiWepSRCRmfbYg3D0PHF94J7WUr2Q+TSZR3feKIvKOF/UcxArgwXA2udauF939vliqkiErlUuTTdSUugwRGQRRA2IssJN9r1xyQAFRZio628hWKCBEykHUO6l13kEAqOpsI5dUQIiUg6h3Uv+EoMWwD3f/mwGvSIa0ys528hW6i1qkHETtYvp5wc/VwLkE81JLGensdGq8nXzFpFKXIiKDIGoX072Fz83sTuCxWCqSIautI08t7XToHgiRshD1RrnuZgBTBrIQGfrS2Ty1lsFTuotapBxEPQexh33PQfyJYI4IKSPpbI4G2tldqRaESDmI2sWks5JCOpPjMDKYRnIVKQuRupjM7FwzG1XwfLSZnRNbVTIktbW1kDDXUN8iZSLqOYhvufvurifuvgv4ViwVyZCVTQfTjSardA5CpBxEDYhi60W9RFaGiUxXQNSoBSFSDqIGxDIz+76ZTTezI8zsX4HlcRYmQ09HWxAQldUjS1yJiAyGqAFxGZAFfgbcDbQBl8ZVlAxNubZgutFKtSBEykLUq5hagatirkWGuHw4H3VlnVoQIuUg6lVMvzKz0QXPx5jZI7FVJUNSZxgQVWpBiJSFqF1M48IrlwBw97fQnNRlpysgktW6LUakHEQNiE4z2zu0hplNpcjorjLMZcO5oip1matIOYh6qer/Ap40s9+Gzz8ALIinJBmysungXw3WJ1IWop6k/qWZzSUIhZXAgwRXMkkZsY4wINSCECkLUU9Sfx74NfCV8HEr8O0I251hZq+Y2Xoz2+8qqPBk9/1m9qKZPWtmR3dbnjSzFWb28+7byuBL5lrJUAmJZKlLEZFBEPUcxOXAe4E33P00YA6wvbcNzCwJXA/MB2YDnzKz2d1W+zqw0t2PAT4DXFvkc1+OWKPELJlLk0loulGRchE1INrdvR3AzKrcfS0ws49t5gHr3X2Du2eBu4Czu60zm6BlQvieU81sYvg5jcBfAjdFrFFiVpFvU0CIlJGoAdEU3gfxAPArM3uQvqccnQxsKnyP8LVCLwDnAZjZPOBwoDFc9gPgq0Bnbx9iZgvMbJmZLdu+vddGjRykVD5NLlFd6jJEZJBECgh3P9fdd7n7t4FvAD8GzuljMyv2Vt2eLwTGmNlKguE8VgA5M/sosM3d+xzvyd1vdPe57j53/Pjxfa0uB6Gys42OCl3BJFIuDnhEVnf/bd9rAUGL4bCC5410a3W4ezNwEYCZGfB6+DgfOMvMzgSqgZFmdpu7X3ig9crAqepsJ5fUTXIi5aK/c1JH8Rwww8ymmVklwUH/ocIVwomHKsOnnweWunuzu1/t7o3uPjXc7nGFQ2m5O9XeTqdaECJlI7Y5Hdw9Z2ZfAh4BksBid19tZpeEyxcBs4BbzCwPrAE+F1c9cnAyuU5qaKcjpXsgRMpFrJP+uPsSYEm31xYV/Pw0MKOP9/gN8JsYypMD0JrJUWcZdukuapGyEWcXkwwj6WyeWtp1F7VIGVFASCTpTI5aMliVhvoWKRcKCIkk3dZCwpxElbqYRMqFAkIi6Ug3A5oLQqScKCAkkkx6DwAV1epiEikXCgiJpKMtmE0upYAQKRsKCIkk1xa0IFK1I0tciYgMFgWERJIL56OuqlULQqRcKCAkks72YD7qqhq1IETKhQJCIunMBgFRUaOrmETKhQJCoskGXUxoqA2RsqGAkEgsbEFoqA2R8qGAkGg60sG/CgiRsqGAkEiSuTQZKiGRLHUpIjJIFBASSbIjTSZRU+oyRGQQKSAkkmQ+TdaqS12GiAwiBYREUplvI5tUC0KknCggJJJUZxu5pC5xFSknCgiJpMrbyFWoBSFSThQQ0id3p7qznXyFWhAi5UQBIX3K5jupoR3XXdQiZUUBIX1KZ/LUWQZP6SY5kXKigJA+pTvy1NIOlRrqW6ScKCCkT+n2DmrJYJXqYhIpJwoI6VNbWysJcxKablSkrCggpE/t6WYAkupiEikrCgjpU0c6mI+6okYBIVJOFBDSp2xbMFmQAkKkvCggpE/59qAFUVmt6UZFyokCQvqUC1sQlbUKCJFyooCQPnWG81FX140qcSUiMpgUENKnzkwwH3VKl7mKlBUFhPTJw4DQfNQi5UUBIX3r6AoI3UktUk5iDQgzO8PMXjGz9WZ2VZHlY8zsfjN70cyeNbOjw9cPM7MnzOxlM1ttZpfHWaf0zroCQoP1iZSV2ALCzJLA9cB8YDbwKTOb3W21rwMr3f0Y4DPAteHrOeAr7j4LOAG4tMi2MkiSHWkyVEKyotSliMggirMFMQ9Y7+4b3D0L3AWc3W2d2cCvAdx9LTDVzCa6+x/d/fnw9T3Ay8DkGGuVXiRyaTJWXeoyRGSQxRkQk4FNBc+b2P8g/wJwHoCZzQMOBxoLVzCzqcAc4PfFPsTMFpjZMjNbtn379oGpXPaRyreRTWi6UZFyE2dAWJHXvNvzhcAYM1sJXAasIOheCt7ArB64F/iyuzcX+xB3v9Hd57r73PHjxw9I4bKvinyabFIBIVJu4uxUbgIOK3jeCGwpXCE86F8EYGYGvB4+MLMUQTjc7u73xVin9KEy30YupYAQKTdxtiCeA2aY2TQzqwTOBx4qXMHMRofLAD4PLHX35jAsfgy87O7fj7FGiaDK28gldYmrSLmJLSDcPQd8CXiE4CTz3e6+2swuMbNLwtVmAavNbC3B1U5dl7OeBHwa+KCZrQwfZ8ZVq/SuyjPkUwoIkXIT63WL7r4EWNLttUUFPz8NzCiy3ZMUP4chg6wj30mNt5GtUECIlBtd2C69Smfz1FmGjIbZkGGqo6ODpqYm2tvbS11KrKqrq2lsbCSVSkXeRgEhvUpnc9STAXUxyTDV1NTEiBEjmDp1KsHpz+HH3dm5cydNTU1MmzYt8nYai0l6lc7kqKMd03zUMky1t7fT0NAwbMMBwMxoaGg44FaSAkJ61ZZuJWFOokpdTDJ8Dedw6NKf31EBIb3KpIP7E5OaC0Kk7CggpFfZdDAftQJCJPDAis2ctPBxpl31C05a+DgPrNh8UO+3a9cufvjDHx7wdmeeeSa7du06qM/uiwJCepVtCwIiVaP5qEUeWLGZq+97ic272nBg8642rr7vpYMKiZ4CIp/P97rdkiVLGD16dL8/NwpdxSS96mgP5qOurFELQoa/7/zXatZsKTrsGwAr/rCLbL5zn9faOvJ89Z4XufPZPxTdZvahI/nWx97V43teddVVvPbaaxx77LGkUinq6+s55JBDWLlyJWvWrOGcc85h06ZNtLe3c/nll7NgwQIApk6dyrJly2hpaWH+/PmcfPLJPPXUU0yePJkHH3yQmpqDHx5HLQjpVT5sQVTWjixxJSKl1z0c+no9ioULFzJ9+nRWrlzJNddcw7PPPst3v/td1qxZA8DixYtZvnw5y5Yt47rrrmPnzp37vce6deu49NJLWb16NaNHj+bee+/tdz2F1IKQXuWzwWxyVepikjLQ2zd9gJMWPs7mXW37vT55dA0/u/jEAalh3rx5+9yrcN1113H//fcDsGnTJtatW0dDQ8M+20ybNo1jjz0WgOOPP56NGzcOSC1qQUivvD0IiMpaBYTIlafPpCaV3Oe1mlSSK0+fOWCfUVf39iXlv/nNb3jsscd4+umneeGFF5gzZ07Rexmqqqr2/pxMJsnlcvut0x9qQUivPBucgzANtSHCOXOCOc+ueeQVtuxq49DRNVx5+sy9r/fHiBEj2LNnT9Flu3fvZsyYMdTW1rJ27VqeeeaZfn9OfyggpHdhFxMKCBEgCImDCYTuGhoaOOmkkzj66KOpqalh4sSJe5edccYZLFq0iGOOOYaZM2dywgknDNjnRqGAkF4lOtLBDykFhEhc7rjjjqKvV1VV8fDDDxdd1nWeYdy4caxatWrv61dcccWA1aVzENIry6XJkoKkvkuIlBsFhPQqmUvTbppuVKQcKSCkVxW5NJmEAkKkHCkgpFepfBsdyepSlyEiJaCAkF6lOtvoSGiyIJFypICQXlV1tpGvUBeTSDnSpSnSqypvJ18xrtRliAwN18yA1m37v143Aa5c16+33LVrF3fccQdf/OIXD3jbH/zgByxYsIDa2nha+WpBSI/ynU6Nt9GpeyBEAsXCobfXI+jvfBAQBEQ6ne73Z/dFLQjpUTqbo9YyZFI6ByFl4uGr4E8v9W/bn/xl8dcnvRvmL+xxs8Lhvj/84Q8zYcIE7r77bjKZDOeeey7f+c53aG1t5ZOf/CRNTU3k83m+8Y1vsHXrVrZs2cJpp53GuHHjeOKJJ/pXdy8UENKjdDZPLRne1DAbIrFZuHAhq1atYuXKlTz66KPcc889PPvss7g7Z511FkuXLmX79u0ceuih/OIXvwCCMZpGjRrF97//fZ544gnGjYunG1gBIT1KZ3KMp52EAkLKRS/f9AH49qiel130i4P++EcffZRHH32UOXPmANDS0sK6des45ZRTuOKKK/ja177GRz/6UU455ZSD/qwoFBDSo3S6lYQ5VqXZ5EQGg7tz9dVXc/HFF++3bPny5SxZsoSrr76aj3zkI3zzm9+MvR6dpJYeZduCqReTCgiRQN2EA3s9gsLhvk8//XQWL15MS0swzP7mzZvZtm0bW7Zsoba2lgsvvJArrriC559/fr9t46AWhPQo0xoGRLW6mESAfl/K2pvC4b7nz5/PBRdcwIknBrPT1dfXc9ttt7F+/XquvPJKEokEqVSKG264AYAFCxYwf/58DjnkEJ2klsHV0RZ8i0lpulGRWHUf7vvyyy/f5/n06dM5/fTT99vusssu47LLLoutLnUxSY862sOAqFZAiJQjBYT0KB8GhOajFilPCgjpUVdAVNUpIGR4c/dSlxC7/vyOCgjpUWcmDAh1MckwVl1dzc6dO4d1SLg7O3fupLr6wIbu10lq6ZFnWwFIVOsyVxm+GhsbaWpqYvv27aUuJVbV1dU0NjYe0DYKCOlZRxAQ6E5qGcZSqRTTpk0rdRlDUqxdTGZ2hpm9YmbrzeyqIsvHmNn9ZvaimT1rZkdH3VbilwhbEGg0V5GyFFtAmFkSuB6YD8wGPmVms7ut9nVgpbsfA3wGuPYAtpWYWUeaLClIqqEpUo7ibEHMA9a7+wZ3zwJ3AWd3W2c28GsAd18LTDWziRG3lZglc2kypvmoRcpVnF8NJwObCp43Ae/rts4LwHnAk2Y2DzgcaIy4LQBmtgBYED5tMbNX+lnvOGBHP7eNU+nr+rYVe7X0dRWnug6M6joww7Guw3taEGdAFDuqdL+ObCFwrZmtBF4CVgC5iNsGL7rfCNzY/zIDZrbM3ece7PsMNNV1YFTXgVFdB6bc6oozIJqAwwqeNwJbCldw92bgIgAzM+D18FHb17YiIhKvOM9BPAfMMLNpZlYJnA88VLiCmY0OlwF8Hlgahkaf24qISLxia0G4e87MvgQ8AiSBxe6+2swuCZcvAmYBt5hZHlgDfK63beOqNXTQ3VQxUV0HRnUdGNV1YMqqLhvOt5eLiEj/aSwmEREpSgEhIiJFlVVARBj6w8zsunD5i2Z23BCp61Qz221mK8NH/LOVB5+72My2mdmqHpaXan/1VVep9tdhZvaEmb1sZqvN7PIi6wz6PotY16DvMzOrDofYeSGs6ztF1inF/opSV0n+xsLPTprZCjP7eZFlA7u/3L0sHgQnu18DjgAqCW7Sm91tnTOBhwnuwzgB+P0QqetU4Ocl2GcfAI4DVvWwfND3V8S6SrW/DgGOC38eAbw6RP7GotQ16Pss3Af14c8p4PfACUNgf0WpqyR/Y+Fn/wNwR7HPH+j9VU4tiCjDd5wN3OKBZ4DRZnbIEKirJNx9KfBmL6uUYn9Fqask3P2P7v58+PMe4GWCUQEKDfo+i1jXoAv3QUv4NBU+ul81U4r9FaWukjCzRuAvgZt6WGVA91c5BUSx4Tu6/08SZZ1S1AVwYtjkfdjM3hVzTVGVYn9FVdL9ZWZTgTkE3z4LlXSf9VIXlGCfhd0lK4FtwK/cfUjsrwh1QWn+xn4AfBXo7GH5gO6vcgqIKMN3RB7iYwBF+czngcPd/T3AvwEPxFxTVKXYX1GUdH+ZWT1wL/BlD2783GdxkU0GZZ/1UVdJ9pm75939WILREuZZwZD/oZLsrwh1Dfr+MrOPAtvcfXlvqxV5rd/7q5wCos+hPyKuM+h1uXtzV5PX3ZcAKTMbF3NdUZRif/WplPvLzFIEB+Hb3f2+IquUZJ/1VVep/8bcfRfwG+CMbotK+jfWU10l2l8nAWeZ2UaCrugPmtlt3dYZ0P1VTgERZfiOh4DPhFcCnADsdvc/lrouM5tkZhb+PI/gv9vOmOuKohT7q0+l2l/hZ/4YeNndv9/DaoO+z6LUVYp9ZmbjzWx0+HMN8BfA2m6rlWJ/9VlXKfaXu1/t7o3uPpXgOPG4u1/YbbUB3V9lMxOMRxv6YwnBVQDrgTThQIJDoK6PA39rZjmgDTjfw0sW4mRmdxJcrTHOzJqAbxGcsCvZ/opYV0n2F8E3vE8DL4X91xBMijWloLZS7LModZVinx0C/NSCCcISwN3u/vNS/z8Zsa5S/Y3tJ879paE2RESkqHLqYhIRkQOggBARkaIUECIiUpQCQkREilJAiIhIUQoIkRKyYFTQ/UblFBkKFBAiIlKUAkIkAjO70II5Alaa2Y/CwdxazOxfzOx5M/u1mY0P1z3WzJ6xYDz++81sTPj6n5nZY+EAb8+b2fTw7evN7B4zW2tmtxfcobvQzNaE7/O9Ev3qUsYUECJ9MLNZwF8BJ4UDuOWB/wnUAc+7+3HAbwnu6Aa4Bfiaux8DvFTw+u3A9eEAb+8HuoZAmAN8GZhNMC/ISWY2FjgXeFf4Pv8nzt9RpBgFhEjfPgQcDzwXDlXxIYIDeSfws3Cd24CTzWwUMNrdfxu+/lPgA2Y2Apjs7vcDuHu7u6fDdZ519yZ37wRWAlOBZqAduMnMziMYNkFkUCkgRPpmwE/d/djwMdPdv11kvd7GrSk2DHOXTMHPeaDC3XMEk0ndC5wD/PLAShY5eAoIkb79Gvi4mU0AMLOxZnY4wf8/Hw/XuQB40t13A2+Z2Snh658GfhvOv9BkZueE71FlZrU9faAFczeMCoeS/jJw7ID/ViJ9KJvRXEX6y93XmNk/Ao+aWQLoAC4FWoF3mdlyYDfBeQqAzwKLwgDYwNsjan4a+JGZ/e/wPT7Ry8eOAB40s2qC1sffD/CvJdInjeYq0k9m1uLu9aWuQyQu6mISEZGi1IIQEZGi1IIQEZGiFBAiIlKUAkJERIpSQIiISFEKCBERKer/A4fSoJGC/+2tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## simple convolutional network(cnn)(chap07)\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 5\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=120,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98574de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep convolutional Network(chap08)\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "network.load_params(\"params.pkl\")\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "window = Tk()\n",
    "window.title('숫자 예측하기')\n",
    "    \n",
    "oldx = oldy = -1\n",
    "\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global oldx, oldy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x, y\n",
    "        # print('EVENT_LBUTTONDOWN: %d, %d' % (x, y))\n",
    "\n",
    "    # elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # print('EVENT_LBUTTONUP: %d, %d' % (x, y))\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx, oldy), (x, y), 0, 5, cv2.LINE_AA)\n",
    "            cv2.imshow('image', img)\n",
    "            oldx, oldy = x, y\n",
    "\n",
    "def crt():\n",
    "    global img, tmp_img\n",
    "    img = np.ones((280, 280), dtype=np.uint8) * 255\n",
    "\n",
    "    cv2.namedWindow('image')\n",
    "    cv2.setMouseCallback('image', on_mouse, img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(3000)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    img = cv2.resize(img, (28,28), interpolation=cv2.INTER_AREA)     # 28*28 resize\n",
    "    cv2.imwrite('tmp.png', img)\n",
    "    img = ~img  # invert\n",
    "    img=img.reshape(-1,1,28,28)\n",
    "    \n",
    "    labels_view=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "    y=network.predict(img)\n",
    "    pred_num=np.argmax(y)\n",
    "    result = \"my predict is %s\"%(labels_view[pred_num])\n",
    "    \n",
    "    tmp_img=Image.open('tmp.png')\n",
    "    tmp_img=ImageTk.PhotoImage(tmp_img)\n",
    "    \n",
    "    Label(window, text=\"파일경로: new\").grid(row=2) # 파일경로 view\n",
    "    Label(window, image=tmp_img).grid(row=3) #사진 view\n",
    "    Label(window, text=result).grid(row=4) # 예측 결과 출력    \n",
    "\n",
    "def open():\n",
    "    global my_image # 함수에서 이미지를 기억하도록 전역변수 선언 (안하면 사진이 안보임)\n",
    "    window.filename = filedialog.askopenfilename(initialdir='', title='파일선택', filetypes=(\n",
    "    ('png files', '*.png'), ('jpg files', '*.jpg'), ('all files', '*.*')))\n",
    " \n",
    "    Label(window, text=\"파일경로: \"+window.filename).grid(row=2) # 파일경로 view\n",
    "    \n",
    "    img = Image.open(window.filename)\n",
    "    my_image = ImageTk.PhotoImage(img)\n",
    "    \n",
    "    img=img.convert(\"L\")                         # gray 저장\n",
    "    img=np.invert(img)                           # 흑백을 반전\n",
    "    \n",
    "    # print(img.shape)                           # img의 shape 확인\n",
    "    img=img.reshape(-1, 1, 28, 28)\n",
    "    \n",
    "    Label(window, image=my_image).grid(row=3) #사진 view\n",
    "    \n",
    "    labels_view=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "    y=network.predict(img)\n",
    "    pred_num=np.argmax(y)\n",
    "    result = \"my predict is %s\"%(labels_view[pred_num])\n",
    "    Label(window, text=result).grid(row=4) # 예측 결과 출력\n",
    "    \n",
    "\n",
    "b_create=Button(window, text='그리기(아무키나 누르면 닫기)', command=crt).grid(row=0)\n",
    "b_open = Button(window, text='파일열기', command=open).grid(row=1)\n",
    "Label(window, text=\"파일 경로\").grid(row=2)\n",
    "Label(window).grid(row=3)\n",
    "Label(window, text=\"예측 결과\").grid(row=4)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2865d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
