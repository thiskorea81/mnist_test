{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************처음에 한 번만 실행해야 함.********************************#\n",
    "# 이미지를 하나씩 잘라서 폴더(img)에 저장                                 #\n",
    "# 형식: %s/oxt_000  : 0폴더, 1폴더, 2폴더 데이터를 각 폴더에 저장         #\n",
    "# 데이터 뻥튀기(좌우대칭, 상하대칭, 좌우상하대칭, +-5도, +-3도 회전) 8배   #\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from dataset.oxt import load_oxt\n",
    "\n",
    "# 디렉토리가 없으면 생성하는 함수\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "# img 디렉토리 생성        \n",
    "createDirectory('./img')\n",
    "\n",
    "# img 내 0, 1, 2 디렉토리 생성\n",
    "for i in range(3):\n",
    "    dir='./img/%d'%(i)\n",
    "    createDirectory(dir)\n",
    "\n",
    "# 노멀라이즈되지 않은 이미지를 불러오기\n",
    "(x_train, t_train), (x_test, t_test)=load_oxt(normalize=False)\n",
    "\n",
    "train_size=len(x_train)\n",
    "test_size=len(x_test)\n",
    "total=train_size+test_size\n",
    "\n",
    "# 원본 트레인, 테스트 사이즈 출력\n",
    "print(train_size, test_size, total)\n",
    "\n",
    "for i in range(train_size):\n",
    "    img = x_train[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_%04d.jpg\"%(t_train[i], i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "for i in range(test_size):\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_%04d.jpg\"%(t_test[i], train_size+i)\n",
    "    cv2.imwrite(fname, img)\n",
    "    \n",
    "\n",
    "# 좌우대칭    \n",
    "for i in range(train_size):\n",
    "    img = x_train[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.flip(img, 1)\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_flip_lr_%04d.jpg\"%(t_train[i], i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "for i in range(test_size):\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.flip(img, 1)\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_flip_lr_%04d.jpg\"%(t_test[i], train_size+i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "# 상하대칭    \n",
    "for i in range(train_size):\n",
    "    img = x_train[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.flip(img, 0)\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_flip_td_%04d.jpg\"%(t_train[i], i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "for i in range(test_size):\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.flip(img, 0)\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_flip_td_%04d.jpg\"%(t_test[i], train_size+i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "# 좌우상하대칭    \n",
    "for i in range(train_size):\n",
    "    img = x_train[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.flip(img, -1)\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_flip_ld_%04d.jpg\"%(t_train[i], i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "for i in range(test_size):\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.flip(img, -1)\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_flip_ld_%04d.jpg\"%(t_test[i], train_size+i)\n",
    "    cv2.imwrite(fname, img)\n",
    "    \n",
    "# 회전(5도)\n",
    "rot_l = cv2.getRotationMatrix2D((14,14), 5, 1)\n",
    "rot_r = cv2.getRotationMatrix2D((14,14), -5, 1)\n",
    "\n",
    "for i in range(train_size):\n",
    "    img = x_train[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.warpAffine(img, rot_l, (0,0))\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_rot_l5_%04d.jpg\"%(t_train[i], i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "for i in range(test_size):\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.warpAffine(img, rot_l, (0,0))\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_rot_l5_%04d.jpg\"%(t_test[i], train_size+i)\n",
    "    cv2.imwrite(fname, img)\n",
    "    \n",
    "\n",
    "# 회전(-5도)\n",
    "for i in range(train_size):\n",
    "    img = x_train[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.warpAffine(img, rot_r, (0,0))\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_rot_r5_%04d.jpg\"%(t_train[i], i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "for i in range(test_size):\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.warpAffine(img, rot_r, (0,0))\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_rot_r5_%04d.jpg\"%(t_test[i], train_size+i)\n",
    "    cv2.imwrite(fname, img)\n",
    "    \n",
    "# 회전(3도)\n",
    "rot_l = cv2.getRotationMatrix2D((14,14), 3, 1)\n",
    "rot_r = cv2.getRotationMatrix2D((14,14), -3, 1)\n",
    "\n",
    "for i in range(train_size):\n",
    "    img = x_train[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.warpAffine(img, rot_l, (0,0))\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_rot_l3_%04d.jpg\"%(t_train[i], i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "for i in range(test_size):\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.warpAffine(img, rot_l, (0,0))\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_rot_l3_%04d.jpg\"%(t_test[i], train_size+i)\n",
    "    cv2.imwrite(fname, img)\n",
    "    \n",
    "\n",
    "# 회전(-3도)\n",
    "for i in range(train_size):\n",
    "    img = x_train[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.warpAffine(img, rot_r, (0,0))\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_rot_r3_%04d.jpg\"%(t_train[i], i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "for i in range(test_size):\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "    img = cv2.warpAffine(img, rot_r, (0,0))\n",
    "    img = ~img\n",
    "    fname=\"img/%s/oxt_rot_r3_%04d.jpg\"%(t_test[i], train_size+i)\n",
    "    cv2.imwrite(fname, img)\n",
    "\n",
    "\n",
    "# 각 폴더에 이미지 불러오기    \n",
    "img_0=glob.glob('./img/0/*.jpg')\n",
    "img_1=glob.glob('./img/1/*.jpg')\n",
    "img_2=glob.glob('./img/2/*.jpg')\n",
    "\n",
    "# 뻥튀기 된 이미지 갯수 세기\n",
    "total_img = len(img_0)+len(img_1)+len(img_2)\n",
    "print(\"total: \", total_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44160, 784)\n",
      "(44160, 3)\n",
      "(11040, 784)\n",
      "(11040, 3)\n",
      "train acc, test acc | 0.3333333333333333, 0.3333333333333333\n",
      "train acc, test acc | 0.546286231884058, 0.5557065217391305\n",
      "train acc, test acc | 0.5740036231884058, 0.5794384057971015\n",
      "train acc, test acc | 0.5965579710144927, 0.5940217391304348\n",
      "train acc, test acc | 0.6609148550724637, 0.6570652173913043\n",
      "train acc, test acc | 0.6698596014492754, 0.6647644927536231\n",
      "train acc, test acc | 0.6754302536231884, 0.6681159420289855\n",
      "train acc, test acc | 0.6826539855072464, 0.6747282608695652\n",
      "train acc, test acc | 0.6916893115942029, 0.6814311594202899\n",
      "train acc, test acc | 0.6997282608695652, 0.688768115942029\n",
      "train acc, test acc | 0.7081748188405798, 0.6983695652173914\n",
      "train acc, test acc | 0.7196784420289855, 0.7114130434782608\n",
      "train acc, test acc | 0.7292346014492753, 0.7207427536231884\n",
      "train acc, test acc | 0.7445652173913043, 0.7358695652173913\n",
      "train acc, test acc | 0.7626132246376811, 0.7526268115942029\n",
      "train acc, test acc | 0.7749320652173913, 0.7669384057971015\n",
      "train acc, test acc | 0.7951539855072464, 0.7855072463768116\n",
      "train acc, test acc | 0.8110054347826087, 0.8028985507246377\n",
      "train acc, test acc | 0.8291213768115943, 0.8181159420289855\n",
      "train acc, test acc | 0.841893115942029, 0.8319746376811594\n",
      "train acc, test acc | 0.8535326086956522, 0.8429347826086957\n",
      "train acc, test acc | 0.863971920289855, 0.8534420289855073\n",
      "train acc, test acc | 0.8722373188405798, 0.8615036231884058\n",
      "train acc, test acc | 0.8781702898550725, 0.8696557971014492\n",
      "train acc, test acc | 0.8867753623188406, 0.8772644927536232\n",
      "train acc, test acc | 0.8934103260869565, 0.8870471014492753\n",
      "train acc, test acc | 0.8984375, 0.8906702898550725\n",
      "train acc, test acc | 0.9040534420289855, 0.8965579710144927\n",
      "train acc, test acc | 0.906544384057971, 0.8995471014492754\n",
      "train acc, test acc | 0.9114809782608696, 0.9031702898550724\n",
      "train acc, test acc | 0.9156702898550725, 0.9066123188405797\n",
      "train acc, test acc | 0.91875, 0.9107789855072463\n",
      "train acc, test acc | 0.9215579710144928, 0.912409420289855\n",
      "train acc, test acc | 0.9234827898550725, 0.9156702898550725\n",
      "train acc, test acc | 0.9272871376811594, 0.9194746376811594\n",
      "train acc, test acc | 0.9289628623188406, 0.9211050724637682\n",
      "train acc, test acc | 0.9307065217391305, 0.922463768115942\n",
      "train acc, test acc | 0.9321557971014492, 0.9241847826086956\n",
      "train acc, test acc | 0.9340353260869565, 0.9266304347826086\n",
      "train acc, test acc | 0.9364809782608695, 0.9273550724637681\n",
      "train acc, test acc | 0.9389492753623189, 0.9289855072463769\n",
      "train acc, test acc | 0.9401041666666666, 0.9320652173913043\n",
      "train acc, test acc | 0.941802536231884, 0.9340579710144927\n",
      "train acc, test acc | 0.9433650362318841, 0.9359601449275362\n",
      "train acc, test acc | 0.9449048913043478, 0.9346920289855073\n",
      "train acc, test acc | 0.9457880434782608, 0.936141304347826\n",
      "train acc, test acc | 0.9476222826086956, 0.9384057971014492\n",
      "train acc, test acc | 0.9488677536231884, 0.9400362318840579\n",
      "train acc, test acc | 0.9498188405797101, 0.9413949275362319\n",
      "train acc, test acc | 0.9511548913043478, 0.9423007246376811\n",
      "train acc, test acc | 0.9529891304347826, 0.9434782608695652\n",
      "train acc, test acc | 0.9545969202898551, 0.9447463768115942\n",
      "train acc, test acc | 0.9553442028985507, 0.9454710144927536\n",
      "train acc, test acc | 0.957518115942029, 0.947463768115942\n",
      "train acc, test acc | 0.9585597826086957, 0.9481884057971014\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAswElEQVR4nO3deXgV5d3/8fc3+0p2toRNZFMQEEQUVBBRcMfdSp/WtuLzs1q70dLWrda2Vp/a7VEfca9a9w0VFUUQrWKJCLJDZE0CJJCF7MlJ7t8fc8AQAkTIyUlyPq/rOlfOLGfmOyHM58w9M/eYcw4REQldYcEuQEREgktBICIS4hQEIiIhTkEgIhLiFAQiIiFOQSAiEuICFgRm9piZFZjZyoNMNzP7u5nlmNmXZnZioGoREZGDC+QRwRPAlENMnwoM8L9mAA8GsBYRETmIgAWBc24RUHSIWS4C/uk8i4FkM+sRqHpERKR5EUFcdyawrdFwrn/c9qYzmtkMvKMG4uPjRw0ePLhNChQR6Sw+//zzXc65jOamBTMIWsw5NxuYDTB69GiXnZ0d5IpERDoWM9tysGnBvGooD+jVaDjLP05ERNpQMINgDvBf/quHxgKlzrkDmoVERCSwAtY0ZGbPAhOAdDPLBW4HIgGcc/8HzAXOBXKASuDaQNUiIiIHF7AgcM5dfZjpDvhhoNYvIiItozuLRURCnIJARCTEdYjLR0VEQkF1XT27K2opq66jqrbee9V5r8raek7sncKxXRNafb0KAhGRo+Sco6zGR2llHaVVdeypqmNPdR17qnzez2of1XX11PoaqPHVU+NroNbXQFWtt+Mvqqhld3kNFbX1h1zP7y46XkEgItIaGhoclXX1VNb4qKitp6LGR2VtPRW1Pmr838Cr67wddbWvnsqaesprfJTX+Kjw/yyr9rGnqo6SKm/nX99w8Oe/m0F0RBjREeFERYQRFR5GdEQYMZHhpMZH0SctjtT4KNITokmNj6JLTCRxERAfUU9cWD2x4T6iYxNJTU0NyO9DQSAiHYavvmHfTri0qo6yah9l1d7P8hrvW3eNr4Fq/468xldPWbXP21lX1lJSVUdJpfdt3R18v32AMIP46AgSoyOI978SoiPITIklOTaS5NgIUmIjSIqPoUtsJN1rNtHFakiwKuKthpiGSsLS+kPvk6GhHj66D+proK4Kqoqhcjdkng8nfhvKdsJ9Q8A1OTqYdDuc9tPW/YX6KQhEpE346hsoqqilrMZH1d5v4XVeO3h5jffteo//2/Xe1x7/jn5PlffzcE0ne0WE2b5v3AkxEd7OOi6KvunxJMdGkhQTTmpEDclhlSRZJQmuguiYWHyZJxEbGU7XtU8TXZlPpK+CCF8FYb4qrPswOOMX3gqevABK86C0EmorobYchl4CZzziTf/9SKir3L+oUd/1ggCDBXd5PyNjITYV4lLBV+3NF5sC438M4dEQ4X+FR0HW6Fb4VzjI7ytgSxaRTs85R3mNj8KyGu9V7v0s2Dvc6H1RRQ2HaD0BvCaULjGRJMVGkhpj9Iiq5IQulWSkVpISXktB9zNIjIngmPKlpPl2EBWbSFRcErEJiUQnJBPZ8wRiIsKI2PQB7MqBmjLv23ZFIcQkwfn3eSuaPRHyl+6/8qwxcMp73vtXn4JdGyA6EaITIDIeErp+PW9KX4hLh6h4iEqAqDjofsLX0y991Nt5R8X7Px/n7eABwsLg1l0QFuFtcFMRUTDptm/073C0FAQiIc5X38Aef1NLaVUdJZW17Kn2UV7to7xmb/PL180xpVW1FFd6TSylVbXU1R+4d48IM9ITounaJZrM5BhG9EoiIzGGjIQousRGkuLbRVrFBhJrdhBftYOYqh1E1RYT/q3nCIuIhHd+BYsf2H+hYRFwzS5v5/nSXbDypf2nx3eFmRu890sehXVzvfdRiRCfDt2O/3reMTOgqsgLh+gu3s+Ebl9Pv34RhEce/Jd24T8O/UsdfO6hpx9q2UGgIBDphJxz7CqvZfPuCjbt8l6FZTX7ml72+E90llbVUV7jO+SyzCDB3z6eFBdFcmwkI9PrGUge3cNKSLMykiJ8JEY2UDfiv0jt1puknZ8R9uWzUFUC1aWwsxS2lML33oakTPjwGVjwe28FYRGQ2APi0sBXBRGRcMxE7xt0bIrXbBKb+vU3avC+2U+6zWuSqa3wfjY0fD39wn+A3e99W4+IOnCjRhyy44N2t6MONAWBSAfiq2+gsLyGHaXV7NxTze6KWkoq6yiu2PstvZaCsho276qgrNEOPiLMyEiMJik2ki6xkfTtEsYxKaWkRVaRGl5DcngNSWFVVGeNJ6prf9IrvqLryoeJrCslvHYPVlUK1SUw7THoPRZWvAQv/+jAAk++COKjoCwfNi6EmGTv23ZSlveN3MK9+U64AvqdDkm9ILE7hIXvv5yBZ3uvg4lJ8l4HE5/e0l+poCAQaTecc5RU1pFXUuW9iqvIL6kiv7SK/JJqdpRWU1BW3Ww7e2xkOClx3gnR9MRoxmZGcIbvE3q5fDJqthFbthkrL4Az7oKR10Du5/DIdw9cUP9HoM9JsHUD5H7s7chjk7028dhk7xs2eDvx77zpNafEp3snPcOjvfZvgOFXeq+DSenrvaRdUBCItDHnHDv2VLN+ZzkbdpbxVWE5OQXlbCgop6Sybr95YyLD6JkcS68uEYzoF07XLukkpXene2IUA3e9T1JdAXGVeUTs2QbFW2DkdBj3I+8SxD+fA2GRkHoMpPWHPuO89+ANX/6E1z4e3eXrk6Jx/m/SvU+Gn64++EYkdN3/5Kl0aAoCkQCq9TWwtaiCVfl7/K9SVufvobjRDj85LpIBXRM49/iuDEoNo1tGBplJsQz4/A6ii9Ziu9ZD3m5v5pHT4eT7wTm482bvWvOYZEjuDRkDvfZ38HbSP1rmjW/a7ALet/vjpwV686WDUBCIHAXnHHklVSzbVsKq/D3sLK3ed7lkQVn1fjv8qPAwhnSL4ezjunNczy6ML3+HnpXriKnIxYo3w+ot0HccTHzV+8C7q8DCYPB5kNTb23l3Pc6bZgY3LIbEbs23lZtBar+Ab790DgoCkW+gtLKOVfmlLMst4YutJSzbVkJhWQ0AkeFGj4QIUrvE0yctjqvTNjDQt54eroCuvjziyrdiYV3gsv94C3viTdi+3GsrzxgMA6dAj+Ffr+wH7x26mIyBgdlICTkKApGDKKms5YutJazKL2Vl3h5WbS9lW1HVvumD0yL4Ts8dnBqVw7HVq0gsXonVVsANud438lcfgeXPete3px7jXRKZMejrFVzzIkTENH9TkUgbUhCI+JVV17FkcxGf5Ozm0427Wb19D85BNLWcnFLGt1L2MKzHbhg5neP79SJl8d3w0Z+9D6cPhP6TvOaYBp93HfqUP8L5f4XImOZXGBnbZtsmcigKAglp24oqeWvFdt5dtYMvc0upb3BERYRxYu9k/jE8l8lb/0JU5Q6sysHeg4EJUyG+P5xwJfQ6GbJO8m56aqrxDVAi7ZiCQELO1t3ezn/uiu2syCsF4ISsJH55SjxTfAvoPvQMogacAkXdYP5irzkn9ZivX3t38BmD9m/qEemgFATSqTnn2FpUyedbisneUkz25iLW7ywHYHivZP44MYEpUV+SsvU9+HwR4CA5CgZM9Hb6lz8e3A0QaQMKAul0CstqeH/NThauK+DzLSXsKveu6kmMjmB070SuGxzNKWNPJSslDv4xCnbnQNqxMGEWDL8aUvoEeQtE2paCQDqFbUWVvLtqB/NW7WTJliKcg8zkWE4fkM7JWdGMt+X03D4f2/AuFAJnb/Q+eMHfvb5u0voHtX6RYFIQSIdVVl3Ha8vyeWHJtn1t/YO7J3LzpAGcc3x3BndPxJb+E97+hffQj9hUGHw+DJoK+Dvs6TsueBsg0k4oCKTDWZFbyr/+s4XXl+VTWVvPkB5d+PW5gzkvq5rMHQtg7R9hwK1gp3o9Xo76rhcAvU+BcP3JizSl/xXSIdT46nl9WT5PfbqFFXmlxESGceHwnkwfmcqwLU9iK9+CD/ydpHU93uujHrzH+wXwEX8inYGCQNq1oopanlm8hSc/3cKu8hoGdUvkdxcM4uJjGkjsMRB8NfDKk94NXef80Wv2UR87It+IgkDapY2F5Tz68SZeXppLdV0DEwZl8MNR8YwuegP77J+wJMLrXTMiGm5e5j0bVkSOiIJA2pU12/fwvx/kMHfldiLDwpg2MpMbhlTSZ/UD8NobXvcN/SfB6O+x74SvQkDkqCgIpF1YlV/K3+dv4N1VO0mIjuDm03oyfUwW6ekZsHYufPUBnPzfcNL3v364ioi0CgWBBNXKvFL++v4G3l+zk8SYCH4+IZMfRLxDTPYDEDMDzrwFBp4DP10LUXHBLlekU1IQSFDU+Or5y3sbeGjRV3SJiWTmpGP4XvwiYv99I1QUwKBzYcA53sxh4QoBkQBSEEibW7+zjJufW8aa7Xu4ekwvfn3uEBLf+zn8+wnvubpXPQO9xgS7TJGQoSCQNtPQ4Hjik83c/c5aEqMjeHEqnDQ8GWIiYewN3k1fx56lB7WItDEFgbSJ7aVVzHzxSz7O2cWlx4bx+4R/EbPgFdjzXbjgb+rSWSSIAhoEZjYF+BsQDjzinLu7yfTewJNAsn+eWc65uYGsSdqWr76BJz7ZzF/eW0+4q+O1E5YwfNMj2HYfnP4LGP/jYJcoEvICFgRmFg7cD0wGcoElZjbHObe60Wy3AC845x40s+OAuUDfQNUkbevzLUX85tWVrN1RxsRBGfw1402Ssv/mNQGd83vvoe0iEnSBPCIYA+Q45zYCmNlzwEVA4yBwQBf/+yQgP4D1SBsprqjl7rfX8nz2Nvp3aeDJi7tz+smjscr+MPgMOHZSsEsUkUYCGQSZwLZGw7nAyU3muQOYZ2Y3AfHAWc0tyMxmADMAevfu3eqFSuuZv2YnP39xOWXVPv44vJArt99D2PJ0OPlDiE9TCIi0Q2FBXv/VwBPOuSzgXOApMzugJufcbOfcaOfc6IyMjDYvUg6vvsHxP++u4/tPZtM/yZE94i2uXnczYZFxcN59uhJIpB0L5BFBHtCr0XCWf1xj3wemADjnPjWzGCAdKAhgXdLKiipqufm5L/howy5uGOaYWfAzbHUunHoTTPwNRMYGu0QROYRABsESYICZ9cMLgKuAbzWZZyswCXjCzIYAMXgPEpQO4svcEv7f00spLKvh7kuGcdWJ3eDl5+HSR6F305ZAEWmPAhYEzjmfmd0IvIt3aehjzrlVZnYnkO2cmwP8DHjYzH6Cd+L4u845F6iapPXU1Tfwr8+28vu31jA8vpi3Br5J8rAHvG6hr3wq2OWJyDcQ0PsI/PcEzG0y7rZG71cDemhsB1JVW8/zS7by8EebyCupZFbP5Vxf/gCWHw6Fa6H32GCXKCLfkO4slhbZU13HU59u4bGPN7G7opYpWXW8kvE83bbN9Z4FfMlsSNYVXSIdkYJADqmhwfHYvzfxt/c3UFbj44yBGfxw4rGMWfJjWDcfJt4Cp/3U6yFURDokBYEcVG5xJT9/cTmLNxYxeVAKv+35GT1HDYL0VEi5C87+PST3OvyCRKRdUxDIAZxzvPpFHre/vgoHPHVaMeO/ugX7dCNE18CEWWoGEulEFASyn+KKWm55bSVvrdjOpN7G35NfIH7Jq5A+CK55yesmWkQ6FQWBAN5RwBtfbueuN1dTXFnLL6cM5vqaxwn77E2Y8GsY/xOIiAp2mSISAAoCYc32PdwxZxWfbSpiQrdqfnNhFgOG9YfqX8DIa6DrkGCXKCIBpCAIYaVVdfzlvfX889PNpMbAK8OXMHLTw9jiQTB0PsR08V4i0qkpCEJQSWUtr32Rxz8+yKG4spY7huRxTfGDhK/bCAOnwNR71EmcSAhREISIuvoGFq4r5JWlucxfU0BtfQMn9U3hzycU03veTEgbANe8DAN0Mlgk1CgIOrkNO8t45rOtzFmeT1FFLWlxkcwcVsnZfaD32FOwhnqIroLhV+tksEiIUhB0Qs45Ps7ZxSMfbeLD9YVEhYdx1YAGvpPwH47Z/ha2dgMU9Iexl0B4BIz6TrBLFpEgUhB0ItV19cxZls+jH29i3c4yMhKj+dnkgfyg/nliP7nXm6nPeO85AcddpPMAIgIoCDq8uvoGPvlqN++s3M67q3ZSVFHLkG7xPDtuByeeehbRaX1gy5kQGwfDLleXECJyAAVBB1Tjq+fjDbt4e+UO3lu9k9KqOuKjwjlzUDo/7LGWQWvvwj5fDXE/h0m3Qp9TvZeISDMUBB1EaWUdC9YV8N7qnSxcV0BFbT2JMRFMHtKNqcN6MKHibSKX3AkbVkHasXDJwzD00mCXLSIdgIKgHdu5p5p3Vu5g3uodfLaxCF+DIyMxmgtHZHLO4BTGha0ictBwr63/9SVeV9DTZnsBEK5/WhFpGe0t2pmSylreXrmDOcvyWbxpN85B/4x4rjv9GM45No4TapcRlvMwvDEHqophxkLoORLOu897TKSIyDekIGgHiipqWbS+kDe/zOfD9YXU1TuOSY/nRxP7c+HQdPr3TIctn8KT46DBB9FdYMBk79r/bsO8hSgEROQIKQiCwFffwBfbSli0vpBF6wv5Mq8U56B7YjQ/OTGci5Jy6Fm8BFv2EURfDz1/Ad2HeZd9HjsZeo2B8Mhgb4aIdBIKgjZQWlXH8m0lLPO/lmwuoqzaR5jBqVkx/OSsgZw+IJ3hc87GVqz3PpTYw+v7v+dIbzg6Ac66I2jbICKdl4IgAKrr6vlwfSHzVu3ki23FbCysACDaahmXWslvsrYzLmINPUuyCY9Ihkkfeh8cdgXEpUK/MyCtv274EpE2oSBoJXtv7JqzLJ/5q/IYWLuaM6PXMi1hD8sm38XIPqmc9MUsola9CBVATJJ3l+8xE8A5b6d/xsxgb4aIhCAFQSu4f0EOj368iT6Vq7gueh6/i/iSOCvDWRgWnsX4cd29fv0jvgsDJ0PGIK/NPyw82KWLiCgIjtbmXRXc++46xh2bxsxeqQxfvg4beCEMnIL1nwjRiV/P3Hd88AoVETkIBcFRWvjB2zwQOZsxUx8kvftomDwdwsKCXZaISIspCI5Cja+e1DVPcWbEcmLSMnQ3r4h0SPrqehTmL13L2Q3/pqj/ND3bV0Q6LAXBUdj10ePEWB3dz7wh2KWIiBwxBcERytm5h/Glb7C9y3DCep4Q7HJERI6YGrWP0Iuf5dDFjWX6hIuCXYqIyFFREByB6rp6nl+2i3GDbybpxBODXY6IyFFR09AR+CD7S0ZVL+aakzKDXYqIyFFTEByB8o8f5uGo+zglvTLYpYiIHLWABoGZTTGzdWaWY2azDjLPFWa22sxWmdm/AllPa1ifX8QZ5W+Rm3oKltov2OWIiBy1gJ0jMLNw4H5gMpALLDGzOc651Y3mGQD8ChjnnCs2s66Bqqe1fPHev7jSSig7Q5eMikjnEMgjgjFAjnNuo3OuFngOaHqJzXXA/c65YgDnXEEA6zlqVbX19Nn0HEUR3Ugcdm6wyxERaRWBDIJMYFuj4Vz/uMYGAgPN7N9mttjMpjS3IDObYWbZZpZdWFgYoHIP75XFa8ls2EH50OnqOVREOo1gXz4aAQwAJgBZwCIzG+acK2k8k3NuNjAbYPTo0a6NawTg6QXLuHVeHmP6PMFz5+qSURHpPFp0RGBmr5jZeWb2TY4g8oBejYaz/OMaywXmOOfqnHObgPV4wdBu1O9cw/r7pnDKgquYMiSNJ753ChYVF+yyRERaTUt37A8A3wI2mNndZjaoBZ9ZAgwws35mFgVcBcxpMs9reEcDmFk6XlPRxhbWFFgVu/DN+Sk8eCrdS5ezsfel/O/VI4mNUpOQiHQuLWoacs69D7xvZknA1f7324CHgaedc3XNfMZnZjcC7wLhwGPOuVVmdieQ7Zyb4592tpmtBuqBmc653a2yZUdjx0oaHp+K1ZTzdP1ZRJ35K66eqOYgEemczLmWNbmbWRowHfg2kA88A4wHhjnnJgSqwKZGjx7tsrOzA7qO3F2lfPx/N/LPmjP48VXnc/bx3QO6PhGRQDOzz51zo5ub1qIjAjN7FRgEPAVc4Jzb7p/0vJkFdq/clpY/x65upzL9qa8o8k3nnzNOZkSv5GBXJSISUC29aujvzrkFzU04WMJ0KM7Bh/fAwj+wMPoSdlZeydM/UAiISGho6cni48wsee+AmaWYWee4tbahAebOhIV/4IOYs7i1/FJm/9coRvVJCXZlIiJtoqVBcF3ja/v9dwJfF5CK2to7s2DJw7yVeBk/KL2Wv1w9itMGZAS7KhGRNtPSIAg3M9s74O9HKCowJbUtt/VTPo8/nR8WXsKfLh3OlKE9gl2SiEibauk5gnfwTgw/5B++3j+uw/td5kM89u+N3Hr+cVw+utfhPyAi0sm0NAh+ibfz/3/+4feARwJSURubu2I7U47vwffHq0tpEQlNLb2hrAF40P/qNOpyl/Hbqj+Q3+WXwS5FRCRoWtrX0AAze8n/AJmNe1+BLi7QSreu4JzwbLp3iQl2KSIiQdPSk8WP4x0N+ICJwD+BpwNVVFupKNgMQHIPNQuJSOhqaRDEOufm43VJscU5dwdwXuDKahu+4q0UuQR6ZqQGuxQRkaBp6cniGn8X1Bv8HcnlAQmBK6tt2J588l06A5Nig12KiEjQtPSI4GYgDvgRMAqv87nvBKqotlLSEMOmiGOIigjkg9pERNq3wx4R+G8eu9I593OgHLg24FW1kXvjZ1ITXc8FwS5ERCSIDvtV2DlXj9fddKeTV1JFZoqeNiYioa2l5wi+MLM5wItAxd6RzrlXAlJVG2goWMf95T9hefgsYGSwyxERCZqWBkEMsBs4s9E4B3TYICjJ38CwsE3kJeqIQERCW0vvLO405wX2KtuxiVQgsXvfYJciIhJULX1C2eN4RwD7cc59r9UraiM1RVuoc+F07d472KWIiARVS5uG3mz0PgaYhvfc4g7LleSxw6WSmdbhb4cQETkqLW0aernxsJk9C3wckIraSB4ZFIUN57KolmahiEjndKR7wQFA19YspK09GTOd3Wk1XBbsQkREgqyl5wjK2P8cwQ68ZxR0WHklVRyboWYhEZGWNg0lBrqQtuRK83iu9NssTP8FXo8ZIiKhq6XPI5hmZkmNhpPN7OKAVRVge3ZuIt1K6dKlS7BLEREJupb2tna7c65074BzrgS4PSAVtYGSHZsBiO/aN6h1iIi0By0Ngubm67CX21QVbgYgRQ+kERFpcRBkm9l9Ztbf/7oP+DyQhQVSffE29rhYenbrFuxSRESCrqVBcBNQCzwPPAdUAz8MVFGBlhPWjzlMICk2MtiliIgEXUuvGqoAZgW4ljbzRvhZbEs+lelmwS5FRCToWnrV0HtmltxoOMXM3g1YVQFWULyHzBQ9nlJEBFreNJTuv1IIAOdcMR31zuLaSl4ruYTLal8PdiUiIu1CS4Ogwcz2ddNpZn1ppjfSjqC8cDNhOKKTOmaOiYi0tpZeAvob4GMz+xAw4DRgRsCqCqCi/I0kADHpfYJdiohIu9DSk8XvmNlovJ3/F8BrQFUA6wqY8oLNACR31z0EIiLQ8pPFPwDmAz8Dfg48BdzRgs9NMbN1ZpZjZge96sjMLjUz5w+bgKor2kqDMzIyFQQiItDycwQ3AycBW5xzE/Ge9l5yqA+YWThwPzAVOA642syOa2a+RP/yP2t52UduTfhgHnIXkd5FPY+KiEDLg6DaOVcNYGbRzrm1wKDDfGYMkOOc2+icq8W7Ee2iZub7HfAnvJvUAu4jN4IXulxLWJjuIRARgZYHQa7/PoLXgPfM7HVgy2E+kwlsa7wM/7h9zOxEoJdz7q1DLcjMZphZtpllFxYWtrDk5lXv3kKfpPCjWoaISGfS0pPF0/xv7zCzBUAS8M7RrNjMwoD7gO+2YP2zgdkAo0ePPvLLVp3jgaLr+DT9MrwLn0RE5Bv3IOqc+7CFs+YBvRoNZ/nH7ZUIDAUWmtfVQ3dgjpld6JzL/qZ1tUR16U5iqMO6ZB5+ZhGRENHSpqEjsQQYYGb9zCwKuAqYs3eic67UOZfunOvrnOsLLAYCFgIAu/K+AiAqTfcQiIjsFbAgcM75gBuBd4E1wAvOuVVmdqeZXRio9R5K6Y5NACTogTQiIvsE9OEyzrm5wNwm4247yLwTAlkLQM0u7/x2WuYxgV6ViEiHEcimoXZnZeQw/ui7hq5dewS7FBGRdiOkguCLut68mXAZERG6fFREZK+QCoKogi8Z2qUy2GWIiLQrHfYB9Edi5u7byEk6FTg/2KWIiLQbIXNEUFdTRTrF1OseAhGR/YRMEBTmeZeORqT0OsycIiKhJWSCoGTHRgBiM/oGtxARkXYmZIKgYt8DafoGtQ4RkfYmZIJgZeRwbqq9ka5Zxwa7FBGRdiVkrhr6ztTxnHf6ScTExgS7FBGRdiVkjgjCwoyuiQoBEZGmQiYIRESkeQoCEZEQpyAQEQlxCgIRkRCnIBARCXEKAhGREKcgEBEJcQoCEZEQpyAQEQlxCgIRkRCnIBARCXEKAhGREKcgEBEJcQoCEZEQpyAQEQlxCgIRkRCnIBARCXEKAhGREKcgEBEJcQoCEZEQpyAQEQlxCgIRkRCnIBARCXEBDQIzm2Jm68wsx8xmNTP9p2a22sy+NLP5ZtYnkPWIiMiBAhYEZhYO3A9MBY4Drjaz45rM9gUw2jl3AvAScE+g6hERkeYF8ohgDJDjnNvonKsFngMuajyDc26Bc67SP7gYyApgPSIi0oxABkEmsK3RcK5/3MF8H3i7uQlmNsPMss0su7CwsBVLFBGRdnGy2MymA6OBe5ub7pyb7Zwb7ZwbnZGR0bbFiYh0chEBXHYe0KvRcJZ/3H7M7CzgN8AZzrmaANYjIiLNCOQRwRJggJn1M7Mo4CpgTuMZzGwk8BBwoXOuIIC1iIjIQQQsCJxzPuBG4F1gDfCCc26Vmd1pZhf6Z7sXSABeNLNlZjbnIIsTEZEACWTTEM65ucDcJuNua/T+rECuX0REDi+gQSAiciTq6urIzc2luro62KV0ODExMWRlZREZGdnizygIRKTdyc3NJTExkb59+2JmwS6nw3DOsXv3bnJzc+nXr1+LP9cuLh8VEWmsurqatLQ0hcA3ZGakpaV94yMpBYGItEsKgSNzJL83BYGISIhTEIiINFFSUsIDDzxwRJ8999xzKSkpad2CAkxBICLSxKGCwOfzHfKzc+fOJTk5OQBVBY6uGhKRdu23b6xidf6eVl3mcT27cPsFxx90+qxZs/jqq68YMWIEkydP5rzzzuPWW28lJSWFtWvXsn79ei6++GK2bdtGdXU1N998MzNmzACgb9++ZGdnU15eztSpUxk/fjyffPIJmZmZvP7668TGxu63rjfeeIO77rqL2tpa0tLSeOaZZ+jWrRvl5eXcdNNNZGdnY2bcfvvtXHrppbzzzjv8+te/pr6+nvT0dObPn3/Uvw8FgYhIE3fffTcrV65k2bJlACxcuJClS5eycuXKfZdlPvbYY6SmplJVVcVJJ53EpZdeSlpa2n7L2bBhA88++ywPP/wwV1xxBS+//DLTp0/fb57x48ezePFizIxHHnmEe+65hz//+c/87ne/IykpiRUrVgBQXFxMYWEh1113HYsWLaJfv34UFRW1yvYqCESkXTvUN/e2NGbMmP2uzf/73//Oq6++CsC2bdvYsGHDAUHQr18/RowYAcCoUaPYvHnzAcvNzc3lyiuvZPv27dTW1u5bx/vvv89zzz23b76UlBTeeOMNTj/99H3zpKamtsq26RyBiEgLxMfH73u/cOFC3n//fT799FOWL1/OyJEjm712Pzo6et/78PDwZs8v3HTTTdx4442sWLGChx56KCh3UysIRESaSExMpKys7KDTS0tLSUlJIS4ujrVr17J48eIjXldpaSmZmd4zu5588sl94ydPnsz999+/b7i4uJixY8eyaNEiNm3aBNBqTUMKAhGRJtLS0hg3bhxDhw5l5syZB0yfMmUKPp+PIUOGMGvWLMaOHXvE67rjjju4/PLLGTVqFOnp6fvG33LLLRQXFzN06FCGDx/OggULyMjIYPbs2VxyySUMHz6cK6+88ojX25g551plQW1l9OjRLjs7O9hliEgArVmzhiFDhgS7jA6rud+fmX3unBvd3Pw6IhARCXEKAhGREKcgEBEJcQoCEZEQpyAQEQlxCgIRkRCnIBARaeJouqEG+Otf/0plZWUrVhRYCgIRkSZCLQjU6ZyItH+Pn3fguOMvhjHXQW0lPHP5gdNHfAtGXgMVu+GF/9p/2rVvHXJ1Tbuhvvfee7n33nt54YUXqKmpYdq0afz2t7+loqKCK664gtzcXOrr67n11lvZuXMn+fn5TJw4kfT0dBYsWLDfsu+8807eeOMNqqqqOPXUU3nooYcwM3Jycvjv//5vCgsLCQ8P58UXX6R///786U9/4umnnyYsLIypU6dy9913f8Nf3uEpCEREmmjaDfW8efPYsGED//nPf3DOceGFF7Jo0SIKCwvp2bMnb73lBUtpaSlJSUncd999LFiwYL8uI/a68cYbue222wD49re/zZtvvskFF1zANddcw6xZs5g2bRrV1dU0NDTw9ttv8/rrr/PZZ58RFxfXan0LNaUgEJH271Df4KPiDj09Pu2wRwCHM2/ePObNm8fIkSMBKC8vZ8OGDZx22mn87Gc/45e//CXnn38+p5122mGXtWDBAu655x4qKyspKiri+OOPZ8KECeTl5TFt2jQAYmJiAK8r6muvvZa4uDig9bqdbkpBICJyGM45fvWrX3H99dcfMG3p0qXMnTuXW265hUmTJu37tt+c6upqbrjhBrKzs+nVqxd33HFHULqdbkoni0VEmmjaDfU555zDY489Rnl5OQB5eXkUFBSQn59PXFwc06dPZ+bMmSxdurTZz++1d6efnp5OeXk5L7300r75s7KyeO211wCoqamhsrKSyZMn8/jjj+878aymIRGRNtK4G+qpU6dy7733smbNGk455RQAEhISePrpp8nJyWHmzJmEhYURGRnJgw8+CMCMGTOYMmUKPXv23O9kcXJyMtdddx1Dhw6le/funHTSSfumPfXUU1x//fXcdtttREZG8uKLLzJlyhSWLVvG6NGjiYqK4txzz+UPf/hDq2+vuqEWkXZH3VAfHXVDLSIi34iCQEQkxCkIRKRd6mjN1u3FkfzeFAQi0u7ExMSwe/duhcE35Jxj9+7d++5DaCldNSQi7U5WVha5ubkUFhYGu5QOJyYmhqysrG/0GQWBiLQ7kZGR9OvXL9hlhIyANg2Z2RQzW2dmOWY2q5np0Wb2vH/6Z2bWN5D1iIjIgQIWBGYWDtwPTAWOA642s+OazPZ9oNg5dyzwF+BPgapHRESaF8gjgjFAjnNuo3OuFngOuKjJPBcBT/rfvwRMMjMLYE0iItJEIM8RZALbGg3nAicfbB7nnM/MSoE0YFfjmcxsBjDDP1huZuuOsKb0psvuhDr7Nmr7Or7Ovo3tdfv6HGxChzhZ7JybDcw+2uWYWfbBbrHuLDr7Nmr7Or7Ovo0dcfsC2TSUB/RqNJzlH9fsPGYWASQBuwNYk4iINBHIIFgCDDCzfmYWBVwFzGkyzxzgO/73lwEfON1BIiLSpgLWNORv878ReBcIBx5zzq0yszuBbOfcHOBR4CkzywGK8MIikI66eakD6OzbqO3r+Dr7Nna47etw3VCLiEjrUl9DIiIhTkEgIhLiQiYIDtfdRUdjZo+ZWYGZrWw0LtXM3jOzDf6fKcGs8WiYWS8zW2Bmq81slZnd7B/fmbYxxsz+Y2bL/dv4W//4fv4uV3L8XbBEBbvWo2Fm4Wb2hZm96R/ubNu32cxWmNkyM8v2j+tQf6chEQQt7O6io3kCmNJk3CxgvnNuADDfP9xR+YCfOeeOA8YCP/T/m3WmbawBznTODQdGAFPMbCxeVyt/8Xe9UozXFUtHdjOwptFwZ9s+gInOuRGN7h/oUH+nIREEtKy7iw7FObcI70qrxhp32fEkcHFb1tSanHPbnXNL/e/L8HYkmXSubXTOuXL/YKT/5YAz8bpcgQ6+jWaWBZwHPOIfNjrR9h1Ch/o7DZUgaK67i8wg1RJI3Zxz2/3vdwDdgllMa/H3SjsS+IxOto3+ZpNlQAHwHvAVUOKc8/ln6eh/q38FfgE0+IfT6FzbB154zzOzz/3d4UAH+zvtEF1MyDfnnHNm1uGvDTazBOBl4MfOuT2N+yTsDNvonKsHRphZMvAqMDi4FbUeMzsfKHDOfW5mE4JcTiCNd87lmVlX4D0zW9t4Ykf4Ow2VI4KWdHfRGew0sx4A/p8FQa7nqJhZJF4IPOOce8U/ulNt417OuRJgAXAKkOzvcgU69t/qOOBCM9uM1xx7JvA3Os/2AeCcy/P/LMAL8zF0sL/TUAmClnR30Rk07rLjO8DrQazlqPjbkh8F1jjn7ms0qTNtY4b/SAAziwUm450LWYDX5Qp04G10zv3KOZflnOuL93/uA+fcNXSS7QMws3gzS9z7HjgbWEkH+zsNmTuLzexcvPbKvd1d/D64FR0dM3sWmIDX5e1O4HbgNeAFoDewBbjCOdf0hHKHYGbjgY+AFXzdvvxrvPMEnWUbT8A7kRiO96XsBefcnWZ2DN436FTgC2C6c64meJUePX/T0M+dc+d3pu3zb8ur/sEI4F/Oud+bWRod6O80ZIJARESaFypNQyIichAKAhGREKcgEBEJcQoCEZEQpyAQEQlxCgKRADOzCXt73hRpjxQEIiIhTkEg4mdm0/3PB1hmZg/5O4QrN7O/+J8XMN/MMvzzjjCzxWb2pZm9ure/eTM71sze9z9jYKmZ9fcvPsHMXjKztWb2jP/Oaczsbv8zF740s/8J0qZLiFMQiABmNgS4EhjnnBsB1APXAPFAtnPueOBDvDu4Af4J/NI5dwLe3c97xz8D3O9/xsCpwN4eKEcCP8Z7HsYxwDj/3afTgOP9y7krkNsocjAKAhHPJGAUsMTfLfQkvB12A/C8f56ngfFmlgQkO+c+9I9/Ejjd3+dMpnPuVQDnXLVzrtI/z3+cc7nOuQZgGdAXKAWqgUfN7BJg77wibUpBIOIx4En/U6ZGOOcGOefuaGa+I+2TpXFfOvVAhL9P/jF4D2k5H3jnCJctclQUBCKe+cBl/j7l9z5ztg/e/5G9PWV+C/jYOVcKFJvZaf7x3wY+9D9JLdfMLvYvI9rM4g62Qv+zFpKcc3OBnwDDA7BdIoelB9OIAM651WZ2C96TpsKAOuCHQAUwxj+tAO88AnhdC/+ff0e/EbjWP/7bwENmdqd/GZcfYrWJwOtmFoN3RPLTVt4skRZR76Mih2Bm5c65hGDXIRJIahoSEQlxOiIQEQlxOiIQEQlxCgIRkRCnIBARCXEKAhGREKcgEBEJcf8f9HVKgGK6ChoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## common.two_layer_net 참조.\n",
    "## 투레이어넷 모델(chap03)\n",
    "\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.img_oxt import load_oxt\n",
    "from common.two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_oxt(one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=3, weight_init_std=0.01)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 240   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.08604408184391\n",
      "=== epoch:1, train acc:0.39121376811594205, test acc:0.39202898550724635 ===\n",
      "train loss:1.0975094915799863\n",
      "train loss:1.0931172648678484\n",
      "train loss:1.079741123158623\n",
      "train loss:1.087446816386158\n",
      "train loss:1.0766950903807502\n",
      "train loss:1.0814746345318815\n",
      "train loss:1.060058507410045\n",
      "train loss:1.0741507847136988\n",
      "train loss:1.077412281807042\n",
      "train loss:1.0500276777485533\n",
      "train loss:1.0506813029286843\n",
      "train loss:1.038116564683016\n",
      "train loss:1.0329280334488151\n",
      "train loss:1.045886888524662\n",
      "train loss:1.0390954320079824\n",
      "train loss:0.9794344492804666\n",
      "train loss:1.0511454074432878\n",
      "train loss:0.9916197073989896\n",
      "train loss:0.9673027840018238\n",
      "train loss:1.009763331297949\n",
      "train loss:0.9594871101824803\n",
      "train loss:0.9705181894424662\n",
      "train loss:0.945590856909402\n",
      "train loss:0.9218486941195894\n",
      "train loss:0.9755756563877315\n",
      "train loss:0.9313561527098344\n",
      "train loss:0.9082175414840089\n",
      "train loss:0.8545812988654783\n",
      "train loss:0.8584770140688607\n",
      "train loss:0.923945545997988\n",
      "train loss:0.8703690976726618\n",
      "train loss:0.8529686412700556\n",
      "train loss:0.7925962452884403\n",
      "train loss:0.8866377642081318\n",
      "train loss:0.8203299851641782\n",
      "train loss:0.7741153327010578\n",
      "train loss:0.7905780401216467\n",
      "train loss:0.7932578100456052\n",
      "train loss:0.7590223462286892\n",
      "train loss:0.7323411950811919\n",
      "train loss:0.794335996936441\n",
      "train loss:0.7027250888447711\n",
      "train loss:0.7816194021516668\n",
      "train loss:0.7763148756265416\n",
      "train loss:0.7137482096281772\n",
      "train loss:0.7634892510540198\n",
      "train loss:0.7509738590768291\n",
      "train loss:0.7771437843682537\n",
      "train loss:0.7679222264662994\n",
      "train loss:0.8054211428023523\n",
      "train loss:0.8050746860143179\n",
      "train loss:0.650496359203625\n",
      "train loss:0.7513327765765719\n",
      "train loss:0.6288935879016158\n",
      "train loss:0.7019381465129492\n",
      "train loss:0.7446985629669141\n",
      "train loss:0.6808706409374478\n",
      "train loss:0.7332968062160783\n",
      "train loss:0.6835758653481835\n",
      "train loss:0.6096358850999065\n",
      "train loss:0.6887676563747733\n",
      "train loss:0.5943426193535056\n",
      "train loss:0.6341360114264876\n",
      "train loss:0.5853916920147516\n",
      "train loss:0.5397840277540418\n",
      "train loss:0.580682296255038\n",
      "train loss:0.606319411866992\n",
      "train loss:0.6078148413912707\n",
      "train loss:0.7295857040577565\n",
      "train loss:0.5257590587660197\n",
      "train loss:0.5760254529922388\n",
      "train loss:0.6285385849414399\n",
      "train loss:0.5367752221631903\n",
      "train loss:0.5628395791312559\n",
      "train loss:0.5609260813351064\n",
      "train loss:0.5075861541470367\n",
      "train loss:0.6576834236524889\n",
      "train loss:0.5304285133096538\n",
      "train loss:0.46980199178350673\n",
      "train loss:0.5962787881464019\n",
      "train loss:0.5401189831941725\n",
      "train loss:0.5032952216270675\n",
      "train loss:0.5063982067853897\n",
      "train loss:0.5254591640761771\n",
      "train loss:0.44639566994004304\n",
      "train loss:0.5924222357161846\n",
      "train loss:0.5000904461071533\n",
      "train loss:0.47617917991597003\n",
      "train loss:0.5228289888201209\n",
      "train loss:0.4946141433257442\n",
      "train loss:0.559854743616322\n",
      "train loss:0.5456800738149333\n",
      "train loss:0.4136949663066446\n",
      "train loss:0.46600969435858974\n",
      "train loss:0.3752157552652716\n",
      "train loss:0.4536825838475474\n",
      "train loss:0.37139143537471825\n",
      "train loss:0.41280636585606406\n",
      "train loss:0.4226687359781542\n",
      "train loss:0.47034972567785155\n",
      "train loss:0.5327031709458553\n",
      "train loss:0.3803064093272311\n",
      "train loss:0.39943854817845914\n",
      "train loss:0.39883450652519575\n",
      "train loss:0.46046268048886946\n",
      "train loss:0.36768349060453454\n",
      "train loss:0.3442444681113797\n",
      "train loss:0.30700784025519906\n",
      "train loss:0.3535404849796866\n",
      "train loss:0.38355557389627204\n",
      "train loss:0.3963943597484019\n",
      "train loss:0.3954483975041022\n",
      "train loss:0.39596918471525\n",
      "train loss:0.31745438778282614\n",
      "train loss:0.41532473486631005\n",
      "train loss:0.38743779322131144\n",
      "train loss:0.2870946999523279\n",
      "train loss:0.4418190301943081\n",
      "train loss:0.39783320756761525\n",
      "train loss:0.37885466802633055\n",
      "train loss:0.3622531994182659\n",
      "train loss:0.3431022816038226\n",
      "train loss:0.3715007281164819\n",
      "train loss:0.3034371024550733\n",
      "train loss:0.2743977421322323\n",
      "train loss:0.35757043724191306\n",
      "train loss:0.25022347774891435\n",
      "train loss:0.31742112852486276\n",
      "train loss:0.27927083264646685\n",
      "train loss:0.2750475575861968\n",
      "train loss:0.33765688480486383\n",
      "train loss:0.2525039560848536\n",
      "train loss:0.27037810454255473\n",
      "train loss:0.3546864555879177\n",
      "train loss:0.22267927158051248\n",
      "train loss:0.3512153622733452\n",
      "train loss:0.3725910141695031\n",
      "train loss:0.23219724951817047\n",
      "train loss:0.3207590383601622\n",
      "train loss:0.2436607863316907\n",
      "train loss:0.33515275590313975\n",
      "train loss:0.27199016799321635\n",
      "train loss:0.31993831549306\n",
      "train loss:0.22592835136492845\n",
      "train loss:0.2814976085143611\n",
      "train loss:0.24154510483419145\n",
      "train loss:0.3157096469850451\n",
      "train loss:0.31204417608734997\n",
      "train loss:0.2182097482323154\n",
      "train loss:0.26613965959519137\n",
      "train loss:0.3046802760711388\n",
      "train loss:0.3204911200674129\n",
      "train loss:0.2854177825155757\n",
      "train loss:0.19447599970103535\n",
      "train loss:0.23999693817474502\n",
      "train loss:0.29631060667663206\n",
      "train loss:0.3340450553924603\n",
      "train loss:0.2781280735495986\n",
      "train loss:0.31810372698680517\n",
      "train loss:0.26363848469074563\n",
      "train loss:0.2826745721806281\n",
      "train loss:0.2052643663158634\n",
      "train loss:0.32445373209282063\n",
      "train loss:0.260220171296965\n",
      "train loss:0.2770155824187467\n",
      "train loss:0.2611568722536813\n",
      "train loss:0.25023996640060614\n",
      "train loss:0.17289016545316382\n",
      "train loss:0.20673091085399828\n",
      "train loss:0.21569317081901698\n",
      "train loss:0.15207953114255804\n",
      "train loss:0.28150971456389506\n",
      "train loss:0.19994769524683637\n",
      "train loss:0.20583445853719506\n",
      "train loss:0.17974197461358918\n",
      "train loss:0.23756732378589213\n",
      "train loss:0.19934136656659546\n",
      "train loss:0.2271732008974616\n",
      "train loss:0.1748713953956532\n",
      "train loss:0.2601419455082881\n",
      "train loss:0.11401732795443147\n",
      "train loss:0.245083836175517\n",
      "train loss:0.193063839216036\n",
      "train loss:0.15022329098451018\n",
      "train loss:0.17562403977009478\n",
      "train loss:0.1649629076672019\n",
      "train loss:0.20521113099562263\n",
      "train loss:0.16065608618861313\n",
      "train loss:0.20572882537992473\n",
      "train loss:0.2566753292946221\n",
      "train loss:0.3292637746834469\n",
      "train loss:0.19738461090453188\n",
      "train loss:0.15813334597914802\n",
      "train loss:0.32179305136337616\n",
      "train loss:0.19375758122111975\n",
      "train loss:0.2255424414534394\n",
      "train loss:0.16281975885214692\n",
      "train loss:0.23816365434405673\n",
      "train loss:0.1772535328431478\n",
      "train loss:0.19952762329696616\n",
      "train loss:0.18879609527871283\n",
      "train loss:0.2453315562021015\n",
      "train loss:0.17417843726616403\n",
      "train loss:0.2154531046477511\n",
      "train loss:0.16973621722020843\n",
      "train loss:0.1396818361084563\n",
      "train loss:0.19244502827275267\n",
      "train loss:0.1887001210205654\n",
      "train loss:0.28061963715121746\n",
      "train loss:0.2904471544603275\n",
      "train loss:0.21318110081106903\n",
      "train loss:0.2123768749111859\n",
      "train loss:0.18289392141965932\n",
      "train loss:0.23238831722618852\n",
      "train loss:0.14248294616167487\n",
      "train loss:0.26105934330792596\n",
      "train loss:0.1724474873300719\n",
      "train loss:0.14784767329098614\n",
      "train loss:0.2004282580822854\n",
      "train loss:0.11932191031460546\n",
      "train loss:0.1723548179312673\n",
      "train loss:0.19913100090719166\n",
      "train loss:0.25961253443013305\n",
      "train loss:0.12298171919593096\n",
      "train loss:0.24709590314142227\n",
      "train loss:0.13715092022307365\n",
      "train loss:0.2166301587210672\n",
      "train loss:0.284114617931568\n",
      "train loss:0.16600271648797824\n",
      "train loss:0.11847176444964291\n",
      "train loss:0.17091554584096566\n",
      "train loss:0.17756863152268262\n",
      "train loss:0.23487206154629453\n",
      "train loss:0.14868344889928486\n",
      "train loss:0.17886303388501304\n",
      "train loss:0.2185745461694359\n",
      "train loss:0.2810713344207657\n",
      "train loss:0.1290199019723495\n",
      "train loss:0.1883395182089415\n",
      "train loss:0.1787704855646153\n",
      "train loss:0.18710760341909918\n",
      "train loss:0.12384616131559939\n",
      "train loss:0.17697343123804446\n",
      "train loss:0.15516770120587778\n",
      "train loss:0.25720091897673725\n",
      "train loss:0.12318864414100283\n",
      "train loss:0.1703103530101797\n",
      "train loss:0.15759826673162786\n",
      "train loss:0.13134017799628198\n",
      "train loss:0.13288984959640757\n",
      "train loss:0.1230033288813204\n",
      "train loss:0.11131046967071452\n",
      "train loss:0.10511483648882194\n",
      "train loss:0.14369314924838925\n",
      "train loss:0.0994017886751075\n",
      "train loss:0.20675665766836945\n",
      "train loss:0.13643125831766312\n",
      "train loss:0.1272650825152146\n",
      "train loss:0.21897327970152916\n",
      "train loss:0.11285709354917924\n",
      "train loss:0.10619544245090197\n",
      "train loss:0.17987092287668313\n",
      "train loss:0.16192357803557608\n",
      "train loss:0.14070143640773564\n",
      "train loss:0.10919386332078299\n",
      "train loss:0.19978835141844975\n",
      "train loss:0.20362476052294157\n",
      "train loss:0.1333039290016696\n",
      "train loss:0.11453352580006225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.18621706547360722\n",
      "train loss:0.07877164353429776\n",
      "train loss:0.11420188178087519\n",
      "train loss:0.21296243018426472\n",
      "train loss:0.14439728508334107\n",
      "train loss:0.08824365044487\n",
      "train loss:0.2173892390981422\n",
      "train loss:0.1454934313614136\n",
      "train loss:0.10797405743378584\n",
      "train loss:0.10414883084398702\n",
      "train loss:0.11795174246188166\n",
      "train loss:0.14140906734869815\n",
      "train loss:0.08419468831411402\n",
      "train loss:0.2564691082249689\n",
      "train loss:0.10300753755255516\n",
      "train loss:0.16538443130001187\n",
      "train loss:0.15454894661842555\n",
      "train loss:0.14452581816705778\n",
      "train loss:0.14983263659140217\n",
      "train loss:0.22268418920592808\n",
      "train loss:0.1624519335834073\n",
      "train loss:0.14553169945161679\n",
      "train loss:0.1247658974303658\n",
      "train loss:0.07464402732886727\n",
      "train loss:0.08559176594835818\n",
      "train loss:0.20497408554388824\n",
      "train loss:0.1775767307527199\n",
      "train loss:0.07042995755384464\n",
      "train loss:0.18102175419398867\n",
      "train loss:0.14198151188139949\n",
      "train loss:0.07937575544814163\n",
      "train loss:0.0891530707800826\n",
      "train loss:0.121476650455691\n",
      "train loss:0.1138298932315954\n",
      "train loss:0.07227827777286437\n",
      "train loss:0.1303298550156541\n",
      "train loss:0.16776797394197462\n",
      "train loss:0.10377776707899873\n",
      "train loss:0.15738510106895234\n",
      "train loss:0.19136406879395806\n",
      "train loss:0.0551063338158057\n",
      "train loss:0.10526013529216956\n",
      "train loss:0.13428699446113418\n",
      "train loss:0.08668681350880673\n",
      "train loss:0.11508899192732411\n",
      "train loss:0.1516185250124096\n",
      "train loss:0.1208061979443925\n",
      "train loss:0.09903637861620404\n",
      "train loss:0.08488447763861569\n",
      "train loss:0.08851376826508292\n",
      "train loss:0.154897175179089\n",
      "train loss:0.04491259710229138\n",
      "train loss:0.2014181530454074\n",
      "train loss:0.0948105435973033\n",
      "train loss:0.10434705822420834\n",
      "train loss:0.16210430214391933\n",
      "train loss:0.10801582705123372\n",
      "train loss:0.09124545760010767\n",
      "train loss:0.11553530828555288\n",
      "train loss:0.13901697783398087\n",
      "train loss:0.1702136072060089\n",
      "train loss:0.08030326506301251\n",
      "train loss:0.06965623479435055\n",
      "train loss:0.10403800542565035\n",
      "train loss:0.1167981786785285\n",
      "train loss:0.18770405770212922\n",
      "train loss:0.1615252152472695\n",
      "train loss:0.1560689614859759\n",
      "train loss:0.17834206790337184\n",
      "train loss:0.19419736737594126\n",
      "train loss:0.07835329359421306\n",
      "train loss:0.10625197275202164\n",
      "train loss:0.1029561368051613\n",
      "train loss:0.16320843360912837\n",
      "train loss:0.060778839378494626\n",
      "train loss:0.09590777611805595\n",
      "train loss:0.1596594005499332\n",
      "train loss:0.21007861247664236\n",
      "train loss:0.11997183300391683\n",
      "train loss:0.15202105952735365\n",
      "train loss:0.1948305901316691\n",
      "train loss:0.07259654971923062\n",
      "train loss:0.10960732476239168\n",
      "train loss:0.09186687149204689\n",
      "train loss:0.08135412403356003\n",
      "train loss:0.11578299576736212\n",
      "train loss:0.1040304902590155\n",
      "train loss:0.17318212326944812\n",
      "train loss:0.10458816245677843\n",
      "train loss:0.10962943237815924\n",
      "train loss:0.15914102969547775\n",
      "train loss:0.12140840835599838\n",
      "train loss:0.15056115294194208\n",
      "train loss:0.10367861031933114\n",
      "train loss:0.09383942945607059\n",
      "train loss:0.09268707955869131\n",
      "train loss:0.13056021491184377\n",
      "train loss:0.12869115021946834\n",
      "train loss:0.08914830326568864\n",
      "=== epoch:2, train acc:0.9590126811594203, test acc:0.9520833333333333 ===\n",
      "train loss:0.1040889230128019\n",
      "train loss:0.10036254031296261\n",
      "train loss:0.10709181665051716\n",
      "train loss:0.12011750561858496\n",
      "train loss:0.09246706292266431\n",
      "train loss:0.16040180566977383\n",
      "train loss:0.1465937337104423\n",
      "train loss:0.1251064189247393\n",
      "train loss:0.0964940415270879\n",
      "train loss:0.08504587985308752\n",
      "train loss:0.08392311577887034\n",
      "train loss:0.05312560548732866\n",
      "train loss:0.16625009820706108\n",
      "train loss:0.13736080972353654\n",
      "train loss:0.11230445810679254\n",
      "train loss:0.07469352090358898\n",
      "train loss:0.07367985627427019\n",
      "train loss:0.18262855526957342\n",
      "train loss:0.14074730799641763\n",
      "train loss:0.10002680092895513\n",
      "train loss:0.236633721248967\n",
      "train loss:0.04155075332710032\n",
      "train loss:0.09366773296107263\n",
      "train loss:0.13408496676631554\n",
      "train loss:0.12456467005370452\n",
      "train loss:0.08762330990069528\n",
      "train loss:0.0964765705945491\n",
      "train loss:0.07318510225382777\n",
      "train loss:0.1688560287239143\n",
      "train loss:0.033684835674964386\n",
      "train loss:0.12328684440323466\n",
      "train loss:0.09570407711083621\n",
      "train loss:0.0668628638059344\n",
      "train loss:0.18765685673162377\n",
      "train loss:0.07012759644066656\n",
      "train loss:0.10293194696701093\n",
      "train loss:0.09254118710632073\n",
      "train loss:0.11878008247561424\n",
      "train loss:0.14396156755352033\n",
      "train loss:0.03798129969379071\n",
      "train loss:0.1499199814554069\n",
      "train loss:0.06581370453871381\n",
      "train loss:0.07855007852439816\n",
      "train loss:0.10006891107779256\n",
      "train loss:0.11785377454739722\n",
      "train loss:0.1858126351802938\n",
      "train loss:0.057086808384537044\n",
      "train loss:0.167311785703006\n",
      "train loss:0.0691537983914347\n",
      "train loss:0.05713158165584821\n",
      "train loss:0.10933967057890076\n",
      "train loss:0.03696969514147301\n",
      "train loss:0.11090482746759443\n",
      "train loss:0.06681315658798453\n",
      "train loss:0.10170099073434272\n",
      "train loss:0.09013649001106054\n",
      "train loss:0.2029048548004533\n",
      "train loss:0.04421346399060357\n",
      "train loss:0.10570562843070459\n",
      "train loss:0.0778391624159218\n",
      "train loss:0.09590593925207545\n",
      "train loss:0.11606206760147363\n",
      "train loss:0.05683874649110909\n",
      "train loss:0.12796377445114335\n",
      "train loss:0.1346519943600176\n",
      "train loss:0.1438792820341998\n",
      "train loss:0.11995331877016749\n",
      "train loss:0.10665110968719145\n",
      "train loss:0.0574717974996356\n",
      "train loss:0.13203394163748353\n",
      "train loss:0.1229727766773448\n",
      "train loss:0.1290688041076025\n",
      "train loss:0.11291049876768865\n",
      "train loss:0.0869983051250207\n",
      "train loss:0.09363627789991116\n",
      "train loss:0.1153974424761978\n",
      "train loss:0.12495773018339963\n",
      "train loss:0.1312166114756653\n",
      "train loss:0.09667434652332135\n",
      "train loss:0.08567350879310584\n",
      "train loss:0.08197525379687676\n",
      "train loss:0.07193922872406724\n",
      "train loss:0.05357864083090071\n",
      "train loss:0.09878442998831698\n",
      "train loss:0.1414318286609843\n",
      "train loss:0.06100074675121287\n",
      "train loss:0.04179497225057613\n",
      "train loss:0.08330668283058766\n",
      "train loss:0.08533516951880228\n",
      "train loss:0.04749877634458096\n",
      "train loss:0.058588350015420204\n",
      "train loss:0.06872823556892502\n",
      "train loss:0.11817153784509607\n",
      "train loss:0.12320357037460107\n",
      "train loss:0.07391202741254727\n",
      "train loss:0.07267904290555333\n",
      "train loss:0.05921962139196298\n",
      "train loss:0.06469467943273248\n",
      "train loss:0.13489995580210604\n",
      "train loss:0.10535337574630835\n",
      "train loss:0.10493439180760936\n",
      "train loss:0.19967417000453752\n",
      "train loss:0.08676434992378704\n",
      "train loss:0.16343510462879987\n",
      "train loss:0.09084214614284528\n",
      "train loss:0.1075911730761465\n",
      "train loss:0.10005731549266485\n",
      "train loss:0.18227624443000778\n",
      "train loss:0.06894388871959625\n",
      "train loss:0.10570667682658456\n",
      "train loss:0.07607189415402442\n",
      "train loss:0.11081690720999\n",
      "train loss:0.09481842518451475\n",
      "train loss:0.0777743062077662\n",
      "train loss:0.16802279252385302\n",
      "train loss:0.0710804453504094\n",
      "train loss:0.08836704639544818\n",
      "train loss:0.0647437410978132\n",
      "train loss:0.10993469872101064\n",
      "train loss:0.08358336280906903\n",
      "train loss:0.10228250843433788\n",
      "train loss:0.06386204920639324\n",
      "train loss:0.051684581351675946\n",
      "train loss:0.1354362926367568\n",
      "train loss:0.09273558037169846\n",
      "train loss:0.09235720478901571\n",
      "train loss:0.07080073547909087\n",
      "train loss:0.05451146428631374\n",
      "train loss:0.05727086435178221\n",
      "train loss:0.067343962849799\n",
      "train loss:0.07832755223411586\n",
      "train loss:0.04347029612226343\n",
      "train loss:0.17105663486176476\n",
      "train loss:0.14590213261640286\n",
      "train loss:0.14666517068163093\n",
      "train loss:0.04016865730720103\n",
      "train loss:0.11019293778938932\n",
      "train loss:0.1293055430887585\n",
      "train loss:0.10198973974976733\n",
      "train loss:0.043275437611090435\n",
      "train loss:0.12023125159813523\n",
      "train loss:0.07994927351672794\n",
      "train loss:0.0861200524550818\n",
      "train loss:0.08474440332362213\n",
      "train loss:0.11508537696176292\n",
      "train loss:0.09671037631023965\n",
      "train loss:0.06456355263969248\n",
      "train loss:0.12597303456009412\n",
      "train loss:0.1380531008358571\n",
      "train loss:0.1631091504807812\n",
      "train loss:0.08067058401619683\n",
      "train loss:0.12495716903769577\n",
      "train loss:0.06105444371420923\n",
      "train loss:0.09613222914885637\n",
      "train loss:0.06751086620587451\n",
      "train loss:0.07416167076146123\n",
      "train loss:0.06394586669793871\n",
      "train loss:0.08317426851656494\n",
      "train loss:0.17562774797244593\n",
      "train loss:0.05773826875589424\n",
      "train loss:0.13299634750147876\n",
      "train loss:0.1033766698838809\n",
      "train loss:0.05390742091333521\n",
      "train loss:0.06102692017706876\n",
      "train loss:0.07308208246147038\n",
      "train loss:0.06465353065489761\n",
      "train loss:0.05601090749084203\n",
      "train loss:0.06667427474954737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03624787645947771\n",
      "train loss:0.16443741795436947\n",
      "train loss:0.09031981587761848\n",
      "train loss:0.13899296856957133\n",
      "train loss:0.07860654250296435\n",
      "train loss:0.050358981400622525\n",
      "train loss:0.0309888049964518\n",
      "train loss:0.15222864184113066\n",
      "train loss:0.19966080851050727\n",
      "train loss:0.10422016690048899\n",
      "train loss:0.06374010496009726\n",
      "train loss:0.08888765113141464\n",
      "train loss:0.0480699195684392\n",
      "train loss:0.04375579772617563\n",
      "train loss:0.02259536940906143\n",
      "train loss:0.09916527872788096\n",
      "train loss:0.06460496037530322\n",
      "train loss:0.08961229083988004\n",
      "train loss:0.1149425106238128\n",
      "train loss:0.07460403176451749\n",
      "train loss:0.0659720396016538\n",
      "train loss:0.12195933892362373\n",
      "train loss:0.06364953067684206\n",
      "train loss:0.05628135279016886\n",
      "train loss:0.10004698582941332\n",
      "train loss:0.08043755841008059\n",
      "train loss:0.07903490756461912\n",
      "train loss:0.12327980478227422\n",
      "train loss:0.10240244970980351\n",
      "train loss:0.022464793529932938\n",
      "train loss:0.062043263672158844\n",
      "train loss:0.08507411081449619\n",
      "train loss:0.08813035128486804\n",
      "train loss:0.10814631595722594\n",
      "train loss:0.08170845297885905\n",
      "train loss:0.09519460932669135\n",
      "train loss:0.025802987181982533\n",
      "train loss:0.1273406291514449\n",
      "train loss:0.14347219620180537\n",
      "train loss:0.046786608505592665\n",
      "train loss:0.04573645923330534\n",
      "train loss:0.027254232153872845\n",
      "train loss:0.051105175040104436\n",
      "train loss:0.055235940495051865\n",
      "train loss:0.09853775110874832\n",
      "train loss:0.0950741244478461\n",
      "train loss:0.05926539280203872\n",
      "train loss:0.05841815431577049\n",
      "train loss:0.06534559496337558\n",
      "train loss:0.05683754839772202\n",
      "train loss:0.14513505203262428\n",
      "train loss:0.06904705179635283\n",
      "train loss:0.08440706192134989\n",
      "train loss:0.04827540443534455\n",
      "train loss:0.11536956103142507\n",
      "train loss:0.14458877812125798\n",
      "train loss:0.1689618821575737\n",
      "train loss:0.06263848443479594\n",
      "train loss:0.060204149389612306\n",
      "train loss:0.0975479381634243\n",
      "train loss:0.11160605311593234\n",
      "train loss:0.036111065574342814\n",
      "train loss:0.05981060632838396\n",
      "train loss:0.10284483410718952\n",
      "train loss:0.04973732847824996\n",
      "train loss:0.1040352518411982\n",
      "train loss:0.05674009204496763\n",
      "train loss:0.17284601178355943\n",
      "train loss:0.065896783149528\n",
      "train loss:0.05457999943875871\n",
      "train loss:0.1003052216287965\n",
      "train loss:0.05217018274347073\n",
      "train loss:0.06204681390127963\n",
      "train loss:0.07609612827825618\n",
      "train loss:0.05232396859957844\n",
      "train loss:0.11026058319689754\n",
      "train loss:0.02751113597229903\n",
      "train loss:0.06476538169757617\n",
      "train loss:0.05737696588778648\n",
      "train loss:0.13194079721250504\n",
      "train loss:0.07951158837505876\n",
      "train loss:0.09001375829756858\n",
      "train loss:0.1127837819133228\n",
      "train loss:0.11328942431696393\n",
      "train loss:0.06871217756222063\n",
      "train loss:0.02376870066545705\n",
      "train loss:0.01893011804858485\n",
      "train loss:0.09238958459144898\n",
      "train loss:0.10044331448012137\n",
      "train loss:0.08278273848832614\n",
      "train loss:0.10211573848020192\n",
      "train loss:0.11868261451886271\n",
      "train loss:0.03605826491949439\n",
      "train loss:0.0735040432957586\n",
      "train loss:0.05550059194108747\n",
      "train loss:0.08982024080256822\n",
      "train loss:0.142655318739033\n",
      "train loss:0.1102861763427758\n",
      "train loss:0.11813267165679081\n",
      "train loss:0.06555012176625089\n",
      "train loss:0.027051846133895812\n",
      "train loss:0.12431292806132624\n",
      "train loss:0.10939514066895571\n",
      "train loss:0.05234735061111727\n",
      "train loss:0.11495243373873434\n",
      "train loss:0.04229361008885164\n",
      "train loss:0.08325400499133352\n",
      "train loss:0.08480910382041373\n",
      "train loss:0.08582955982276395\n",
      "train loss:0.04268244071471031\n",
      "train loss:0.08706738807274957\n",
      "train loss:0.03567124930796986\n",
      "train loss:0.13567251670418182\n",
      "train loss:0.0603159989794448\n",
      "train loss:0.08621490111785997\n",
      "train loss:0.0321501500457679\n",
      "train loss:0.05757693653679576\n",
      "train loss:0.11447316771013462\n",
      "train loss:0.0716424169708432\n",
      "train loss:0.17499972156045937\n",
      "train loss:0.09749160691504999\n",
      "train loss:0.07508647859897413\n",
      "train loss:0.058634232985260416\n",
      "train loss:0.02683143536932361\n",
      "train loss:0.07203635472703292\n",
      "train loss:0.04545082745879731\n",
      "train loss:0.0673655880169853\n",
      "train loss:0.08397299910470624\n",
      "train loss:0.22410887712701036\n",
      "train loss:0.06893807807344261\n",
      "train loss:0.09874146489682946\n",
      "train loss:0.11250064652947604\n",
      "train loss:0.0978165228344398\n",
      "train loss:0.07011373053821639\n",
      "train loss:0.04869669946800101\n",
      "train loss:0.04468969385616896\n",
      "train loss:0.03764523559594902\n",
      "train loss:0.10357567645992241\n",
      "train loss:0.07000512917943154\n",
      "train loss:0.058362934739655446\n",
      "train loss:0.09659607027984819\n",
      "train loss:0.16887676542167832\n",
      "train loss:0.08482104112242535\n",
      "train loss:0.07442259588549736\n",
      "train loss:0.04396374590589035\n",
      "train loss:0.06624666910142266\n",
      "train loss:0.08745046913467158\n",
      "train loss:0.03796841408932001\n",
      "train loss:0.03386428206131786\n",
      "train loss:0.09886348438752487\n",
      "train loss:0.09577037328881348\n",
      "train loss:0.03111772085456995\n",
      "train loss:0.08768209559388877\n",
      "train loss:0.05620969818532396\n",
      "train loss:0.05816139845461851\n",
      "train loss:0.03825200475208497\n",
      "train loss:0.0883182883808297\n",
      "train loss:0.08921193995839737\n",
      "train loss:0.16425091578694312\n",
      "train loss:0.032544118661439705\n",
      "train loss:0.046072238539391255\n",
      "train loss:0.08788176866036125\n",
      "train loss:0.04141976587807069\n",
      "train loss:0.11689841307845664\n",
      "train loss:0.05651961532963415\n",
      "train loss:0.1374017207590825\n",
      "train loss:0.07556048449147733\n",
      "train loss:0.09214349733899921\n",
      "train loss:0.07528829428071313\n",
      "train loss:0.06480450812079214\n",
      "train loss:0.11803895692700855\n",
      "train loss:0.04559848622580256\n",
      "train loss:0.09130399809028472\n",
      "train loss:0.08724115669973857\n",
      "train loss:0.03887631907272265\n",
      "train loss:0.04713923845500761\n",
      "train loss:0.14863262302773392\n",
      "train loss:0.035153895841080786\n",
      "train loss:0.035380682766521995\n",
      "train loss:0.02422817880245737\n",
      "train loss:0.17151570851939937\n",
      "train loss:0.06437516231484941\n",
      "train loss:0.08311091308827054\n",
      "train loss:0.05388728557053015\n",
      "train loss:0.08773406644095533\n",
      "train loss:0.08716990046791466\n",
      "train loss:0.08411737054203566\n",
      "train loss:0.05185520229152989\n",
      "train loss:0.05574161481372499\n",
      "train loss:0.07519109466146104\n",
      "train loss:0.048617420213293586\n",
      "train loss:0.08547945427646289\n",
      "train loss:0.05336799272362831\n",
      "train loss:0.14902646751507534\n",
      "train loss:0.060309684383574674\n",
      "train loss:0.05878102567258092\n",
      "train loss:0.06117562688889103\n",
      "train loss:0.03538381727774725\n",
      "train loss:0.107254078826117\n",
      "train loss:0.08853623872392251\n",
      "=== epoch:3, train acc:0.9733016304347826, test acc:0.9651268115942029 ===\n",
      "train loss:0.10132210741149379\n",
      "train loss:0.04791377708638704\n",
      "train loss:0.09143783853296197\n",
      "train loss:0.060318578667541284\n",
      "train loss:0.1590392270565167\n",
      "train loss:0.04167909940376486\n",
      "train loss:0.10564637935285096\n",
      "train loss:0.05745741494926951\n",
      "train loss:0.07290744633047212\n",
      "train loss:0.06598630025240275\n",
      "train loss:0.06191710439674454\n",
      "train loss:0.07857858306647675\n",
      "train loss:0.04455606093184137\n",
      "train loss:0.08163422589349002\n",
      "train loss:0.06997683318721518\n",
      "train loss:0.03449365949444343\n",
      "train loss:0.0733906231765004\n",
      "train loss:0.0922601561184797\n",
      "train loss:0.04096834573508335\n",
      "train loss:0.04610592877027469\n",
      "train loss:0.024443653321609457\n",
      "train loss:0.05757631190221748\n",
      "train loss:0.07423259413953404\n",
      "train loss:0.07354710074180981\n",
      "train loss:0.09547510036017419\n",
      "train loss:0.11332176164516666\n",
      "train loss:0.09576305298637797\n",
      "train loss:0.07799901572915084\n",
      "train loss:0.02176652115773164\n",
      "train loss:0.056999313117720454\n",
      "train loss:0.012655723859508496\n",
      "train loss:0.06682263499905776\n",
      "train loss:0.027737660454072124\n",
      "train loss:0.016660928819082158\n",
      "train loss:0.01791123821464131\n",
      "train loss:0.07902385494200391\n",
      "train loss:0.029501754337082034\n",
      "train loss:0.05298983532307391\n",
      "train loss:0.03784654040674075\n",
      "train loss:0.045941309878477006\n",
      "train loss:0.01316411546050666\n",
      "train loss:0.09051930711763842\n",
      "train loss:0.03480576650206911\n",
      "train loss:0.019203437430037315\n",
      "train loss:0.1200586465452201\n",
      "train loss:0.12060882121666161\n",
      "train loss:0.07024621983525448\n",
      "train loss:0.05734308675027865\n",
      "train loss:0.08008836294259686\n",
      "train loss:0.08794450327935203\n",
      "train loss:0.047038351014488375\n",
      "train loss:0.024106326793564236\n",
      "train loss:0.07353767769511424\n",
      "train loss:0.04184110843274103\n",
      "train loss:0.03470372931776175\n",
      "train loss:0.035512258685163146\n",
      "train loss:0.04365358247042026\n",
      "train loss:0.06967825527695097\n",
      "train loss:0.10651884069990646\n",
      "train loss:0.06618593566687295\n",
      "train loss:0.059095160335677945\n",
      "train loss:0.04939342715259188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02897656902068023\n",
      "train loss:0.027135467560895868\n",
      "train loss:0.058974671358571124\n",
      "train loss:0.02748707161803173\n",
      "train loss:0.02320664533167131\n",
      "train loss:0.03276915933311359\n",
      "train loss:0.022985737880257616\n",
      "train loss:0.04645461874031563\n",
      "train loss:0.0471437402832155\n",
      "train loss:0.14517284933552818\n",
      "train loss:0.08826539999025422\n",
      "train loss:0.07931304359669764\n",
      "train loss:0.09462374899216965\n",
      "train loss:0.02371423931735298\n",
      "train loss:0.06245830185047545\n",
      "train loss:0.09318089622311462\n",
      "train loss:0.11635846173422036\n",
      "train loss:0.027056369244097808\n",
      "train loss:0.05287700075725997\n",
      "train loss:0.04047342298783229\n",
      "train loss:0.07687527166681779\n",
      "train loss:0.04995104091470233\n",
      "train loss:0.07123499068985385\n",
      "train loss:0.03294117505091427\n",
      "train loss:0.09801016298185111\n",
      "train loss:0.016878435314826676\n",
      "train loss:0.1499960468004483\n",
      "train loss:0.026663986429405994\n",
      "train loss:0.1576751335325662\n",
      "train loss:0.06507179443421195\n",
      "train loss:0.11888328428198026\n",
      "train loss:0.12323256805397023\n",
      "train loss:0.07071592887252319\n",
      "train loss:0.09130786311125517\n",
      "train loss:0.04196269272991242\n",
      "train loss:0.016967099990098537\n",
      "train loss:0.05517771113863897\n",
      "train loss:0.0479218920973629\n",
      "train loss:0.08423043541197285\n",
      "train loss:0.07579611778467292\n",
      "train loss:0.06664819582459888\n",
      "train loss:0.11045070320339234\n",
      "train loss:0.08678523782153243\n",
      "train loss:0.06684664990649458\n",
      "train loss:0.05174632424220936\n",
      "train loss:0.07653188783562784\n",
      "train loss:0.03393331927461217\n",
      "train loss:0.15096431572690727\n",
      "train loss:0.06558670264314224\n",
      "train loss:0.07206620646369576\n",
      "train loss:0.030677912918159408\n",
      "train loss:0.057509393763816447\n",
      "train loss:0.10901875069941698\n",
      "train loss:0.04859184127934483\n",
      "train loss:0.06500241831622242\n",
      "train loss:0.11406804568659643\n",
      "train loss:0.032352035466788595\n",
      "train loss:0.09683988246641659\n",
      "train loss:0.026326706597980577\n",
      "train loss:0.03402605800690795\n",
      "train loss:0.017361624188621142\n",
      "train loss:0.08946995315614616\n",
      "train loss:0.029780405785815707\n",
      "train loss:0.04452875063352539\n",
      "train loss:0.022795039856411677\n",
      "train loss:0.042731390793436366\n",
      "train loss:0.025732030731302525\n",
      "train loss:0.06436488567616076\n",
      "train loss:0.07321853457137836\n",
      "train loss:0.042733845258684934\n",
      "train loss:0.089291617490761\n",
      "train loss:0.07643291533459831\n",
      "train loss:0.07193615745296987\n",
      "train loss:0.026598848425773283\n",
      "train loss:0.06120322079525118\n",
      "train loss:0.03967689954991659\n",
      "train loss:0.04864087517215453\n",
      "train loss:0.07769178746461163\n",
      "train loss:0.06239000436593626\n",
      "train loss:0.04244140533743949\n",
      "train loss:0.03714614580999932\n",
      "train loss:0.012044643149315627\n",
      "train loss:0.10775461109715263\n",
      "train loss:0.10211267577419289\n",
      "train loss:0.0957362355294318\n",
      "train loss:0.018681108491590822\n",
      "train loss:0.03686598026984985\n",
      "train loss:0.054585391174829155\n",
      "train loss:0.04080330638743211\n",
      "train loss:0.02758967443933043\n",
      "train loss:0.06676724668637313\n",
      "train loss:0.11758947524287007\n",
      "train loss:0.029777172359914676\n",
      "train loss:0.02228536702467753\n",
      "train loss:0.030364898912216158\n",
      "train loss:0.025215425307045677\n",
      "train loss:0.024141707722739245\n",
      "train loss:0.018235682391879768\n",
      "train loss:0.02083573560742143\n",
      "train loss:0.010727698455833812\n",
      "train loss:0.11179379552504817\n",
      "train loss:0.05237303736289837\n",
      "train loss:0.053590126058952345\n",
      "train loss:0.06241768723137668\n",
      "train loss:0.13178862992809884\n",
      "train loss:0.04762487324778411\n",
      "train loss:0.036601256216240094\n",
      "train loss:0.04619845132055859\n",
      "train loss:0.07963198835361919\n",
      "train loss:0.04728293919581999\n",
      "train loss:0.09863057140992697\n",
      "train loss:0.018699883752638837\n",
      "train loss:0.016466221117775924\n",
      "train loss:0.05182363232592288\n",
      "train loss:0.09918471685862539\n",
      "train loss:0.018903348280089112\n",
      "train loss:0.024353369197509536\n",
      "train loss:0.03774463782272029\n",
      "train loss:0.06794702436352366\n",
      "train loss:0.024004247602548188\n",
      "train loss:0.04236725101403328\n",
      "train loss:0.013165813139700892\n",
      "train loss:0.03596372561289445\n",
      "train loss:0.059312781611400474\n",
      "train loss:0.03104329702248025\n",
      "train loss:0.05750891714230724\n",
      "train loss:0.035108165477964505\n",
      "train loss:0.10309406477935862\n",
      "train loss:0.06587500881283787\n",
      "train loss:0.019419228857431272\n",
      "train loss:0.053918842532321806\n",
      "train loss:0.0636652490611401\n",
      "train loss:0.03835115053774997\n",
      "train loss:0.023948768756673622\n",
      "train loss:0.07629787509201286\n",
      "train loss:0.10067693999352026\n",
      "train loss:0.061739068722882456\n",
      "train loss:0.06490997266080963\n",
      "train loss:0.06662237999411415\n",
      "train loss:0.03907771922628161\n",
      "train loss:0.0511773329142164\n",
      "train loss:0.03486712605037598\n",
      "train loss:0.019456817431979755\n",
      "train loss:0.03770352101663377\n",
      "train loss:0.03366167754608974\n",
      "train loss:0.03380339564636053\n",
      "train loss:0.057560488166515135\n",
      "train loss:0.046894202992396404\n",
      "train loss:0.07766105639834922\n",
      "train loss:0.027099086315626613\n",
      "train loss:0.01673954584458654\n",
      "train loss:0.042185678385402575\n",
      "train loss:0.020007581805218562\n",
      "train loss:0.035311927836659485\n",
      "train loss:0.0645892780293554\n",
      "train loss:0.06386231300492831\n",
      "train loss:0.02915489048832327\n",
      "train loss:0.04788656832334563\n",
      "train loss:0.060763085001144294\n",
      "train loss:0.03210993371172518\n",
      "train loss:0.03316844866362883\n",
      "train loss:0.08772718225743312\n",
      "train loss:0.04025526858655499\n",
      "train loss:0.056115305858775805\n",
      "train loss:0.031993662402229\n",
      "train loss:0.027916875637444674\n",
      "train loss:0.06790166418404171\n",
      "train loss:0.051203151666785\n",
      "train loss:0.08001880437555652\n",
      "train loss:0.05212011664316031\n",
      "train loss:0.0645447813741555\n",
      "train loss:0.0335778909234789\n",
      "train loss:0.033694101219211445\n",
      "train loss:0.11867841691965099\n",
      "train loss:0.09143080204282115\n",
      "train loss:0.0473353388419629\n",
      "train loss:0.11096039098570479\n",
      "train loss:0.046112314532456705\n",
      "train loss:0.029367398452226565\n",
      "train loss:0.02642202181877571\n",
      "train loss:0.03364611460922606\n",
      "train loss:0.04012356555227856\n",
      "train loss:0.06886699097377515\n",
      "train loss:0.042876749205082616\n",
      "train loss:0.0909646921885478\n",
      "train loss:0.06105323308555442\n",
      "train loss:0.11220571563799232\n",
      "train loss:0.05658607256265332\n",
      "train loss:0.03160707174135337\n",
      "train loss:0.01019458429347831\n",
      "train loss:0.055107569705542626\n",
      "train loss:0.08792186792330617\n",
      "train loss:0.08091432008239022\n",
      "train loss:0.0353454730822255\n",
      "train loss:0.017211528112621558\n",
      "train loss:0.03313064388307466\n",
      "train loss:0.02078109189490169\n",
      "train loss:0.0289545795362585\n",
      "train loss:0.03332802286586883\n",
      "train loss:0.09685568762993599\n",
      "train loss:0.034248645256468514\n",
      "train loss:0.06685681597433443\n",
      "train loss:0.04387248762371843\n",
      "train loss:0.039237284077795725\n",
      "train loss:0.033929153972155256\n",
      "train loss:0.04608287691883057\n",
      "train loss:0.09739862082142\n",
      "train loss:0.046511865267073293\n",
      "train loss:0.03181764719097042\n",
      "train loss:0.032109333302212835\n",
      "train loss:0.030463252894106875\n",
      "train loss:0.030466884311084498\n",
      "train loss:0.03634510873733367\n",
      "train loss:0.04376307779777893\n",
      "train loss:0.05947323564278458\n",
      "train loss:0.03737883121963624\n",
      "train loss:0.1305953336642206\n",
      "train loss:0.04671460734472566\n",
      "train loss:0.020502996682133064\n",
      "train loss:0.09148639435333333\n",
      "train loss:0.02801789737033961\n",
      "train loss:0.10054050330491518\n",
      "train loss:0.045663576456295686\n",
      "train loss:0.03110022842113358\n",
      "train loss:0.036207964332620905\n",
      "train loss:0.11445061242253732\n",
      "train loss:0.11845565834935104\n",
      "train loss:0.05875205106339942\n",
      "train loss:0.04761128382763869\n",
      "train loss:0.12346817249086971\n",
      "train loss:0.09790155980740188\n",
      "train loss:0.06285959341217157\n",
      "train loss:0.049961806000572755\n",
      "train loss:0.10116129736596156\n",
      "train loss:0.024296395025460178\n",
      "train loss:0.1114469242453489\n",
      "train loss:0.04608588462624127\n",
      "train loss:0.01840850421182481\n",
      "train loss:0.020311361748894356\n",
      "train loss:0.04298500025950942\n",
      "train loss:0.08240405641725443\n",
      "train loss:0.1255235513939836\n",
      "train loss:0.057051292058814436\n",
      "train loss:0.029899122314707\n",
      "train loss:0.04624329744789811\n",
      "train loss:0.0535172256640284\n",
      "train loss:0.15384209556373182\n",
      "train loss:0.06804441747729374\n",
      "train loss:0.049503099939311804\n",
      "train loss:0.028190172351231023\n",
      "train loss:0.07669186796748481\n",
      "train loss:0.04027945213138816\n",
      "train loss:0.040145354284564415\n",
      "train loss:0.023511051078736512\n",
      "train loss:0.07459028076386814\n",
      "train loss:0.03758750990468845\n",
      "train loss:0.05271155682749593\n",
      "train loss:0.01342547121506898\n",
      "train loss:0.023413121721100143\n",
      "train loss:0.06313754940077893\n",
      "train loss:0.061477219825537666\n",
      "train loss:0.06500612096807841\n",
      "train loss:0.006968290314269933\n",
      "train loss:0.051056285686786024\n",
      "train loss:0.010241101093885784\n",
      "train loss:0.07048811185933358\n",
      "train loss:0.07512046501442972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07412815260709694\n",
      "train loss:0.009595224107609535\n",
      "train loss:0.02608753075429761\n",
      "train loss:0.05681760101621503\n",
      "train loss:0.12102517649880291\n",
      "train loss:0.061607782000329764\n",
      "train loss:0.020005250507233105\n",
      "train loss:0.046319915977150135\n",
      "train loss:0.02128759420511737\n",
      "train loss:0.08252867202216961\n",
      "train loss:0.024109390175178026\n",
      "train loss:0.019929576589291283\n",
      "train loss:0.038007765390336484\n",
      "train loss:0.008596302172953723\n",
      "train loss:0.05297322605911351\n",
      "train loss:0.037958136427091976\n",
      "train loss:0.044634801406009644\n",
      "train loss:0.05800490013422429\n",
      "train loss:0.049412714748672246\n",
      "train loss:0.07015396784254294\n",
      "train loss:0.05224361528942164\n",
      "train loss:0.03988294576074057\n",
      "train loss:0.008975872745968724\n",
      "train loss:0.05428155337077696\n",
      "train loss:0.051810906121860144\n",
      "train loss:0.04193702306592385\n",
      "train loss:0.019893374142188013\n",
      "train loss:0.017676347295084997\n",
      "train loss:0.025132020007298746\n",
      "train loss:0.07305922336401854\n",
      "train loss:0.06471333288643276\n",
      "train loss:0.09293179983474248\n",
      "train loss:0.03452330865166679\n",
      "train loss:0.12721060326945138\n",
      "train loss:0.07464607475176414\n",
      "train loss:0.06740739119496106\n",
      "train loss:0.03968322714503276\n",
      "train loss:0.03264766964112921\n",
      "train loss:0.07602907148673842\n",
      "=== epoch:4, train acc:0.9820425724637681, test acc:0.9743659420289855 ===\n",
      "train loss:0.04274477969104647\n",
      "train loss:0.043914288396283495\n",
      "train loss:0.01923631596243324\n",
      "train loss:0.041276087888091235\n",
      "train loss:0.03395926585871175\n",
      "train loss:0.2033935049521057\n",
      "train loss:0.049950296029228194\n",
      "train loss:0.03350140814682683\n",
      "train loss:0.059969744351987805\n",
      "train loss:0.012914535378628024\n",
      "train loss:0.04761047296138451\n",
      "train loss:0.07983740152584422\n",
      "train loss:0.03536305558733009\n",
      "train loss:0.03301456571243115\n",
      "train loss:0.043325977303117304\n",
      "train loss:0.09721116277438129\n",
      "train loss:0.07635394854347374\n",
      "train loss:0.04681180024216553\n",
      "train loss:0.04076561010678971\n",
      "train loss:0.08076141068193683\n",
      "train loss:0.08661595047722619\n",
      "train loss:0.03510370675778688\n",
      "train loss:0.06673065789029048\n",
      "train loss:0.04980269274464639\n",
      "train loss:0.036072857819073004\n",
      "train loss:0.058733837951103395\n",
      "train loss:0.030553461169658416\n",
      "train loss:0.027985496151782037\n",
      "train loss:0.10556048360605254\n",
      "train loss:0.0802044884959054\n",
      "train loss:0.03654871315791109\n",
      "train loss:0.03744769577832547\n",
      "train loss:0.01534756033602193\n",
      "train loss:0.05735674226056827\n",
      "train loss:0.03384103690240701\n",
      "train loss:0.06827619483888266\n",
      "train loss:0.12403633279809116\n",
      "train loss:0.057897105608330834\n",
      "train loss:0.06670734014785491\n",
      "train loss:0.08831870460204932\n",
      "train loss:0.035715786225983454\n",
      "train loss:0.03446204563079818\n",
      "train loss:0.043621982287008795\n",
      "train loss:0.11892995023776204\n",
      "train loss:0.03899662505572324\n",
      "train loss:0.02554186012460231\n",
      "train loss:0.04328100103197923\n",
      "train loss:0.07159025018101152\n",
      "train loss:0.04104529380414238\n",
      "train loss:0.06751876042913298\n",
      "train loss:0.012502049500966938\n",
      "train loss:0.04598446843553784\n",
      "train loss:0.04920582043045117\n",
      "train loss:0.053783729009374635\n",
      "train loss:0.03620526065994111\n",
      "train loss:0.030107769094197205\n",
      "train loss:0.04008337096900614\n",
      "train loss:0.06020250053168061\n",
      "train loss:0.05155133655947937\n",
      "train loss:0.012756286303460549\n",
      "train loss:0.023784867331467775\n",
      "train loss:0.03545613088055748\n",
      "train loss:0.034676180025288356\n",
      "train loss:0.01723471262087619\n",
      "train loss:0.05550256862484562\n",
      "train loss:0.01080136406243287\n",
      "train loss:0.01713649244337303\n",
      "train loss:0.039497723591395174\n",
      "train loss:0.05743134970898187\n",
      "train loss:0.057052461792715024\n",
      "train loss:0.034965853552436074\n",
      "train loss:0.009261277338594937\n",
      "train loss:0.028980486653743486\n",
      "train loss:0.09322909437574949\n",
      "train loss:0.024966265148952917\n",
      "train loss:0.02122935345133944\n",
      "train loss:0.1309511962851262\n",
      "train loss:0.015704089798847264\n",
      "train loss:0.03333488135887118\n",
      "train loss:0.017647905489752033\n",
      "train loss:0.008406929236898175\n",
      "train loss:0.031388780480361804\n",
      "train loss:0.08374342863631662\n",
      "train loss:0.02461435374446732\n",
      "train loss:0.05257096259278189\n",
      "train loss:0.008879214935547365\n",
      "train loss:0.017494732672361395\n",
      "train loss:0.08144877493309859\n",
      "train loss:0.039839818388253935\n",
      "train loss:0.021062448271074407\n",
      "train loss:0.052396173285683884\n",
      "train loss:0.09335418529547015\n",
      "train loss:0.03787850942442684\n",
      "train loss:0.01827159487430245\n",
      "train loss:0.010595920770721034\n",
      "train loss:0.03236111348311696\n",
      "train loss:0.0028809186656970076\n",
      "train loss:0.061046942794597055\n",
      "train loss:0.03693389400180807\n",
      "train loss:0.04406084485709498\n",
      "train loss:0.03680850322365206\n",
      "train loss:0.053341573047621584\n",
      "train loss:0.017298317242291618\n",
      "train loss:0.04352960793453969\n",
      "train loss:0.02281443124320113\n",
      "train loss:0.020511943135812005\n",
      "train loss:0.046418845160535446\n",
      "train loss:0.0142904550543315\n",
      "train loss:0.021575918103918196\n",
      "train loss:0.016602713782795528\n",
      "train loss:0.06770828169186234\n",
      "train loss:0.03203298098397551\n",
      "train loss:0.035019221576870437\n",
      "train loss:0.08479137538025987\n",
      "train loss:0.027201661413479388\n",
      "train loss:0.01834525121392456\n",
      "train loss:0.059594320897782035\n",
      "train loss:0.004015203621178871\n",
      "train loss:0.011166243257989903\n",
      "train loss:0.022800535263125307\n",
      "train loss:0.048664720136396535\n",
      "train loss:0.021497349240076194\n",
      "train loss:0.028837708178902476\n",
      "train loss:0.029117963999270687\n",
      "train loss:0.056032347288076365\n",
      "train loss:0.021941871372577585\n",
      "train loss:0.014284005593771151\n",
      "train loss:0.07385679094328114\n",
      "train loss:0.022673564746786175\n",
      "train loss:0.041509738911559166\n",
      "train loss:0.048534876266608386\n",
      "train loss:0.048264176687550904\n",
      "train loss:0.057201545042896575\n",
      "train loss:0.06940444179160564\n",
      "train loss:0.07891004809824394\n",
      "train loss:0.014178802413633047\n",
      "train loss:0.08572550836154448\n",
      "train loss:0.03963872073910503\n",
      "train loss:0.027466555761177108\n",
      "train loss:0.010291059803727033\n",
      "train loss:0.03287678542134769\n",
      "train loss:0.06709720233227845\n",
      "train loss:0.0436147816817895\n",
      "train loss:0.03777245376127844\n",
      "train loss:0.04910147831049953\n",
      "train loss:0.11419183507323444\n",
      "train loss:0.09300691926854679\n",
      "train loss:0.0054505256491983334\n",
      "train loss:0.014297380826808391\n",
      "train loss:0.02705765449480364\n",
      "train loss:0.03232303963879844\n",
      "train loss:0.011089769220861308\n",
      "train loss:0.07308589896419138\n",
      "train loss:0.0649304086636746\n",
      "train loss:0.031228708438281853\n",
      "train loss:0.046466274710097615\n",
      "train loss:0.05058328322420474\n",
      "train loss:0.037086735869218276\n",
      "train loss:0.09106678028915577\n",
      "train loss:0.05041206502160707\n",
      "train loss:0.02598738713564177\n",
      "train loss:0.04367043772198728\n",
      "train loss:0.023706180978046904\n",
      "train loss:0.05830535390462034\n",
      "train loss:0.06702923717551582\n",
      "train loss:0.03428737200265391\n",
      "train loss:0.048981482445433565\n",
      "train loss:0.10965917653745126\n",
      "train loss:0.025634987653248398\n",
      "train loss:0.04158371724426001\n",
      "train loss:0.023662501697153886\n",
      "train loss:0.05360747103154164\n",
      "train loss:0.017658335744490754\n",
      "train loss:0.03271087352022342\n",
      "train loss:0.02735520820433233\n",
      "train loss:0.06530937278193027\n",
      "train loss:0.04016958461963816\n",
      "train loss:0.03974248203997668\n",
      "train loss:0.009294151027122789\n",
      "train loss:0.09858604223374269\n",
      "train loss:0.0111978844693123\n",
      "train loss:0.052198782702415715\n",
      "train loss:0.01803487634766606\n",
      "train loss:0.031626815130486936\n",
      "train loss:0.034550686740703274\n",
      "train loss:0.03759579867036707\n",
      "train loss:0.026795371660965704\n",
      "train loss:0.03341419068217792\n",
      "train loss:0.02458274830897825\n",
      "train loss:0.08282315815054773\n",
      "train loss:0.13533638299529843\n",
      "train loss:0.02382834219340404\n",
      "train loss:0.046668544466479056\n",
      "train loss:0.05178373655030888\n",
      "train loss:0.07573024857548798\n",
      "train loss:0.013734630562364188\n",
      "train loss:0.09998063589706142\n",
      "train loss:0.01570251841539009\n",
      "train loss:0.01896184899767054\n",
      "train loss:0.00874528390260374\n",
      "train loss:0.040398407544978816\n",
      "train loss:0.04449093680460581\n",
      "train loss:0.020263610702765302\n",
      "train loss:0.016019401474362115\n",
      "train loss:0.02857627432997967\n",
      "train loss:0.03357033588348266\n",
      "train loss:0.07440897241274559\n",
      "train loss:0.09704425074396986\n",
      "train loss:0.02574994453956787\n",
      "train loss:0.022254417007249425\n",
      "train loss:0.14532008709617125\n",
      "train loss:0.06506091901404809\n",
      "train loss:0.030265504717850635\n",
      "train loss:0.05970676364413639\n",
      "train loss:0.0287307979133679\n",
      "train loss:0.049308748436928666\n",
      "train loss:0.03041580685242246\n",
      "train loss:0.07097419052465366\n",
      "train loss:0.03302949117532504\n",
      "train loss:0.04780990743876561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.030363054227070134\n",
      "train loss:0.021646305688501396\n",
      "train loss:0.02522757276351321\n",
      "train loss:0.04056235048228739\n",
      "train loss:0.055670699338832876\n",
      "train loss:0.03636437220019276\n",
      "train loss:0.020747384138480998\n",
      "train loss:0.06036295208233902\n",
      "train loss:0.015528871907631362\n",
      "train loss:0.06515902739119996\n",
      "train loss:0.02223109723950645\n",
      "train loss:0.10497890381788573\n",
      "train loss:0.04282961753741613\n",
      "train loss:0.04080247156575164\n",
      "train loss:0.00896945225694935\n",
      "train loss:0.014371420092818459\n",
      "train loss:0.035773466618697784\n",
      "train loss:0.04158898461295061\n",
      "train loss:0.03624243231440249\n",
      "train loss:0.06852868441588017\n",
      "train loss:0.038327362356531176\n",
      "train loss:0.024719895171281384\n",
      "train loss:0.024521789970003285\n",
      "train loss:0.026972844810240086\n",
      "train loss:0.061211854846155093\n",
      "train loss:0.03034120834468361\n",
      "train loss:0.011634882775130806\n",
      "train loss:0.027706106034300106\n",
      "train loss:0.012517516237029873\n",
      "train loss:0.049071550544629486\n",
      "train loss:0.06856420254131151\n",
      "train loss:0.03457111150020544\n",
      "train loss:0.022241035251383982\n",
      "train loss:0.09554320836641421\n",
      "train loss:0.016206118196253186\n",
      "train loss:0.015800551140896044\n",
      "train loss:0.05945287648415345\n",
      "train loss:0.06919825730385047\n",
      "train loss:0.11742862096823119\n",
      "train loss:0.039595903482422375\n",
      "train loss:0.04397926836122758\n",
      "train loss:0.022066970815122672\n",
      "train loss:0.019578191821143603\n",
      "train loss:0.020528910482872774\n",
      "train loss:0.04406747437315807\n",
      "train loss:0.04192667347102108\n",
      "train loss:0.0964448561342381\n",
      "train loss:0.013886502934019277\n",
      "train loss:0.02541746130506487\n",
      "train loss:0.03682744568008785\n",
      "train loss:0.04916934854431571\n",
      "train loss:0.09841555262681613\n",
      "train loss:0.02412907935681297\n",
      "train loss:0.010259164033622458\n",
      "train loss:0.04290739334948223\n",
      "train loss:0.017850523466684736\n",
      "train loss:0.0349640258127135\n",
      "train loss:0.09140706699844131\n",
      "train loss:0.02747811297544893\n",
      "train loss:0.02178588427140298\n",
      "train loss:0.02934636073957746\n",
      "train loss:0.03588636390870416\n",
      "train loss:0.11864814379125965\n",
      "train loss:0.047275064241416836\n",
      "train loss:0.03523038757971134\n",
      "train loss:0.10736817936224403\n",
      "train loss:0.009472530601765476\n",
      "train loss:0.03418288564200816\n",
      "train loss:0.09142374875105688\n",
      "train loss:0.027690552235253362\n",
      "train loss:0.04573113436765163\n",
      "train loss:0.014184695521538082\n",
      "train loss:0.07770160027458714\n",
      "train loss:0.047562088309143095\n",
      "train loss:0.09632096290890452\n",
      "train loss:0.014201392160763637\n",
      "train loss:0.03707933265608967\n",
      "train loss:0.031774677201655104\n",
      "train loss:0.01975100708741708\n",
      "train loss:0.01530652407647996\n",
      "train loss:0.07148305552169167\n",
      "train loss:0.04785384982308342\n",
      "train loss:0.07459198478144106\n",
      "train loss:0.01154576202993199\n",
      "train loss:0.046470809110817024\n",
      "train loss:0.09294486516677741\n",
      "train loss:0.09441783864150316\n",
      "train loss:0.03790449345293936\n",
      "train loss:0.08613613842257369\n",
      "train loss:0.0878216200866491\n",
      "train loss:0.013346803379733452\n",
      "train loss:0.024747156392844305\n",
      "train loss:0.032487832224194574\n",
      "train loss:0.048947862327882\n",
      "train loss:0.034731915789752515\n",
      "train loss:0.029013242467631196\n",
      "train loss:0.03717807146010842\n",
      "train loss:0.08472240472278468\n",
      "train loss:0.050638599197391616\n",
      "train loss:0.027095202214694622\n",
      "train loss:0.044559436550884256\n",
      "train loss:0.09380066213028453\n",
      "train loss:0.035543475649956864\n",
      "train loss:0.0159831299296711\n",
      "train loss:0.023388284942954436\n",
      "train loss:0.04335825434383324\n",
      "train loss:0.038412611719261344\n",
      "train loss:0.017315621283281648\n",
      "train loss:0.02089584047389468\n",
      "train loss:0.006688268340787179\n",
      "train loss:0.07140682224336592\n",
      "train loss:0.06069341389618295\n",
      "train loss:0.06363661140029021\n",
      "train loss:0.027389571477831214\n",
      "train loss:0.03287325159877992\n",
      "train loss:0.03657111725652292\n",
      "train loss:0.06386815332852684\n",
      "train loss:0.06196150841241586\n",
      "train loss:0.03328452950900435\n",
      "train loss:0.05374288353675267\n",
      "train loss:0.021114733841782165\n",
      "train loss:0.01520489229516989\n",
      "train loss:0.02011207075478164\n",
      "train loss:0.042806571909255034\n",
      "train loss:0.04051713114538956\n",
      "train loss:0.015495378810403908\n",
      "train loss:0.0744540493834769\n",
      "train loss:0.009983919263028503\n",
      "train loss:0.04169089994304375\n",
      "train loss:0.0538426479223488\n",
      "train loss:0.08859835515782193\n",
      "train loss:0.01966166130700971\n",
      "train loss:0.017776702206261038\n",
      "train loss:0.0711001161024582\n",
      "train loss:0.009595041578594317\n",
      "train loss:0.01100849532958174\n",
      "train loss:0.046123193974902846\n",
      "train loss:0.03743635672219181\n",
      "train loss:0.03579314391465029\n",
      "train loss:0.01826518861496754\n",
      "train loss:0.044340827685209826\n",
      "train loss:0.03542819367386675\n",
      "train loss:0.023360185262076137\n",
      "train loss:0.022289231543255756\n",
      "train loss:0.03261912299689234\n",
      "train loss:0.04400389078715198\n",
      "train loss:0.035064982049336904\n",
      "train loss:0.060230906982844744\n",
      "=== epoch:5, train acc:0.9873414855072464, test acc:0.9790760869565217 ===\n",
      "train loss:0.024559181704761495\n",
      "train loss:0.021530818043250657\n",
      "train loss:0.05134747175185486\n",
      "train loss:0.013019654965678194\n",
      "train loss:0.055946952565495554\n",
      "train loss:0.1008613983503493\n",
      "train loss:0.06307642081421479\n",
      "train loss:0.029031867885832292\n",
      "train loss:0.02575283425719525\n",
      "train loss:0.04487825353584031\n",
      "train loss:0.014707967151576441\n",
      "train loss:0.02800116305166146\n",
      "train loss:0.0059727543127969926\n",
      "train loss:0.016466931539861562\n",
      "train loss:0.029552245391787867\n",
      "train loss:0.03633503821763067\n",
      "train loss:0.015595172270007392\n",
      "train loss:0.07051525828138704\n",
      "train loss:0.032444759885515796\n",
      "train loss:0.0339408998781728\n",
      "train loss:0.025190274448066704\n",
      "train loss:0.011366064938219468\n",
      "train loss:0.08691786438041231\n",
      "train loss:0.021191714811508725\n",
      "train loss:0.016005092568608773\n",
      "train loss:0.022203775757256235\n",
      "train loss:0.01712573422869493\n",
      "train loss:0.020961680120133906\n",
      "train loss:0.05602378457846009\n",
      "train loss:0.007431188636473463\n",
      "train loss:0.025147073824978036\n",
      "train loss:0.029898065809832862\n",
      "train loss:0.008590800928946445\n",
      "train loss:0.025119789861504226\n",
      "train loss:0.01585257957765969\n",
      "train loss:0.09156839435387971\n",
      "train loss:0.011325567926084825\n",
      "train loss:0.026220075805436456\n",
      "train loss:0.04153997152456297\n",
      "train loss:0.06786332007355286\n",
      "train loss:0.014836899445551685\n",
      "train loss:0.024517304852594363\n",
      "train loss:0.0362088876480394\n",
      "train loss:0.015971512870761154\n",
      "train loss:0.04946050014169332\n",
      "train loss:0.029264494568338337\n",
      "train loss:0.10451971318961183\n",
      "train loss:0.04018400983887352\n",
      "train loss:0.016537525683126834\n",
      "train loss:0.04891043778110255\n",
      "train loss:0.04306353397779576\n",
      "train loss:0.01055786072578068\n",
      "train loss:0.015071196366484728\n",
      "train loss:0.04160103254557091\n",
      "train loss:0.013770438455156072\n",
      "train loss:0.009042760954218191\n",
      "train loss:0.027634172729548837\n",
      "train loss:0.003989791649822375\n",
      "train loss:0.027939979937821935\n",
      "train loss:0.049894983821551796\n",
      "train loss:0.02798889892110327\n",
      "train loss:0.05786180546540279\n",
      "train loss:0.027528363734546923\n",
      "train loss:0.052588892881180106\n",
      "train loss:0.02086593140232536\n",
      "train loss:0.025853790692180155\n",
      "train loss:0.035640513934033016\n",
      "train loss:0.0885510933487983\n",
      "train loss:0.03955811991104893\n",
      "train loss:0.05439090484466469\n",
      "train loss:0.018099234840941242\n",
      "train loss:0.05642710899942057\n",
      "train loss:0.06010141697021195\n",
      "train loss:0.08265837830094995\n",
      "train loss:0.060460832705640205\n",
      "train loss:0.07641079442404718\n",
      "train loss:0.023795900300910115\n",
      "train loss:0.052453063238682866\n",
      "train loss:0.027557019100602036\n",
      "train loss:0.06957697607864975\n",
      "train loss:0.02989835589144788\n",
      "train loss:0.018558013889250997\n",
      "train loss:0.016631813510946274\n",
      "train loss:0.034875122213897346\n",
      "train loss:0.023516182405516266\n",
      "train loss:0.1180250891123169\n",
      "train loss:0.019261759778580998\n",
      "train loss:0.03787435722440853\n",
      "train loss:0.027500054099863173\n",
      "train loss:0.03808129633809387\n",
      "train loss:0.022163023933783114\n",
      "train loss:0.021186522375074273\n",
      "train loss:0.022104242638397123\n",
      "train loss:0.06625606303521664\n",
      "train loss:0.0638389206965172\n",
      "train loss:0.020216794967119957\n",
      "train loss:0.01712178466600369\n",
      "train loss:0.03441654917747077\n",
      "train loss:0.011995742437213556\n",
      "train loss:0.0730087788441483\n",
      "train loss:0.051137540869031266\n",
      "train loss:0.011851728876541305\n",
      "train loss:0.03521609878525791\n",
      "train loss:0.027374516405436106\n",
      "train loss:0.03312427816541483\n",
      "train loss:0.01449054933938613\n",
      "train loss:0.012065709941756412\n",
      "train loss:0.017719610244865885\n",
      "train loss:0.031148514145235243\n",
      "train loss:0.005564736919507529\n",
      "train loss:0.012121155626900764\n",
      "train loss:0.032829699637592295\n",
      "train loss:0.003006815031597671\n",
      "train loss:0.0022537060248774294\n",
      "train loss:0.05520959205935883\n",
      "train loss:0.008330805019825254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.039237902245849596\n",
      "train loss:0.01686762886585843\n",
      "train loss:0.003837709963212706\n",
      "train loss:0.0638912037720317\n",
      "train loss:0.05084512747765493\n",
      "train loss:0.03610167955151859\n",
      "train loss:0.016577752650185292\n",
      "train loss:0.029835999714729687\n",
      "train loss:0.07303454651800305\n",
      "train loss:0.05728733517467397\n",
      "train loss:0.018541277730252975\n",
      "train loss:0.018240245409953115\n",
      "train loss:0.02775454979277938\n",
      "train loss:0.033239149787346454\n",
      "train loss:0.0910489653613717\n",
      "train loss:0.020951932456393832\n",
      "train loss:0.03713769198583803\n",
      "train loss:0.01043837762791116\n",
      "train loss:0.024356111678290788\n",
      "train loss:0.0399779575651034\n",
      "train loss:0.03624465152036481\n",
      "train loss:0.027995599951595077\n",
      "train loss:0.024820815710180934\n",
      "train loss:0.10866202118375148\n",
      "train loss:0.022627368840482647\n",
      "train loss:0.01173389728299295\n",
      "train loss:0.023261139208329538\n",
      "train loss:0.025591911376065837\n",
      "train loss:0.013370187346447682\n",
      "train loss:0.03679058400218417\n",
      "train loss:0.01155059688424254\n",
      "train loss:0.01699681861816983\n",
      "train loss:0.04413830182801203\n",
      "train loss:0.0105516184263456\n",
      "train loss:0.07768462116219524\n",
      "train loss:0.014464112865249696\n",
      "train loss:0.10163302029075288\n",
      "train loss:0.005868904355512417\n",
      "train loss:0.08038497956219336\n",
      "train loss:0.07453194824178556\n",
      "train loss:0.07534772809364215\n",
      "train loss:0.030435339857443813\n",
      "train loss:0.031841445491842355\n",
      "train loss:0.007246254002472235\n",
      "train loss:0.00831271106141589\n",
      "train loss:0.033192920300365324\n",
      "train loss:0.014409826862877229\n",
      "train loss:0.025974430379689613\n",
      "train loss:0.02066902356490829\n",
      "train loss:0.049671131200581795\n",
      "train loss:0.06918949189737775\n",
      "train loss:0.04148936486268463\n",
      "train loss:0.0203166523476063\n",
      "train loss:0.022523847986020504\n",
      "train loss:0.016361195040947383\n",
      "train loss:0.02343492681907728\n",
      "train loss:0.03305535141501018\n",
      "train loss:0.04650308212343765\n",
      "train loss:0.13336706420900601\n",
      "train loss:0.06211046720130568\n",
      "train loss:0.027733583594002426\n",
      "train loss:0.0240489410514243\n",
      "train loss:0.03468531071693666\n",
      "train loss:0.02941088333502239\n",
      "train loss:0.029414950433544747\n",
      "train loss:0.03426113349520073\n",
      "train loss:0.01984653935059528\n",
      "train loss:0.048127827401042676\n",
      "train loss:0.05598172260509277\n",
      "train loss:0.009059269539026537\n",
      "train loss:0.01064971875902607\n",
      "train loss:0.05112948857976815\n",
      "train loss:0.0656724734613375\n",
      "train loss:0.04890234172211987\n",
      "train loss:0.02470656319716291\n",
      "train loss:0.024269823850678916\n",
      "train loss:0.15711766081385609\n",
      "train loss:0.035000882707798844\n",
      "train loss:0.025089801219578132\n",
      "train loss:0.03538691181922771\n",
      "train loss:0.04817162530486573\n",
      "train loss:0.020526509304750237\n",
      "train loss:0.02282554927574987\n",
      "train loss:0.0194802250152779\n",
      "train loss:0.013388969152326066\n",
      "train loss:0.0627167889190898\n",
      "train loss:0.03812582554363773\n",
      "train loss:0.04286683796350278\n",
      "train loss:0.02851197653637153\n",
      "train loss:0.08093212239084403\n",
      "train loss:0.01688069235541547\n",
      "train loss:0.013097921134408897\n",
      "train loss:0.018761951985834444\n",
      "train loss:0.038784207925598904\n",
      "train loss:0.06423590844856673\n",
      "train loss:0.02601426636231481\n",
      "train loss:0.010328974303280388\n",
      "train loss:0.007941182739804688\n",
      "train loss:0.013210419855197617\n",
      "train loss:0.007179256203530747\n",
      "train loss:0.03383846345975986\n",
      "train loss:0.02069633346438172\n",
      "train loss:0.012626552317924316\n",
      "train loss:0.0338741137956484\n",
      "train loss:0.02805025933433788\n",
      "train loss:0.008565759498443242\n",
      "train loss:0.018770600019556865\n",
      "train loss:0.006603962586953412\n",
      "train loss:0.0086131150901723\n",
      "train loss:0.032369559206595684\n",
      "train loss:0.00809136255075574\n",
      "train loss:0.025027731822578066\n",
      "train loss:0.11984407755376933\n",
      "train loss:0.08019262542543035\n",
      "train loss:0.051777232078787476\n",
      "train loss:0.04640508541388318\n",
      "train loss:0.06704550218277532\n",
      "train loss:0.04186714174145382\n",
      "train loss:0.047955201746346404\n",
      "train loss:0.07118199165511714\n",
      "train loss:0.07682106288449651\n",
      "train loss:0.015041065213066333\n",
      "train loss:0.022111096242003574\n",
      "train loss:0.057765472813160176\n",
      "train loss:0.051280709677846675\n",
      "train loss:0.04739724405818455\n",
      "train loss:0.01962872714621306\n",
      "train loss:0.018465730707151125\n",
      "train loss:0.01533729335078152\n",
      "train loss:0.025549867148896385\n",
      "train loss:0.025956826723005817\n",
      "train loss:0.02157925116435367\n",
      "train loss:0.01397472745296456\n",
      "train loss:0.010756054895602394\n",
      "train loss:0.08425780198012275\n",
      "train loss:0.04739037407123767\n",
      "train loss:0.07787863419411355\n",
      "train loss:0.017843684337960273\n",
      "train loss:0.01836746295914303\n",
      "train loss:0.05466144015620316\n",
      "train loss:0.025849653653286026\n",
      "train loss:0.09063113461725596\n",
      "train loss:0.008135257566581807\n",
      "train loss:0.013998183971015517\n",
      "train loss:0.009845224227984579\n",
      "train loss:0.02618922663164239\n",
      "train loss:0.07014611774298334\n",
      "train loss:0.02093555258508689\n",
      "train loss:0.027116028065579546\n",
      "train loss:0.03494215562301292\n",
      "train loss:0.009404303165825273\n",
      "train loss:0.045764356955264186\n",
      "train loss:0.008715827436632352\n",
      "train loss:0.02620731024588401\n",
      "train loss:0.017353980960065598\n",
      "train loss:0.0132082692194697\n",
      "train loss:0.020181079585109025\n",
      "train loss:0.0064293836471060834\n",
      "train loss:0.011245795856511077\n",
      "train loss:0.02217066605400443\n",
      "train loss:0.0174892219394177\n",
      "train loss:0.03795226588834897\n",
      "train loss:0.005970183821158401\n",
      "train loss:0.02285975463280424\n",
      "train loss:0.04327867017106838\n",
      "train loss:0.03326027356394243\n",
      "train loss:0.019586122186358447\n",
      "train loss:0.05017762359574464\n",
      "train loss:0.02474287143367372\n",
      "train loss:0.006160937979643057\n",
      "train loss:0.064978490450717\n",
      "train loss:0.04414804875739885\n",
      "train loss:0.01158000457372913\n",
      "train loss:0.033093099552089146\n",
      "train loss:0.024086865555126832\n",
      "train loss:0.04981321894763526\n",
      "train loss:0.022041216999825135\n",
      "train loss:0.026051278382416037\n",
      "train loss:0.026951009673277616\n",
      "train loss:0.014785271178851535\n",
      "train loss:0.005685730637577125\n",
      "train loss:0.03098594772491513\n",
      "train loss:0.06325223826940236\n",
      "train loss:0.026813641599763103\n",
      "train loss:0.03335687900945145\n",
      "train loss:0.05013715673558376\n",
      "train loss:0.076474598144332\n",
      "train loss:0.025282212939069345\n",
      "train loss:0.009273259095508695\n",
      "train loss:0.027058406378718414\n",
      "train loss:0.0207475040537445\n",
      "train loss:0.040367672274646486\n",
      "train loss:0.06634503944365995\n",
      "train loss:0.020172603608946602\n",
      "train loss:0.010931266812442997\n",
      "train loss:0.02194489754083356\n",
      "train loss:0.03881378565165429\n",
      "train loss:0.010151347659182545\n",
      "train loss:0.029005284621882222\n",
      "train loss:0.018295923144898554\n",
      "train loss:0.05754700070251427\n",
      "train loss:0.01986020804199949\n",
      "train loss:0.05266080632219725\n",
      "train loss:0.01037320664708048\n",
      "train loss:0.012594334993074037\n",
      "train loss:0.019190031485842196\n",
      "train loss:0.008746445564515629\n",
      "train loss:0.041312601450315296\n",
      "train loss:0.008577590938750579\n",
      "train loss:0.009542182803671773\n",
      "train loss:0.01991516578626618\n",
      "train loss:0.026262727341594974\n",
      "train loss:0.04362733330938753\n",
      "train loss:0.010666027427667571\n",
      "train loss:0.03351534105054566\n",
      "train loss:0.021020490174493884\n",
      "train loss:0.015067916646688101\n",
      "train loss:0.07222318531731038\n",
      "train loss:0.05488289088297549\n",
      "train loss:0.012894947218995024\n",
      "train loss:0.015857121026105165\n",
      "train loss:0.07204238679211829\n",
      "train loss:0.022220702850663902\n",
      "train loss:0.008843706147874284\n",
      "train loss:0.05370586425658666\n",
      "train loss:0.010749441028046314\n",
      "train loss:0.08872349427997644\n",
      "train loss:0.011551274011764536\n",
      "train loss:0.03778527627975984\n",
      "train loss:0.04703788651033983\n",
      "train loss:0.022813122172898038\n",
      "train loss:0.026057381323345775\n",
      "train loss:0.013883026889603389\n",
      "train loss:0.011911223141971568\n",
      "train loss:0.00858909429822466\n",
      "train loss:0.014643988676558892\n",
      "train loss:0.007802518988564598\n",
      "train loss:0.006413347867340556\n",
      "train loss:0.06525903931118303\n",
      "train loss:0.008521078854778834\n",
      "train loss:0.04794668772071157\n",
      "train loss:0.03432708032747484\n",
      "train loss:0.011603018059650683\n",
      "train loss:0.08259417315035215\n",
      "train loss:0.0059414882077822246\n",
      "train loss:0.019811915796519766\n",
      "train loss:0.0048588350430921745\n",
      "train loss:0.04055534643732049\n",
      "train loss:0.024183380789943552\n",
      "train loss:0.03511544754310197\n",
      "train loss:0.023197492074169105\n",
      "train loss:0.03014128325290884\n",
      "=== epoch:6, train acc:0.9904438405797101, test acc:0.9823369565217391 ===\n",
      "train loss:0.0062349380848736565\n",
      "train loss:0.007693329927646818\n",
      "train loss:0.013808051780934454\n",
      "train loss:0.011439055688216375\n",
      "train loss:0.014087245510331699\n",
      "train loss:0.04668721012315821\n",
      "train loss:0.06394211192824872\n",
      "train loss:0.007307414089638082\n",
      "train loss:0.03561116287862665\n",
      "train loss:0.02685642795987371\n",
      "train loss:0.028526369024254924\n",
      "train loss:0.004370225374126999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011765931418884561\n",
      "train loss:0.07810294143333675\n",
      "train loss:0.023392348308850144\n",
      "train loss:0.05830708432778883\n",
      "train loss:0.05383391443801824\n",
      "train loss:0.018716012990179148\n",
      "train loss:0.028945270785666347\n",
      "train loss:0.017918971483075783\n",
      "train loss:0.04098598219894599\n",
      "train loss:0.04369602125207986\n",
      "train loss:0.03323138209934627\n",
      "train loss:0.03363914007689596\n",
      "train loss:0.028147928271755218\n",
      "train loss:0.012102469934979376\n",
      "train loss:0.028647586118204886\n",
      "train loss:0.01972060517580563\n",
      "train loss:0.0554171445801976\n",
      "train loss:0.012515098948080497\n",
      "train loss:0.03373697368079446\n",
      "train loss:0.035386303124818407\n",
      "train loss:0.005284099247595056\n",
      "train loss:0.05084575069245002\n",
      "train loss:0.025634473622240715\n",
      "train loss:0.006015704937234859\n",
      "train loss:0.008817083935862054\n",
      "train loss:0.02520398531337429\n",
      "train loss:0.05290054945099982\n",
      "train loss:0.01677289566822595\n",
      "train loss:0.0647168227855749\n",
      "train loss:0.04034492033032115\n",
      "train loss:0.009084285575708147\n",
      "train loss:0.03895320820657026\n",
      "train loss:0.034102900993286396\n",
      "train loss:0.031187683330102793\n",
      "train loss:0.011526277751054921\n",
      "train loss:0.02955683888964881\n",
      "train loss:0.015826508297195944\n",
      "train loss:0.005653874009363089\n",
      "train loss:0.05693553533108518\n",
      "train loss:0.05266585751900695\n",
      "train loss:0.009131591878925881\n",
      "train loss:0.03207600355137452\n",
      "train loss:0.03988120807794427\n",
      "train loss:0.007862400332047149\n",
      "train loss:0.05677608242053471\n",
      "train loss:0.04422105910213026\n",
      "train loss:0.07236402731617837\n",
      "train loss:0.08436772309791915\n",
      "train loss:0.010300670924505567\n",
      "train loss:0.0775557750313209\n",
      "train loss:0.03247162774275925\n",
      "train loss:0.012270463800186428\n",
      "train loss:0.020163953330022983\n",
      "train loss:0.030707801453674435\n",
      "train loss:0.052128548653608255\n",
      "train loss:0.011479258841581725\n",
      "train loss:0.00479757860795813\n",
      "train loss:0.02028005709984303\n",
      "train loss:0.015200356590543503\n",
      "train loss:0.01623571981367789\n",
      "train loss:0.023765040054625874\n",
      "train loss:0.00840599435609356\n",
      "train loss:0.012685393946037116\n",
      "train loss:0.008296484381049095\n",
      "train loss:0.11548073829373534\n",
      "train loss:0.03936532050889312\n",
      "train loss:0.01603928707246967\n",
      "train loss:0.039812039154707324\n",
      "train loss:0.011692380585827637\n",
      "train loss:0.0204189397295653\n",
      "train loss:0.034956874946967524\n",
      "train loss:0.005189908062250519\n",
      "train loss:0.023970986864472188\n",
      "train loss:0.0032803898248321564\n",
      "train loss:0.015519547281633236\n",
      "train loss:0.004949971341537515\n",
      "train loss:0.020603876062405768\n",
      "train loss:0.057549970861695506\n",
      "train loss:0.03470451248528678\n",
      "train loss:0.035636968692516285\n",
      "train loss:0.043422283145940224\n",
      "train loss:0.03755870440514902\n",
      "train loss:0.015852984463921645\n",
      "train loss:0.014161035662292588\n",
      "train loss:0.05254041518624001\n",
      "train loss:0.020750096747901292\n",
      "train loss:0.06117726132142118\n",
      "train loss:0.014017034261178478\n",
      "train loss:0.017526084530323317\n",
      "train loss:0.05943299039986957\n",
      "train loss:0.012797096727539573\n",
      "train loss:0.05422987994513197\n",
      "train loss:0.023734309393470633\n",
      "train loss:0.008016738346978943\n",
      "train loss:0.01642375658011218\n",
      "train loss:0.013600235584353365\n",
      "train loss:0.01937875331430327\n",
      "train loss:0.01779869688054686\n",
      "train loss:0.06399658545286699\n",
      "train loss:0.004883155626562441\n",
      "train loss:0.013259022433496078\n",
      "train loss:0.049995803602943714\n",
      "train loss:0.01502227389266644\n",
      "train loss:0.017488140889885286\n",
      "train loss:0.04997251882188199\n",
      "train loss:0.032895776510097924\n",
      "train loss:0.006108523225468835\n",
      "train loss:0.013923052295217174\n",
      "train loss:0.013085533646176943\n",
      "train loss:0.03466653806063591\n",
      "train loss:0.03425450688375838\n",
      "train loss:0.026780292368699037\n",
      "train loss:0.0029070555680579006\n",
      "train loss:0.03925545326901688\n",
      "train loss:0.009819834779020679\n",
      "train loss:0.01969373421510112\n",
      "train loss:0.006265344386504904\n",
      "train loss:0.025709811200835944\n",
      "train loss:0.015873284787123795\n",
      "train loss:0.03207119073484445\n",
      "train loss:0.042836548565399056\n",
      "train loss:0.004438848644661534\n",
      "train loss:0.01152293494606017\n",
      "train loss:0.028757470128060715\n",
      "train loss:0.013839010265599494\n",
      "train loss:0.01945318193901408\n",
      "train loss:0.0701271099993139\n",
      "train loss:0.04641822222025757\n",
      "train loss:0.02820592381336359\n",
      "train loss:0.02275534267217803\n",
      "train loss:0.033547812603212636\n",
      "train loss:0.01439075763066858\n",
      "train loss:0.01547030102231477\n",
      "train loss:0.02256505345099446\n",
      "train loss:0.0060295014483617935\n",
      "train loss:0.046039766074919754\n",
      "train loss:0.007033346983435924\n",
      "train loss:0.014378150170539948\n",
      "train loss:0.01864831705212414\n",
      "train loss:0.02366821135950053\n",
      "train loss:0.03875151251460426\n",
      "train loss:0.02081370355327706\n",
      "train loss:0.03296221348737789\n",
      "train loss:0.024774333337625694\n",
      "train loss:0.022399737206599307\n",
      "train loss:0.009696421682163968\n",
      "train loss:0.03469748875815819\n",
      "train loss:0.008451384432305914\n",
      "train loss:0.024804079216434405\n",
      "train loss:0.03658362861090073\n",
      "train loss:0.005411845505512354\n",
      "train loss:0.007327917167017804\n",
      "train loss:0.016508895911883738\n",
      "train loss:0.04266305999738028\n",
      "train loss:0.032568800853698385\n",
      "train loss:0.005330008343565471\n",
      "train loss:0.039415987749549984\n",
      "train loss:0.05185879421577989\n",
      "train loss:0.045936647210324116\n",
      "train loss:0.03812904764266205\n",
      "train loss:0.025999737241957102\n",
      "train loss:0.03643562971667139\n",
      "train loss:0.011401423597371467\n",
      "train loss:0.025892741325891925\n",
      "train loss:0.019702810919366313\n",
      "train loss:0.016887907359840606\n",
      "train loss:0.0031126062548084824\n",
      "train loss:0.07050421542793205\n",
      "train loss:0.017998317706213286\n",
      "train loss:0.031305910180429254\n",
      "train loss:0.02269922991029723\n",
      "train loss:0.03417379110369771\n",
      "train loss:0.010913312260714073\n",
      "train loss:0.014877146939481663\n",
      "train loss:0.02928255030412569\n",
      "train loss:0.006680405689964732\n",
      "train loss:0.015788767749376837\n",
      "train loss:0.022013343651223424\n",
      "train loss:0.010126562115610345\n",
      "train loss:0.02072858778710841\n",
      "train loss:0.014412850925427894\n",
      "train loss:0.006404912849715115\n",
      "train loss:0.00827675003249288\n",
      "train loss:0.045725293033171\n",
      "train loss:0.007844375558069246\n",
      "train loss:0.0075204347583922105\n",
      "train loss:0.03672724115560421\n",
      "train loss:0.014648692035802343\n",
      "train loss:0.030115971881499903\n",
      "train loss:0.00446695476908827\n",
      "train loss:0.011596310549908508\n",
      "train loss:0.03876115570935087\n",
      "train loss:0.012019939437360693\n",
      "train loss:0.032015215589661625\n",
      "train loss:0.047393794429403786\n",
      "train loss:0.013342474953033612\n",
      "train loss:0.01907697323804502\n",
      "train loss:0.017093157257247263\n",
      "train loss:0.036271385517965535\n",
      "train loss:0.01384398298804078\n",
      "train loss:0.011595694687336337\n",
      "train loss:0.008390620464000657\n",
      "train loss:0.021790559562981305\n",
      "train loss:0.03399478335196187\n",
      "train loss:0.011931017077922107\n",
      "train loss:0.013598758500695241\n",
      "train loss:0.05191597632415791\n",
      "train loss:0.0740740778737068\n",
      "train loss:0.018712789109327603\n",
      "train loss:0.03253058688846637\n",
      "train loss:0.012526471191644508\n",
      "train loss:0.018523442472346316\n",
      "train loss:0.031729343785920176\n",
      "train loss:0.06001221488714939\n",
      "train loss:0.07984550371391645\n",
      "train loss:0.02266239916646194\n",
      "train loss:0.01989289609209196\n",
      "train loss:0.005971749325177415\n",
      "train loss:0.008263785943420213\n",
      "train loss:0.01939607059924004\n",
      "train loss:0.03228711061818433\n",
      "train loss:0.006637509818330356\n",
      "train loss:0.010152889875565969\n",
      "train loss:0.024006586195507683\n",
      "train loss:0.06145758090475121\n",
      "train loss:0.010313920579109943\n",
      "train loss:0.03486812387821413\n",
      "train loss:0.025492487245202332\n",
      "train loss:0.01898263526183234\n",
      "train loss:0.05249861040967497\n",
      "train loss:0.03209282520641393\n",
      "train loss:0.04063335117044484\n",
      "train loss:0.005301290524203641\n",
      "train loss:0.014980498735451271\n",
      "train loss:0.16110658154732757\n",
      "train loss:0.015418478414705809\n",
      "train loss:0.04228319458680834\n",
      "train loss:0.003272345338084731\n",
      "train loss:0.04944348279221969\n",
      "train loss:0.07006837952307628\n",
      "train loss:0.030638449599446466\n",
      "train loss:0.07835051616350984\n",
      "train loss:0.01700176918517399\n",
      "train loss:0.012170218225995988\n",
      "train loss:0.00819823744347452\n",
      "train loss:0.013829500174545995\n",
      "train loss:0.015984137971087057\n",
      "train loss:0.00651322246822351\n",
      "train loss:0.009420985626952764\n",
      "train loss:0.03348550199935751\n",
      "train loss:0.029152878838553404\n",
      "train loss:0.007599211191671062\n",
      "train loss:0.011763323856554004\n",
      "train loss:0.031437925709290174\n",
      "train loss:0.01375419380626681\n",
      "train loss:0.01674162799961177\n",
      "train loss:0.040203836044808386\n",
      "train loss:0.01090753955830226\n",
      "train loss:0.020791697616294503\n",
      "train loss:0.02186897964993125\n",
      "train loss:0.022637366122031852\n",
      "train loss:0.0677229390802133\n",
      "train loss:0.044062631925720463\n",
      "train loss:0.01691898794337999\n",
      "train loss:0.06434889092534171\n",
      "train loss:0.009387854624196954\n",
      "train loss:0.025174821279053076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03715429880186621\n",
      "train loss:0.023209531851367624\n",
      "train loss:0.030942568136293473\n",
      "train loss:0.0573887951219474\n",
      "train loss:0.010866032552624076\n",
      "train loss:0.006321849291075553\n",
      "train loss:0.008998158280929222\n",
      "train loss:0.013670637198498923\n",
      "train loss:0.007084746379714292\n",
      "train loss:0.009694885065022604\n",
      "train loss:0.003787536988165883\n",
      "train loss:0.02595141248647311\n",
      "train loss:0.012516160813967024\n",
      "train loss:0.007043955987705897\n",
      "train loss:0.011889619174355041\n",
      "train loss:0.011127146327370314\n",
      "train loss:0.08868615027429998\n",
      "train loss:0.018946810504551048\n",
      "train loss:0.007413578873963711\n",
      "train loss:0.0055424302746513\n",
      "train loss:0.01653476524542409\n",
      "train loss:0.008095601252951567\n",
      "train loss:0.02334810632293939\n",
      "train loss:0.0053205939866164875\n",
      "train loss:0.013563671298441986\n",
      "train loss:0.045022182327714905\n",
      "train loss:0.010294099423797583\n",
      "train loss:0.06779774357907509\n",
      "train loss:0.00452831243188865\n",
      "train loss:0.002961472783344015\n",
      "train loss:0.042076288106256715\n",
      "train loss:0.06183673834694628\n",
      "train loss:0.017446337131133433\n",
      "train loss:0.007354289252581959\n",
      "train loss:0.037500414230145676\n",
      "train loss:0.00876305795386526\n",
      "train loss:0.012742471794000393\n",
      "train loss:0.006886360445016949\n",
      "train loss:0.014124764735070537\n",
      "train loss:0.005593600188241482\n",
      "train loss:0.03003284467049069\n",
      "train loss:0.005257802425549157\n",
      "train loss:0.008116321807564577\n",
      "train loss:0.009293856379974775\n",
      "train loss:0.0036632831127860893\n",
      "train loss:0.04704063016809893\n",
      "train loss:0.038776202088461977\n",
      "train loss:0.008370595629361346\n",
      "train loss:0.003979206824128873\n",
      "train loss:0.020171274148851955\n",
      "train loss:0.009313220618048604\n",
      "train loss:0.026659155332746532\n",
      "train loss:0.03634500484288276\n",
      "train loss:0.025678390487352938\n",
      "train loss:0.04115819845199419\n",
      "train loss:0.037540965896648584\n",
      "train loss:0.09457947934847222\n",
      "train loss:0.024134618704515602\n",
      "train loss:0.0036791482115419273\n",
      "train loss:0.008560004982669353\n",
      "train loss:0.016858228935225924\n",
      "train loss:0.012075779587217127\n",
      "train loss:0.016502256437879257\n",
      "train loss:0.03905406555000864\n",
      "train loss:0.006482498127171508\n",
      "train loss:0.06796882685785294\n",
      "train loss:0.10215835933536539\n",
      "train loss:0.025936120179090135\n",
      "train loss:0.029935091945535047\n",
      "train loss:0.03261474192614996\n",
      "train loss:0.017076052404565844\n",
      "train loss:0.04260976975969029\n",
      "train loss:0.043735276702375994\n",
      "train loss:0.03266847918542118\n",
      "train loss:0.008115278599773627\n",
      "train loss:0.05785346677455503\n",
      "train loss:0.023619701418950534\n",
      "train loss:0.07519077459395745\n",
      "train loss:0.03965923649445978\n",
      "train loss:0.00882176789682118\n",
      "train loss:0.03624407825941189\n",
      "train loss:0.04655634251215643\n",
      "train loss:0.017905394277153652\n",
      "train loss:0.05049610839988545\n",
      "train loss:0.06483563707408796\n",
      "train loss:0.026929230866277572\n",
      "train loss:0.04734957079631819\n",
      "train loss:0.009999081765132676\n",
      "train loss:0.014283069090952285\n",
      "=== epoch:7, train acc:0.9914855072463769, test acc:0.9816123188405798 ===\n",
      "train loss:0.05780445281116673\n",
      "train loss:0.009291165328966126\n",
      "train loss:0.03264574465310085\n",
      "train loss:0.008165914550356033\n",
      "train loss:0.008780610201545051\n",
      "train loss:0.038625131166601816\n",
      "train loss:0.012590396301168877\n",
      "train loss:0.02896752319151697\n",
      "train loss:0.009281850836856365\n",
      "train loss:0.03906326839598716\n",
      "train loss:0.0498877606546358\n",
      "train loss:0.032827143130084356\n",
      "train loss:0.010391019684336195\n",
      "train loss:0.01409561151405819\n",
      "train loss:0.038721476768116644\n",
      "train loss:0.01865573255159053\n",
      "train loss:0.007622951198907575\n",
      "train loss:0.013085114781683022\n",
      "train loss:0.006227346943574058\n",
      "train loss:0.012389685090856096\n",
      "train loss:0.007736929200681511\n",
      "train loss:0.03075096483692171\n",
      "train loss:0.007568308832132659\n",
      "train loss:0.008282737379419869\n",
      "train loss:0.013759305463730146\n",
      "train loss:0.010648414862724517\n",
      "train loss:0.01734548264294494\n",
      "train loss:0.020220901115542804\n",
      "train loss:0.0057791931028308985\n",
      "train loss:0.059819281219572966\n",
      "train loss:0.013637915247625396\n",
      "train loss:0.03573278004134461\n",
      "train loss:0.059730890023219935\n",
      "train loss:0.07770093380760497\n",
      "train loss:0.01005127442202085\n",
      "train loss:0.010893287694968138\n",
      "train loss:0.029102260398098115\n",
      "train loss:0.02228829528495879\n",
      "train loss:0.03041521285363623\n",
      "train loss:0.013461201280949468\n",
      "train loss:0.026559475166238848\n",
      "train loss:0.011560729692275144\n",
      "train loss:0.042757091568266854\n",
      "train loss:0.029478700716433295\n",
      "train loss:0.030906143224661543\n",
      "train loss:0.007301394227046591\n",
      "train loss:0.024564938655994597\n",
      "train loss:0.016473380820631336\n",
      "train loss:0.019260673294832022\n",
      "train loss:0.05732893137289979\n",
      "train loss:0.016869330844645106\n",
      "train loss:0.008303627402077839\n",
      "train loss:0.026459394062173687\n",
      "train loss:0.007742481109662944\n",
      "train loss:0.011228969021534157\n",
      "train loss:0.034909953307341826\n",
      "train loss:0.010625604159395419\n",
      "train loss:0.04843350662495392\n",
      "train loss:0.006495426174960887\n",
      "train loss:0.023351714622889208\n",
      "train loss:0.010770368479091559\n",
      "train loss:0.015132037764992714\n",
      "train loss:0.033870790429063956\n",
      "train loss:0.035918940801070894\n",
      "train loss:0.0174092140967025\n",
      "train loss:0.0443498035195031\n",
      "train loss:0.05368211015397846\n",
      "train loss:0.02384049806201648\n",
      "train loss:0.011889637082034514\n",
      "train loss:0.05071182023157817\n",
      "train loss:0.016364742620895874\n",
      "train loss:0.014712734795474644\n",
      "train loss:0.06730713475043326\n",
      "train loss:0.01884938046389795\n",
      "train loss:0.038087734445701994\n",
      "train loss:0.027815933204884704\n",
      "train loss:0.00999565749206312\n",
      "train loss:0.011547771046821946\n",
      "train loss:0.012403315251214807\n",
      "train loss:0.006868182030242868\n",
      "train loss:0.010136138542265739\n",
      "train loss:0.010006667487666042\n",
      "train loss:0.04744727542358184\n",
      "train loss:0.07434775595147193\n",
      "train loss:0.026604305354164037\n",
      "train loss:0.018377420720598434\n",
      "train loss:0.06712420356815395\n",
      "train loss:0.010223933034897818\n",
      "train loss:0.008372875357393702\n",
      "train loss:0.016576311437149494\n",
      "train loss:0.04967988482210579\n",
      "train loss:0.013578227885454852\n",
      "train loss:0.012604844570250413\n",
      "train loss:0.03309145673156438\n",
      "train loss:0.04838827453699804\n",
      "train loss:0.016869904124483085\n",
      "train loss:0.010579509419063418\n",
      "train loss:0.06170168247192594\n",
      "train loss:0.0044867649553637385\n",
      "train loss:0.0068008772642027164\n",
      "train loss:0.03268540358792324\n",
      "train loss:0.006350686618320723\n",
      "train loss:0.009289145513057527\n",
      "train loss:0.005875831955184763\n",
      "train loss:0.01559717336906358\n",
      "train loss:0.020355396687949463\n",
      "train loss:0.011817849892686453\n",
      "train loss:0.009201990521188693\n",
      "train loss:0.0059027316741338265\n",
      "train loss:0.025602507754832658\n",
      "train loss:0.014968989121894571\n",
      "train loss:0.003574102463420348\n",
      "train loss:0.01200332584371767\n",
      "train loss:0.02551971598456079\n",
      "train loss:0.007631730319135357\n",
      "train loss:0.010669749971435485\n",
      "train loss:0.008368891738327146\n",
      "train loss:0.00835504041754284\n",
      "train loss:0.0030519932052158806\n",
      "train loss:0.003920740891770648\n",
      "train loss:0.03850288542212151\n",
      "train loss:0.017593738082640923\n",
      "train loss:0.004394623204464079\n",
      "train loss:0.024004920981866653\n",
      "train loss:0.021547612497240944\n",
      "train loss:0.06171427257108935\n",
      "train loss:0.014242612523189995\n",
      "train loss:0.006186895652830528\n",
      "train loss:0.007007062893132924\n",
      "train loss:0.0033213267424910954\n",
      "train loss:0.0029319902548412017\n",
      "train loss:0.013395039873898807\n",
      "train loss:0.01018004101982996\n",
      "train loss:0.05999749858818772\n",
      "train loss:0.02583678618451254\n",
      "train loss:0.050619662803725075\n",
      "train loss:0.004534169908753146\n",
      "train loss:0.0624598718077242\n",
      "train loss:0.04189912817255385\n",
      "train loss:0.02617537162637318\n",
      "train loss:0.04322813648699501\n",
      "train loss:0.06408688001771594\n",
      "train loss:0.05358298878355925\n",
      "train loss:0.025255532701560366\n",
      "train loss:0.048577455129039014\n",
      "train loss:0.016055847212287214\n",
      "train loss:0.010867923211067719\n",
      "train loss:0.015539505830845391\n",
      "train loss:0.012359729947575076\n",
      "train loss:0.042202106044630414\n",
      "train loss:0.054954706023401356\n",
      "train loss:0.020768929952484663\n",
      "train loss:0.04892830621305437\n",
      "train loss:0.025966204085657953\n",
      "train loss:0.009262279505870446\n",
      "train loss:0.004797024591397184\n",
      "train loss:0.04384683598930085\n",
      "train loss:0.016134031008978065\n",
      "train loss:0.022636486969356162\n",
      "train loss:0.05143047775899654\n",
      "train loss:0.013842624616142274\n",
      "train loss:0.009577545741482806\n",
      "train loss:0.01657068826306787\n",
      "train loss:0.005526840717634801\n",
      "train loss:0.004665272348878328\n",
      "train loss:0.03138599682341057\n",
      "train loss:0.005148641506993907\n",
      "train loss:0.02253445013811047\n",
      "train loss:0.011570298338051599\n",
      "train loss:0.013529071151153881\n",
      "train loss:0.004376299727652033\n",
      "train loss:0.025013861148455174\n",
      "train loss:0.029206756165336592\n",
      "train loss:0.013052110624424844\n",
      "train loss:0.0039022999725848015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006730184388928347\n",
      "train loss:0.0059365318997123264\n",
      "train loss:0.025502700377681986\n",
      "train loss:0.005402765715259894\n",
      "train loss:0.009448438097566502\n",
      "train loss:0.012324214144657316\n",
      "train loss:0.0028978728664618525\n",
      "train loss:0.00719130411703421\n",
      "train loss:0.031889773250972676\n",
      "train loss:0.01846376012909725\n",
      "train loss:0.013745393179322283\n",
      "train loss:0.027021692982783133\n",
      "train loss:0.025088764296506316\n",
      "train loss:0.0032149532895965976\n",
      "train loss:0.016231692642110912\n",
      "train loss:0.03754554931477569\n",
      "train loss:0.02413701911794226\n",
      "train loss:0.05100635925457653\n",
      "train loss:0.014347725398343957\n",
      "train loss:0.0037789516368748667\n",
      "train loss:0.01709831946577663\n",
      "train loss:0.030829807018596486\n",
      "train loss:0.05972225491633384\n",
      "train loss:0.003657848986156445\n",
      "train loss:0.023256579681833364\n",
      "train loss:0.011746442497233608\n",
      "train loss:0.019629131719709533\n",
      "train loss:0.034439943545362214\n",
      "train loss:0.011100936360414756\n",
      "train loss:0.012401027236488987\n",
      "train loss:0.004579747072031247\n",
      "train loss:0.031986060546984114\n",
      "train loss:0.009192389354140691\n",
      "train loss:0.0032450806010756003\n",
      "train loss:0.02029659851845814\n",
      "train loss:0.021950384381735837\n",
      "train loss:0.002425285428327442\n",
      "train loss:0.008772302120878019\n",
      "train loss:0.0014163823049001929\n",
      "train loss:0.012942997511200899\n",
      "train loss:0.02078910515434881\n",
      "train loss:0.02208844516184368\n",
      "train loss:0.021120188769691815\n",
      "train loss:0.016029741546763857\n",
      "train loss:0.008613204363210733\n",
      "train loss:0.02319440357241709\n",
      "train loss:0.03309608540846517\n",
      "train loss:0.033716870852175326\n",
      "train loss:0.009916618078835825\n",
      "train loss:0.020782541898497972\n",
      "train loss:0.0031590019733243806\n",
      "train loss:0.02106000641348664\n",
      "train loss:0.02998399271139077\n",
      "train loss:0.041056504350765397\n",
      "train loss:0.050158753238349015\n",
      "train loss:0.015674317209541055\n",
      "train loss:0.014359417313995319\n",
      "train loss:0.00374081245923701\n",
      "train loss:0.01284747395922009\n",
      "train loss:0.011686439718667596\n",
      "train loss:0.0075306037215288855\n",
      "train loss:0.01853705805649906\n",
      "train loss:0.009540002734750823\n",
      "train loss:0.03596481791562651\n",
      "train loss:0.03175204662902723\n",
      "train loss:0.004928254898856044\n",
      "train loss:0.008613978689137502\n",
      "train loss:0.04804433853963888\n",
      "train loss:0.020068003689815445\n",
      "train loss:0.007234340546918678\n",
      "train loss:0.03359986029026503\n",
      "train loss:0.014387577662385269\n",
      "train loss:0.008912495701110301\n",
      "train loss:0.005534833555002278\n",
      "train loss:0.011327330538564407\n",
      "train loss:0.00824522841487393\n",
      "train loss:0.0019360712232986419\n",
      "train loss:0.012583736718853813\n",
      "train loss:0.07969732891817373\n",
      "train loss:0.013609494234564114\n",
      "train loss:0.008655811190924227\n",
      "train loss:0.013241467728808557\n",
      "train loss:0.007350637281883197\n",
      "train loss:0.04480610786142051\n",
      "train loss:0.009540535087795314\n",
      "train loss:0.025254683803826793\n",
      "train loss:0.026249183156124237\n",
      "train loss:0.03152016991925487\n",
      "train loss:0.014444131722151076\n",
      "train loss:0.039660107245758296\n",
      "train loss:0.007198968602521965\n",
      "train loss:0.012442310771382631\n",
      "train loss:0.02359136955210174\n",
      "train loss:0.015172152389598384\n",
      "train loss:0.021759817959294308\n",
      "train loss:0.003803788779839091\n",
      "train loss:0.014077735265622235\n",
      "train loss:0.01161222997022685\n",
      "train loss:0.00784702479373344\n",
      "train loss:0.002487440613102566\n",
      "train loss:0.0053438714183307425\n",
      "train loss:0.013504960226308437\n",
      "train loss:0.003097470388322332\n",
      "train loss:0.0023079185485143983\n",
      "train loss:0.008175267792361844\n",
      "train loss:0.035191554229779\n",
      "train loss:0.03172696548537186\n",
      "train loss:0.003758247147698367\n",
      "train loss:0.0056791793341941805\n",
      "train loss:0.012782550259843947\n",
      "train loss:0.012558362026401641\n",
      "train loss:0.015201281579089712\n",
      "train loss:0.002057926620810275\n",
      "train loss:0.011853750571458743\n",
      "train loss:0.022445344699358785\n",
      "train loss:0.004573707418425511\n",
      "train loss:0.03538483299058604\n",
      "train loss:0.020909259267592815\n",
      "train loss:0.039554458381749126\n",
      "train loss:0.02716006482749752\n",
      "train loss:0.012584920120139408\n",
      "train loss:0.011146123180664994\n",
      "train loss:0.041439525210742664\n",
      "train loss:0.004229035688299224\n",
      "train loss:0.008998432988048043\n",
      "train loss:0.014188581510227226\n",
      "train loss:0.01342735659499596\n",
      "train loss:0.014112020794220142\n",
      "train loss:0.05631917613105539\n",
      "train loss:0.02767650046881783\n",
      "train loss:0.002843421484506517\n",
      "train loss:0.0162672669474666\n",
      "train loss:0.009009093479686753\n",
      "train loss:0.03224137037915271\n",
      "train loss:0.037700928213016495\n",
      "train loss:0.029493658031068147\n",
      "train loss:0.01409201076568377\n",
      "train loss:0.006539117462187014\n",
      "train loss:0.013445052690533612\n",
      "train loss:0.035640098864788965\n",
      "train loss:0.027659205852940474\n",
      "train loss:0.004842014632487704\n",
      "train loss:0.04512533430374876\n",
      "train loss:0.018353290226876557\n",
      "train loss:0.02988861560874297\n",
      "train loss:0.023161658492400795\n",
      "train loss:0.018946337816903216\n",
      "train loss:0.04397101401700052\n",
      "train loss:0.01232018935778032\n",
      "train loss:0.012238340855212993\n",
      "train loss:0.0357527837660609\n",
      "train loss:0.006171794933600111\n",
      "train loss:0.010378408805396887\n",
      "train loss:0.006232739944811391\n",
      "train loss:0.04167004914294538\n",
      "train loss:0.006702536380194775\n",
      "train loss:0.011670816174230235\n",
      "train loss:0.017027155154237694\n",
      "train loss:0.004005600472642359\n",
      "train loss:0.007812750027757569\n",
      "train loss:0.009257420753224443\n",
      "train loss:0.024128290447882984\n",
      "train loss:0.00979558040140995\n",
      "train loss:0.019015079204112217\n",
      "train loss:0.043777692507002745\n",
      "train loss:0.006842383462702292\n",
      "train loss:0.004863488934555044\n",
      "train loss:0.023121178654931903\n",
      "train loss:0.027335389104680537\n",
      "train loss:0.007743487338227299\n",
      "train loss:0.005815266678027165\n",
      "train loss:0.0077440167096984\n",
      "train loss:0.04037489310881104\n",
      "train loss:0.07301357366041712\n",
      "train loss:0.0057703026921381104\n",
      "train loss:0.001448521694172658\n",
      "train loss:0.004129591719611368\n",
      "train loss:0.039420704265089715\n",
      "train loss:0.010374300659556699\n",
      "train loss:0.011856683675783465\n",
      "train loss:0.006945535158032815\n",
      "train loss:0.004913323514380117\n",
      "train loss:0.049545355112046975\n",
      "train loss:0.047494356422618206\n",
      "train loss:0.007912936473242234\n",
      "train loss:0.016883022566328423\n",
      "train loss:0.00812894772371911\n",
      "train loss:0.01669541673740503\n",
      "train loss:0.008496873302836208\n",
      "train loss:0.03214414683487563\n",
      "train loss:0.007577601294770862\n",
      "train loss:0.012325738717224958\n",
      "train loss:0.03449351828334314\n",
      "=== epoch:8, train acc:0.9939764492753623, test acc:0.9852355072463768 ===\n",
      "train loss:0.017793060088772957\n",
      "train loss:0.01989380118155115\n",
      "train loss:0.00616442943830241\n",
      "train loss:0.015861984263852994\n",
      "train loss:0.006881575022358298\n",
      "train loss:0.04697338852924267\n",
      "train loss:0.025474073588558344\n",
      "train loss:0.016861736604880027\n",
      "train loss:0.00396680174364488\n",
      "train loss:0.006179822120246914\n",
      "train loss:0.008583971312686527\n",
      "train loss:0.0073163879250010555\n",
      "train loss:0.01026894942368836\n",
      "train loss:0.003892622869329495\n",
      "train loss:0.018579128180753815\n",
      "train loss:0.033783480284908206\n",
      "train loss:0.022958407077445283\n",
      "train loss:0.007138110829094854\n",
      "train loss:0.014621996079721209\n",
      "train loss:0.008980672402307599\n",
      "train loss:0.012995667595806806\n",
      "train loss:0.006638258747045069\n",
      "train loss:0.05123555638016533\n",
      "train loss:0.016053166204663138\n",
      "train loss:0.002052484278036308\n",
      "train loss:0.022937798545433163\n",
      "train loss:0.0061276314607235744\n",
      "train loss:0.008020312717436614\n",
      "train loss:0.011178642895981408\n",
      "train loss:0.01136335617919049\n",
      "train loss:0.029995548738696455\n",
      "train loss:0.00572711186249651\n",
      "train loss:0.03222845761912159\n",
      "train loss:0.016431144815905775\n",
      "train loss:0.020106141458951034\n",
      "train loss:0.04709206593275759\n",
      "train loss:0.015879950009173527\n",
      "train loss:0.01090177697743907\n",
      "train loss:0.026277192311873903\n",
      "train loss:0.01648999100908494\n",
      "train loss:0.03073744830522042\n",
      "train loss:0.019559909648996524\n",
      "train loss:0.0706738436824623\n",
      "train loss:0.03389832032900886\n",
      "train loss:0.0334453108017424\n",
      "train loss:0.010129421389437808\n",
      "train loss:0.011787521631602354\n",
      "train loss:0.0524484733540074\n",
      "train loss:0.008159075642641789\n",
      "train loss:0.0019042511935915473\n",
      "train loss:0.04779880442517213\n",
      "train loss:0.017671734895373933\n",
      "train loss:0.007316230809005048\n",
      "train loss:0.01708464167250637\n",
      "train loss:0.002559994534668721\n",
      "train loss:0.02382220939370554\n",
      "train loss:0.0121279446470481\n",
      "train loss:0.012308198416607357\n",
      "train loss:0.010506083273336636\n",
      "train loss:0.005922858917153283\n",
      "train loss:0.01817382635791981\n",
      "train loss:0.0167178418213751\n",
      "train loss:0.013570378724933113\n",
      "train loss:0.03584075163338487\n",
      "train loss:0.049621291999289115\n",
      "train loss:0.043963720931187805\n",
      "train loss:0.013860884626960486\n",
      "train loss:0.008837208464735392\n",
      "train loss:0.01827536505668487\n",
      "train loss:0.04729991108874545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026305349294652353\n",
      "train loss:0.0182391485640631\n",
      "train loss:0.009413945214662912\n",
      "train loss:0.02530510774950077\n",
      "train loss:0.004726193997584362\n",
      "train loss:0.02917721050514683\n",
      "train loss:0.008315189764917715\n",
      "train loss:0.006734046631429023\n",
      "train loss:0.03854227927314912\n",
      "train loss:0.015654312598969742\n",
      "train loss:0.01023089579561594\n",
      "train loss:0.011542058282996674\n",
      "train loss:0.006865672285781886\n",
      "train loss:0.06753035423763035\n",
      "train loss:0.0064326292889748445\n",
      "train loss:0.012091822597334689\n",
      "train loss:0.019928490747968954\n",
      "train loss:0.015670315242924678\n",
      "train loss:0.017004153009468743\n",
      "train loss:0.00468198904584014\n",
      "train loss:0.004249054521791561\n",
      "train loss:0.008617935206453993\n",
      "train loss:0.01412955093194426\n",
      "train loss:0.027432423496340144\n",
      "train loss:0.02991421023587424\n",
      "train loss:0.035578433185075344\n",
      "train loss:0.041186718508371974\n",
      "train loss:0.009069335269841765\n",
      "train loss:0.03191102549271382\n",
      "train loss:0.011771504691153003\n",
      "train loss:0.01278958663519878\n",
      "train loss:0.06743638776507567\n",
      "train loss:0.008734530900422973\n",
      "train loss:0.024569461355653358\n",
      "train loss:0.021633740669426128\n",
      "train loss:0.00387827209407895\n",
      "train loss:0.02289508239034945\n",
      "train loss:0.01139964808556413\n",
      "train loss:0.005710953933594043\n",
      "train loss:0.004331166034452312\n",
      "train loss:0.008375022033152785\n",
      "train loss:0.03545990730533726\n",
      "train loss:0.031910224626031956\n",
      "train loss:0.0096455920777287\n",
      "train loss:0.004366808490608228\n",
      "train loss:0.019834672416217006\n",
      "train loss:0.009382466352396037\n",
      "train loss:0.00571479979392439\n",
      "train loss:0.006771351909037034\n",
      "train loss:0.007365289217964152\n",
      "train loss:0.04925902137335087\n",
      "train loss:0.030308799142057818\n",
      "train loss:0.006468493818397582\n",
      "train loss:0.00723992277105609\n",
      "train loss:0.05128971139821313\n",
      "train loss:0.011518888113969337\n",
      "train loss:0.008785925485393612\n",
      "train loss:0.012511983735631282\n",
      "train loss:0.04397405472511033\n",
      "train loss:0.02568132879438122\n",
      "train loss:0.002807643540551294\n",
      "train loss:0.03003820608828339\n",
      "train loss:0.012129228722979231\n",
      "train loss:0.009413069199312693\n",
      "train loss:0.030711021336097384\n",
      "train loss:0.04177260406018236\n",
      "train loss:0.022049486386491186\n",
      "train loss:0.006532709246338869\n",
      "train loss:0.05031839317256467\n",
      "train loss:0.05125031251471865\n",
      "train loss:0.0030898036028170327\n",
      "train loss:0.011551038396483545\n",
      "train loss:0.011519731470290144\n",
      "train loss:0.01858769548316591\n",
      "train loss:0.026940233692989472\n",
      "train loss:0.004037651062462881\n",
      "train loss:0.0026498403606109544\n",
      "train loss:0.007189835914214782\n",
      "train loss:0.009285730209502241\n",
      "train loss:0.006977773507994489\n",
      "train loss:0.01661973841607259\n",
      "train loss:0.026352033966279758\n",
      "train loss:0.028949879811790154\n",
      "train loss:0.020236758071423853\n",
      "train loss:0.011993523404099586\n",
      "train loss:0.008403844930468416\n",
      "train loss:0.002959188393303074\n",
      "train loss:0.013406279936011593\n",
      "train loss:0.0056210057293357525\n",
      "train loss:0.007367146033548451\n",
      "train loss:0.01852734923541372\n",
      "train loss:0.004927662062938226\n",
      "train loss:0.007630688177346907\n",
      "train loss:0.03451470702317707\n",
      "train loss:0.013418525338261862\n",
      "train loss:0.03395308347564731\n",
      "train loss:0.006572761379778637\n",
      "train loss:0.005765313977553497\n",
      "train loss:0.008756770457024355\n",
      "train loss:0.006435025536999007\n",
      "train loss:0.015638481341748105\n",
      "train loss:0.00956695755278564\n",
      "train loss:0.01580947749333498\n",
      "train loss:0.018369364215326704\n",
      "train loss:0.006200381592803047\n",
      "train loss:0.05949976115666707\n",
      "train loss:0.0044537801707907184\n",
      "train loss:0.016898640795209398\n",
      "train loss:0.02820101255218224\n",
      "train loss:0.012094881836729687\n",
      "train loss:0.009506170758606883\n",
      "train loss:0.008597880067813342\n",
      "train loss:0.02657140527679313\n",
      "train loss:0.004066161965786935\n",
      "train loss:0.03967874396372505\n",
      "train loss:0.005796933999636977\n",
      "train loss:0.0031213576671477385\n",
      "train loss:0.026649987124514808\n",
      "train loss:0.007088364193010482\n",
      "train loss:0.06840494273814915\n",
      "train loss:0.01423106033717178\n",
      "train loss:0.03255592670518044\n",
      "train loss:0.021372179498799528\n",
      "train loss:0.007854432119993811\n",
      "train loss:0.01207560428197743\n",
      "train loss:0.006982943303460063\n",
      "train loss:0.007335686215547682\n",
      "train loss:0.00404622653710918\n",
      "train loss:0.0075643238125723935\n",
      "train loss:0.03728351002203194\n",
      "train loss:0.018510490161658885\n",
      "train loss:0.004826146660030466\n",
      "train loss:0.011295420041310547\n",
      "train loss:0.008327327334711775\n",
      "train loss:0.06406524113397526\n",
      "train loss:0.02023850827343338\n",
      "train loss:0.04351906557406459\n",
      "train loss:0.01109114366505098\n",
      "train loss:0.0218004891212159\n",
      "train loss:0.018635391811764344\n",
      "train loss:0.015489074639493533\n",
      "train loss:0.011982859646363697\n",
      "train loss:0.0030736337405625116\n",
      "train loss:0.013453630062201705\n",
      "train loss:0.011807179862309\n",
      "train loss:0.016415382896738582\n",
      "train loss:0.012180444415540203\n",
      "train loss:0.005203962010542411\n",
      "train loss:0.005858164295123809\n",
      "train loss:0.0024904216586415996\n",
      "train loss:0.011465341829346935\n",
      "train loss:0.0032290850710020697\n",
      "train loss:0.0029693267840092516\n",
      "train loss:0.002748274657178211\n",
      "train loss:0.006520223198394794\n",
      "train loss:0.019270780681625608\n",
      "train loss:0.004401647036606606\n",
      "train loss:0.008701920737571776\n",
      "train loss:0.010625742288027009\n",
      "train loss:0.007109437532484231\n",
      "train loss:0.0063572737790079745\n",
      "train loss:0.0031571707554423753\n",
      "train loss:0.004871956904159142\n",
      "train loss:0.013170241623500062\n",
      "train loss:0.017676902187335863\n",
      "train loss:0.02043381571004414\n",
      "train loss:0.0158618404214987\n",
      "train loss:0.0034861816840917764\n",
      "train loss:0.0007523707631750867\n",
      "train loss:0.002751695948733149\n",
      "train loss:0.007595946222871365\n",
      "train loss:0.05409101792708371\n",
      "train loss:0.006601060923205155\n",
      "train loss:0.00864224360374417\n",
      "train loss:0.008195304331539272\n",
      "train loss:0.03642236945925829\n",
      "train loss:0.031395697263458075\n",
      "train loss:0.035630954450714854\n",
      "train loss:0.00808290937327725\n",
      "train loss:0.004589186337246342\n",
      "train loss:0.02530148579893822\n",
      "train loss:0.034639324950054125\n",
      "train loss:0.017294541022996858\n",
      "train loss:0.016423838097324114\n",
      "train loss:0.04830227328003311\n",
      "train loss:0.005800761303848252\n",
      "train loss:0.051831805400693445\n",
      "train loss:0.00819902799804393\n",
      "train loss:0.016401912577054274\n",
      "train loss:0.02763822809097128\n",
      "train loss:0.00697772178770627\n",
      "train loss:0.03382043900667617\n",
      "train loss:0.02400418589422557\n",
      "train loss:0.006323451756757496\n",
      "train loss:0.061990232018414027\n",
      "train loss:0.0036138230881579093\n",
      "train loss:0.004893130703307334\n",
      "train loss:0.007992747959492806\n",
      "train loss:0.0016994084015411193\n",
      "train loss:0.009186348088285385\n",
      "train loss:0.047461974786853926\n",
      "train loss:0.015059223903772068\n",
      "train loss:0.016117647248859755\n",
      "train loss:0.003121128902567238\n",
      "train loss:0.02872472098967461\n",
      "train loss:0.009421408130422061\n",
      "train loss:0.0037104918043952195\n",
      "train loss:0.016809311469962406\n",
      "train loss:0.025164538319765773\n",
      "train loss:0.011680296494034589\n",
      "train loss:0.009579652500910663\n",
      "train loss:0.005191813599368596\n",
      "train loss:0.01638900894786041\n",
      "train loss:0.004706539959609119\n",
      "train loss:0.01737703214217166\n",
      "train loss:0.04552263169254834\n",
      "train loss:0.01074924276172847\n",
      "train loss:0.01748754378305688\n",
      "train loss:0.008388957577103062\n",
      "train loss:0.006695841838610247\n",
      "train loss:0.015022728325832206\n",
      "train loss:0.015978020201971466\n",
      "train loss:0.005776703806855937\n",
      "train loss:0.011856851452559942\n",
      "train loss:0.0083944233134153\n",
      "train loss:0.026563889550610367\n",
      "train loss:0.0021411608784446044\n",
      "train loss:0.009218339993014154\n",
      "train loss:0.0435377809193788\n",
      "train loss:0.02329861194282015\n",
      "train loss:0.0024350815735445968\n",
      "train loss:0.021910263117996806\n",
      "train loss:0.007636996121530533\n",
      "train loss:0.011881377262442655\n",
      "train loss:0.006568788744801596\n",
      "train loss:0.027709084389702716\n",
      "train loss:0.017880425421655775\n",
      "train loss:0.02595845305671818\n",
      "train loss:0.013217274134645162\n",
      "train loss:0.0018086835409416935\n",
      "train loss:0.09376997889494837\n",
      "train loss:0.006126794120986147\n",
      "train loss:0.003499925659996553\n",
      "train loss:0.006825230001789828\n",
      "train loss:0.015123637528884449\n",
      "train loss:0.021169419717058168\n",
      "train loss:0.024276278158249842\n",
      "train loss:0.005879077064448018\n",
      "train loss:0.003426026117866977\n",
      "train loss:0.0033058826509283186\n",
      "train loss:0.001824566238646599\n",
      "train loss:0.011830958682492971\n",
      "train loss:0.008218859052633828\n",
      "train loss:0.027986492249093897\n",
      "train loss:0.029565919930059394\n",
      "train loss:0.027423639228271523\n",
      "train loss:0.0557047093318226\n",
      "train loss:0.014320845724350401\n",
      "train loss:0.006974502641259162\n",
      "train loss:0.005359927015766898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02625828201997159\n",
      "train loss:0.0036039469982610305\n",
      "train loss:0.030123319060607532\n",
      "train loss:0.0077327199832353775\n",
      "train loss:0.00410215208857929\n",
      "train loss:0.01752404193989141\n",
      "train loss:0.008295661697762767\n",
      "train loss:0.011247521586717124\n",
      "train loss:0.014687943918753455\n",
      "train loss:0.002985522277273493\n",
      "train loss:0.001777175546134276\n",
      "train loss:0.011387049129421305\n",
      "train loss:0.023208257520727426\n",
      "train loss:0.029845738954792568\n",
      "train loss:0.004636484654481118\n",
      "train loss:0.025068428797629782\n",
      "train loss:0.0177556438563947\n",
      "train loss:0.0023616834514875213\n",
      "train loss:0.0022465669432134693\n",
      "train loss:0.01621440041249563\n",
      "train loss:0.02006196845045761\n",
      "train loss:0.008786154172382562\n",
      "train loss:0.00369495657073957\n",
      "train loss:0.01433661271335914\n",
      "train loss:0.02932455612641841\n",
      "train loss:0.0024340432837835686\n",
      "train loss:0.0017424176531780071\n",
      "train loss:0.003546611066150551\n",
      "train loss:0.02203962496914606\n",
      "train loss:0.004686511861679058\n",
      "train loss:0.014850098902643345\n",
      "train loss:0.027720700003526343\n",
      "train loss:0.006914507726464458\n",
      "train loss:0.006864259627575467\n",
      "train loss:0.03717768504007845\n",
      "train loss:0.013374182909954197\n",
      "train loss:0.0076578448190490166\n",
      "train loss:0.01905902821017208\n",
      "=== epoch:9, train acc:0.994338768115942, test acc:0.9856884057971015 ===\n",
      "train loss:0.0016561918436828603\n",
      "train loss:0.004452640198876613\n",
      "train loss:0.001864971195453762\n",
      "train loss:0.023473657475901445\n",
      "train loss:0.009282719743116194\n",
      "train loss:0.005589732850553614\n",
      "train loss:0.01142049697623528\n",
      "train loss:0.002469799479377943\n",
      "train loss:0.0031916831600049176\n",
      "train loss:0.0019909864572302104\n",
      "train loss:0.014977969081251692\n",
      "train loss:0.03439001590055614\n",
      "train loss:0.004986229230819511\n",
      "train loss:0.013721955219060562\n",
      "train loss:0.0039223339242982665\n",
      "train loss:0.006869537474458372\n",
      "train loss:0.024910008840563356\n",
      "train loss:0.030772789526480524\n",
      "train loss:0.013953957897574613\n",
      "train loss:0.03351891201255887\n",
      "train loss:0.020700256191780245\n",
      "train loss:0.008489461199669973\n",
      "train loss:0.023751189600000618\n",
      "train loss:0.003575773692573002\n",
      "train loss:0.007134481339920501\n",
      "train loss:0.012457825042230863\n",
      "train loss:0.005410957897669127\n",
      "train loss:0.022266211585655248\n",
      "train loss:0.014768556217850119\n",
      "train loss:0.025270711272773857\n",
      "train loss:0.01204514308119851\n",
      "train loss:0.02107839400802946\n",
      "train loss:0.01577409980574908\n",
      "train loss:0.010970152819494504\n",
      "train loss:0.02061342940138187\n",
      "train loss:0.009927600100496141\n",
      "train loss:0.015038274073182959\n",
      "train loss:0.009095286842703476\n",
      "train loss:0.030597591624632034\n",
      "train loss:0.006512921442660384\n",
      "train loss:0.024903025703221403\n",
      "train loss:0.023510955407680837\n",
      "train loss:0.037278936788403876\n",
      "train loss:0.00445686096321228\n",
      "train loss:0.0638745702794192\n",
      "train loss:0.003278298614190359\n",
      "train loss:0.012449918434043496\n",
      "train loss:0.0402149308468579\n",
      "train loss:0.005539895909304856\n",
      "train loss:0.005323517987113415\n",
      "train loss:0.003080845483774463\n",
      "train loss:0.02445075913259797\n",
      "train loss:0.018920118848169583\n",
      "train loss:0.008081038300966802\n",
      "train loss:0.02390391086539612\n",
      "train loss:0.05154609163411989\n",
      "train loss:0.002913153287692674\n",
      "train loss:0.04795513346905643\n",
      "train loss:0.035901381371392246\n",
      "train loss:0.003761984496100588\n",
      "train loss:0.0033807989252608696\n",
      "train loss:0.012534049961644278\n",
      "train loss:0.0026785768848741343\n",
      "train loss:0.008633883709394117\n",
      "train loss:0.016371871843931744\n",
      "train loss:0.036119113451997954\n",
      "train loss:0.00821250274740783\n",
      "train loss:0.018761876206778116\n",
      "train loss:0.01940306657618657\n",
      "train loss:0.0077172125190821525\n",
      "train loss:0.04156098157148488\n",
      "train loss:0.014782459053134179\n",
      "train loss:0.004193568664080998\n",
      "train loss:0.009904950398341963\n",
      "train loss:0.006350770574368816\n",
      "train loss:0.008509649104253721\n",
      "train loss:0.035630802609958365\n",
      "train loss:0.00727848578716588\n",
      "train loss:0.0307789694939964\n",
      "train loss:0.001973970923119886\n",
      "train loss:0.0035812733098663754\n",
      "train loss:0.00449989773815246\n",
      "train loss:0.03192385984457662\n",
      "train loss:0.004502630590537289\n",
      "train loss:0.055799937249883885\n",
      "train loss:0.0038715714745510637\n",
      "train loss:0.023079449858018682\n",
      "train loss:0.00918619914396995\n",
      "train loss:0.0059540469694175785\n",
      "train loss:0.0018227089996110978\n",
      "train loss:0.006892817417363404\n",
      "train loss:0.014876491922844303\n",
      "train loss:0.009342537081268419\n",
      "train loss:0.0045190931455727345\n",
      "train loss:0.0015409712363178279\n",
      "train loss:0.03180285755557454\n",
      "train loss:0.01432571574184434\n",
      "train loss:0.0016633368042163123\n",
      "train loss:0.006233069894262818\n",
      "train loss:0.004716018309749876\n",
      "train loss:0.01213312561034394\n",
      "train loss:0.0015227209817601029\n",
      "train loss:0.018876168883936048\n",
      "train loss:0.002808679956405553\n",
      "train loss:0.028337674529021774\n",
      "train loss:0.0026705107955921556\n",
      "train loss:0.003738451687766085\n",
      "train loss:0.009088533716769504\n",
      "train loss:0.009684256486571787\n",
      "train loss:0.03100384327307694\n",
      "train loss:0.00328253917400409\n",
      "train loss:0.027445153447333004\n",
      "train loss:0.014284837479835728\n",
      "train loss:0.004802951113154669\n",
      "train loss:0.0040908800494846905\n",
      "train loss:0.014282238429722871\n",
      "train loss:0.03489914485531427\n",
      "train loss:0.003964535757271287\n",
      "train loss:0.04168062358644875\n",
      "train loss:0.005283146136339995\n",
      "train loss:0.0032173173050665297\n",
      "train loss:0.02917145159434608\n",
      "train loss:0.011829377067485118\n",
      "train loss:0.006002055352194979\n",
      "train loss:0.006340206272972841\n",
      "train loss:0.001549368719803019\n",
      "train loss:0.005046886645785004\n",
      "train loss:0.00287858481425157\n",
      "train loss:0.0022135995363919787\n",
      "train loss:0.011507344398166829\n",
      "train loss:0.0024955344676189438\n",
      "train loss:0.017614653029690956\n",
      "train loss:0.016147147129340008\n",
      "train loss:0.009623995080627829\n",
      "train loss:0.019947301555900472\n",
      "train loss:0.007973392650317431\n",
      "train loss:0.008687383986778584\n",
      "train loss:0.04418284853685942\n",
      "train loss:0.012858079299951744\n",
      "train loss:0.02480689007436884\n",
      "train loss:0.012871445585131118\n",
      "train loss:0.01486871280726799\n",
      "train loss:0.021152285606318624\n",
      "train loss:0.03959022428640469\n",
      "train loss:0.025367995997728463\n",
      "train loss:0.018254492290010946\n",
      "train loss:0.0029209591722418405\n",
      "train loss:0.0038245303460651904\n",
      "train loss:0.004549983147269978\n",
      "train loss:0.006087218225903122\n",
      "train loss:0.009185207620174156\n",
      "train loss:0.002617468284561703\n",
      "train loss:0.017648140167740238\n",
      "train loss:0.007480796039171872\n",
      "train loss:0.018452466097742717\n",
      "train loss:0.006338848762569131\n",
      "train loss:0.005603545158845511\n",
      "train loss:0.0065044927524108166\n",
      "train loss:0.011772734869224\n",
      "train loss:0.005172775037200335\n",
      "train loss:0.024171120112655327\n",
      "train loss:0.018816922203128264\n",
      "train loss:0.006091497965814233\n",
      "train loss:0.00895993448414445\n",
      "train loss:0.011057688679520627\n",
      "train loss:0.05500306585543217\n",
      "train loss:0.009080472953737663\n",
      "train loss:0.003747793870649041\n",
      "train loss:0.005159238139004994\n",
      "train loss:0.009855636879079577\n",
      "train loss:0.0020428621324796266\n",
      "train loss:0.005866316548786035\n",
      "train loss:0.05810249739795352\n",
      "train loss:0.03191353925291162\n",
      "train loss:0.050786492630318654\n",
      "train loss:0.0070620240156499545\n",
      "train loss:0.012705019101683061\n",
      "train loss:0.002745800672266761\n",
      "train loss:0.018995344825477777\n",
      "train loss:0.00319755127002114\n",
      "train loss:0.0010727140221561487\n",
      "train loss:0.03505730859407968\n",
      "train loss:0.044954097078593595\n",
      "train loss:0.014271723788383846\n",
      "train loss:0.00868331259735078\n",
      "train loss:0.002715496848233128\n",
      "train loss:0.00625161584205533\n",
      "train loss:0.032974749313124295\n",
      "train loss:0.045333572318740606\n",
      "train loss:0.01206058724641283\n",
      "train loss:0.002370730669467967\n",
      "train loss:0.002756049967099811\n",
      "train loss:0.011308016278630931\n",
      "train loss:0.009557379330636058\n",
      "train loss:0.057645078447020937\n",
      "train loss:0.01244886282572468\n",
      "train loss:0.022603145765268392\n",
      "train loss:0.003306676514241791\n",
      "train loss:0.0025558136658594415\n",
      "train loss:0.00258704062369896\n",
      "train loss:0.01687931488562119\n",
      "train loss:0.003438164959581751\n",
      "train loss:0.04310612685655189\n",
      "train loss:0.01432297992372427\n",
      "train loss:0.006365230481025132\n",
      "train loss:0.005020187893746462\n",
      "train loss:0.01901577817270937\n",
      "train loss:0.010554194164097478\n",
      "train loss:0.018917615092266988\n",
      "train loss:0.03450588578257431\n",
      "train loss:0.0104062952119779\n",
      "train loss:0.0012794718834750578\n",
      "train loss:0.03413410464163\n",
      "train loss:0.014504907417797268\n",
      "train loss:0.00733493400280247\n",
      "train loss:0.02457729622501809\n",
      "train loss:0.00567227999175898\n",
      "train loss:0.007167434116749313\n",
      "train loss:0.01542838897233439\n",
      "train loss:0.0222285289118741\n",
      "train loss:0.01568527682269535\n",
      "train loss:0.01792683659368451\n",
      "train loss:0.012918551295701939\n",
      "train loss:0.00862465665749266\n",
      "train loss:0.002366421555869931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007254898115519915\n",
      "train loss:0.04791545604133064\n",
      "train loss:0.005259747547170641\n",
      "train loss:0.010069031230449232\n",
      "train loss:0.03243007559196816\n",
      "train loss:0.021972392925211914\n",
      "train loss:0.0024357082189034726\n",
      "train loss:0.0020990098445776524\n",
      "train loss:0.002916746149808208\n",
      "train loss:0.0024789691522250096\n",
      "train loss:0.002264527930568257\n",
      "train loss:0.006797809082049433\n",
      "train loss:0.008113607655413793\n",
      "train loss:0.02652683709957428\n",
      "train loss:0.030632114700750546\n",
      "train loss:0.00467390144513567\n",
      "train loss:0.019286922615804947\n",
      "train loss:0.01784317038055648\n",
      "train loss:0.038506124916641335\n",
      "train loss:0.019887813972285607\n",
      "train loss:0.08452485317347162\n",
      "train loss:0.003940655791218503\n",
      "train loss:0.014130967062700395\n",
      "train loss:0.022039248915359317\n",
      "train loss:0.017694743751973066\n",
      "train loss:0.015293692821471508\n",
      "train loss:0.06057111391272262\n",
      "train loss:0.0419905479905563\n",
      "train loss:0.01672064426691248\n",
      "train loss:0.011864279423935585\n",
      "train loss:0.003877617076127137\n",
      "train loss:0.010416785990690814\n",
      "train loss:0.021710142835943736\n",
      "train loss:0.028962690286520022\n",
      "train loss:0.009411542096055622\n",
      "train loss:0.02555803657806325\n",
      "train loss:0.006405772360892204\n",
      "train loss:0.010240121042452654\n",
      "train loss:0.009584732788895767\n",
      "train loss:0.02515109741195772\n",
      "train loss:0.0034504700999455776\n",
      "train loss:0.020340079182345403\n",
      "train loss:0.01857376516407093\n",
      "train loss:0.03292050776194896\n",
      "train loss:0.014501543059202277\n",
      "train loss:0.008656162653135617\n",
      "train loss:0.01039210209426395\n",
      "train loss:0.004086727033366619\n",
      "train loss:0.019263544803614332\n",
      "train loss:0.004238058278314594\n",
      "train loss:0.023627994748666076\n",
      "train loss:0.04973110741867442\n",
      "train loss:0.002488669634773012\n",
      "train loss:0.006064240276769964\n",
      "train loss:0.004063134314147236\n",
      "train loss:0.0056352716041876754\n",
      "train loss:0.00384448192431157\n",
      "train loss:0.010495439173988992\n",
      "train loss:0.004875265806057416\n",
      "train loss:0.003168190142585773\n",
      "train loss:0.004254951467344618\n",
      "train loss:0.0019273798570470636\n",
      "train loss:0.014385490322458535\n",
      "train loss:0.008608349950938938\n",
      "train loss:0.002737650618668769\n",
      "train loss:0.0023366722090453\n",
      "train loss:0.009450572761586175\n",
      "train loss:0.011022667432311005\n",
      "train loss:0.010372071454818048\n",
      "train loss:0.00578744506224654\n",
      "train loss:0.009659793512940617\n",
      "train loss:0.04904587957504218\n",
      "train loss:0.002359355251233139\n",
      "train loss:0.017974535688049353\n",
      "train loss:0.013602090468281116\n",
      "train loss:0.008574293431184649\n",
      "train loss:0.014195105316955788\n",
      "train loss:0.019509039663409777\n",
      "train loss:0.00502418285470185\n",
      "train loss:0.005639559489787072\n",
      "train loss:0.0038076657496274166\n",
      "train loss:0.005374836588589626\n",
      "train loss:0.0036343399644616276\n",
      "train loss:0.04238912382021416\n",
      "train loss:0.006149081969585638\n",
      "train loss:0.003963926098322619\n",
      "train loss:0.0036758009828877823\n",
      "train loss:0.04253131649844018\n",
      "train loss:0.0018821700828898938\n",
      "train loss:0.0015290267748186937\n",
      "train loss:0.014859260036806808\n",
      "train loss:0.004353263798071934\n",
      "train loss:0.03938853908319727\n",
      "train loss:0.017661725229475827\n",
      "train loss:0.008223650485461618\n",
      "train loss:0.009748366965882342\n",
      "train loss:0.02678272611875364\n",
      "train loss:0.014488605659265432\n",
      "train loss:0.005818754795895637\n",
      "train loss:0.019234920360520415\n",
      "train loss:0.018137397207071075\n",
      "train loss:0.018993856401395132\n",
      "train loss:0.0036256438910924746\n",
      "train loss:0.006493752366171498\n",
      "train loss:0.02657416318414664\n",
      "train loss:0.009017923622911369\n",
      "train loss:0.010899331327720592\n",
      "train loss:0.07451735521594878\n",
      "train loss:0.016397572033807272\n",
      "train loss:0.016239315147541362\n",
      "train loss:0.004233960411953523\n",
      "train loss:0.009383963086495606\n",
      "train loss:0.030449564156151358\n",
      "train loss:0.007024376116556616\n",
      "train loss:0.009669729444414315\n",
      "train loss:0.0049600482344633046\n",
      "train loss:0.0030741421362052647\n",
      "train loss:0.013173794199020102\n",
      "train loss:0.011421801999880582\n",
      "train loss:0.0035165160305768734\n",
      "train loss:0.012828598610296706\n",
      "train loss:0.003818733945522429\n",
      "train loss:0.06006334705689302\n",
      "train loss:0.013717497451374506\n",
      "train loss:0.014748581517621947\n",
      "train loss:0.02992122632272237\n",
      "train loss:0.002691126775599807\n",
      "train loss:0.022408976340789193\n",
      "train loss:0.04408431540784004\n",
      "train loss:0.00481858107505158\n",
      "train loss:0.006474528939633478\n",
      "train loss:0.009970683150801124\n",
      "train loss:0.002513301803835578\n",
      "train loss:0.007897345537382423\n",
      "train loss:0.023639033726747402\n",
      "train loss:0.010202151703628155\n",
      "train loss:0.017542407500587047\n",
      "train loss:0.002899993354038233\n",
      "train loss:0.002261801633614281\n",
      "train loss:0.0022894135114593073\n",
      "train loss:0.012237059269196274\n",
      "train loss:0.015705183171746486\n",
      "train loss:0.005628137077547803\n",
      "=== epoch:10, train acc:0.9941802536231884, test acc:0.9846920289855072 ===\n",
      "train loss:0.01807364752210895\n",
      "train loss:0.030683193439482427\n",
      "train loss:0.043205682155255255\n",
      "train loss:0.004251497848669509\n",
      "train loss:0.021208148015244413\n",
      "train loss:0.03852433007024008\n",
      "train loss:0.005146363211240659\n",
      "train loss:0.06104722108009681\n",
      "train loss:0.004911538648799707\n",
      "train loss:0.012683524637073807\n",
      "train loss:0.0049762258309403356\n",
      "train loss:0.0033251398696560654\n",
      "train loss:0.0035895286934435095\n",
      "train loss:0.018687073045566268\n",
      "train loss:0.03768863176820252\n",
      "train loss:0.02297397559953993\n",
      "train loss:0.023795206603381344\n",
      "train loss:0.056988951046119646\n",
      "train loss:0.03930087037206113\n",
      "train loss:0.006213744034495758\n",
      "train loss:0.04833538906773378\n",
      "train loss:0.00959124300245088\n",
      "train loss:0.008333696295710364\n",
      "train loss:0.016413493892163594\n",
      "train loss:0.017179594102952733\n",
      "train loss:0.013404333247057022\n",
      "train loss:0.02365176831339706\n",
      "train loss:0.010078922380118201\n",
      "train loss:0.007080271910997528\n",
      "train loss:0.006663504699806702\n",
      "train loss:0.0052213198201399875\n",
      "train loss:0.011258462519756426\n",
      "train loss:0.016803240432453\n",
      "train loss:0.012842268101783542\n",
      "train loss:0.0063376994986146335\n",
      "train loss:0.007633794261483323\n",
      "train loss:0.006983188503265001\n",
      "train loss:0.0025027280635324606\n",
      "train loss:0.0049478394514549185\n",
      "train loss:0.01737314263494075\n",
      "train loss:0.003518471038258001\n",
      "train loss:0.011832059098572618\n",
      "train loss:0.011974297250794469\n",
      "train loss:0.002638518162503521\n",
      "train loss:0.005013963097196581\n",
      "train loss:0.0095353713196031\n",
      "train loss:0.009021367087918711\n",
      "train loss:0.021634837053954484\n",
      "train loss:0.0037221218144150793\n",
      "train loss:0.0267312788629979\n",
      "train loss:0.006896436120448577\n",
      "train loss:0.052721572909888666\n",
      "train loss:0.0023959563947571136\n",
      "train loss:0.01158286078880768\n",
      "train loss:0.045613697680774674\n",
      "train loss:0.05348620493853837\n",
      "train loss:0.03215660708766551\n",
      "train loss:0.003840598325014432\n",
      "train loss:0.007956938972924328\n",
      "train loss:0.004253816051812211\n",
      "train loss:0.003499966330614809\n",
      "train loss:0.029831532409445607\n",
      "train loss:0.021161817392146134\n",
      "train loss:0.0028081629465449304\n",
      "train loss:0.00528379888081224\n",
      "train loss:0.003455093528154547\n",
      "train loss:0.022614003994039858\n",
      "train loss:0.0025616211531689368\n",
      "train loss:0.020384707686004575\n",
      "train loss:0.03261975063014241\n",
      "train loss:0.013250634248839873\n",
      "train loss:0.02238490790149703\n",
      "train loss:0.014952073923639533\n",
      "train loss:0.03185294858973086\n",
      "train loss:0.02058469922161969\n",
      "train loss:0.005319180152482192\n",
      "train loss:0.016434696711041863\n",
      "train loss:0.03342547424794847\n",
      "train loss:0.004755769958324948\n",
      "train loss:0.0049896621115238975\n",
      "train loss:0.03271625461043726\n",
      "train loss:0.021863296993404117\n",
      "train loss:0.007275127744053284\n",
      "train loss:0.01951951632541059\n",
      "train loss:0.015829221697148677\n",
      "train loss:0.004301180284069508\n",
      "train loss:0.005065262430510991\n",
      "train loss:0.022873896560540573\n",
      "train loss:0.03033813540229611\n",
      "train loss:0.006844693093950744\n",
      "train loss:0.017154026296718524\n",
      "train loss:0.004721287373227495\n",
      "train loss:0.011940922521111919\n",
      "train loss:0.00661691798867333\n",
      "train loss:0.07325193253002539\n",
      "train loss:0.01524390229007242\n",
      "train loss:0.03791240343327833\n",
      "train loss:0.02153465717070322\n",
      "train loss:0.015033065356628465\n",
      "train loss:0.011073852932085638\n",
      "train loss:0.0023687237663469907\n",
      "train loss:0.03263712645517044\n",
      "train loss:0.04444277369645442\n",
      "train loss:0.003329881082400965\n",
      "train loss:0.01872413091718968\n",
      "train loss:0.00845551641438208\n",
      "train loss:0.06415698956227002\n",
      "train loss:0.007450844831585447\n",
      "train loss:0.015756787740521784\n",
      "train loss:0.012528237502508295\n",
      "train loss:0.007769796221219276\n",
      "train loss:0.0069844487806188515\n",
      "train loss:0.040058076449894855\n",
      "train loss:0.010361154540554677\n",
      "train loss:0.025636762394105485\n",
      "train loss:0.02592179631601783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.022199658940171015\n",
      "train loss:0.0344859271581497\n",
      "train loss:0.00876062779634473\n",
      "train loss:0.006515896276567381\n",
      "train loss:0.01847834002768616\n",
      "train loss:0.008047599516693133\n",
      "train loss:0.008433927353781972\n",
      "train loss:0.0022677170719969807\n",
      "train loss:0.013580318650365412\n",
      "train loss:0.041036460247971134\n",
      "train loss:0.03675714275560303\n",
      "train loss:0.023402072741583613\n",
      "train loss:0.012170149759161383\n",
      "train loss:0.013215238224571522\n",
      "train loss:0.029723826208864854\n",
      "train loss:0.008179306235719773\n",
      "train loss:0.019048508404689087\n",
      "train loss:0.021399982440398875\n",
      "train loss:0.016673367274242012\n",
      "train loss:0.06055293304260768\n",
      "train loss:0.008340445125187522\n",
      "train loss:0.00826883144783835\n",
      "train loss:0.007846809405601592\n",
      "train loss:0.02908946864733281\n",
      "train loss:0.015630072254508402\n",
      "train loss:0.005506480585843529\n",
      "train loss:0.01513819844072087\n",
      "train loss:0.06539157884128778\n",
      "train loss:0.02259896489516062\n",
      "train loss:0.008688803995501532\n",
      "train loss:0.02944697550619203\n",
      "train loss:0.012896528457723124\n",
      "train loss:0.0057345195225418375\n",
      "train loss:0.0061828197265890745\n",
      "train loss:0.0035770398524088403\n",
      "train loss:0.004993671585223672\n",
      "train loss:0.0075040595438966694\n",
      "train loss:0.005992333073215385\n",
      "train loss:0.016225622950840048\n",
      "train loss:0.00960409589180907\n",
      "train loss:0.0026897994487827723\n",
      "train loss:0.04536302127973957\n",
      "train loss:0.019286531716167763\n",
      "train loss:0.011262984518064284\n",
      "train loss:0.0032041089285334296\n",
      "train loss:0.0021701875347088524\n",
      "train loss:0.004347992814927073\n",
      "train loss:0.02729874987359166\n",
      "train loss:0.0029079300305111825\n",
      "train loss:0.019020921266837687\n",
      "train loss:0.003636252155123734\n",
      "train loss:0.03476510023462227\n",
      "train loss:0.011918705175002663\n",
      "train loss:0.0022614393202966764\n",
      "train loss:0.02333355898182696\n",
      "train loss:0.021029545223625514\n",
      "train loss:0.028127156154637102\n",
      "train loss:0.008700354785554964\n",
      "train loss:0.05942249418870674\n",
      "train loss:0.008258810586132962\n",
      "train loss:0.03008094364517525\n",
      "train loss:0.005640806575306176\n",
      "train loss:0.056867621652843856\n",
      "train loss:0.001972415295820479\n",
      "train loss:0.010623157148122437\n",
      "train loss:0.03008649432498731\n",
      "train loss:0.014060870931998936\n",
      "train loss:0.010940499273508427\n",
      "train loss:0.0068229770557648286\n",
      "train loss:0.0035460400502039164\n",
      "train loss:0.012731652268844148\n",
      "train loss:0.011951461774809404\n",
      "train loss:0.004935273455743604\n",
      "train loss:0.02702097085324048\n",
      "train loss:0.006915324539857417\n",
      "train loss:0.0030797682274436187\n",
      "train loss:0.007849013118201633\n",
      "train loss:0.003428203706745342\n",
      "train loss:0.006059036734543063\n",
      "train loss:0.004222982231954751\n",
      "train loss:0.001973441670323159\n",
      "train loss:0.0030720917037829424\n",
      "train loss:0.01753582409258322\n",
      "train loss:0.013254176145870345\n",
      "train loss:0.007836288726593914\n",
      "train loss:0.009683152695520413\n",
      "train loss:0.020205715531826356\n",
      "train loss:0.05240724815234919\n",
      "train loss:0.02780737233831477\n",
      "train loss:0.0021562722265442884\n",
      "train loss:0.0038182288298017914\n",
      "train loss:0.005550385338538876\n",
      "train loss:0.0016515154766903357\n",
      "train loss:0.009084931332594881\n",
      "train loss:0.009895994192969307\n",
      "train loss:0.019501809665434803\n",
      "train loss:0.0022180342128400197\n",
      "train loss:0.002227521756631853\n",
      "train loss:0.010419212442410187\n",
      "train loss:0.0216084287012101\n",
      "train loss:0.0066768818063350655\n",
      "train loss:0.0041875928829785535\n",
      "train loss:0.006806647084267659\n",
      "train loss:0.01848364354590456\n",
      "train loss:0.005434120748872311\n",
      "train loss:0.004305132955019317\n",
      "train loss:0.017183014443816518\n",
      "train loss:0.007988930059707933\n",
      "train loss:0.005005313908372988\n",
      "train loss:0.0037408327526912625\n",
      "train loss:0.014539977203110684\n",
      "train loss:0.002116590380222007\n",
      "train loss:0.004703578411398617\n",
      "train loss:0.00457300655663569\n",
      "train loss:0.006591694584100517\n",
      "train loss:0.005424131204782103\n",
      "train loss:0.004797793089795246\n",
      "train loss:0.012810365436520539\n",
      "train loss:0.007321426984836867\n",
      "train loss:0.0044860365562630795\n",
      "train loss:0.004585015686650449\n",
      "train loss:0.03703699379535481\n",
      "train loss:0.014416825659090289\n",
      "train loss:0.004366371341505137\n",
      "train loss:0.014464383856658939\n",
      "train loss:0.005128312852407407\n",
      "train loss:0.018839351123977773\n",
      "train loss:0.002642242020812862\n",
      "train loss:0.013335744400713868\n",
      "train loss:0.018063966917824525\n",
      "train loss:0.007739896938542238\n",
      "train loss:0.0010781168985653099\n",
      "train loss:0.0027320421159936284\n",
      "train loss:0.0053357555318118395\n",
      "train loss:0.0029270532563002763\n",
      "train loss:0.0022002467174090227\n",
      "train loss:0.0023955333214698235\n",
      "train loss:0.0035372106392691244\n",
      "train loss:0.006597546392360387\n",
      "train loss:0.013040386951247429\n",
      "train loss:0.019057337455146248\n",
      "train loss:0.0045841940872264125\n",
      "train loss:0.01423193254906809\n",
      "train loss:0.005323138884064745\n",
      "train loss:0.00643051557574501\n",
      "train loss:0.0019563006812728934\n",
      "train loss:0.0038180798901928706\n",
      "train loss:0.008163008547420742\n",
      "train loss:0.0027141267746370306\n",
      "train loss:0.002051374174753232\n",
      "train loss:0.027472485645737534\n",
      "train loss:0.005145921801555823\n",
      "train loss:0.010749807293875011\n",
      "train loss:0.015579894553752598\n",
      "train loss:0.03628593600492521\n",
      "train loss:0.0042837029833789324\n",
      "train loss:0.010619272212616077\n",
      "train loss:0.007362353392504293\n",
      "train loss:0.0067609559912309635\n",
      "train loss:0.038264745405353386\n",
      "train loss:0.018479764003536184\n",
      "train loss:0.006995762026180926\n",
      "train loss:0.037003488341131\n",
      "train loss:0.011442020719072403\n",
      "train loss:0.009811458331977675\n",
      "train loss:0.010957706841704513\n",
      "train loss:0.0052137687289544234\n",
      "train loss:0.05598123276169793\n",
      "train loss:0.060709767410445266\n",
      "train loss:0.005831017064300033\n",
      "train loss:0.03379952733350754\n",
      "train loss:0.013340212357547874\n",
      "train loss:0.005106903397980794\n",
      "train loss:0.004583008383268567\n",
      "train loss:0.009354466829269251\n",
      "train loss:0.005636531666570368\n",
      "train loss:0.03934209277511069\n",
      "train loss:0.011661495700511322\n",
      "train loss:0.011378587754826792\n",
      "train loss:0.008432903572483736\n",
      "train loss:0.03384788504293609\n",
      "train loss:0.030007750420278662\n",
      "train loss:0.013618367425303264\n",
      "train loss:0.009911884693245504\n",
      "train loss:0.031259299956387834\n",
      "train loss:0.0058088002615661015\n",
      "train loss:0.00809779650608686\n",
      "train loss:0.001904850098803712\n",
      "train loss:0.05113116982094006\n",
      "train loss:0.0025664507378726073\n",
      "train loss:0.009942157872441884\n",
      "train loss:0.01970294361947533\n",
      "train loss:0.019327450514370837\n",
      "train loss:0.010634977168067791\n",
      "train loss:0.04351456019997569\n",
      "train loss:0.003448473347745161\n",
      "train loss:0.008640409239781066\n",
      "train loss:0.010318221965055663\n",
      "train loss:0.01077563739358353\n",
      "train loss:0.029080886400292265\n",
      "train loss:0.0032837682421184345\n",
      "train loss:0.0441321688253178\n",
      "train loss:0.000910934562784143\n",
      "train loss:0.005474087706949422\n",
      "train loss:0.00529572183147781\n",
      "train loss:0.10142286775556576\n",
      "train loss:0.019296018498390872\n",
      "train loss:0.04803536389403342\n",
      "train loss:0.03536498273933672\n",
      "train loss:0.019548935076906256\n",
      "train loss:0.001438802666722886\n",
      "train loss:0.00723092753245998\n",
      "train loss:0.006384561708791794\n",
      "train loss:0.003715585453644189\n",
      "train loss:0.01820390421680823\n",
      "train loss:0.0025851313707634456\n",
      "train loss:0.003119215607844499\n",
      "train loss:0.011206918118821001\n",
      "train loss:0.021698910776460623\n",
      "train loss:0.0023311748199633248\n",
      "train loss:0.01393784289127617\n",
      "train loss:0.018102916051877357\n",
      "train loss:0.04361867024966321\n",
      "train loss:0.019174391850843183\n",
      "train loss:0.023368983246787718\n",
      "train loss:0.001649775251711786\n",
      "train loss:0.00815659619008347\n",
      "train loss:0.00522955790127603\n",
      "train loss:0.0033305821572162326\n",
      "train loss:0.049349749174136655\n",
      "train loss:0.008485939772639414\n",
      "train loss:0.0023509216630570105\n",
      "train loss:0.0025277779545669495\n",
      "train loss:0.006282360843134705\n",
      "train loss:0.0044153211054677455\n",
      "train loss:0.003932891943150858\n",
      "train loss:0.005307540303015571\n",
      "train loss:0.022620872089549805\n",
      "train loss:0.0014977320121766357\n",
      "train loss:0.004293656485055138\n",
      "train loss:0.04871391819736359\n",
      "train loss:0.01303037963548865\n",
      "train loss:0.03553922573935508\n",
      "train loss:0.008184704553252674\n",
      "train loss:0.0009528060335074856\n",
      "train loss:0.029509470344491237\n",
      "train loss:0.007743831364236655\n",
      "train loss:0.023059445080837106\n",
      "train loss:0.005751448781338017\n",
      "train loss:0.0044951961658296034\n",
      "train loss:0.014598097068223792\n",
      "train loss:0.0033804902335608806\n",
      "=== epoch:11, train acc:0.9958106884057971, test acc:0.9856884057971015 ===\n",
      "train loss:0.0033922352017490146\n",
      "train loss:0.00901434578501321\n",
      "train loss:0.023053598914071365\n",
      "train loss:0.007926564572424546\n",
      "train loss:0.007826422156291465\n",
      "train loss:0.02065105545717277\n",
      "train loss:0.003424134706223972\n",
      "train loss:0.011424372645874752\n",
      "train loss:0.008554421324029792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00259836504998302\n",
      "train loss:0.0137006564027761\n",
      "train loss:0.004670213429640482\n",
      "train loss:0.010453756096135254\n",
      "train loss:0.01695882875892951\n",
      "train loss:0.019715757718043393\n",
      "train loss:0.013630878181880244\n",
      "train loss:0.004638069462270437\n",
      "train loss:0.0024944268965665798\n",
      "train loss:0.009743182187497482\n",
      "train loss:0.0032950747394913846\n",
      "train loss:0.015755630941043187\n",
      "train loss:0.004976623780313059\n",
      "train loss:0.019450991193319986\n",
      "train loss:0.012290712435587981\n",
      "train loss:0.020276873874706745\n",
      "train loss:0.0021359038511564983\n",
      "train loss:0.02193488899227566\n",
      "train loss:0.018166883978263694\n",
      "train loss:0.020202973223124584\n",
      "train loss:0.008074945024924297\n",
      "train loss:0.006082741381335041\n",
      "train loss:0.013412058303917422\n",
      "train loss:0.0017793468028803599\n",
      "train loss:0.006155601737805303\n",
      "train loss:0.04102128721748834\n",
      "train loss:0.01117772635514525\n",
      "train loss:0.005402340670201704\n",
      "train loss:0.006463926438321704\n",
      "train loss:0.03231093992946008\n",
      "train loss:0.015014787452425375\n",
      "train loss:0.008771052425116927\n",
      "train loss:0.01445733905534134\n",
      "train loss:0.048197877948798866\n",
      "train loss:0.0031039683749908434\n",
      "train loss:0.011290921713392334\n",
      "train loss:0.018423057814375966\n",
      "train loss:0.008722764842998894\n",
      "train loss:0.009069334410098266\n",
      "train loss:0.00303157381084983\n",
      "train loss:0.015467962275540804\n",
      "train loss:0.010775181656304086\n",
      "train loss:0.005304675953122124\n",
      "train loss:0.02131665311420572\n",
      "train loss:0.006080925755827052\n",
      "train loss:0.006594059914259439\n",
      "train loss:0.0036686902881721503\n",
      "train loss:0.005740754997780349\n",
      "train loss:0.019083884475312302\n",
      "train loss:0.01151463573367109\n",
      "train loss:0.04614133391073856\n",
      "train loss:0.003931207241659119\n",
      "train loss:0.009827127468307561\n",
      "train loss:0.0017011161606515308\n",
      "train loss:0.002440618231311037\n",
      "train loss:0.01090077562370311\n",
      "train loss:0.0038626487940268055\n",
      "train loss:0.01554290051529899\n",
      "train loss:0.006677253449444121\n",
      "train loss:0.015364594027138577\n",
      "train loss:0.007494528094250716\n",
      "train loss:0.0036162161197886874\n",
      "train loss:0.0024353531537708055\n",
      "train loss:0.007602000565973355\n",
      "train loss:0.01936935184864889\n",
      "train loss:0.0029162095954568634\n",
      "train loss:0.008477299142640924\n",
      "train loss:0.02613731741233353\n",
      "train loss:0.001204133474839549\n",
      "train loss:0.014375939472376476\n",
      "train loss:0.0027665526529777286\n",
      "train loss:0.007087976365436746\n",
      "train loss:0.017158509603644394\n",
      "train loss:0.0021570314719901906\n",
      "train loss:0.015553442988049998\n",
      "train loss:0.005395204244671766\n",
      "train loss:0.017857284358131807\n",
      "train loss:0.02030562145579266\n",
      "train loss:0.0035442553236857627\n",
      "train loss:0.01670259242138352\n",
      "train loss:0.001566797767382652\n",
      "train loss:0.00537921872754061\n",
      "train loss:0.004614636375409635\n",
      "train loss:0.008625524233797933\n",
      "train loss:0.011093697953363558\n",
      "train loss:0.006239374481365556\n",
      "train loss:0.024189492831133908\n",
      "train loss:0.025121511348777156\n",
      "train loss:0.025249768518857508\n",
      "train loss:0.0058232546260118204\n",
      "train loss:0.012180335163190649\n",
      "train loss:0.038065131012995385\n",
      "train loss:0.039152429218723306\n",
      "train loss:0.007599095915746005\n",
      "train loss:0.009573259588812099\n",
      "train loss:0.004706632716046862\n",
      "train loss:0.014982846630057578\n",
      "train loss:0.0088472743174585\n",
      "train loss:0.003172241529071416\n",
      "train loss:0.009117259262906617\n",
      "train loss:0.01181859785768422\n",
      "train loss:0.016142730032574517\n",
      "train loss:0.0051066460858197275\n",
      "train loss:0.004284832747313076\n",
      "train loss:0.02020555581186933\n",
      "train loss:0.0055782008073570815\n",
      "train loss:0.018458834492199035\n",
      "train loss:0.004599858534999746\n",
      "train loss:0.008835580698734212\n",
      "train loss:0.021247101620705134\n",
      "train loss:0.01665850634783963\n",
      "train loss:0.007598507592993399\n",
      "train loss:0.019030878679361797\n",
      "train loss:0.005467930202432011\n",
      "train loss:0.01658942146102143\n",
      "train loss:0.013334610772866299\n",
      "train loss:0.013390770970852084\n",
      "train loss:0.012320257302672248\n",
      "train loss:0.020617513278209296\n",
      "train loss:0.007078174233755297\n",
      "train loss:0.037637419764069306\n",
      "train loss:0.0066702768888685145\n",
      "train loss:0.007347951948965674\n",
      "train loss:0.007476010917215546\n",
      "train loss:0.010092833897543434\n",
      "train loss:0.009583917969343693\n",
      "train loss:0.014376799487509775\n",
      "train loss:0.006813015541702257\n",
      "train loss:0.003119770849359384\n",
      "train loss:0.004975901291252011\n",
      "train loss:0.0167750368645005\n",
      "train loss:0.0018556907566388092\n",
      "train loss:0.0055813025776663815\n",
      "train loss:0.004731638113899896\n",
      "train loss:0.0033419240541624705\n",
      "train loss:0.04439782043277018\n",
      "train loss:0.003156907819338745\n",
      "train loss:0.027158126591010093\n",
      "train loss:0.003176911506865306\n",
      "train loss:0.007298269510453212\n",
      "train loss:0.021740305882392546\n",
      "train loss:0.008066405429047054\n",
      "train loss:0.0032216108676743557\n",
      "train loss:0.007982589850809792\n",
      "train loss:0.01467222628658201\n",
      "train loss:0.0039448852266655504\n",
      "train loss:0.0030803547600406775\n",
      "train loss:0.005476869355196221\n",
      "train loss:0.044033102567622724\n",
      "train loss:0.020280420484395274\n",
      "train loss:0.001940685321496287\n",
      "train loss:0.03767207700361138\n",
      "train loss:0.010227436339055759\n",
      "train loss:0.011089547658071026\n",
      "train loss:0.0067544466237501165\n",
      "train loss:0.006742106742105811\n",
      "train loss:0.033085078083672365\n",
      "train loss:0.002904985546830487\n",
      "train loss:0.009801545226562753\n",
      "train loss:0.004276703490552366\n",
      "train loss:0.006936360838677728\n",
      "train loss:0.0030922024183901897\n",
      "train loss:0.022153309924386154\n",
      "train loss:0.01246318121661982\n",
      "train loss:0.011600061906889324\n",
      "train loss:0.005507137846542326\n",
      "train loss:0.004314647073908067\n",
      "train loss:0.030256355748892953\n",
      "train loss:0.012166046986528475\n",
      "train loss:0.006803778872209012\n",
      "train loss:0.005168042177696949\n",
      "train loss:0.014460177199551569\n",
      "train loss:0.011856514478551784\n",
      "train loss:0.003524030067474613\n",
      "train loss:0.005950877971830879\n",
      "train loss:0.006389858664150259\n",
      "train loss:0.013995129647398998\n",
      "train loss:0.0033836918361648638\n",
      "train loss:0.01325502786464665\n",
      "train loss:0.0026242373415695823\n",
      "train loss:0.027307598420060256\n",
      "train loss:0.0033161779380151235\n",
      "train loss:0.011342209045442834\n",
      "train loss:0.00393693038603514\n",
      "train loss:0.006901293748104311\n",
      "train loss:0.001892572092591568\n",
      "train loss:0.003279092009513905\n",
      "train loss:0.002966832244513264\n",
      "train loss:0.011380311238828565\n",
      "train loss:0.016095543890937647\n",
      "train loss:0.003206743607758472\n",
      "train loss:0.01910720891222609\n",
      "train loss:0.006574150609386032\n",
      "train loss:0.02350276665673976\n",
      "train loss:0.002611753284542969\n",
      "train loss:0.006123450946891378\n",
      "train loss:0.012810405386978665\n",
      "train loss:0.0014699655649713498\n",
      "train loss:0.009965813376968283\n",
      "train loss:0.00826663992338422\n",
      "train loss:0.06275164787951246\n",
      "train loss:0.000823445183427169\n",
      "train loss:0.00294265998020023\n",
      "train loss:0.007512483020771069\n",
      "train loss:0.011138514663102074\n",
      "train loss:0.012454838587209817\n",
      "train loss:0.018003585344578153\n",
      "train loss:0.01274826821336852\n",
      "train loss:0.010095029561539858\n",
      "train loss:0.002029835688098237\n",
      "train loss:0.003990498563117254\n",
      "train loss:0.017770795993281963\n",
      "train loss:0.004619054495613522\n",
      "train loss:0.0018498033246484905\n",
      "train loss:0.001631285545173245\n",
      "train loss:0.00215793562939432\n",
      "train loss:0.020356558996772165\n",
      "train loss:0.03106007543934847\n",
      "train loss:0.005587539901664824\n",
      "train loss:0.0020043316260647793\n",
      "train loss:0.03555633586076274\n",
      "train loss:0.006475634758186451\n",
      "train loss:0.00734536245456059\n",
      "train loss:0.0211845297169992\n",
      "train loss:0.002151372673580366\n",
      "train loss:0.009413584288576554\n",
      "train loss:0.005958659733236158\n",
      "train loss:0.005892391677656015\n",
      "train loss:0.034873615110607804\n",
      "train loss:0.0051122587846323675\n",
      "train loss:0.0019453488724890638\n",
      "train loss:0.013877596961130337\n",
      "train loss:0.008987729146249951\n",
      "train loss:0.01163261558477449\n",
      "train loss:0.02700939144004685\n",
      "train loss:0.005822953142237995\n",
      "train loss:0.00250514627653955\n",
      "train loss:0.0025624390673992374\n",
      "train loss:0.015431763185241558\n",
      "train loss:0.007391052394927146\n",
      "train loss:0.0014340733731158265\n",
      "train loss:0.007231309033759842\n",
      "train loss:0.008557083782370635\n",
      "train loss:0.007404380837446832\n",
      "train loss:0.0060115393941660026\n",
      "train loss:0.019653019846466318\n",
      "train loss:0.001877745024590552\n",
      "train loss:0.0022488446089188358\n",
      "train loss:0.03902844196458874\n",
      "train loss:0.005121012207056624\n",
      "train loss:0.009983449274609606\n",
      "train loss:0.03937012018101314\n",
      "train loss:0.008092518065096707\n",
      "train loss:0.0024140516540254674\n",
      "train loss:0.03952176266864937\n",
      "train loss:0.0033943972779675725\n",
      "train loss:0.0018694343223850081\n",
      "train loss:0.013014533352186938\n",
      "train loss:0.0067420056099264615\n",
      "train loss:0.003289043867426041\n",
      "train loss:0.0034062085632651047\n",
      "train loss:0.004213615330753135\n",
      "train loss:0.008540002257825068\n",
      "train loss:0.0006124260256294896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008391592812787051\n",
      "train loss:0.0036533507645679763\n",
      "train loss:0.0014508696162461494\n",
      "train loss:0.009045706037790683\n",
      "train loss:0.0077430067198538685\n",
      "train loss:0.018876823639274117\n",
      "train loss:0.00037428948558657115\n",
      "train loss:0.0038670265472742766\n",
      "train loss:0.004035914933722109\n",
      "train loss:0.0012083268720794252\n",
      "train loss:0.01232363737889929\n",
      "train loss:0.005918038608644016\n",
      "train loss:0.004360817387280313\n",
      "train loss:0.00786242798030657\n",
      "train loss:0.005293821024359905\n",
      "train loss:0.023083949843986692\n",
      "train loss:0.00631803374641259\n",
      "train loss:0.006292766332649563\n",
      "train loss:0.007660476077085701\n",
      "train loss:0.009480674500273704\n",
      "train loss:0.001768486083028334\n",
      "train loss:0.0025201499151643273\n",
      "train loss:0.03219553166950749\n",
      "train loss:0.0026829011063052664\n",
      "train loss:0.003725012361768407\n",
      "train loss:0.007977048139965555\n",
      "train loss:0.0017610653557596121\n",
      "train loss:0.03602644286088842\n",
      "train loss:0.010840989803375563\n",
      "train loss:0.006073897890724785\n",
      "train loss:0.006089095168469563\n",
      "train loss:0.01376067164040062\n",
      "train loss:0.011853527444795928\n",
      "train loss:0.06103388677659785\n",
      "train loss:0.006886792356358205\n",
      "train loss:0.001230040888461128\n",
      "train loss:0.016121024725418306\n",
      "train loss:0.012045853523409731\n",
      "train loss:0.012707319632470926\n",
      "train loss:0.0036400261448536466\n",
      "train loss:0.0014209647454615166\n",
      "train loss:0.009631269613690962\n",
      "train loss:0.013032499285569744\n",
      "train loss:0.04225987183680228\n",
      "train loss:0.004371240713691748\n",
      "train loss:0.007112106892819191\n",
      "train loss:0.004826439571886039\n",
      "train loss:0.001949583951377613\n",
      "train loss:0.059641809514241854\n",
      "train loss:0.0037348995885138907\n",
      "train loss:0.0014743394640452142\n",
      "train loss:0.004113497876378659\n",
      "train loss:0.004139220896802654\n",
      "train loss:0.003510363229842151\n",
      "train loss:0.025654804941864805\n",
      "train loss:0.004542856038873351\n",
      "train loss:0.006443335695517547\n",
      "train loss:0.014625118325155097\n",
      "train loss:0.006305584209143077\n",
      "train loss:0.007387956982498086\n",
      "train loss:0.0030683275202085985\n",
      "train loss:0.006831555568577753\n",
      "train loss:0.002283379407586952\n",
      "train loss:0.0033205968064216034\n",
      "train loss:0.027531071889799766\n",
      "train loss:0.003391393045714042\n",
      "train loss:0.02507102435525432\n",
      "train loss:0.013680943218649646\n",
      "train loss:0.009875906384156289\n",
      "train loss:0.0028926729979270945\n",
      "train loss:0.004222040245470805\n",
      "train loss:0.008469276811859237\n",
      "train loss:0.008537473111936087\n",
      "train loss:0.004565354025011232\n",
      "train loss:0.003200386327032097\n",
      "train loss:0.009697668719053303\n",
      "train loss:0.011449036945443723\n",
      "train loss:0.004334967223886767\n",
      "train loss:0.002959521110609022\n",
      "train loss:0.03942268385848869\n",
      "train loss:0.006516245659111391\n",
      "train loss:0.005313349593803178\n",
      "train loss:0.016902645841320254\n",
      "train loss:0.015669774450392304\n",
      "train loss:0.002202573554431314\n",
      "train loss:0.038448526947917484\n",
      "train loss:0.0051545458242253745\n",
      "train loss:0.002373783783136816\n",
      "train loss:0.007289499508627606\n",
      "train loss:0.020887233250546863\n",
      "train loss:0.017709951013109078\n",
      "train loss:0.0033056377049683985\n",
      "train loss:0.005608618199352146\n",
      "train loss:0.0028366436526093735\n",
      "train loss:0.016447469433329507\n",
      "=== epoch:12, train acc:0.9966938405797101, test acc:0.9868659420289855 ===\n",
      "train loss:0.02083052592267962\n",
      "train loss:0.015790834723661648\n",
      "train loss:0.0073682097583905055\n",
      "train loss:0.018281896652577012\n",
      "train loss:0.017900813526936985\n",
      "train loss:0.007205038346924741\n",
      "train loss:0.005908376590608694\n",
      "train loss:0.006177219444520543\n",
      "train loss:0.013813530272464132\n",
      "train loss:0.0064980350341048\n",
      "train loss:0.01019304125155907\n",
      "train loss:0.004461515510125276\n",
      "train loss:0.009043543218729987\n",
      "train loss:0.01978868777639387\n",
      "train loss:0.017019072484682055\n",
      "train loss:0.003884913408411467\n",
      "train loss:0.047615844869959956\n",
      "train loss:0.031455629695901016\n",
      "train loss:0.005655319715111052\n",
      "train loss:0.00931217503299197\n",
      "train loss:0.007202736020832117\n",
      "train loss:0.009383879043132877\n",
      "train loss:0.020298241481469616\n",
      "train loss:0.0176607360809297\n",
      "train loss:0.0027879242434192754\n",
      "train loss:0.007332080078907404\n",
      "train loss:0.0013821323928506948\n",
      "train loss:0.010703433458947042\n",
      "train loss:0.002986239834630079\n",
      "train loss:0.004644110738601214\n",
      "train loss:0.033793192070131005\n",
      "train loss:0.009320925580620695\n",
      "train loss:0.002497487893900964\n",
      "train loss:0.00562569793829281\n",
      "train loss:0.002681800105523157\n",
      "train loss:0.01586642836505914\n",
      "train loss:0.0076001340173957295\n",
      "train loss:0.006873226804283369\n",
      "train loss:0.007558432090729146\n",
      "train loss:0.0017044469390185995\n",
      "train loss:0.021615664380378614\n",
      "train loss:0.004907805907580041\n",
      "train loss:0.011700328055906177\n",
      "train loss:0.0022360021912001676\n",
      "train loss:0.008698830555766125\n",
      "train loss:0.014533565999747323\n",
      "train loss:0.0033880693385628666\n",
      "train loss:0.0026812168219637407\n",
      "train loss:0.013421463677766057\n",
      "train loss:0.005693771362372683\n",
      "train loss:0.0017535870627654823\n",
      "train loss:0.009615183502079044\n",
      "train loss:0.005152102288929969\n",
      "train loss:0.003273770897096584\n",
      "train loss:0.0009997020484576462\n",
      "train loss:0.010054889211913077\n",
      "train loss:0.019350302408914097\n",
      "train loss:0.0028450434275316765\n",
      "train loss:0.012895320241086439\n",
      "train loss:0.0019631268918516185\n",
      "train loss:0.005542659499165831\n",
      "train loss:0.0009770939359187976\n",
      "train loss:0.002396854534390593\n",
      "train loss:0.0009799469264139755\n",
      "train loss:0.015426460081152383\n",
      "train loss:0.01239466154417768\n",
      "train loss:0.018195543757905844\n",
      "train loss:0.0015481874434551302\n",
      "train loss:0.018977613886534996\n",
      "train loss:0.0038780594399999155\n",
      "train loss:0.038730343937814195\n",
      "train loss:0.0021892723405892898\n",
      "train loss:0.013929090787563072\n",
      "train loss:0.07535231178350292\n",
      "train loss:0.0020454699840854198\n",
      "train loss:0.009688646797533621\n",
      "train loss:0.00448370398227287\n",
      "train loss:0.00634994532200703\n",
      "train loss:0.006995177849080551\n",
      "train loss:0.0014853779768647457\n",
      "train loss:0.005073845120916943\n",
      "train loss:0.005700561576755826\n",
      "train loss:0.030595076384938857\n",
      "train loss:0.002337868115625763\n",
      "train loss:0.007346452925666947\n",
      "train loss:0.0023204628587374086\n",
      "train loss:0.0016101488348357715\n",
      "train loss:0.002268440548417349\n",
      "train loss:0.03111802248820172\n",
      "train loss:0.0018050017320092948\n",
      "train loss:0.006964936242585671\n",
      "train loss:0.01959856476029139\n",
      "train loss:0.009824404576911904\n",
      "train loss:0.027091150395204676\n",
      "train loss:0.012030696031205634\n",
      "train loss:0.004041782296494915\n",
      "train loss:0.002439221090104776\n",
      "train loss:0.018993438209804602\n",
      "train loss:0.007666390794270087\n",
      "train loss:0.012187941600441387\n",
      "train loss:0.02876505801773423\n",
      "train loss:0.003667178642360666\n",
      "train loss:0.003739694299274321\n",
      "train loss:0.005742597330839493\n",
      "train loss:0.007160448050088367\n",
      "train loss:0.010565954152293333\n",
      "train loss:0.0064153593938494295\n",
      "train loss:0.0027612296987253866\n",
      "train loss:0.0013083267199749766\n",
      "train loss:0.008068797734538856\n",
      "train loss:0.0017159707874869069\n",
      "train loss:0.002860416704171158\n",
      "train loss:0.0044318763644107416\n",
      "train loss:0.010555754195160085\n",
      "train loss:0.01391737263187831\n",
      "train loss:0.03880133668363918\n",
      "train loss:0.006011786407627485\n",
      "train loss:0.002242918241473549\n",
      "train loss:0.03157688100307474\n",
      "train loss:0.01633098742184712\n",
      "train loss:0.0036655839570171617\n",
      "train loss:0.005917531921376314\n",
      "train loss:0.04099602698390954\n",
      "train loss:0.017895455481560112\n",
      "train loss:0.0029560623496915238\n",
      "train loss:0.003093743007458341\n",
      "train loss:0.007622101811911681\n",
      "train loss:0.005790070848990912\n",
      "train loss:0.009377180341968333\n",
      "train loss:0.004824591167380957\n",
      "train loss:0.0019223530239548918\n",
      "train loss:0.012545188801354424\n",
      "train loss:0.01068871355152445\n",
      "train loss:0.011361775585403215\n",
      "train loss:0.006977808929625143\n",
      "train loss:0.008165634682529807\n",
      "train loss:0.0034683377656607706\n",
      "train loss:0.028320995643454003\n",
      "train loss:0.0012934840738581463\n",
      "train loss:0.004388167832723596\n",
      "train loss:0.008623364520236737\n",
      "train loss:0.0034250318936230226\n",
      "train loss:0.00785031830188648\n",
      "train loss:0.002402073216031005\n",
      "train loss:0.002010569903926573\n",
      "train loss:0.003405286751533826\n",
      "train loss:0.011036208349548547\n",
      "train loss:0.017431478975623027\n",
      "train loss:0.012136143960449071\n",
      "train loss:0.008015124172669212\n",
      "train loss:0.0029745148004087507\n",
      "train loss:0.013856456105862749\n",
      "train loss:0.005908409570950796\n",
      "train loss:0.005270078855609191\n",
      "train loss:0.00719648316920841\n",
      "train loss:0.005426698610497525\n",
      "train loss:0.0013031125842657661\n",
      "train loss:0.004763856467305443\n",
      "train loss:0.02382131022027693\n",
      "train loss:0.001971620637246138\n",
      "train loss:0.018760969537473703\n",
      "train loss:0.001312680247897483\n",
      "train loss:0.02242179417816619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022803944890409924\n",
      "train loss:0.004338179973546135\n",
      "train loss:0.007939792284642469\n",
      "train loss:0.02388214493654494\n",
      "train loss:0.004286757345783829\n",
      "train loss:0.01537026418881431\n",
      "train loss:0.001305327168800268\n",
      "train loss:0.015251353597443786\n",
      "train loss:0.015962021087111058\n",
      "train loss:0.013541781115530793\n",
      "train loss:0.003634396787970205\n",
      "train loss:0.008787253098843496\n",
      "train loss:0.001899507751105938\n",
      "train loss:0.007254205227056139\n",
      "train loss:0.015627479264897458\n",
      "train loss:0.06259567638115736\n",
      "train loss:0.011881001728902392\n",
      "train loss:0.017134705780191606\n",
      "train loss:0.0031083728774619823\n",
      "train loss:0.006855081977106403\n",
      "train loss:0.004403400820770945\n",
      "train loss:0.0065947207355103905\n",
      "train loss:0.011772770207278578\n",
      "train loss:0.021722806976047625\n",
      "train loss:0.005793697265567283\n",
      "train loss:0.004511516715896534\n",
      "train loss:0.00869872922030225\n",
      "train loss:0.00569729682048114\n",
      "train loss:0.01185149678534441\n",
      "train loss:0.01109820993362826\n",
      "train loss:0.005328218433492244\n",
      "train loss:0.03688991462890785\n",
      "train loss:0.003739850907926759\n",
      "train loss:0.0046843734014638\n",
      "train loss:0.0022544414427853794\n",
      "train loss:0.005394867717429007\n",
      "train loss:0.04448098085203407\n",
      "train loss:0.004212033492732135\n",
      "train loss:0.0022050075900185593\n",
      "train loss:0.007989837315496797\n",
      "train loss:0.006482013795932597\n",
      "train loss:0.030647873353866376\n",
      "train loss:0.005615114973622901\n",
      "train loss:0.006324019764720745\n",
      "train loss:0.02736898026011307\n",
      "train loss:0.018003497095397957\n",
      "train loss:0.0035751374810174498\n",
      "train loss:0.006143399182537369\n",
      "train loss:0.02468322405342361\n",
      "train loss:0.006350133368851245\n",
      "train loss:0.01703211055636944\n",
      "train loss:0.019263152538502335\n",
      "train loss:0.01561871822770478\n",
      "train loss:0.01661253179085207\n",
      "train loss:0.006102674638647998\n",
      "train loss:0.01861922867150469\n",
      "train loss:0.015988687026268884\n",
      "train loss:0.011380865520482288\n",
      "train loss:0.0023927465664125495\n",
      "train loss:0.007362215573085738\n",
      "train loss:0.0065581606476745906\n",
      "train loss:0.001906266471092799\n",
      "train loss:0.026125133177136606\n",
      "train loss:0.004392911963266145\n",
      "train loss:0.018666125527215197\n",
      "train loss:0.020696900489255966\n",
      "train loss:0.004961156997803844\n",
      "train loss:0.002640699284980703\n",
      "train loss:0.011097731802843189\n",
      "train loss:0.0016854928403184448\n",
      "train loss:0.015760354599427494\n",
      "train loss:0.03069543185807745\n",
      "train loss:0.010795985948250875\n",
      "train loss:0.008871887616986818\n",
      "train loss:0.007677553823011085\n",
      "train loss:0.00662684058340288\n",
      "train loss:0.023075879522192977\n",
      "train loss:0.0016080034492703774\n",
      "train loss:0.005606102627471902\n",
      "train loss:0.01882450405983553\n",
      "train loss:0.003966952396927766\n",
      "train loss:0.005591815913714457\n",
      "train loss:0.009294644399262132\n",
      "train loss:0.025280088513831823\n",
      "train loss:0.03726236106545842\n",
      "train loss:0.015518822137232189\n",
      "train loss:0.018400192438167748\n",
      "train loss:0.004509302523322669\n",
      "train loss:0.006603314762619473\n",
      "train loss:0.0053836343981757215\n",
      "train loss:0.007508951868602254\n",
      "train loss:0.006825893483482236\n",
      "train loss:0.03117148975737549\n",
      "train loss:0.013805062722845643\n",
      "train loss:0.011474943606414682\n",
      "train loss:0.0058094658544590545\n",
      "train loss:0.00444529633838048\n",
      "train loss:0.0036411749261046496\n",
      "train loss:0.013609507643718589\n",
      "train loss:0.022799473099396658\n",
      "train loss:0.031248253596273264\n",
      "train loss:0.007284760109687447\n",
      "train loss:0.010228430998746334\n",
      "train loss:0.004821924711299097\n",
      "train loss:0.00431731169538503\n",
      "train loss:0.026515582438388096\n",
      "train loss:0.012052927355236172\n",
      "train loss:0.008752439820714908\n",
      "train loss:0.022962914128755566\n",
      "train loss:0.012710382403968507\n",
      "train loss:0.006846797608776767\n",
      "train loss:0.005512287789440585\n",
      "train loss:0.01359154712524316\n",
      "train loss:0.010966627322609624\n",
      "train loss:0.008233519858396808\n",
      "train loss:0.008828370463743136\n",
      "train loss:0.005042970985120893\n",
      "train loss:0.008896991060614813\n",
      "train loss:0.0028884130208580703\n",
      "train loss:0.014691511801195888\n",
      "train loss:0.021876692686891578\n",
      "train loss:0.011638699587167975\n",
      "train loss:0.002753220433358025\n",
      "train loss:0.014326777123617369\n",
      "train loss:0.014653174372339301\n",
      "train loss:0.005288851904101116\n",
      "train loss:0.008647025786146552\n",
      "train loss:0.016392034347349548\n",
      "train loss:0.0038285233550111935\n",
      "train loss:0.010487444517888392\n",
      "train loss:0.005881169606910176\n",
      "train loss:0.008781792290214465\n",
      "train loss:0.011085177829650551\n",
      "train loss:0.030528390056329385\n",
      "train loss:0.010164651440602685\n",
      "train loss:0.011769229718489963\n",
      "train loss:0.004320482492939279\n",
      "train loss:0.03249621895520306\n",
      "train loss:0.01383127064375859\n",
      "train loss:0.013668151258568661\n",
      "train loss:0.004528189160374839\n",
      "train loss:0.03136704756883827\n",
      "train loss:0.003825446050100442\n",
      "train loss:0.01553140049098358\n",
      "train loss:0.004034260254670717\n",
      "train loss:0.0038249464129527784\n",
      "train loss:0.02944137232593451\n",
      "train loss:0.00909971874974232\n",
      "train loss:0.008373310979331534\n",
      "train loss:0.002604553583979904\n",
      "train loss:0.0032684326351501555\n",
      "train loss:0.011664298244134957\n",
      "train loss:0.008512381673558778\n",
      "train loss:0.0066583771700619195\n",
      "train loss:0.028683506586483838\n",
      "train loss:0.008784962224063211\n",
      "train loss:0.003973402641409275\n",
      "train loss:0.0006522044208885481\n",
      "train loss:0.0030973530988868477\n",
      "train loss:0.0008800942919181331\n",
      "train loss:0.010579195405130309\n",
      "train loss:0.0035336398325059555\n",
      "train loss:0.00219341004263452\n",
      "train loss:0.003743250006098919\n",
      "train loss:0.005768439829076723\n",
      "train loss:0.0032806049409143936\n",
      "train loss:0.0012992055188374228\n",
      "train loss:0.0368952990994847\n",
      "train loss:0.01217122953715963\n",
      "train loss:0.008665312390440473\n",
      "train loss:0.006158936683439289\n",
      "train loss:0.0019025172386921078\n",
      "train loss:0.0008819633300115435\n",
      "train loss:0.0017226504632578145\n",
      "train loss:0.004485480234254767\n",
      "train loss:0.0014049285457397105\n",
      "train loss:0.010004801088973692\n",
      "train loss:0.00854394190115638\n",
      "train loss:0.0024405098089753064\n",
      "train loss:0.002837637292039389\n",
      "train loss:0.009926890977652918\n",
      "train loss:0.028329200425595495\n",
      "train loss:0.003219914710530619\n",
      "train loss:0.007358435818268329\n",
      "train loss:0.0008231665591863809\n",
      "train loss:0.0021180329346958742\n",
      "train loss:0.0029778467525319874\n",
      "train loss:0.008679641878552186\n",
      "train loss:0.012129612456215319\n",
      "train loss:0.04434215311557165\n",
      "train loss:0.006349462886975606\n",
      "train loss:0.0110082705335249\n",
      "train loss:0.0029969368227425837\n",
      "train loss:0.002784443980924948\n",
      "train loss:0.0010611578004463714\n",
      "train loss:0.002349488409982765\n",
      "train loss:0.0016984494707151453\n",
      "train loss:0.006942427553730845\n",
      "train loss:0.0018703186896652888\n",
      "train loss:0.0027625133096848805\n",
      "train loss:0.005446699010845534\n",
      "train loss:0.006865737059738976\n",
      "train loss:0.04909079795900749\n",
      "train loss:0.03871243576853624\n",
      "train loss:0.000488362879840241\n",
      "=== epoch:13, train acc:0.9963088768115942, test acc:0.9858695652173913 ===\n",
      "train loss:0.0013418740362036257\n",
      "train loss:0.001104851408841581\n",
      "train loss:0.02248177991861305\n",
      "train loss:0.0012635986355440981\n",
      "train loss:0.04724052958162061\n",
      "train loss:0.003621250961646949\n",
      "train loss:0.008663844220021564\n",
      "train loss:0.020840061972112304\n",
      "train loss:0.01826418921998694\n",
      "train loss:0.0026147159458027773\n",
      "train loss:0.019209344399475504\n",
      "train loss:0.0046957849877832265\n",
      "train loss:0.003946132504532225\n",
      "train loss:0.0038034149109091348\n",
      "train loss:0.007378331250129139\n",
      "train loss:0.0038135020253169303\n",
      "train loss:0.002693863315538549\n",
      "train loss:0.0024062723871565166\n",
      "train loss:0.006582391944458883\n",
      "train loss:0.0325311049386999\n",
      "train loss:0.018940014246680285\n",
      "train loss:0.004056635974187177\n",
      "train loss:0.006167005215710531\n",
      "train loss:0.006887146240217392\n",
      "train loss:0.01653518129715569\n",
      "train loss:0.019055235157816937\n",
      "train loss:0.003984137878682403\n",
      "train loss:0.031021918478694812\n",
      "train loss:0.0013105441055873042\n",
      "train loss:0.007288630652836662\n",
      "train loss:0.0093425425639016\n",
      "train loss:0.03146134592024491\n",
      "train loss:0.0036716755595057634\n",
      "train loss:0.0028527362635455264\n",
      "train loss:0.007640482546797089\n",
      "train loss:0.0038596454674381248\n",
      "train loss:0.016045113445111163\n",
      "train loss:0.031022208152435504\n",
      "train loss:0.024997716184012735\n",
      "train loss:0.014228141884935786\n",
      "train loss:0.020542500369043638\n",
      "train loss:0.007074857391480077\n",
      "train loss:0.0058546037538708484\n",
      "train loss:0.007642331822625382\n",
      "train loss:0.00875752992810632\n",
      "train loss:0.005053127902003157\n",
      "train loss:0.006587742119799062\n",
      "train loss:0.012018597724286428\n",
      "train loss:0.004569494421759411\n",
      "train loss:0.00281278063845255\n",
      "train loss:0.005724978686874251\n",
      "train loss:0.018910388144101252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01552815344917802\n",
      "train loss:0.0027303084841608727\n",
      "train loss:0.021329762851784395\n",
      "train loss:0.01630123082722316\n",
      "train loss:0.0059477847023164535\n",
      "train loss:0.0057645187703212215\n",
      "train loss:0.002937508528156264\n",
      "train loss:0.005674717713880257\n",
      "train loss:0.005781335667947043\n",
      "train loss:0.0009478885089768289\n",
      "train loss:0.00781540605240162\n",
      "train loss:0.0024636327981124974\n",
      "train loss:0.005980848285454499\n",
      "train loss:0.003212852165817223\n",
      "train loss:0.0037031277752271117\n",
      "train loss:0.002024550344645332\n",
      "train loss:0.012045578377618337\n",
      "train loss:0.016719017893230777\n",
      "train loss:0.003016700577476486\n",
      "train loss:0.002513821528345819\n",
      "train loss:0.004504451585613281\n",
      "train loss:0.002655278374949742\n",
      "train loss:0.002891288867836552\n",
      "train loss:0.004381813658332045\n",
      "train loss:0.004631422185777958\n",
      "train loss:0.01267215456494732\n",
      "train loss:0.06041773400907462\n",
      "train loss:0.0021756763196711187\n",
      "train loss:0.01580100285884119\n",
      "train loss:0.0025180581087791607\n",
      "train loss:0.005711611174212278\n",
      "train loss:0.015942271809090202\n",
      "train loss:0.024233124777409226\n",
      "train loss:0.054749514717053686\n",
      "train loss:0.0027434532055595883\n",
      "train loss:0.004316799388845855\n",
      "train loss:0.0037596417588808234\n",
      "train loss:0.0027949188569444464\n",
      "train loss:0.002642243205277636\n",
      "train loss:0.014491910610663575\n",
      "train loss:0.004982554845942743\n",
      "train loss:0.00394279649280982\n",
      "train loss:0.0022791220472087093\n",
      "train loss:0.0011421017868477878\n",
      "train loss:0.0011918275694579742\n",
      "train loss:0.0014667337770845406\n",
      "train loss:0.002929187901713074\n",
      "train loss:0.00339231272829089\n",
      "train loss:0.0027590825364822305\n",
      "train loss:0.004411265773011729\n",
      "train loss:0.015572655003178781\n",
      "train loss:0.00788295882586176\n",
      "train loss:0.0214543531163943\n",
      "train loss:0.009096562266616348\n",
      "train loss:0.008810530291247953\n",
      "train loss:0.017894149515547943\n",
      "train loss:0.0037418260183336286\n",
      "train loss:0.013864619061071145\n",
      "train loss:0.0026014163396039635\n",
      "train loss:0.009736850760275032\n",
      "train loss:0.027487380294093502\n",
      "train loss:0.006076814869191487\n",
      "train loss:0.003850374087264164\n",
      "train loss:0.010644095329923244\n",
      "train loss:0.018758747182062534\n",
      "train loss:0.00436114461699495\n",
      "train loss:0.0036750441322475026\n",
      "train loss:0.032656506342087555\n",
      "train loss:0.00242724916220655\n",
      "train loss:0.004007380156822389\n",
      "train loss:0.022359243475944195\n",
      "train loss:0.0058821385230614755\n",
      "train loss:0.00439066832210097\n",
      "train loss:0.056516210697183475\n",
      "train loss:0.0049719138299161685\n",
      "train loss:0.020839539992150366\n",
      "train loss:0.021184663337997445\n",
      "train loss:0.0031998941254458373\n",
      "train loss:0.004985713816609982\n",
      "train loss:0.0031178545807425276\n",
      "train loss:0.0054616742642016654\n",
      "train loss:0.014429289695877902\n",
      "train loss:0.02580435470949953\n",
      "train loss:0.07614321090487214\n",
      "train loss:0.01289442539310131\n",
      "train loss:0.004394538132418968\n",
      "train loss:0.009898681276268936\n",
      "train loss:0.008615441699789042\n",
      "train loss:0.007312819821432897\n",
      "train loss:0.05055213440178097\n",
      "train loss:0.02719477082110102\n",
      "train loss:0.003874916533698122\n",
      "train loss:0.0022720594819003194\n",
      "train loss:0.0028423429282809242\n",
      "train loss:0.044039829066370786\n",
      "train loss:0.01690789393973048\n",
      "train loss:0.02948136614296699\n",
      "train loss:0.0623339854489598\n",
      "train loss:0.00797992524563204\n",
      "train loss:0.006789276598726394\n",
      "train loss:0.015863351453923598\n",
      "train loss:0.050076755930422934\n",
      "train loss:0.003088359464922545\n",
      "train loss:0.004438559553599466\n",
      "train loss:0.0063573836908087135\n",
      "train loss:0.005828588603167598\n",
      "train loss:0.001703050757377043\n",
      "train loss:0.0028955960929309067\n",
      "train loss:0.002232138207037521\n",
      "train loss:0.00333471721733976\n",
      "train loss:0.0028417534739101076\n",
      "train loss:0.006941694402127487\n",
      "train loss:0.0061189484299589\n",
      "train loss:0.0032270190672861734\n",
      "train loss:0.008652960162456117\n",
      "train loss:0.003664202007114095\n",
      "train loss:0.015014322779138872\n",
      "train loss:0.015125917842546006\n",
      "train loss:0.0060294744548872155\n",
      "train loss:0.004739444074807041\n",
      "train loss:0.03817649031545041\n",
      "train loss:0.012919184780928895\n",
      "train loss:0.0037188348990355455\n",
      "train loss:0.004723992356080245\n",
      "train loss:0.0008231998880528312\n",
      "train loss:0.0038597115502384807\n",
      "train loss:0.00936470699094564\n",
      "train loss:0.002762811590528297\n",
      "train loss:0.004871962400945716\n",
      "train loss:0.011527356989684283\n",
      "train loss:0.002328737700805228\n",
      "train loss:0.024766944761827992\n",
      "train loss:0.0049159631134568825\n",
      "train loss:0.0014668357095518024\n",
      "train loss:0.0028825273153776703\n",
      "train loss:0.0050929896941787085\n",
      "train loss:0.029258609560479352\n",
      "train loss:0.0038058311063330964\n",
      "train loss:0.004378297834803208\n",
      "train loss:0.0013346140844513465\n",
      "train loss:0.018165077665367117\n",
      "train loss:0.010661402774601073\n",
      "train loss:0.0008630382657472296\n",
      "train loss:0.011332075728201104\n",
      "train loss:0.03636171704457229\n",
      "train loss:0.005523820934061444\n",
      "train loss:0.00258417283215194\n",
      "train loss:0.012230134621707085\n",
      "train loss:0.0037727393621463825\n",
      "train loss:0.036828214901389655\n",
      "train loss:0.0004674059237223586\n",
      "train loss:0.02036437733661205\n",
      "train loss:0.011043081885101395\n",
      "train loss:0.0010938850776562041\n",
      "train loss:0.05769634028144698\n",
      "train loss:0.005870598486862442\n",
      "train loss:0.007599181753677278\n",
      "train loss:0.00998844206879699\n",
      "train loss:0.003077695589424667\n",
      "train loss:0.01936796985613641\n",
      "train loss:0.010989682143265145\n",
      "train loss:0.0025253595622423694\n",
      "train loss:0.00225921259706272\n",
      "train loss:0.0019892110639889884\n",
      "train loss:0.020936899694684062\n",
      "train loss:0.055536506204712205\n",
      "train loss:0.007994282045485636\n",
      "train loss:0.0025876477420469085\n",
      "train loss:0.004360032532988623\n",
      "train loss:0.009582333930750066\n",
      "train loss:0.0008147614489552119\n",
      "train loss:0.009860868656280008\n",
      "train loss:0.001613111604872526\n",
      "train loss:0.0015296278591614336\n",
      "train loss:0.0011817304375408753\n",
      "train loss:0.02118390897235656\n",
      "train loss:0.01443067676581025\n",
      "train loss:0.004795082560264646\n",
      "train loss:0.016350733637154294\n",
      "train loss:0.0012442041897460902\n",
      "train loss:0.003320010557359123\n",
      "train loss:0.0015042710725677736\n",
      "train loss:0.00234320288918576\n",
      "train loss:0.002554704180231325\n",
      "train loss:0.0006097250501037592\n",
      "train loss:0.004366126018679987\n",
      "train loss:0.000589181117675752\n",
      "train loss:0.0033507543557173935\n",
      "train loss:0.013725387437311045\n",
      "train loss:0.01443585422217922\n",
      "train loss:0.003256713006854317\n",
      "train loss:0.0047540056710592355\n",
      "train loss:0.0007545781282899863\n",
      "train loss:0.002344959607318298\n",
      "train loss:0.048644328003541994\n",
      "train loss:0.0027408294153287824\n",
      "train loss:0.0029295777718654392\n",
      "train loss:0.004385975867850933\n",
      "train loss:0.005412233396155708\n",
      "train loss:0.003029739372354834\n",
      "train loss:0.002243240059524114\n",
      "train loss:0.0015849399818610864\n",
      "train loss:0.003220104562844206\n",
      "train loss:0.015420515567554314\n",
      "train loss:0.0022351255768771968\n",
      "train loss:0.004781699001113843\n",
      "train loss:0.0021191043786523357\n",
      "train loss:0.0007786908563201921\n",
      "train loss:0.011252697925528495\n",
      "train loss:0.0021926609692260496\n",
      "train loss:0.004389778794172377\n",
      "train loss:0.032253243128742656\n",
      "train loss:0.007711393181281435\n",
      "train loss:0.020659131970563575\n",
      "train loss:0.0061539332130314895\n",
      "train loss:0.004661678666337799\n",
      "train loss:0.009474103149674654\n",
      "train loss:0.0018409156334198635\n",
      "train loss:0.005069278513273758\n",
      "train loss:0.003670155996545139\n",
      "train loss:0.01314185218225953\n",
      "train loss:0.006494054101302549\n",
      "train loss:0.011434338680258402\n",
      "train loss:0.001953045565329678\n",
      "train loss:0.07090182113161347\n",
      "train loss:0.0006259278357138048\n",
      "train loss:0.003860667238942811\n",
      "train loss:0.0007892116535369459\n",
      "train loss:0.02336616720875255\n",
      "train loss:0.013357610901670248\n",
      "train loss:0.00480599384703699\n",
      "train loss:0.013132382061639665\n",
      "train loss:0.012511333683444313\n",
      "train loss:0.0023347159174025704\n",
      "train loss:0.04220526489534759\n",
      "train loss:0.0021944404624848275\n",
      "train loss:0.018902450034359638\n",
      "train loss:0.0043368184388189015\n",
      "train loss:0.014187613945893145\n",
      "train loss:0.004011120538886196\n",
      "train loss:0.004728375527756306\n",
      "train loss:0.026614227685004946\n",
      "train loss:0.008004818439186786\n",
      "train loss:0.011827499266614487\n",
      "train loss:0.01437274066548407\n",
      "train loss:0.003834688442913227\n",
      "train loss:0.046373190290679905\n",
      "train loss:0.0023360024347982788\n",
      "train loss:0.01138879430128895\n",
      "train loss:0.003747615030649077\n",
      "train loss:0.012808049055176024\n",
      "train loss:0.013210134396674384\n",
      "train loss:0.03022579427241386\n",
      "train loss:0.0025789516460132766\n",
      "train loss:0.005746200554512303\n",
      "train loss:0.021923440191961404\n",
      "train loss:0.014466520000166272\n",
      "train loss:0.019853742347814226\n",
      "train loss:0.003551777168868896\n",
      "train loss:0.008345379856626004\n",
      "train loss:0.0035923531873207496\n",
      "train loss:0.0056496022705765075\n",
      "train loss:0.0035631956051372653\n",
      "train loss:0.009632342251342406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00914599038923927\n",
      "train loss:0.014669920051340806\n",
      "train loss:0.006638980056834284\n",
      "train loss:0.004243753643994954\n",
      "train loss:0.00626854230576247\n",
      "train loss:0.0032957551273626127\n",
      "train loss:0.004750584079890008\n",
      "train loss:0.0065292583468668985\n",
      "train loss:0.0027350927017235505\n",
      "train loss:0.0027149499926698776\n",
      "train loss:0.0019092316479038455\n",
      "train loss:0.005952570916635779\n",
      "train loss:0.00784792142800267\n",
      "train loss:0.00732204456821038\n",
      "train loss:0.002091716874437183\n",
      "train loss:0.0018114986819304036\n",
      "train loss:0.0011377676079450255\n",
      "train loss:0.019488471205624112\n",
      "train loss:0.010837155616495227\n",
      "train loss:0.0016693517053598\n",
      "train loss:0.0027270177599588996\n",
      "train loss:0.0058063759386785905\n",
      "train loss:0.0005409963817663393\n",
      "train loss:0.0014493431246225808\n",
      "train loss:0.03309893840484996\n",
      "train loss:0.0013065021435005862\n",
      "train loss:0.0022678961108114903\n",
      "train loss:0.0036692040937676344\n",
      "train loss:0.004850480951136977\n",
      "train loss:0.011347825123328348\n",
      "train loss:0.0020674445555979282\n",
      "train loss:0.001965278606890918\n",
      "train loss:0.04538750566668535\n",
      "train loss:0.004002519707385503\n",
      "train loss:0.0037463779222457324\n",
      "train loss:0.005982109520213465\n",
      "train loss:0.004296891711210902\n",
      "train loss:0.019902772523849067\n",
      "train loss:0.010010905038315254\n",
      "train loss:0.009989917610564066\n",
      "train loss:0.006282832297739502\n",
      "train loss:0.0031764337536649436\n",
      "train loss:0.005440672800701372\n",
      "train loss:0.002429643837177718\n",
      "train loss:0.005485552331714604\n",
      "train loss:0.003055240222941242\n",
      "train loss:0.01637881236107953\n",
      "train loss:0.011707393822490897\n",
      "train loss:0.002427725620250146\n",
      "train loss:0.016757471440054343\n",
      "train loss:0.0017738973590217485\n",
      "train loss:0.003975225437823668\n",
      "=== epoch:14, train acc:0.9971240942028986, test acc:0.9883152173913043 ===\n",
      "train loss:0.016989471578925653\n",
      "train loss:0.006242102321365106\n",
      "train loss:0.02120513108520627\n",
      "train loss:0.0037129302474081406\n",
      "train loss:0.00572283301299966\n",
      "train loss:0.0034529962882440812\n",
      "train loss:0.004717176083560973\n",
      "train loss:0.04369325352278153\n",
      "train loss:0.0033057104248853703\n",
      "train loss:0.00257554157096911\n",
      "train loss:0.00045050984644262593\n",
      "train loss:0.0011479064211514164\n",
      "train loss:0.008706904343770082\n",
      "train loss:0.0017026858319207213\n",
      "train loss:0.004318309236730037\n",
      "train loss:0.0007872624805382727\n",
      "train loss:0.006221657399810885\n",
      "train loss:0.0008832033810745638\n",
      "train loss:0.0013121668642837572\n",
      "train loss:0.0013772542526314876\n",
      "train loss:0.01898211171564054\n",
      "train loss:0.02183059566117804\n",
      "train loss:0.0059107115460217035\n",
      "train loss:0.0007770564896136342\n",
      "train loss:0.013285902385686783\n",
      "train loss:0.0019161923549556531\n",
      "train loss:0.014942424348095859\n",
      "train loss:0.00986116580376684\n",
      "train loss:0.0025777177844497562\n",
      "train loss:0.013848389402738285\n",
      "train loss:0.03209863588531957\n",
      "train loss:0.0046639299338230075\n",
      "train loss:0.00549361954561635\n",
      "train loss:0.019268439038929566\n",
      "train loss:0.004843259804168828\n",
      "train loss:0.0023841100688069047\n",
      "train loss:0.018616328724133234\n",
      "train loss:0.004438304193825375\n",
      "train loss:0.006724924651522533\n",
      "train loss:0.011131840469424562\n",
      "train loss:0.005721242630969746\n",
      "train loss:0.017052970235788143\n",
      "train loss:0.0044741314501791744\n",
      "train loss:0.016794660975306533\n",
      "train loss:0.004347570336542683\n",
      "train loss:0.00857465643392508\n",
      "train loss:0.003177413418328073\n",
      "train loss:0.01006836922626343\n",
      "train loss:0.004606912795893007\n",
      "train loss:0.014316366515996992\n",
      "train loss:0.003855750097260822\n",
      "train loss:0.02692488788998929\n",
      "train loss:0.003785256837418956\n",
      "train loss:0.0019977621308294004\n",
      "train loss:0.019037188370072546\n",
      "train loss:0.007221030993308495\n",
      "train loss:0.0018830500794105366\n",
      "train loss:0.006994321269282553\n",
      "train loss:0.004512637957232506\n",
      "train loss:0.0012788352599431322\n",
      "train loss:0.004782294279386964\n",
      "train loss:0.003200028977949321\n",
      "train loss:0.004371914874610764\n",
      "train loss:0.010578006209189245\n",
      "train loss:0.002021576269825219\n",
      "train loss:0.00491220250574777\n",
      "train loss:0.0032949616492042874\n",
      "train loss:0.006663996899974053\n",
      "train loss:0.0013015290316653347\n",
      "train loss:0.0039774826295395724\n",
      "train loss:0.003555768883576113\n",
      "train loss:0.005407312506152573\n",
      "train loss:0.007430093245099265\n",
      "train loss:0.0013956150829308297\n",
      "train loss:0.013316571671581337\n",
      "train loss:0.03910929705957051\n",
      "train loss:0.0010845147752650676\n",
      "train loss:0.00256454506914717\n",
      "train loss:0.003220453824318352\n",
      "train loss:0.01041680361736704\n",
      "train loss:0.0008164081522898115\n",
      "train loss:0.018553940060492897\n",
      "train loss:0.0008747103828380428\n",
      "train loss:0.00117898111000309\n",
      "train loss:0.001087163948612381\n",
      "train loss:0.025757152690901293\n",
      "train loss:0.02965063232195608\n",
      "train loss:0.01916893075786184\n",
      "train loss:0.011585574909657665\n",
      "train loss:0.03631602785974513\n",
      "train loss:0.029432394522538843\n",
      "train loss:0.004501625732326807\n",
      "train loss:0.0012836093197451965\n",
      "train loss:0.001355410500734168\n",
      "train loss:0.0009770191893673894\n",
      "train loss:0.004588558086078771\n",
      "train loss:0.0025263198395007657\n",
      "train loss:0.033678602333782615\n",
      "train loss:0.01624696028468439\n",
      "train loss:0.016662470256450505\n",
      "train loss:0.000642144065810054\n",
      "train loss:0.015031553386155378\n",
      "train loss:0.012741296031070156\n",
      "train loss:0.013739943707079361\n",
      "train loss:0.02972702053059939\n",
      "train loss:0.0015875590136790953\n",
      "train loss:0.007066556497325318\n",
      "train loss:0.0040030638415520774\n",
      "train loss:0.016607180270867678\n",
      "train loss:0.004834507093257031\n",
      "train loss:0.010573308918879696\n",
      "train loss:0.0012649029026971803\n",
      "train loss:0.0021094763042898957\n",
      "train loss:0.005871542294550503\n",
      "train loss:0.001998465041691833\n",
      "train loss:0.0028510902356286725\n",
      "train loss:0.0008398331131027534\n",
      "train loss:0.0029425478367041797\n",
      "train loss:0.004390833872776583\n",
      "train loss:0.0032862252105066354\n",
      "train loss:0.013308393530933977\n",
      "train loss:0.0037222819023269905\n",
      "train loss:0.004004477125789662\n",
      "train loss:0.00899402394845973\n",
      "train loss:0.009313035712336366\n",
      "train loss:0.00297710618070349\n",
      "train loss:0.003220532312170411\n",
      "train loss:0.001633889820479723\n",
      "train loss:0.0038969476352489624\n",
      "train loss:0.01939269875343775\n",
      "train loss:0.01067123264569178\n",
      "train loss:0.007659279537647775\n",
      "train loss:0.015278408713776873\n",
      "train loss:0.0175682770440685\n",
      "train loss:0.0034368837261035375\n",
      "train loss:0.004075589369208855\n",
      "train loss:0.0060987621524689496\n",
      "train loss:0.0033502187289411434\n",
      "train loss:0.002956738664649188\n",
      "train loss:0.00834187944709477\n",
      "train loss:0.001111093494906591\n",
      "train loss:0.0027472304125454408\n",
      "train loss:0.0030607362468693835\n",
      "train loss:0.012066400904152208\n",
      "train loss:0.017112330375781793\n",
      "train loss:0.008932530851472525\n",
      "train loss:0.010750231479607273\n",
      "train loss:0.002783797020662751\n",
      "train loss:0.009502319114967508\n",
      "train loss:0.007750347874282247\n",
      "train loss:0.009423407451276306\n",
      "train loss:0.0054762429985241124\n",
      "train loss:0.00430570287012842\n",
      "train loss:0.0014179515137988903\n",
      "train loss:0.016017861432861664\n",
      "train loss:0.0033882006735953744\n",
      "train loss:0.012214189712642128\n",
      "train loss:0.004073242324449226\n",
      "train loss:0.03883677832004593\n",
      "train loss:0.0024754242109330496\n",
      "train loss:0.0032349618757189827\n",
      "train loss:0.003085868823240949\n",
      "train loss:0.03867030288681594\n",
      "train loss:0.007741453588626472\n",
      "train loss:0.0029304547364222317\n",
      "train loss:0.0055259525844096455\n",
      "train loss:0.0033628662082132396\n",
      "train loss:0.005279586474677643\n",
      "train loss:0.005696708851900132\n",
      "train loss:0.014471132527430925\n",
      "train loss:0.004439772982715235\n",
      "train loss:0.08014873800772122\n",
      "train loss:0.01817842354637338\n",
      "train loss:0.008890494009309023\n",
      "train loss:0.007603779328043624\n",
      "train loss:0.010446240899761362\n",
      "train loss:0.010914249746619514\n",
      "train loss:0.006370654299033294\n",
      "train loss:0.001920885781985389\n",
      "train loss:0.005255501953446541\n",
      "train loss:0.006039478285970403\n",
      "train loss:0.006632482528794444\n",
      "train loss:0.0031836886718599544\n",
      "train loss:0.0029183710621688663\n",
      "train loss:0.0016296869789345825\n",
      "train loss:0.0014341532753679024\n",
      "train loss:0.025128635083376327\n",
      "train loss:0.004306811693072886\n",
      "train loss:0.0043510649086813775\n",
      "train loss:0.010109264286612133\n",
      "train loss:0.040411563864885564\n",
      "train loss:0.0007103594957047489\n",
      "train loss:0.000836511030235267\n",
      "train loss:0.0025200959691561065\n",
      "train loss:0.023900048911540062\n",
      "train loss:0.0018126402433923767\n",
      "train loss:0.0039529249536430985\n",
      "train loss:0.0029408296454837826\n",
      "train loss:0.007109003851626932\n",
      "train loss:0.010442634110816144\n",
      "train loss:0.008175320155919624\n",
      "train loss:0.003245546637709658\n",
      "train loss:0.02693611422528979\n",
      "train loss:0.0015790608136248164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.016994111021388352\n",
      "train loss:0.0014989618120807148\n",
      "train loss:0.0017446724125070184\n",
      "train loss:0.004282889257648626\n",
      "train loss:0.0014191495336868204\n",
      "train loss:0.013679619895413527\n",
      "train loss:0.002867260069210255\n",
      "train loss:0.015278814107945925\n",
      "train loss:0.0011389787940826175\n",
      "train loss:0.003213001754759851\n",
      "train loss:0.001571612728774882\n",
      "train loss:0.0020929842295569897\n",
      "train loss:0.03877660396424778\n",
      "train loss:0.002272892989369586\n",
      "train loss:0.0017065000608962576\n",
      "train loss:0.0007641373881487996\n",
      "train loss:0.0011969486987898092\n",
      "train loss:0.001566951044964395\n",
      "train loss:0.003335753326151539\n",
      "train loss:0.009490125930296632\n",
      "train loss:0.0037471476317057785\n",
      "train loss:0.0028993125555667344\n",
      "train loss:0.001471128574084376\n",
      "train loss:0.004291628372440198\n",
      "train loss:0.009784002455904337\n",
      "train loss:0.0038404235904254402\n",
      "train loss:0.0011801813931687937\n",
      "train loss:0.007584865281616106\n",
      "train loss:0.0017624392402655615\n",
      "train loss:0.005922426554836005\n",
      "train loss:0.0014136582507247037\n",
      "train loss:0.04445204352272435\n",
      "train loss:0.0007781160506889856\n",
      "train loss:0.01047577713249573\n",
      "train loss:0.01519428583501253\n",
      "train loss:0.0078064310126032405\n",
      "train loss:0.012289369271984818\n",
      "train loss:0.012325671929673375\n",
      "train loss:0.00923125771908715\n",
      "train loss:0.0008948912629463997\n",
      "train loss:0.005974456341557815\n",
      "train loss:0.006575316734505299\n",
      "train loss:0.0013427816878723198\n",
      "train loss:0.003199702614891228\n",
      "train loss:0.021790752730684607\n",
      "train loss:0.001613394468983895\n",
      "train loss:0.011181578131266004\n",
      "train loss:0.011022335223362824\n",
      "train loss:0.006507205708887784\n",
      "train loss:0.0021683072715113234\n",
      "train loss:0.021101063383109145\n",
      "train loss:0.00546873783128034\n",
      "train loss:0.00306742854388687\n",
      "train loss:0.009232136212315768\n",
      "train loss:0.005744777757484264\n",
      "train loss:0.004961805578889674\n",
      "train loss:0.006290374336700968\n",
      "train loss:0.004660740229535697\n",
      "train loss:0.006559321473331128\n",
      "train loss:0.0020798569281995096\n",
      "train loss:0.005757125973173147\n",
      "train loss:0.005131331889786587\n",
      "train loss:0.007100759689007931\n",
      "train loss:0.0010157351250935605\n",
      "train loss:0.0012313376630264372\n",
      "train loss:0.0031887993690501827\n",
      "train loss:0.003329956842213864\n",
      "train loss:0.0031542045918967598\n",
      "train loss:0.017696314657578642\n",
      "train loss:0.008263953150208133\n",
      "train loss:0.0011466696989904962\n",
      "train loss:0.0017486529140400007\n",
      "train loss:0.0093263072347254\n",
      "train loss:0.0060189132541651124\n",
      "train loss:0.002063392362409272\n",
      "train loss:0.004676318714172543\n",
      "train loss:0.0023845469587958136\n",
      "train loss:0.004971483777307348\n",
      "train loss:0.00947561699032313\n",
      "train loss:0.0021831550675032335\n",
      "train loss:0.007413617705469319\n",
      "train loss:0.0007925555929322492\n",
      "train loss:0.007140581588642762\n",
      "train loss:0.0003021540141601687\n",
      "train loss:0.02625847335598874\n",
      "train loss:0.013416786097524943\n",
      "train loss:0.01207368451743024\n",
      "train loss:0.003070118377716764\n",
      "train loss:0.0008193014008164699\n",
      "train loss:0.014285914222542193\n",
      "train loss:0.001007323330382128\n",
      "train loss:0.002052575256497039\n",
      "train loss:0.006357367946170128\n",
      "train loss:0.0022337409842277237\n",
      "train loss:0.0024183030792127736\n",
      "train loss:0.007165773496781671\n",
      "train loss:0.0018728631269539478\n",
      "train loss:0.003959029755733769\n",
      "train loss:0.0009390060468380974\n",
      "train loss:0.002045736889949504\n",
      "train loss:0.0007238459768810215\n",
      "train loss:0.006572104106125001\n",
      "train loss:0.02384446440528163\n",
      "train loss:0.0006544172030381272\n",
      "train loss:0.01771088275403184\n",
      "train loss:0.001977310784151099\n",
      "train loss:0.003064680940733411\n",
      "train loss:0.0009044514137422372\n",
      "train loss:0.0011008434643171\n",
      "train loss:0.0008305137167950737\n",
      "train loss:0.00047133393670386486\n",
      "train loss:0.013412838038006226\n",
      "train loss:0.004451493257110796\n",
      "train loss:0.01172854570120992\n",
      "train loss:0.011392119075397262\n",
      "train loss:0.019123042274946805\n",
      "train loss:0.008649999376287028\n",
      "train loss:0.001502687555517078\n",
      "train loss:0.0618597117010696\n",
      "train loss:0.023746193976367697\n",
      "train loss:0.01738409705880364\n",
      "train loss:0.00022154092798823568\n",
      "train loss:0.0018596740557329633\n",
      "train loss:0.0012084740681898682\n",
      "train loss:0.012121582914965541\n",
      "train loss:0.001078361601818136\n",
      "train loss:0.003206237763639249\n",
      "train loss:0.0007796779256036469\n",
      "train loss:0.002299871209836246\n",
      "train loss:0.009386492034771089\n",
      "train loss:0.0030229456119570063\n",
      "train loss:0.0020411987726579326\n",
      "train loss:0.003952642124625069\n",
      "train loss:0.01959894276538969\n",
      "train loss:0.0027090864172191033\n",
      "train loss:0.02610226621719848\n",
      "train loss:0.0033943895112039115\n",
      "train loss:0.006383697030870191\n",
      "train loss:0.0027609279933079943\n",
      "train loss:0.0036865368352978723\n",
      "train loss:0.00939950767127213\n",
      "train loss:0.02374038717269456\n",
      "train loss:0.01710875656505548\n",
      "train loss:0.0029347100239295624\n",
      "train loss:0.0008859782901959334\n",
      "train loss:0.003344003403835753\n",
      "train loss:0.002045226005458421\n",
      "train loss:0.021789705150571173\n",
      "train loss:0.003283175779417591\n",
      "train loss:0.006328093928205069\n",
      "train loss:0.0047296680655760535\n",
      "train loss:0.004640716299031774\n",
      "train loss:0.015184182069988065\n",
      "train loss:0.005840847926228717\n",
      "train loss:0.02508212328904213\n",
      "train loss:0.0035075660277784407\n",
      "train loss:0.008905941234097008\n",
      "train loss:0.0037909416574061967\n",
      "train loss:0.005478738157687095\n",
      "train loss:0.00538671819909599\n",
      "train loss:0.010438379169994913\n",
      "train loss:0.004242548500112153\n",
      "train loss:0.004444354633562598\n",
      "train loss:0.000738814717220762\n",
      "=== epoch:15, train acc:0.9966032608695652, test acc:0.9873188405797102 ===\n",
      "train loss:0.007508855580559807\n",
      "train loss:0.001128444304517885\n",
      "train loss:0.01256698722481519\n",
      "train loss:0.007091904181462895\n",
      "train loss:0.0005250288494819855\n",
      "train loss:0.0010948718014014828\n",
      "train loss:0.042417805252815986\n",
      "train loss:0.003759066687425688\n",
      "train loss:0.006548943972752962\n",
      "train loss:0.0009402620258856414\n",
      "train loss:0.008055066470746447\n",
      "train loss:0.0023700764918942944\n",
      "train loss:0.004608278680041318\n",
      "train loss:0.004620697199129971\n",
      "train loss:0.006929128623929589\n",
      "train loss:0.006305698569670564\n",
      "train loss:0.036453696470975024\n",
      "train loss:0.006365110727162532\n",
      "train loss:0.010595760220779642\n",
      "train loss:0.013423496603836894\n",
      "train loss:0.012499110017568331\n",
      "train loss:0.0008058994681316424\n",
      "train loss:0.004214956743553639\n",
      "train loss:0.005823636944679735\n",
      "train loss:0.0028055269574875944\n",
      "train loss:0.005254493288257293\n",
      "train loss:0.004115888362872419\n",
      "train loss:0.009736204745923483\n",
      "train loss:0.0008985023045865565\n",
      "train loss:0.05125602877603509\n",
      "train loss:0.014568333752901804\n",
      "train loss:0.003164252924744442\n",
      "train loss:0.004573972804787538\n",
      "train loss:0.005000876446485167\n",
      "train loss:0.002787793743521964\n",
      "train loss:0.012174152984569007\n",
      "train loss:0.004866140965923153\n",
      "train loss:0.003707318363492267\n",
      "train loss:0.002451289845701491\n",
      "train loss:0.005108821802597139\n",
      "train loss:0.0008640404445281258\n",
      "train loss:0.005334813994014695\n",
      "train loss:0.0005085290374561783\n",
      "train loss:0.008614878365038102\n",
      "train loss:0.004077682551874174\n",
      "train loss:0.006900285915000137\n",
      "train loss:0.004505376611721355\n",
      "train loss:0.003314684288825349\n",
      "train loss:0.0031169369012901803\n",
      "train loss:0.0022610916827783944\n",
      "train loss:0.0019225025548906048\n",
      "train loss:0.007815263917659831\n",
      "train loss:0.0031033559947559394\n",
      "train loss:0.002105814877088424\n",
      "train loss:0.005862102290764546\n",
      "train loss:0.002119968106564116\n",
      "train loss:0.0016875149539070443\n",
      "train loss:0.005299913630403503\n",
      "train loss:0.003252146999023896\n",
      "train loss:0.0011521900272081706\n",
      "train loss:0.002942525908245173\n",
      "train loss:0.0025648409329322636\n",
      "train loss:0.003717626786925402\n",
      "train loss:0.00463602231717361\n",
      "train loss:0.002448513544346829\n",
      "train loss:0.0015070661938916445\n",
      "train loss:0.0023083973890492483\n",
      "train loss:0.0019803178229434483\n",
      "train loss:0.0008219531926855866\n",
      "train loss:0.0022583883893657996\n",
      "train loss:0.005192389337820172\n",
      "train loss:0.008656199364556135\n",
      "train loss:0.006492850677088091\n",
      "train loss:0.025780939078911106\n",
      "train loss:0.0017245460482413354\n",
      "train loss:0.008308944330560558\n",
      "train loss:0.007644930948556285\n",
      "train loss:0.00415768768667628\n",
      "train loss:0.0043203799400597575\n",
      "train loss:0.03998050335600655\n",
      "train loss:0.0016111583232896872\n",
      "train loss:0.009032426785629896\n",
      "train loss:0.005794610099331135\n",
      "train loss:0.009212191040369352\n",
      "train loss:0.012988976900067069\n",
      "train loss:0.001614393133534485\n",
      "train loss:0.004328216157429068\n",
      "train loss:0.005765608609118867\n",
      "train loss:0.0009103420113016878\n",
      "train loss:0.006598148983533065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0015244008276039266\n",
      "train loss:0.0019261319425713326\n",
      "train loss:0.0041188489658359915\n",
      "train loss:0.002035082353219068\n",
      "train loss:0.0012172566282202186\n",
      "train loss:0.007388563329025709\n",
      "train loss:0.04098078594601035\n",
      "train loss:0.0030071900053583642\n",
      "train loss:0.008854866844189286\n",
      "train loss:0.0013989022630747838\n",
      "train loss:0.008635079058266997\n",
      "train loss:0.01156668465899758\n",
      "train loss:0.0028176679488180136\n",
      "train loss:0.0010127180583924232\n",
      "train loss:0.005985035584167525\n",
      "train loss:0.002198577164374401\n",
      "train loss:0.017926960863184863\n",
      "train loss:0.02773976169089909\n",
      "train loss:0.0037948860983123287\n",
      "train loss:0.0057758056172648505\n",
      "train loss:0.018319097142376728\n",
      "train loss:0.012587476866669367\n",
      "train loss:0.004116778839128549\n",
      "train loss:0.004978334762595109\n",
      "train loss:0.007436690734739684\n",
      "train loss:0.0027333723678189445\n",
      "train loss:0.005543437071488166\n",
      "train loss:0.014359164316167012\n",
      "train loss:0.0012833384787026881\n",
      "train loss:0.0005917300927626211\n",
      "train loss:0.0066704154025053215\n",
      "train loss:0.008902284707400466\n",
      "train loss:0.020804833363796196\n",
      "train loss:0.0023946220236944113\n",
      "train loss:0.006484381397306943\n",
      "train loss:0.000949151556809138\n",
      "train loss:0.0027644803848816605\n",
      "train loss:0.002274669410508831\n",
      "train loss:0.0019589580378020365\n",
      "train loss:0.003934697756323588\n",
      "train loss:0.00349094249821126\n",
      "train loss:0.01038930813129565\n",
      "train loss:0.008562800386801848\n",
      "train loss:0.0012853001668378012\n",
      "train loss:0.002671261433969522\n",
      "train loss:0.010521038715679177\n",
      "train loss:0.003053987810579576\n",
      "train loss:0.004642821131232539\n",
      "train loss:0.0007405243870255855\n",
      "train loss:0.006495822784731442\n",
      "train loss:0.0024921189468912978\n",
      "train loss:0.0014056849901970157\n",
      "train loss:0.00047268653227267276\n",
      "train loss:0.013492084427435276\n",
      "train loss:0.0008409402849648482\n",
      "train loss:0.008339014796535683\n",
      "train loss:0.024311633511601004\n",
      "train loss:0.001800285339502516\n",
      "train loss:0.010564962584898946\n",
      "train loss:0.0024999569454879425\n",
      "train loss:0.00477477382693703\n",
      "train loss:0.00018291191357708934\n",
      "train loss:0.0007089964368439532\n",
      "train loss:0.0008041287737307573\n",
      "train loss:0.0023768938932719644\n",
      "train loss:0.0018251439500688417\n",
      "train loss:0.0005516450985247268\n",
      "train loss:0.002807209014396013\n",
      "train loss:0.006658828579187776\n",
      "train loss:0.0005112729963461881\n",
      "train loss:0.0016280287810282567\n",
      "train loss:0.0021426464293839388\n",
      "train loss:0.015186044352327248\n",
      "train loss:0.025586145869110028\n",
      "train loss:0.010705907794709101\n",
      "train loss:0.002246313318291515\n",
      "train loss:0.001773066899976305\n",
      "train loss:0.00161866332016405\n",
      "train loss:0.007905553115942245\n",
      "train loss:0.0037314638698479844\n",
      "train loss:0.0012143116061278584\n",
      "train loss:0.0007855343088705825\n",
      "train loss:0.001721463622247224\n",
      "train loss:0.004904106845329144\n",
      "train loss:0.008132287297744319\n",
      "train loss:0.0009020953914650375\n",
      "train loss:0.027814963328293904\n",
      "train loss:0.0016462761824066418\n",
      "train loss:0.002565761193105216\n",
      "train loss:0.006533035798410717\n",
      "train loss:0.0020272490267267324\n",
      "train loss:0.009596091934339386\n",
      "train loss:0.00048509657797812626\n",
      "train loss:0.011610326101058837\n",
      "train loss:0.0026651550863693446\n",
      "train loss:0.0008339932949652441\n",
      "train loss:0.0007863038740512122\n",
      "train loss:0.0020655737141871086\n",
      "train loss:0.007880925794263752\n",
      "train loss:0.0014175786970097605\n",
      "train loss:0.002823704382765891\n",
      "train loss:0.007588117643583746\n",
      "train loss:0.012781135978975594\n",
      "train loss:0.0090065790920097\n",
      "train loss:0.01285507491704168\n",
      "train loss:0.0032870759052268284\n",
      "train loss:0.01662874582381302\n",
      "train loss:0.007109656258133224\n",
      "train loss:0.005324487978945891\n",
      "train loss:0.0044101823847772755\n",
      "train loss:0.0062638905363482066\n",
      "train loss:0.0018525542702905096\n",
      "train loss:0.03345313020677491\n",
      "train loss:0.0010967387487978433\n",
      "train loss:0.0018839619431782655\n",
      "train loss:0.0022178264909160942\n",
      "train loss:0.006104823758702555\n",
      "train loss:0.010488869425929935\n",
      "train loss:0.004806699857320263\n",
      "train loss:0.022238734084918853\n",
      "train loss:0.00953007570122676\n",
      "train loss:0.015577048524595365\n",
      "train loss:0.024511250089703052\n",
      "train loss:0.006252004838861457\n",
      "train loss:0.0032271014877542146\n",
      "train loss:0.011365912758643083\n",
      "train loss:0.015390010386776922\n",
      "train loss:0.01605939644996031\n",
      "train loss:0.004126937252419058\n",
      "train loss:0.00331142965013149\n",
      "train loss:0.01317078058019063\n",
      "train loss:0.0043162496943369945\n",
      "train loss:0.00685327732711434\n",
      "train loss:0.009716518315927514\n",
      "train loss:0.0040020433771944955\n",
      "train loss:0.02862483025969028\n",
      "train loss:0.0028269824535723767\n",
      "train loss:0.004037293946598142\n",
      "train loss:0.0015698379714598777\n",
      "train loss:0.002416805018577743\n",
      "train loss:0.001183125691446242\n",
      "train loss:0.018312863554619533\n",
      "train loss:0.0022512740724223647\n",
      "train loss:0.004728514617988181\n",
      "train loss:0.010972368456831106\n",
      "train loss:0.019437113484468842\n",
      "train loss:0.014790192255406617\n",
      "train loss:0.0037787072631442872\n",
      "train loss:0.005407790664710874\n",
      "train loss:0.002128989077494987\n",
      "train loss:0.01219735348031575\n",
      "train loss:0.01306676686346112\n",
      "train loss:0.009654896100175558\n",
      "train loss:0.0014316335190248733\n",
      "train loss:0.016432120032661885\n",
      "train loss:0.004077910992230683\n",
      "train loss:0.000885478273459851\n",
      "train loss:0.002507338873570142\n",
      "train loss:0.00042993726740432094\n",
      "train loss:0.006701918231909089\n",
      "train loss:0.0028544718799204177\n",
      "train loss:0.006499520621796471\n",
      "train loss:0.0010800024704946357\n",
      "train loss:0.013352285179877573\n",
      "train loss:0.006224889853999085\n",
      "train loss:0.007632917137738042\n",
      "train loss:0.0008813946645949333\n",
      "train loss:0.00376039626797995\n",
      "train loss:0.001223809186614144\n",
      "train loss:0.053803746613494144\n",
      "train loss:0.01369219260069194\n",
      "train loss:0.0007017261380678637\n",
      "train loss:0.006434236111555802\n",
      "train loss:0.0011537327084409602\n",
      "train loss:0.019907194248427542\n",
      "train loss:0.0033560573950401954\n",
      "train loss:0.006244283897023193\n",
      "train loss:0.002967695730661358\n",
      "train loss:0.004600010103057083\n",
      "train loss:0.003639827062656001\n",
      "train loss:0.003179956997316133\n",
      "train loss:0.0047475758997358114\n",
      "train loss:0.0009571631234196718\n",
      "train loss:0.010797868913220708\n",
      "train loss:0.008173961545901146\n",
      "train loss:0.015166594669265152\n",
      "train loss:0.006160669197826394\n",
      "train loss:0.01779445405055023\n",
      "train loss:0.003935807862964587\n",
      "train loss:0.0018475932375526323\n",
      "train loss:0.0007484730855355979\n",
      "train loss:0.0036591216369031843\n",
      "train loss:0.023337017569952344\n",
      "train loss:0.001573965791426876\n",
      "train loss:0.004157899502067497\n",
      "train loss:0.0005068400776958228\n",
      "train loss:0.005129087211483639\n",
      "train loss:0.0040824588924259575\n",
      "train loss:0.00673089926955515\n",
      "train loss:0.0005169900302804881\n",
      "train loss:0.0024791507737379646\n",
      "train loss:0.0006836715630460807\n",
      "train loss:0.025046861357452804\n",
      "train loss:0.0028656485366136937\n",
      "train loss:0.0020598013962041897\n",
      "train loss:0.004616172346633014\n",
      "train loss:0.0026402073778457095\n",
      "train loss:0.0018753650638613582\n",
      "train loss:0.026951149324195765\n",
      "train loss:0.009615005991998271\n",
      "train loss:0.007242224385673078\n",
      "train loss:0.012942069391961526\n",
      "train loss:0.018154015641701098\n",
      "train loss:0.00230560968632513\n",
      "train loss:0.01059494349065259\n",
      "train loss:0.006231315886142563\n",
      "train loss:0.012731410648432615\n",
      "train loss:0.002086464388584656\n",
      "train loss:0.003281220967789304\n",
      "train loss:0.006590607538601203\n",
      "train loss:0.003488660748796322\n",
      "train loss:0.0006361301125171691\n",
      "train loss:0.00303127735622378\n",
      "train loss:0.00746957146346205\n",
      "train loss:0.004063885669303682\n",
      "train loss:0.006608569445478007\n",
      "train loss:0.01850019047416813\n",
      "train loss:0.006244233692053989\n",
      "train loss:0.003086815295483253\n",
      "train loss:0.0009539032167527102\n",
      "train loss:0.0061126590223074175\n",
      "train loss:0.006375283060831281\n",
      "train loss:0.004767020250105031\n",
      "train loss:0.015072373924631063\n",
      "train loss:0.004113127606909236\n",
      "train loss:0.008553538994415097\n",
      "train loss:0.004443451432576841\n",
      "train loss:0.002001407171070478\n",
      "train loss:0.004382826577610535\n",
      "train loss:0.01095001070689859\n",
      "train loss:0.005240298865114454\n",
      "train loss:0.005318438636995731\n",
      "train loss:0.007879844066474798\n",
      "train loss:0.0029651114514378366\n",
      "train loss:0.005675303165401802\n",
      "train loss:0.007854796611197212\n",
      "train loss:0.005770732423124433\n",
      "train loss:0.0025197032711091537\n",
      "train loss:0.0006789359314217038\n",
      "train loss:0.009691177627924718\n",
      "train loss:0.012255702235503667\n",
      "train loss:0.0014936001571450193\n",
      "train loss:0.00758404234608584\n",
      "train loss:0.006492488646369139\n",
      "train loss:0.002021913757722233\n",
      "train loss:0.0013261281708694334\n",
      "train loss:0.003857134163934178\n",
      "train loss:0.0013082544415363958\n",
      "train loss:0.0597441657251915\n",
      "train loss:0.018200425080334814\n",
      "train loss:0.004227750407006475\n",
      "train loss:0.012507902896796754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0031397399044630994\n",
      "train loss:0.0014750912005172501\n",
      "train loss:0.006365488505052104\n",
      "train loss:0.002369221802051584\n",
      "train loss:0.011943655380875632\n",
      "train loss:0.005875815160565834\n",
      "train loss:0.0015850710635690907\n",
      "train loss:0.0027450379943491027\n",
      "train loss:0.0021526574789500225\n",
      "train loss:0.0015135059575982835\n",
      "train loss:0.0006314435812814266\n",
      "train loss:0.0013653751456301267\n",
      "train loss:0.005029486124882013\n",
      "train loss:0.002522793022598493\n",
      "train loss:0.006228244270034554\n",
      "train loss:0.0017689542562202717\n",
      "=== epoch:16, train acc:0.9977807971014493, test acc:0.9876811594202899 ===\n",
      "train loss:0.0108717722800357\n",
      "train loss:0.007748296701168213\n",
      "train loss:0.002430341616942371\n",
      "train loss:0.0039885858309043655\n",
      "train loss:0.0007475885555144416\n",
      "train loss:0.004799201974630604\n",
      "train loss:0.002319576341717643\n",
      "train loss:0.001263690131883518\n",
      "train loss:0.0028543027283038655\n",
      "train loss:0.01411245191317932\n",
      "train loss:0.0016982010431056927\n",
      "train loss:0.003980197110396179\n",
      "train loss:0.002677984688484258\n",
      "train loss:0.010175596740183097\n",
      "train loss:0.006329422611116331\n",
      "train loss:0.004885130980461564\n",
      "train loss:0.004383173627183867\n",
      "train loss:0.0021603498804467856\n",
      "train loss:0.012434065676430734\n",
      "train loss:0.0011574271563750205\n",
      "train loss:0.0013068396980436372\n",
      "train loss:0.0018959958128237535\n",
      "train loss:0.005170019760740052\n",
      "train loss:0.0020271741447897935\n",
      "train loss:0.024078874084715644\n",
      "train loss:0.036235364515782145\n",
      "train loss:0.002329942432889008\n",
      "train loss:0.000834208909243827\n",
      "train loss:0.01728211069447576\n",
      "train loss:0.007576086192777425\n",
      "train loss:0.004347245771351533\n",
      "train loss:0.011079841277642532\n",
      "train loss:0.001805080615946495\n",
      "train loss:0.00547820650016879\n",
      "train loss:0.0026622567195618103\n",
      "train loss:0.0027973246910559016\n",
      "train loss:0.019455514902446767\n",
      "train loss:0.0058151957475672846\n",
      "train loss:0.0034070829545520135\n",
      "train loss:0.026972104765038536\n",
      "train loss:0.04189503785552566\n",
      "train loss:0.0066614847159571396\n",
      "train loss:0.004127372460326414\n",
      "train loss:0.002638440592773088\n",
      "train loss:0.0011248708324867076\n",
      "train loss:0.003467242426372763\n",
      "train loss:0.001018006153326777\n",
      "train loss:0.0029173861217794096\n",
      "train loss:0.0025423024424029664\n",
      "train loss:0.012658130770530239\n",
      "train loss:0.004934628439513094\n",
      "train loss:0.001355565575088448\n",
      "train loss:0.004529532656266823\n",
      "train loss:0.012412978382429213\n",
      "train loss:0.0029732027357374053\n",
      "train loss:0.002201284421075504\n",
      "train loss:0.03261635571077644\n",
      "train loss:0.010772731028853585\n",
      "train loss:0.002075533463851254\n",
      "train loss:0.010346908462028145\n",
      "train loss:0.00957676987470678\n",
      "train loss:0.008136068815102775\n",
      "train loss:0.006859519789220007\n",
      "train loss:0.0028257075193644935\n",
      "train loss:0.005778193394887676\n",
      "train loss:0.04571199546878656\n",
      "train loss:0.00633619252853373\n",
      "train loss:0.006640453495157398\n",
      "train loss:0.006977748627512618\n",
      "train loss:0.0035612966183183733\n",
      "train loss:0.008180357359330056\n",
      "train loss:0.019290072363533764\n",
      "train loss:0.006373383107162166\n",
      "train loss:0.028777994665354054\n",
      "train loss:0.007230555676723855\n",
      "train loss:0.008840765079326794\n",
      "train loss:0.007208285526693883\n",
      "train loss:0.0043473302624556405\n",
      "train loss:0.011716019511431528\n",
      "train loss:0.006462989665384695\n",
      "train loss:0.002474188662592805\n",
      "train loss:0.015671892192135904\n",
      "train loss:0.04038642926959568\n",
      "train loss:0.004362716724560111\n",
      "train loss:0.007178326450698471\n",
      "train loss:0.012164185653951476\n",
      "train loss:0.00907466151546088\n",
      "train loss:0.0064508418984217785\n",
      "train loss:0.0036534342389133324\n",
      "train loss:0.0015185802452532472\n",
      "train loss:0.001928321014863739\n",
      "train loss:0.0031784094842307988\n",
      "train loss:0.00740617907398165\n",
      "train loss:0.007630076298517001\n",
      "train loss:0.017138979257463372\n",
      "train loss:0.0028583429388331417\n",
      "train loss:0.007970056763498498\n",
      "train loss:0.0038463556873941968\n",
      "train loss:0.0012272496075010182\n",
      "train loss:0.024418275189382825\n",
      "train loss:0.0009128478803713366\n",
      "train loss:0.011984142449544443\n",
      "train loss:0.0024138814633835\n",
      "train loss:0.00047469522649959173\n",
      "train loss:0.014000755890294873\n",
      "train loss:0.001753733642663025\n",
      "train loss:0.014845532977342972\n",
      "train loss:0.002425133460873558\n",
      "train loss:0.0023291396299706863\n",
      "train loss:0.0012666930149092088\n",
      "train loss:0.00883061954311235\n",
      "train loss:0.008620021776437871\n",
      "train loss:0.0025755981460559\n",
      "train loss:0.00163855578918486\n",
      "train loss:0.001925235886941911\n",
      "train loss:0.0017917396563661397\n",
      "train loss:0.002156610957202143\n",
      "train loss:0.009122729725596522\n",
      "train loss:0.00044143042488548485\n",
      "train loss:0.00590341202429746\n",
      "train loss:0.0013632449646631395\n",
      "train loss:0.003629922641730251\n",
      "train loss:0.0007250984554723044\n",
      "train loss:0.0002799688641605871\n",
      "train loss:0.002323762226154967\n",
      "train loss:0.029948465764805084\n",
      "train loss:0.002072695000025074\n",
      "train loss:0.024019576510389797\n",
      "train loss:0.0027562090871889825\n",
      "train loss:0.0041920483231028816\n",
      "train loss:0.0006626545042114804\n",
      "train loss:0.0019305054857661694\n",
      "train loss:0.0009927416794883554\n",
      "train loss:0.0031666088845631536\n",
      "train loss:0.0014690852815833603\n",
      "train loss:0.0005349340696550428\n",
      "train loss:0.018878962800029143\n",
      "train loss:0.0011768534792786925\n",
      "train loss:0.0038558228276991497\n",
      "train loss:0.012314416622582907\n",
      "train loss:0.0020678866892273108\n",
      "train loss:0.0006648799607332211\n",
      "train loss:0.008823517556456991\n",
      "train loss:0.0039734427810695395\n",
      "train loss:0.008133573360764595\n",
      "train loss:0.002080699584898606\n",
      "train loss:0.0027558852035353245\n",
      "train loss:0.0004735077554124575\n",
      "train loss:0.004171881181291942\n",
      "train loss:0.00424192976807938\n",
      "train loss:0.038265985751216994\n",
      "train loss:0.04340383803386415\n",
      "train loss:0.004979774271498219\n",
      "train loss:0.005977793340540923\n",
      "train loss:0.0024667850874736134\n",
      "train loss:0.015223088400628962\n",
      "train loss:0.005236771928801273\n",
      "train loss:0.014861051689253835\n",
      "train loss:0.0033770841126533183\n",
      "train loss:0.013794212954843304\n",
      "train loss:0.055998690228477484\n",
      "train loss:0.005200118759093496\n",
      "train loss:0.0013719550351499272\n",
      "train loss:0.0037367918561542987\n",
      "train loss:0.00416751833625171\n",
      "train loss:0.002920524984640818\n",
      "train loss:0.005897317741685834\n",
      "train loss:0.0069241861553729165\n",
      "train loss:0.0031313572374154853\n",
      "train loss:0.0021331179685936184\n",
      "train loss:0.003566797007296114\n",
      "train loss:0.0026853304504587234\n",
      "train loss:0.003881906113790541\n",
      "train loss:0.0027655733010393305\n",
      "train loss:0.007179308153924241\n",
      "train loss:0.001505567813648582\n",
      "train loss:0.004467251106441752\n",
      "train loss:0.0007754963959902981\n",
      "train loss:0.001753129071577442\n",
      "train loss:0.00527631437626173\n",
      "train loss:0.0013782172311711796\n",
      "train loss:0.009223372024366476\n",
      "train loss:0.003596704609766023\n",
      "train loss:0.018698902258389813\n",
      "train loss:0.001705930107703099\n",
      "train loss:0.0024313485771985536\n",
      "train loss:0.010721084839873253\n",
      "train loss:0.0057516050966320365\n",
      "train loss:0.003922481661152136\n",
      "train loss:0.002679806939600374\n",
      "train loss:0.0094805533188945\n",
      "train loss:0.04652907843626382\n",
      "train loss:0.003346191308440314\n",
      "train loss:0.0030998615696846282\n",
      "train loss:0.0029690825000313345\n",
      "train loss:0.0026084456933291003\n",
      "train loss:0.0022047832619056253\n",
      "train loss:0.0024675120590191375\n",
      "train loss:0.0006637872237834818\n",
      "train loss:0.001506554662262769\n",
      "train loss:0.0022215712815350118\n",
      "train loss:0.017630550000910232\n",
      "train loss:0.0023859066979026763\n",
      "train loss:0.0035474646631410544\n",
      "train loss:0.01847541731898562\n",
      "train loss:0.0033877634066997054\n",
      "train loss:0.0019002313179349107\n",
      "train loss:0.004871988008238749\n",
      "train loss:0.005714698592755997\n",
      "train loss:0.013053689143932436\n",
      "train loss:0.0013834562431754142\n",
      "train loss:0.0048403792314785496\n",
      "train loss:0.04480885442704225\n",
      "train loss:0.0023717324920504365\n",
      "train loss:0.01013675109887576\n",
      "train loss:0.004841323661003197\n",
      "train loss:0.003161330045915516\n",
      "train loss:0.009919363520141122\n",
      "train loss:0.0007060383869493913\n",
      "train loss:0.006583763429381612\n",
      "train loss:0.006328024221090892\n",
      "train loss:0.008541393811076861\n",
      "train loss:0.002817203029177044\n",
      "train loss:0.006208231780497268\n",
      "train loss:0.0038048120115676265\n",
      "train loss:0.008866565757281964\n",
      "train loss:0.0041180791598482\n",
      "train loss:0.0017093955584344225\n",
      "train loss:0.00259611320333315\n",
      "train loss:0.006107698692486944\n",
      "train loss:0.003943347653667577\n",
      "train loss:0.015355185145878416\n",
      "train loss:0.0014506591005690004\n",
      "train loss:0.00696757782828219\n",
      "train loss:0.008611042315828423\n",
      "train loss:0.015706596577101408\n",
      "train loss:0.0005447087293859954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004720975632228374\n",
      "train loss:0.0024956586346856695\n",
      "train loss:0.0071826940362821\n",
      "train loss:0.0023418111689334636\n",
      "train loss:0.0006175600034606651\n",
      "train loss:0.007669420366053721\n",
      "train loss:0.001156153402548722\n",
      "train loss:0.001959435282618308\n",
      "train loss:0.0015171736400528782\n",
      "train loss:0.013056329657165123\n",
      "train loss:0.005135386638468071\n",
      "train loss:0.0039641711531439505\n",
      "train loss:0.0017454897609311029\n",
      "train loss:0.0001679707925117613\n",
      "train loss:0.0016736382495385602\n",
      "train loss:0.001036698429126184\n",
      "train loss:0.0015173439887853624\n",
      "train loss:0.0002360934581397534\n",
      "train loss:0.005958007926791647\n",
      "train loss:0.00048016279055045736\n",
      "train loss:0.004117986844464475\n",
      "train loss:0.0022612562069143378\n",
      "train loss:0.003849373385620147\n",
      "train loss:0.008384894741852706\n",
      "train loss:0.0033973398397617077\n",
      "train loss:0.001031755088014365\n",
      "train loss:0.046054784998543104\n",
      "train loss:0.0006360850455110397\n",
      "train loss:0.0021569393257261623\n",
      "train loss:0.006919898219905696\n",
      "train loss:0.0009466746714560758\n",
      "train loss:0.011258031818479237\n",
      "train loss:0.001019420377679169\n",
      "train loss:0.002202507162027468\n",
      "train loss:0.014604987436111846\n",
      "train loss:0.0020822808744599933\n",
      "train loss:0.0019343971109230503\n",
      "train loss:0.002542265928379638\n",
      "train loss:0.0018615441624929706\n",
      "train loss:0.006577065246936946\n",
      "train loss:0.014356466360039594\n",
      "train loss:0.001443304572350479\n",
      "train loss:0.0011111676442304157\n",
      "train loss:0.006345433059684975\n",
      "train loss:0.016020430236031512\n",
      "train loss:0.018258153805256947\n",
      "train loss:0.018534890229829726\n",
      "train loss:0.0014447225518210165\n",
      "train loss:0.0041965251791414755\n",
      "train loss:0.0003369977755995615\n",
      "train loss:0.003299422248367779\n",
      "train loss:0.00040702257864523697\n",
      "train loss:0.02454192575566272\n",
      "train loss:0.009471303416176718\n",
      "train loss:0.0008029613416890605\n",
      "train loss:0.003752943264483739\n",
      "train loss:0.0009531680397823071\n",
      "train loss:0.003529664903567543\n",
      "train loss:0.0023325856750929124\n",
      "train loss:0.001976844816848146\n",
      "train loss:0.009094472167729899\n",
      "train loss:0.006272944006267363\n",
      "train loss:0.0007635290732951444\n",
      "train loss:0.008225965542160383\n",
      "train loss:0.00410590975939354\n",
      "train loss:0.0017125095372747593\n",
      "train loss:0.0011971506069428466\n",
      "train loss:0.000937039178689604\n",
      "train loss:0.00509301423020487\n",
      "train loss:0.007784936789213235\n",
      "train loss:0.009724393010993182\n",
      "train loss:0.005496439912654397\n",
      "train loss:0.00290451131024978\n",
      "train loss:0.007268927429615605\n",
      "train loss:0.011087037304714331\n",
      "train loss:0.0027745048948353565\n",
      "train loss:0.0018271287863176103\n",
      "train loss:0.0025301426984301136\n",
      "train loss:0.0056579006273579\n",
      "train loss:0.002688355867614273\n",
      "train loss:0.0006696419476462071\n",
      "train loss:0.027429611869098557\n",
      "train loss:0.007146029407548936\n",
      "train loss:0.003116460715873732\n",
      "train loss:0.0023710790290418326\n",
      "train loss:0.004631990992691388\n",
      "train loss:0.016378067443738046\n",
      "train loss:0.009750346637101249\n",
      "train loss:0.001315720079571396\n",
      "train loss:0.0008934613502067962\n",
      "train loss:0.004963196126736246\n",
      "train loss:0.020630698020306572\n",
      "train loss:0.0020965151641489503\n",
      "train loss:0.0022383841572848687\n",
      "train loss:0.006689181472424227\n",
      "train loss:0.003140756396099553\n",
      "train loss:0.0053756428623637185\n",
      "train loss:0.0010776937233020459\n",
      "train loss:0.0036045965178174433\n",
      "train loss:0.014996903236919826\n",
      "train loss:0.015409723162603058\n",
      "train loss:0.018101801080270947\n",
      "train loss:0.0022491863130550778\n",
      "train loss:0.0008261271207832545\n",
      "train loss:0.002351315812004348\n",
      "train loss:0.03020346183087793\n",
      "train loss:0.004215989581099533\n",
      "train loss:0.001011420675100307\n",
      "train loss:0.0006954944755799723\n",
      "train loss:0.0009262366483277403\n",
      "train loss:0.0006358292488491785\n",
      "train loss:0.0036666314896238194\n",
      "train loss:0.0023510397230371077\n",
      "train loss:0.005493042454492341\n",
      "train loss:0.00951874183086488\n",
      "train loss:0.006193870202196648\n",
      "train loss:0.0009004170614002859\n",
      "train loss:0.005992721123153523\n",
      "train loss:0.003038570890913943\n",
      "train loss:0.010851983001430853\n",
      "train loss:0.0011624156082357554\n",
      "train loss:0.0014710728024633012\n",
      "train loss:0.0016813679235582674\n",
      "train loss:0.002001041452862531\n",
      "train loss:0.01121532110878896\n",
      "train loss:0.004594177159837756\n",
      "train loss:0.0051333241139357\n",
      "train loss:0.037440743868651045\n",
      "train loss:0.0010588411165736006\n",
      "train loss:0.015470728771976099\n",
      "train loss:0.0012124977725625158\n",
      "=== epoch:17, train acc:0.9968523550724637, test acc:0.9875 ===\n",
      "train loss:0.011473109889101564\n",
      "train loss:0.0007395680420904444\n",
      "train loss:0.004009851423035743\n",
      "train loss:0.008267630300131392\n",
      "train loss:0.0008014482543565273\n",
      "train loss:0.0012062484477395146\n",
      "train loss:0.010684937340168168\n",
      "train loss:0.006655380455644276\n",
      "train loss:0.007096375206186425\n",
      "train loss:0.02748158400051507\n",
      "train loss:0.007957621875523438\n",
      "train loss:0.009287162862588\n",
      "train loss:0.0007906110277984266\n",
      "train loss:0.002331753175958658\n",
      "train loss:0.0026770613627051395\n",
      "train loss:0.001835167643681305\n",
      "train loss:0.004187418787521443\n",
      "train loss:0.0006864148500986836\n",
      "train loss:0.005803110553558258\n",
      "train loss:0.003080532268656843\n",
      "train loss:0.003048510116383349\n",
      "train loss:0.00046124672379120455\n",
      "train loss:0.004338699091383708\n",
      "train loss:0.0006599258068702155\n",
      "train loss:0.005295796356173441\n",
      "train loss:0.02123068284722601\n",
      "train loss:0.003688786551911636\n",
      "train loss:0.0012491581374316667\n",
      "train loss:0.01628856598878425\n",
      "train loss:0.0028810248906300587\n",
      "train loss:0.025875465155652748\n",
      "train loss:0.003821658594642973\n",
      "train loss:0.0019098840173424406\n",
      "train loss:0.005546035338606638\n",
      "train loss:0.004170132203155453\n",
      "train loss:0.0024193987888490682\n",
      "train loss:0.011597871442082542\n",
      "train loss:0.0099611658868925\n",
      "train loss:0.01959241041810976\n",
      "train loss:0.003459859042741087\n",
      "train loss:0.003315529807512771\n",
      "train loss:0.0008600105404520964\n",
      "train loss:0.012235192110043643\n",
      "train loss:0.02140472999306691\n",
      "train loss:0.0018602606878825212\n",
      "train loss:0.0011908419661937053\n",
      "train loss:0.008310258649225442\n",
      "train loss:0.001888929271134998\n",
      "train loss:0.009069966392808505\n",
      "train loss:0.018910300947866394\n",
      "train loss:0.003522479484305119\n",
      "train loss:0.0010132358624903943\n",
      "train loss:0.0010897455139151993\n",
      "train loss:0.0023958544435058677\n",
      "train loss:0.0015604559777456764\n",
      "train loss:0.005262428796933046\n",
      "train loss:0.0041285416525625495\n",
      "train loss:0.0008021927392023958\n",
      "train loss:0.004493115253251815\n",
      "train loss:0.0034318261287808157\n",
      "train loss:0.02645345805177796\n",
      "train loss:0.002753212965604326\n",
      "train loss:0.01403438319619357\n",
      "train loss:0.007057659311973699\n",
      "train loss:0.0021895645480272956\n",
      "train loss:0.0014388835008106399\n",
      "train loss:0.0038103345993327482\n",
      "train loss:0.008546538755667642\n",
      "train loss:0.007172581448410639\n",
      "train loss:0.015084819642674763\n",
      "train loss:0.006352064624619275\n",
      "train loss:0.013315310611571282\n",
      "train loss:0.0035642403471107856\n",
      "train loss:0.004177027703405892\n",
      "train loss:0.010302971935317344\n",
      "train loss:0.0009314569969820082\n",
      "train loss:0.004520783009421035\n",
      "train loss:0.012656627831038733\n",
      "train loss:0.020276809705164933\n",
      "train loss:0.005747379351818256\n",
      "train loss:0.002669967252286197\n",
      "train loss:0.002879085140436407\n",
      "train loss:0.000632975931770155\n",
      "train loss:0.006467422281503749\n",
      "train loss:0.033073253782262564\n",
      "train loss:0.04110055565569794\n",
      "train loss:0.002217958296847493\n",
      "train loss:0.0015067368525039395\n",
      "train loss:0.00851888168735839\n",
      "train loss:0.0072227332904058915\n",
      "train loss:0.009152171400197444\n",
      "train loss:0.006333341400991651\n",
      "train loss:0.009899800935075028\n",
      "train loss:0.005888484100717852\n",
      "train loss:0.020146348398008187\n",
      "train loss:0.0065547105438251195\n",
      "train loss:0.013389655259475402\n",
      "train loss:0.0015300718759163972\n",
      "train loss:0.015573054457576674\n",
      "train loss:0.0036704890496360807\n",
      "train loss:0.012812333280089771\n",
      "train loss:0.0023583858328318566\n",
      "train loss:0.006084072478399287\n",
      "train loss:0.024643864602191534\n",
      "train loss:0.01520332477750371\n",
      "train loss:0.009731637877784778\n",
      "train loss:0.00518213082658952\n",
      "train loss:0.005965398795350549\n",
      "train loss:0.005130091609903428\n",
      "train loss:0.014242762406683115\n",
      "train loss:0.002266367780276052\n",
      "train loss:0.016136245114902803\n",
      "train loss:0.04897536896451699\n",
      "train loss:0.0036116749182708557\n",
      "train loss:0.00672156798656181\n",
      "train loss:0.004208714658833279\n",
      "train loss:0.005449135233638784\n",
      "train loss:0.004877627192217556\n",
      "train loss:0.02439590772705843\n",
      "train loss:0.006382048314573793\n",
      "train loss:0.0023168081732142117\n",
      "train loss:0.006425839404953516\n",
      "train loss:0.00844820133953682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015638643307864138\n",
      "train loss:0.013260641640690877\n",
      "train loss:0.03326320560109845\n",
      "train loss:0.0025868866375718795\n",
      "train loss:0.00657243449417022\n",
      "train loss:0.002451306934006643\n",
      "train loss:0.006165242440576\n",
      "train loss:0.0030786951636601096\n",
      "train loss:0.005322127868729454\n",
      "train loss:0.0109022208096762\n",
      "train loss:0.00129152715842839\n",
      "train loss:0.0034937810363184314\n",
      "train loss:0.0028846160126075504\n",
      "train loss:0.0024996968590229717\n",
      "train loss:0.033755183225742065\n",
      "train loss:0.008620394894399036\n",
      "train loss:0.0014930348070318002\n",
      "train loss:0.004061580328253626\n",
      "train loss:0.0007990357763526937\n",
      "train loss:0.001692285668159425\n",
      "train loss:0.0022247321237942002\n",
      "train loss:0.006534114004231676\n",
      "train loss:0.011882711735271246\n",
      "train loss:0.025078349670564683\n",
      "train loss:0.0026367036244829846\n",
      "train loss:0.009960078384859636\n",
      "train loss:0.0032507877051465577\n",
      "train loss:0.008845968925052702\n",
      "train loss:0.0034442479178360143\n",
      "train loss:0.001033346740883829\n",
      "train loss:0.005661250866586905\n",
      "train loss:0.02761215908729721\n",
      "train loss:0.021302660780913942\n",
      "train loss:0.0007706614870291573\n",
      "train loss:0.0020561866567631653\n",
      "train loss:0.0012380891326268175\n",
      "train loss:0.0019877246000028137\n",
      "train loss:0.0007808820062370039\n",
      "train loss:0.004440574220165328\n",
      "train loss:0.0021302767855786724\n",
      "train loss:0.002353608000309912\n",
      "train loss:0.02164885880589174\n",
      "train loss:0.004437187489894185\n",
      "train loss:0.000890303686751649\n",
      "train loss:0.0018144405963706552\n",
      "train loss:0.016842044018964258\n",
      "train loss:0.006786555074835504\n",
      "train loss:0.0011797065682702184\n",
      "train loss:0.0028620072351958127\n",
      "train loss:0.005422548766098228\n",
      "train loss:0.0044950663321516975\n",
      "train loss:0.0028948404747342793\n",
      "train loss:0.004359666863594601\n",
      "train loss:0.005351021368470584\n",
      "train loss:0.0019114335054493852\n",
      "train loss:0.012306404528271912\n",
      "train loss:0.006500476448772183\n",
      "train loss:0.03175929197365439\n",
      "train loss:0.004275971179287519\n",
      "train loss:0.012189920532997027\n",
      "train loss:0.011979118110509812\n",
      "train loss:0.004590240910545642\n",
      "train loss:0.0007638415578749501\n",
      "train loss:0.005041114600156956\n",
      "train loss:0.004356325902985555\n",
      "train loss:0.0015459347106369914\n",
      "train loss:0.004056548686255457\n",
      "train loss:0.0020661393804520876\n",
      "train loss:0.0029908580578998168\n",
      "train loss:0.001233174384957576\n",
      "train loss:0.005140570600169481\n",
      "train loss:0.007555570764721681\n",
      "train loss:0.008346476567468649\n",
      "train loss:0.0004339582278860055\n",
      "train loss:0.003928409181454908\n",
      "train loss:0.0010379671454663077\n",
      "train loss:0.004633321287925393\n",
      "train loss:0.0012361141375323455\n",
      "train loss:0.009244896690267967\n",
      "train loss:0.0009277707367872873\n",
      "train loss:0.0018673717773441151\n",
      "train loss:0.0051481309742008345\n",
      "train loss:0.0019543824973423203\n",
      "train loss:0.0030170162557658013\n",
      "train loss:0.005881179165836799\n",
      "train loss:0.001546626814453711\n",
      "train loss:0.0019128640217806446\n",
      "train loss:0.00583563558757509\n",
      "train loss:0.0031409661416776625\n",
      "train loss:0.0009454112174055317\n",
      "train loss:0.009572864863240941\n",
      "train loss:0.004699154850221519\n",
      "train loss:0.0017380992428047974\n",
      "train loss:0.005001944843532602\n",
      "train loss:0.008119275722434314\n",
      "train loss:0.01223749565878984\n",
      "train loss:0.0030833117755257543\n",
      "train loss:0.004017402718853722\n",
      "train loss:0.0055383916890792305\n",
      "train loss:0.002857856382585474\n",
      "train loss:0.011084288817509308\n",
      "train loss:0.0006958561328323868\n",
      "train loss:0.008726067100283787\n",
      "train loss:0.03491079811084377\n",
      "train loss:0.002478058348614905\n",
      "train loss:0.002147426264519658\n",
      "train loss:0.0019557004461278377\n",
      "train loss:0.022486498998542062\n",
      "train loss:0.00852653962259745\n",
      "train loss:0.017809306825939956\n",
      "train loss:0.0199460459580132\n",
      "train loss:0.008111281570547744\n",
      "train loss:0.008143813694584322\n",
      "train loss:0.04924784681375611\n",
      "train loss:0.005239887620469039\n",
      "train loss:0.0010622179616530342\n",
      "train loss:0.007229907540373074\n",
      "train loss:0.005621109147203875\n",
      "train loss:0.0016112081847457415\n",
      "train loss:0.0036377091695008346\n",
      "train loss:0.008744487389186062\n",
      "train loss:0.002184838276080694\n",
      "train loss:0.0010283927763506384\n",
      "train loss:0.0016528192627855974\n",
      "train loss:0.0034402151055493314\n",
      "train loss:0.0015994170532464735\n",
      "train loss:0.002362285001115345\n",
      "train loss:0.0013425286964311232\n",
      "train loss:0.004858029063432978\n",
      "train loss:0.0004922689693025281\n",
      "train loss:0.0006199267732935221\n",
      "train loss:0.0037890344283482776\n",
      "train loss:0.001801352790063955\n",
      "train loss:0.0026651259004552936\n",
      "train loss:0.0006073510206232468\n",
      "train loss:0.0027758897440582206\n",
      "train loss:0.00391403164887335\n",
      "train loss:0.022021981401693643\n",
      "train loss:0.017997006493535268\n",
      "train loss:0.016231311587861813\n",
      "train loss:0.008065490544980769\n",
      "train loss:0.0029231227258449716\n",
      "train loss:0.00046917395136255696\n",
      "train loss:0.0008384071890688242\n",
      "train loss:0.0022026022486401143\n",
      "train loss:0.012052862475382986\n",
      "train loss:0.010467212769060532\n",
      "train loss:0.004800540253777189\n",
      "train loss:0.01163150699402917\n",
      "train loss:0.00218937925384554\n",
      "train loss:0.0014448141995151598\n",
      "train loss:0.003530131342100124\n",
      "train loss:0.0009441899842703146\n",
      "train loss:0.006063419732496835\n",
      "train loss:0.0009857480905517478\n",
      "train loss:0.003462585386855106\n",
      "train loss:0.013817359469906233\n",
      "train loss:0.0008841915854309455\n",
      "train loss:0.0016428122661583285\n",
      "train loss:0.0027896312145704594\n",
      "train loss:0.0015069389236699064\n",
      "train loss:0.002743027111163242\n",
      "train loss:0.023439236500164565\n",
      "train loss:0.010445720521862076\n",
      "train loss:0.006739949591467116\n",
      "train loss:0.004569060157784783\n",
      "train loss:0.0014516059120870705\n",
      "train loss:0.0023906326475436725\n",
      "train loss:0.0027989380238988477\n",
      "train loss:0.0030038810494640625\n",
      "train loss:0.0028629702479610122\n",
      "train loss:0.001122753784683679\n",
      "train loss:0.001506397219006087\n",
      "train loss:0.001371677156859417\n",
      "train loss:0.0011784090205910834\n",
      "train loss:0.0005872861967694522\n",
      "train loss:0.0036040984184995332\n",
      "train loss:0.009787592788574048\n",
      "train loss:0.012966782627802962\n",
      "train loss:0.022729684100758468\n",
      "train loss:0.009940171515621408\n",
      "train loss:0.008746460364831458\n",
      "train loss:0.023111339624768287\n",
      "train loss:0.001359087647788318\n",
      "train loss:0.0029884783340857067\n",
      "train loss:0.0011821339619808027\n",
      "train loss:0.02139610543590601\n",
      "train loss:0.007612667499272284\n",
      "train loss:0.0041389833151255105\n",
      "train loss:0.0076215929760167925\n",
      "train loss:0.0022054861139758604\n",
      "train loss:0.008555329019778983\n",
      "train loss:0.04422362210415534\n",
      "train loss:0.0034161999123264292\n",
      "train loss:0.0008893006674283617\n",
      "train loss:0.0005983765013890779\n",
      "train loss:0.0016829286409300172\n",
      "train loss:0.010409526603238071\n",
      "train loss:0.0017893612569704182\n",
      "train loss:0.0010292126651746587\n",
      "train loss:0.003627847836619184\n",
      "train loss:0.018438863129622136\n",
      "train loss:0.0026759206612961073\n",
      "train loss:0.0074014612311072035\n",
      "train loss:0.003851791170736031\n",
      "train loss:0.02144244648691523\n",
      "train loss:0.0018234955707342475\n",
      "train loss:0.001695335852167117\n",
      "train loss:0.0013136948837584545\n",
      "train loss:0.0010467440017560376\n",
      "train loss:0.0025851383652848487\n",
      "train loss:0.001069415643637473\n",
      "train loss:0.0037185902046927024\n",
      "train loss:0.017008835492403847\n",
      "train loss:0.007763977159312476\n",
      "train loss:0.001817946056243249\n",
      "train loss:0.0010330548184121352\n",
      "train loss:0.006815882038708776\n",
      "train loss:0.0016869280759480062\n",
      "train loss:0.005307473616847164\n",
      "train loss:0.0003517285700212138\n",
      "train loss:0.004881105260116066\n",
      "train loss:0.004237073541418167\n",
      "train loss:0.001649102897474681\n",
      "train loss:0.0022650821732865156\n",
      "train loss:0.004302244834028094\n",
      "train loss:0.002134885303700756\n",
      "train loss:0.0010154621223792718\n",
      "train loss:0.015911784906564228\n",
      "train loss:0.0005103703911396231\n",
      "train loss:0.009458097200126005\n",
      "train loss:0.006114619572800144\n",
      "train loss:0.005485157885104472\n",
      "train loss:0.0016607992960104882\n",
      "train loss:0.005084530576211345\n",
      "train loss:0.0016953409905114943\n",
      "train loss:0.038469816707448604\n",
      "train loss:0.0066268272055270494\n",
      "train loss:0.02986314772193407\n",
      "train loss:0.005209808324501109\n",
      "train loss:0.005951915806870472\n",
      "train loss:0.0032074306611349903\n",
      "train loss:0.0064104016854148035\n",
      "train loss:0.0019560348399090223\n",
      "train loss:0.002151686508781965\n",
      "=== epoch:18, train acc:0.9978713768115942, test acc:0.9877717391304348 ===\n",
      "train loss:0.011360898296578456\n",
      "train loss:0.010919816904422702\n",
      "train loss:0.01400809456110483\n",
      "train loss:0.006062346894703061\n",
      "train loss:0.0019312691435722522\n",
      "train loss:0.0026965386063187184\n",
      "train loss:0.0057208455014632585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00115851296848709\n",
      "train loss:0.009603981542138873\n",
      "train loss:0.01635592005730756\n",
      "train loss:0.0007598619410557272\n",
      "train loss:0.0039507371916454375\n",
      "train loss:0.009255745501141471\n",
      "train loss:0.003590247815457748\n",
      "train loss:0.007465707651955725\n",
      "train loss:0.005913362593341321\n",
      "train loss:0.01658526276972657\n",
      "train loss:0.0018433324346631946\n",
      "train loss:0.010215959621005176\n",
      "train loss:0.006660143211649695\n",
      "train loss:0.007511409119026644\n",
      "train loss:0.003566580959883922\n",
      "train loss:0.0028968206183318467\n",
      "train loss:0.002753108281671579\n",
      "train loss:0.002010825065024205\n",
      "train loss:0.002197723684246609\n",
      "train loss:0.005575141757622354\n",
      "train loss:0.0039223167544660716\n",
      "train loss:0.0033702344302701153\n",
      "train loss:0.004184197182130444\n",
      "train loss:0.0008237306608550254\n",
      "train loss:0.0036766288712300177\n",
      "train loss:0.0021079780726701567\n",
      "train loss:0.01469180355995668\n",
      "train loss:0.00043606893112076855\n",
      "train loss:0.0004739031718331307\n",
      "train loss:0.0022792684613302753\n",
      "train loss:0.0007130242687400067\n",
      "train loss:0.0027083577807825343\n",
      "train loss:0.018488290927045268\n",
      "train loss:0.0018685690240152722\n",
      "train loss:0.0047226109572565496\n",
      "train loss:0.0035796124593470225\n",
      "train loss:0.0030346388266472555\n",
      "train loss:0.012063956442840798\n",
      "train loss:0.0008175590788105827\n",
      "train loss:0.005923431375491076\n",
      "train loss:0.00995494131099368\n",
      "train loss:0.0012985210350173464\n",
      "train loss:0.0064737269263897375\n",
      "train loss:0.0045690978837305\n",
      "train loss:0.002638694069957396\n",
      "train loss:0.0011111075697830236\n",
      "train loss:0.006780320371912163\n",
      "train loss:0.00038067954819049797\n",
      "train loss:0.005774909965691883\n",
      "train loss:0.0007047206581865457\n",
      "train loss:0.013215618983256685\n",
      "train loss:0.002339831071104809\n",
      "train loss:0.0009974856689649542\n",
      "train loss:0.006506957502284003\n",
      "train loss:0.010180255569792313\n",
      "train loss:0.01562508206043339\n",
      "train loss:0.005015676688373303\n",
      "train loss:0.005113051806847467\n",
      "train loss:0.006873775991252936\n",
      "train loss:0.025687841564356974\n",
      "train loss:0.023721095193745538\n",
      "train loss:0.020617669322467055\n",
      "train loss:0.000676259279986101\n",
      "train loss:0.002252876033824086\n",
      "train loss:0.0028869325763544226\n",
      "train loss:0.002001809269242592\n",
      "train loss:0.0008686725205523435\n",
      "train loss:0.001781363380262282\n",
      "train loss:0.0013594672222791231\n",
      "train loss:0.002803837157827027\n",
      "train loss:0.0008935385936024986\n",
      "train loss:0.004739842041770427\n",
      "train loss:0.002205256000172934\n",
      "train loss:0.0032283729502957386\n",
      "train loss:0.0006581103211008917\n",
      "train loss:0.00515239663274891\n",
      "train loss:0.004893931312771308\n",
      "train loss:0.014273039108184421\n",
      "train loss:0.002811869923717569\n",
      "train loss:0.0066580563104080386\n",
      "train loss:0.0016964680595047009\n",
      "train loss:0.0008603201262370822\n",
      "train loss:0.009789068652301829\n",
      "train loss:0.003421075265376972\n",
      "train loss:0.0025172747972430454\n",
      "train loss:0.003138646543748674\n",
      "train loss:0.0016011699583299386\n",
      "train loss:0.0031993625311319625\n",
      "train loss:0.011149029570507011\n",
      "train loss:0.023622227010919473\n",
      "train loss:0.006466952710156049\n",
      "train loss:0.002495989527736418\n",
      "train loss:0.0020042798524847615\n",
      "train loss:0.006444238763472202\n",
      "train loss:0.008464651750992407\n",
      "train loss:0.014027251833444302\n",
      "train loss:0.0010503007780717619\n",
      "train loss:0.026972851888175862\n",
      "train loss:0.0029789383894277864\n",
      "train loss:0.012663488545870625\n",
      "train loss:0.02740361546043273\n",
      "train loss:0.0011337418931052117\n",
      "train loss:0.0031016310583210447\n",
      "train loss:0.008708685263166102\n",
      "train loss:0.005090303013133601\n",
      "train loss:0.0009806545228452414\n",
      "train loss:0.004221506628534579\n",
      "train loss:0.01854677787401226\n",
      "train loss:0.004492206385024946\n",
      "train loss:0.0022729546035940014\n",
      "train loss:0.0049832771133201245\n",
      "train loss:0.001717895220705753\n",
      "train loss:0.014774865366118132\n",
      "train loss:0.0021052528852636503\n",
      "train loss:0.006615772153107991\n",
      "train loss:0.016688665834612367\n",
      "train loss:0.01570337514860626\n",
      "train loss:0.0181147437275518\n",
      "train loss:0.0018429166623180105\n",
      "train loss:0.0066554204739539225\n",
      "train loss:0.0007974101868932469\n",
      "train loss:0.0007465344359799791\n",
      "train loss:0.0008997641024370943\n",
      "train loss:0.0025763282025343644\n",
      "train loss:0.0020953248743133504\n",
      "train loss:0.003176786338190198\n",
      "train loss:0.0011734739942034546\n",
      "train loss:0.00145929162735585\n",
      "train loss:0.0018135045880856892\n",
      "train loss:0.002922226435637314\n",
      "train loss:0.001282316138155228\n",
      "train loss:0.0005282472606652028\n",
      "train loss:0.0003847775712981744\n",
      "train loss:0.005965256007255073\n",
      "train loss:0.0009371477316207093\n",
      "train loss:0.011135475271071239\n",
      "train loss:0.0008688063647824753\n",
      "train loss:0.000428452925844488\n",
      "train loss:0.0006942467727960037\n",
      "train loss:0.001908028425328143\n",
      "train loss:0.0010553704425228388\n",
      "train loss:0.0001476925769205249\n",
      "train loss:0.010798464536558543\n",
      "train loss:0.005924992535982693\n",
      "train loss:0.00503393988794524\n",
      "train loss:0.00032450280211852167\n",
      "train loss:0.0014741174015738437\n",
      "train loss:0.004892619430939398\n",
      "train loss:0.004010456667340225\n",
      "train loss:0.0007382643249935508\n",
      "train loss:0.0003773443166479277\n",
      "train loss:0.00048473459230408546\n",
      "train loss:0.0015523397727374778\n",
      "train loss:0.006037878435028993\n",
      "train loss:0.0003557269495445327\n",
      "train loss:0.0019489917864235603\n",
      "train loss:0.004127339037887478\n",
      "train loss:0.008074775921569891\n",
      "train loss:0.002638787084195063\n",
      "train loss:0.007916280197224597\n",
      "train loss:0.014106750174994964\n",
      "train loss:0.00047503474869544\n",
      "train loss:0.004439239890776783\n",
      "train loss:0.001431714515864256\n",
      "train loss:0.0026814601270272265\n",
      "train loss:0.0002449678014946889\n",
      "train loss:0.011524224016704852\n",
      "train loss:0.0015616050433165044\n",
      "train loss:0.004746144725962013\n",
      "train loss:0.00795329205430806\n",
      "train loss:0.008832013177103233\n",
      "train loss:0.0072615461757928905\n",
      "train loss:0.0017172326347099135\n",
      "train loss:0.008411914767856252\n",
      "train loss:0.003952643806951755\n",
      "train loss:0.0018330385163619859\n",
      "train loss:0.0018327658772362232\n",
      "train loss:0.0010804122958650284\n",
      "train loss:0.0018753164436150637\n",
      "train loss:0.0021381424564721656\n",
      "train loss:0.0083265740144008\n",
      "train loss:0.0015445225783327528\n",
      "train loss:0.004301883278156367\n",
      "train loss:0.0012190025291534776\n",
      "train loss:0.0067962053721993985\n",
      "train loss:0.0010905320455344555\n",
      "train loss:0.0042525067244725875\n",
      "train loss:0.010077490429444075\n",
      "train loss:0.001139629104095918\n",
      "train loss:0.004269548541928343\n",
      "train loss:0.015939124313173333\n",
      "train loss:0.003384036029030895\n",
      "train loss:0.0019303344984686389\n",
      "train loss:0.007027450019557682\n",
      "train loss:0.007520846878551253\n",
      "train loss:0.004414801187205595\n",
      "train loss:0.05332131776967419\n",
      "train loss:0.010611507324324946\n",
      "train loss:0.00888275960120293\n",
      "train loss:0.0008303780870666785\n",
      "train loss:0.00385429140509004\n",
      "train loss:0.007782034709044771\n",
      "train loss:0.0033456781632371702\n",
      "train loss:0.0038024260279447457\n",
      "train loss:0.0018069590399880926\n",
      "train loss:0.0026922647324453663\n",
      "train loss:0.014780717832151007\n",
      "train loss:0.0005225151165936872\n",
      "train loss:0.0005047520154360295\n",
      "train loss:0.034951836440432954\n",
      "train loss:0.01413504698735035\n",
      "train loss:0.002470228200172593\n",
      "train loss:0.00023073721446150575\n",
      "train loss:0.003571853047501067\n",
      "train loss:0.022785131010517778\n",
      "train loss:0.0017813023274808144\n",
      "train loss:0.0016663506555777388\n",
      "train loss:0.004619098772862319\n",
      "train loss:0.027137877329566643\n",
      "train loss:0.00845670505798762\n",
      "train loss:0.004825582686195787\n",
      "train loss:0.019420332107519523\n",
      "train loss:0.009180671902126429\n",
      "train loss:0.013122801012017465\n",
      "train loss:0.004147403021559646\n",
      "train loss:0.005265649380357832\n",
      "train loss:0.015948627708317276\n",
      "train loss:0.0038499333999850336\n",
      "train loss:0.0026493188587341115\n",
      "train loss:0.007901127123247744\n",
      "train loss:0.01983005618291649\n",
      "train loss:0.0037818843792611426\n",
      "train loss:0.0026169732753519004\n",
      "train loss:0.003408811733063623\n",
      "train loss:0.004993176711567219\n",
      "train loss:0.002850583817292233\n",
      "train loss:0.007902339059301966\n",
      "train loss:0.008927318549465131\n",
      "train loss:0.002888349846960812\n",
      "train loss:0.017959509089695447\n",
      "train loss:0.006055486870397178\n",
      "train loss:0.02082180328182557\n",
      "train loss:0.006629763495232558\n",
      "train loss:0.007127667754021125\n",
      "train loss:0.0066194878882431555\n",
      "train loss:0.06002140386549629\n",
      "train loss:0.007294122314645411\n",
      "train loss:0.012849001593269873\n",
      "train loss:0.001662215634587284\n",
      "train loss:0.0034925087711724684\n",
      "train loss:0.0015836436326949592\n",
      "train loss:0.0016119779808528316\n",
      "train loss:0.007211879251045315\n",
      "train loss:0.011752470043095164\n",
      "train loss:0.019763243005589445\n",
      "train loss:0.003946753228500173\n",
      "train loss:0.006725582701387348\n",
      "train loss:0.003258515384974709\n",
      "train loss:0.004684152929205145\n",
      "train loss:0.0029800504806017894\n",
      "train loss:0.0033012792110149874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011730472911607925\n",
      "train loss:0.01941173796110531\n",
      "train loss:0.0004484711031937941\n",
      "train loss:0.005376819864474287\n",
      "train loss:0.0009493334938514136\n",
      "train loss:0.001635020740113689\n",
      "train loss:0.013551026329097687\n",
      "train loss:0.007423545717942617\n",
      "train loss:0.0017971984950810851\n",
      "train loss:0.002393480543346357\n",
      "train loss:0.0023397633336470105\n",
      "train loss:0.014155846397856074\n",
      "train loss:0.0032482488466251966\n",
      "train loss:0.004656917806845052\n",
      "train loss:0.001994858214438926\n",
      "train loss:0.0022921144776922578\n",
      "train loss:0.0008991073996134749\n",
      "train loss:0.003371757752322758\n",
      "train loss:0.008593742115613241\n",
      "train loss:0.00701448083278257\n",
      "train loss:0.0033397042144768267\n",
      "train loss:0.004824397638393238\n",
      "train loss:0.0046542448080583824\n",
      "train loss:0.0016629070843952255\n",
      "train loss:0.0034304368263783206\n",
      "train loss:0.000768935867681581\n",
      "train loss:0.005016692756954979\n",
      "train loss:0.004906794886054632\n",
      "train loss:0.0011477741799950597\n",
      "train loss:0.0004229900381270823\n",
      "train loss:0.004645887362491496\n",
      "train loss:0.010950001499732942\n",
      "train loss:0.0014521139034159437\n",
      "train loss:0.001511915679353471\n",
      "train loss:0.014270919484974607\n",
      "train loss:0.0006422543261115477\n",
      "train loss:0.0019196754472548326\n",
      "train loss:0.000881735146509384\n",
      "train loss:0.01940931616346259\n",
      "train loss:0.001548132733858861\n",
      "train loss:0.013645702066372221\n",
      "train loss:0.007630332394337881\n",
      "train loss:0.01528722207449927\n",
      "train loss:0.0036346120701364034\n",
      "train loss:0.036430424659900755\n",
      "train loss:0.001459749295444356\n",
      "train loss:0.0015636103999539473\n",
      "train loss:0.0018677011848236044\n",
      "train loss:0.006608473663731342\n",
      "train loss:0.008458840407442233\n",
      "train loss:0.006811300124239453\n",
      "train loss:0.008978187360821628\n",
      "train loss:0.0051153667475142\n",
      "train loss:0.003438585309608839\n",
      "train loss:0.0027049550720919815\n",
      "train loss:0.00269509497981431\n",
      "train loss:0.005291269364990817\n",
      "train loss:0.005240388935744604\n",
      "train loss:0.0036943231043109572\n",
      "train loss:0.0048334776374012785\n",
      "train loss:0.0013112379145006382\n",
      "train loss:0.003144492422842863\n",
      "train loss:0.005315235582859259\n",
      "train loss:0.0045642561185507986\n",
      "train loss:0.0015733354319397096\n",
      "train loss:0.0019896230912518314\n",
      "train loss:0.0029306256535402884\n",
      "train loss:0.003888121464493667\n",
      "train loss:0.005827711120036639\n",
      "train loss:0.003889020142665745\n",
      "train loss:0.00129014652850776\n",
      "train loss:0.010618610791109644\n",
      "train loss:0.004222937892334628\n",
      "train loss:0.006483441839244321\n",
      "train loss:0.0006614278265869272\n",
      "train loss:0.0011273615491507198\n",
      "train loss:0.01959497956584159\n",
      "train loss:0.010081307974609783\n",
      "train loss:0.013384252795672529\n",
      "train loss:0.003579105074877154\n",
      "train loss:0.005444553088487787\n",
      "train loss:0.010191007978291592\n",
      "train loss:0.001651076447890798\n",
      "train loss:0.010080860126084055\n",
      "train loss:0.0021096783067161033\n",
      "train loss:0.0009517174347857656\n",
      "train loss:0.0008529038123090882\n",
      "train loss:0.013361332249682143\n",
      "train loss:0.0022535099078770443\n",
      "train loss:0.0016820306459743993\n",
      "train loss:0.005496678103527835\n",
      "train loss:0.002366709976027755\n",
      "train loss:0.0031935239035587077\n",
      "train loss:0.003317122369243668\n",
      "train loss:0.001171190829696438\n",
      "train loss:0.001794209896227864\n",
      "train loss:0.0012197595716743794\n",
      "train loss:0.0025068851364442478\n",
      "train loss:0.011322340470190768\n",
      "train loss:0.005982565231967067\n",
      "=== epoch:19, train acc:0.9982110507246377, test acc:0.9878623188405797 ===\n",
      "train loss:0.001965136908574224\n",
      "train loss:0.005307090169081726\n",
      "train loss:0.0010785194449320285\n",
      "train loss:0.0011606893093612633\n",
      "train loss:0.0004957615970687559\n",
      "train loss:0.003061762527200258\n",
      "train loss:0.0004130944287306483\n",
      "train loss:0.0008446023633082796\n",
      "train loss:0.0014832453663067994\n",
      "train loss:0.0008480827442972797\n",
      "train loss:0.000893083398685391\n",
      "train loss:0.004604957843932817\n",
      "train loss:0.00015328350695473054\n",
      "train loss:0.008343255538857852\n",
      "train loss:0.009146507180163932\n",
      "train loss:0.0010462377649938994\n",
      "train loss:0.001474578525891167\n",
      "train loss:0.024283059474198107\n",
      "train loss:0.010419825689990257\n",
      "train loss:0.006271581711328371\n",
      "train loss:0.0005712609840357464\n",
      "train loss:0.003138784367324042\n",
      "train loss:0.0008933551815483302\n",
      "train loss:0.0021097255338600306\n",
      "train loss:0.0010911813855878124\n",
      "train loss:0.009619813192576905\n",
      "train loss:0.000535107093056981\n",
      "train loss:0.0016320000599781134\n",
      "train loss:0.005245266585846054\n",
      "train loss:0.0022611304598972393\n",
      "train loss:0.0029452664668333075\n",
      "train loss:0.003102897337749877\n",
      "train loss:0.0026800058247788182\n",
      "train loss:0.0025090049191447816\n",
      "train loss:0.003476394851280379\n",
      "train loss:0.0034809913467009025\n",
      "train loss:0.012263009086524822\n",
      "train loss:0.01352194319010523\n",
      "train loss:0.011794760608232167\n",
      "train loss:0.003318526078279186\n",
      "train loss:0.0009959199363196454\n",
      "train loss:0.016561916285546655\n",
      "train loss:0.0034628016919227987\n",
      "train loss:0.0011845905085215113\n",
      "train loss:0.00997467049342206\n",
      "train loss:0.0010773735534384428\n",
      "train loss:0.016573510667364583\n",
      "train loss:0.018075514529464785\n",
      "train loss:0.002337234006818809\n",
      "train loss:0.021210757248631317\n",
      "train loss:0.00532660284258879\n",
      "train loss:0.0308525728244682\n",
      "train loss:0.0017408236569517355\n",
      "train loss:0.007086598181225098\n",
      "train loss:0.009028275213031577\n",
      "train loss:0.008240333265752357\n",
      "train loss:0.0027748860451392806\n",
      "train loss:0.004694157468384286\n",
      "train loss:0.044718122813916385\n",
      "train loss:0.01250334793729012\n",
      "train loss:0.00398408968540257\n",
      "train loss:0.007136651016291707\n",
      "train loss:0.026531784610276023\n",
      "train loss:0.004723064937390927\n",
      "train loss:0.0027848274378987144\n",
      "train loss:0.0028997989052421324\n",
      "train loss:0.0013896779988875369\n",
      "train loss:0.002104611652890837\n",
      "train loss:0.003144451405491097\n",
      "train loss:0.007043984373853217\n",
      "train loss:0.0012801472489767272\n",
      "train loss:0.0072167925655329\n",
      "train loss:0.0052703349436019516\n",
      "train loss:0.004925386094344981\n",
      "train loss:0.018669254719703352\n",
      "train loss:0.001341520140332525\n",
      "train loss:0.0014482366304122344\n",
      "train loss:0.006885353090741119\n",
      "train loss:0.004782810558538266\n",
      "train loss:0.0016080380020409694\n",
      "train loss:0.004210261980720786\n",
      "train loss:0.013975473175523282\n",
      "train loss:0.00466404978360078\n",
      "train loss:0.0025398345071330794\n",
      "train loss:0.0016934979875892194\n",
      "train loss:0.0016874470269365217\n",
      "train loss:0.000863381528326157\n",
      "train loss:0.0012719816227550077\n",
      "train loss:0.005247306194516878\n",
      "train loss:0.0010164764866620018\n",
      "train loss:0.004986480493930839\n",
      "train loss:0.004424538610153159\n",
      "train loss:0.0006215949203727226\n",
      "train loss:0.0029496013953645346\n",
      "train loss:0.005641848331352641\n",
      "train loss:0.0012715885755982005\n",
      "train loss:0.005583927056788502\n",
      "train loss:0.004214062145305153\n",
      "train loss:0.0017875620613343147\n",
      "train loss:0.005433249581026353\n",
      "train loss:0.0019280949523868334\n",
      "train loss:0.0015635819152167209\n",
      "train loss:0.0006797274870608411\n",
      "train loss:0.011974495372400175\n",
      "train loss:0.002602534903228726\n",
      "train loss:0.0071142042476493\n",
      "train loss:0.0012252508503782101\n",
      "train loss:0.0014613491189078742\n",
      "train loss:0.00871319990920246\n",
      "train loss:0.0026872982371669496\n",
      "train loss:0.01748369672484758\n",
      "train loss:0.0009326981243930977\n",
      "train loss:0.0006728584228596934\n",
      "train loss:0.005368742990344803\n",
      "train loss:0.0021558220714235064\n",
      "train loss:0.0009348451403042167\n",
      "train loss:0.00588509942999261\n",
      "train loss:0.002547466152108263\n",
      "train loss:0.002675969032709709\n",
      "train loss:0.0009180375023358851\n",
      "train loss:0.0036125842719044927\n",
      "train loss:0.0009784562481884105\n",
      "train loss:0.007264886711319837\n",
      "train loss:0.04080217976396568\n",
      "train loss:0.0014335585071228\n",
      "train loss:0.0061512471503873956\n",
      "train loss:0.0006405804273726535\n",
      "train loss:0.009285734070815259\n",
      "train loss:0.0013390138976368685\n",
      "train loss:0.0012036194150814577\n",
      "train loss:0.006918964272777331\n",
      "train loss:0.003340118789195035\n",
      "train loss:0.014419830751262816\n",
      "train loss:0.0037523525045937193\n",
      "train loss:0.004592752585144341\n",
      "train loss:0.003962924798646166\n",
      "train loss:0.00627000908494819\n",
      "train loss:0.0020430987357161474\n",
      "train loss:0.005336307553424108\n",
      "train loss:0.004250189222898146\n",
      "train loss:0.003862635507243298\n",
      "train loss:0.002465512858814674\n",
      "train loss:0.008347433658819379\n",
      "train loss:0.025116818066134704\n",
      "train loss:0.009203704484794323\n",
      "train loss:0.0025439881872763915\n",
      "train loss:0.012876855721847848\n",
      "train loss:0.001643629831240052\n",
      "train loss:0.0054425968646010315\n",
      "train loss:0.014868755157198286\n",
      "train loss:0.016005369922101262\n",
      "train loss:0.005421563693573838\n",
      "train loss:0.00372289627902606\n",
      "train loss:0.002005148184830195\n",
      "train loss:0.0007105899701191114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0038508509427604355\n",
      "train loss:0.00566425287527153\n",
      "train loss:0.022393005243422383\n",
      "train loss:0.015904004333851102\n",
      "train loss:0.0034344830961483015\n",
      "train loss:0.0004235631848471213\n",
      "train loss:0.00036763207774980454\n",
      "train loss:0.0011314023688143503\n",
      "train loss:0.0017415033247225144\n",
      "train loss:0.00699442609615275\n",
      "train loss:0.0005478357128726214\n",
      "train loss:0.004494103480825353\n",
      "train loss:0.008506216818759198\n",
      "train loss:0.006661399086824946\n",
      "train loss:0.00809556496294705\n",
      "train loss:0.004137300366973464\n",
      "train loss:0.01849993137356854\n",
      "train loss:0.0019213005601265744\n",
      "train loss:0.0016755098615323226\n",
      "train loss:0.001948689139629199\n",
      "train loss:0.007127279028692903\n",
      "train loss:0.0008003005989267523\n",
      "train loss:0.006416236229488997\n",
      "train loss:0.000820206047285743\n",
      "train loss:0.0057129085670210725\n",
      "train loss:0.0056580755993465995\n",
      "train loss:0.00436140110247024\n",
      "train loss:0.0024570002785221975\n",
      "train loss:0.00452233067853294\n",
      "train loss:0.0015321183335261072\n",
      "train loss:0.004302068637107615\n",
      "train loss:0.004184033673398791\n",
      "train loss:0.0012631590206300298\n",
      "train loss:0.009109067219628002\n",
      "train loss:0.005621621681531247\n",
      "train loss:0.003749844943625463\n",
      "train loss:0.0002778378613577306\n",
      "train loss:0.0004315858461068788\n",
      "train loss:0.004329117777277791\n",
      "train loss:0.0018941904728171\n",
      "train loss:0.001182531293540577\n",
      "train loss:0.0016812520170012336\n",
      "train loss:0.0065930378550906055\n",
      "train loss:0.0033176704819113984\n",
      "train loss:0.008149164000880265\n",
      "train loss:0.0015642645241817975\n",
      "train loss:0.0034626023013270965\n",
      "train loss:0.013700225831577597\n",
      "train loss:0.001914909098908089\n",
      "train loss:0.002680954713506283\n",
      "train loss:0.007305727331941934\n",
      "train loss:0.0039639977931477605\n",
      "train loss:0.0019966274404031215\n",
      "train loss:0.00307827664517996\n",
      "train loss:0.001948060137338701\n",
      "train loss:0.005418180095540079\n",
      "train loss:0.005332418975548573\n",
      "train loss:0.004305333249561481\n",
      "train loss:0.003425377976151366\n",
      "train loss:0.005071728395130926\n",
      "train loss:0.008526300197917617\n",
      "train loss:0.011018079202669976\n",
      "train loss:0.008947922879503948\n",
      "train loss:0.004477316656460877\n",
      "train loss:0.010314953861505858\n",
      "train loss:0.0022314252127444523\n",
      "train loss:0.022345959166194942\n",
      "train loss:0.001977663046235459\n",
      "train loss:0.0012274184484814467\n",
      "train loss:0.0030039692476851046\n",
      "train loss:0.0020105817693040016\n",
      "train loss:0.014575023337316322\n",
      "train loss:0.009457643861846282\n",
      "train loss:0.002505897053408576\n",
      "train loss:0.0030005325312586306\n",
      "train loss:0.0015228326876167658\n",
      "train loss:0.00183662638572403\n",
      "train loss:0.00568708271619813\n",
      "train loss:0.0033583492613806294\n",
      "train loss:0.002524855495868966\n",
      "train loss:0.0017768646401243981\n",
      "train loss:0.02332278624501153\n",
      "train loss:0.0006192136385049641\n",
      "train loss:0.002494286536976921\n",
      "train loss:0.004690117407646227\n",
      "train loss:0.0019064332048750923\n",
      "train loss:0.002994439762171485\n",
      "train loss:0.003839201341080988\n",
      "train loss:0.0012688609469287692\n",
      "train loss:0.00331440961562109\n",
      "train loss:0.0011341829553975426\n",
      "train loss:0.0003802348779969644\n",
      "train loss:0.0012459980809155086\n",
      "train loss:0.0017781500637396826\n",
      "train loss:0.0035482365251846945\n",
      "train loss:0.0018640378277843793\n",
      "train loss:0.0011282104922602494\n",
      "train loss:0.008044798048383199\n",
      "train loss:0.008273383629391338\n",
      "train loss:0.005034629291417177\n",
      "train loss:0.002185908758859157\n",
      "train loss:0.000934417901522938\n",
      "train loss:0.01638545869679934\n",
      "train loss:0.0037184775894323493\n",
      "train loss:0.008623890492343193\n",
      "train loss:0.005537805026115633\n",
      "train loss:0.00511495977926707\n",
      "train loss:0.0007375597603183936\n",
      "train loss:0.0015763795626435036\n",
      "train loss:0.0038566474858167735\n",
      "train loss:0.0017151880596870278\n",
      "train loss:0.007443072768714896\n",
      "train loss:0.003476550469992507\n",
      "train loss:0.002892628764409764\n",
      "train loss:0.0007444006501620607\n",
      "train loss:0.00376693518625285\n",
      "train loss:0.0010624569746925819\n",
      "train loss:0.002688639156992962\n",
      "train loss:0.0044594266467379625\n",
      "train loss:0.011562197774463812\n",
      "train loss:0.0011463748471208226\n",
      "train loss:0.013192733945768123\n",
      "train loss:0.003935796885345903\n",
      "train loss:0.005309035745077863\n",
      "train loss:0.007817850625902371\n",
      "train loss:0.0035753645885194555\n",
      "train loss:0.002988724117545385\n",
      "train loss:0.002653711713983513\n",
      "train loss:0.0010243820941401428\n",
      "train loss:0.005755514819108675\n",
      "train loss:0.0034174439550140826\n",
      "train loss:0.013027137569897923\n",
      "train loss:0.033683840498547564\n",
      "train loss:0.0012788906125475068\n",
      "train loss:0.005085561017056994\n",
      "train loss:0.0029552508381971787\n",
      "train loss:0.0011821592729139255\n",
      "train loss:0.008493346195928697\n",
      "train loss:0.0029120724795837012\n",
      "train loss:0.0005281556215387677\n",
      "train loss:0.0016067935075152159\n",
      "train loss:0.004024744680416609\n",
      "train loss:0.0016156279648067299\n",
      "train loss:0.005554216558879833\n",
      "train loss:0.0011994811177030824\n",
      "train loss:0.0004472796855761257\n",
      "train loss:0.0055047677174309365\n",
      "train loss:0.0012983597777804234\n",
      "train loss:0.0043941523189410464\n",
      "train loss:0.000764812364240216\n",
      "train loss:0.002472683959841615\n",
      "train loss:0.0018860992331458132\n",
      "train loss:0.0033552713015225027\n",
      "train loss:0.0031081061666781494\n",
      "train loss:0.011278276022669112\n",
      "train loss:0.0003050056130428551\n",
      "train loss:0.0010840565838653234\n",
      "train loss:0.0008382033665488205\n",
      "train loss:0.00043083777612271286\n",
      "train loss:0.00041202485376812666\n",
      "train loss:0.007487213420315742\n",
      "train loss:0.0009048118902639841\n",
      "train loss:0.00280900799600806\n",
      "train loss:0.0006081890423148252\n",
      "train loss:0.002395169282137761\n",
      "train loss:0.009647694243960078\n",
      "train loss:0.0016966498568695262\n",
      "train loss:0.01634728489740052\n",
      "train loss:0.0032854766452305997\n",
      "train loss:0.0014865576096097489\n",
      "train loss:0.004735217094249798\n",
      "train loss:0.0003062719385169641\n",
      "train loss:0.0019195606697744148\n",
      "train loss:0.0064796636985883374\n",
      "train loss:0.0014498449729031413\n",
      "train loss:0.003917822727122972\n",
      "train loss:0.0034469729112262303\n",
      "train loss:0.004796572742263714\n",
      "train loss:0.0044531066036102235\n",
      "train loss:0.0036103431713910904\n",
      "train loss:0.0014006528211606474\n",
      "train loss:0.002107987500822068\n",
      "train loss:0.0017196989098739088\n",
      "train loss:0.005905193676934273\n",
      "train loss:0.0034674500578116673\n",
      "train loss:0.0012666469738046792\n",
      "train loss:0.008043281126219461\n",
      "train loss:0.0005507666998370351\n",
      "train loss:0.003083085439013678\n",
      "train loss:0.0014602368378552654\n",
      "train loss:0.000664951102462784\n",
      "train loss:0.012463491975755157\n",
      "train loss:0.0030207890095633387\n",
      "train loss:0.0005016159516657609\n",
      "train loss:0.0011907729269107865\n",
      "train loss:0.001544967316547639\n",
      "train loss:0.00842381173959666\n",
      "train loss:0.0009577124158165403\n",
      "train loss:0.005233277727431805\n",
      "train loss:0.0006120279680459698\n",
      "train loss:0.0007797626036132565\n",
      "train loss:0.005533101135950047\n",
      "train loss:0.0015265373800505014\n",
      "train loss:0.009015638337462717\n",
      "train loss:0.0027132518118362977\n",
      "train loss:0.0007267454019538064\n",
      "train loss:0.043891126457460336\n",
      "train loss:0.0018173145354588\n",
      "train loss:0.0018211594278795937\n",
      "train loss:0.006591892472850436\n",
      "train loss:0.0038324568772041914\n",
      "train loss:0.0019618405314802676\n",
      "train loss:0.013537575760062476\n",
      "=== epoch:20, train acc:0.998143115942029, test acc:0.9870471014492753 ===\n",
      "train loss:0.0014929028068215292\n",
      "train loss:0.00382238688058847\n",
      "train loss:0.00339758348929444\n",
      "train loss:0.0009635570809069133\n",
      "train loss:0.0029223011306773895\n",
      "train loss:0.0007217227811199103\n",
      "train loss:0.006487583205968234\n",
      "train loss:0.001955619998194823\n",
      "train loss:0.002637278734065696\n",
      "train loss:0.0012916614684177425\n",
      "train loss:0.0019074798161397982\n",
      "train loss:0.006422770501551352\n",
      "train loss:0.0012014733453000474\n",
      "train loss:0.004328339345313141\n",
      "train loss:0.006110328253911159\n",
      "train loss:0.005687876204526577\n",
      "train loss:0.010176168757147218\n",
      "train loss:0.001601070428909234\n",
      "train loss:0.0008646051101230471\n",
      "train loss:0.003400359385482459\n",
      "train loss:0.004244236723006048\n",
      "train loss:0.0010823674229910147\n",
      "train loss:0.019628270621897804\n",
      "train loss:0.0005276650098626675\n",
      "train loss:0.0013018528458235725\n",
      "train loss:0.0013961567782883645\n",
      "train loss:0.001199218470545177\n",
      "train loss:0.0022547154472563743\n",
      "train loss:0.0015268306495948417\n",
      "train loss:0.00043380791596307907\n",
      "train loss:0.010739260323139667\n",
      "train loss:0.0018312908900846871\n",
      "train loss:0.0006089287413365045\n",
      "train loss:0.00325547725658512\n",
      "train loss:0.0025165473300578054\n",
      "train loss:0.0013558752688742695\n",
      "train loss:0.0017445435825352456\n",
      "train loss:0.0017492078569856274\n",
      "train loss:0.0012304335110311748\n",
      "train loss:0.0034724478558948724\n",
      "train loss:0.0012739537093713487\n",
      "train loss:0.0024214171485134523\n",
      "train loss:0.0008651256301160481\n",
      "train loss:0.001269773537450604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0012686041720895741\n",
      "train loss:0.011565040103769419\n",
      "train loss:0.000630003726883735\n",
      "train loss:0.001206751740274571\n",
      "train loss:0.001278792540509911\n",
      "train loss:0.005850624812532648\n",
      "train loss:0.0012917449838169795\n",
      "train loss:0.015858633990069825\n",
      "train loss:0.01459986899321417\n",
      "train loss:0.0019676760263173825\n",
      "train loss:0.0038929955137055466\n",
      "train loss:0.007006996342328546\n",
      "train loss:0.0008665027928836225\n",
      "train loss:0.0038265016737665304\n",
      "train loss:0.0009644885632024374\n",
      "train loss:0.017001861473955045\n",
      "train loss:0.000526514077887138\n",
      "train loss:0.0027190951888911028\n",
      "train loss:0.0026479057698245113\n",
      "train loss:0.005209605487640355\n",
      "train loss:0.0006658491977892833\n",
      "train loss:0.004262703548552832\n",
      "train loss:0.001685326519306929\n",
      "train loss:0.0020344102402885264\n",
      "train loss:0.0026339063052502236\n",
      "train loss:0.0018951753516606032\n",
      "train loss:0.007953567530949656\n",
      "train loss:0.0018752369230405066\n",
      "train loss:0.0036352113073303037\n",
      "train loss:0.0006569712787580998\n",
      "train loss:0.0048650888016855106\n",
      "train loss:0.005332050746305902\n",
      "train loss:0.0004886752626199986\n",
      "train loss:0.0023656076437105823\n",
      "train loss:0.0462662744667404\n",
      "train loss:0.0036092261615508184\n",
      "train loss:0.03926565628629054\n",
      "train loss:0.0032911873496753214\n",
      "train loss:0.0005237297432106971\n",
      "train loss:0.013472930854928991\n",
      "train loss:0.0024954167712647407\n",
      "train loss:0.002857220683799589\n",
      "train loss:0.0012518045601664825\n",
      "train loss:0.0029504279228336023\n",
      "train loss:0.002493055140808163\n",
      "train loss:0.005167794361115374\n",
      "train loss:0.0007717959536401836\n",
      "train loss:0.0009511035922752051\n",
      "train loss:0.006408418771366509\n",
      "train loss:0.005020747310154427\n",
      "train loss:0.005501312019473193\n",
      "train loss:0.0060692142412568425\n",
      "train loss:0.0007043545286304374\n",
      "train loss:0.015012986413662048\n",
      "train loss:0.001531324842656821\n",
      "train loss:0.0030722912146634355\n",
      "train loss:0.017089027136823413\n",
      "train loss:0.0011470474011804155\n",
      "train loss:0.0015882642050427114\n",
      "train loss:0.007314271828379709\n",
      "train loss:0.0040742848117326985\n",
      "train loss:0.020114954300021904\n",
      "train loss:0.0045187112900580365\n",
      "train loss:0.015761202347955843\n",
      "train loss:0.005124176485297448\n",
      "train loss:0.006378214483359261\n",
      "train loss:0.0012826647092964226\n",
      "train loss:0.0030690945983568997\n",
      "train loss:0.0017247223262992753\n",
      "train loss:0.0016222303753800735\n",
      "train loss:0.013987212022919773\n",
      "train loss:0.005113240343333407\n",
      "train loss:0.004195875106564008\n",
      "train loss:0.0036880843725069015\n",
      "train loss:0.0029191823891256685\n",
      "train loss:0.0020976031376951196\n",
      "train loss:0.0014096911463117741\n",
      "train loss:0.010927465190695089\n",
      "train loss:0.001305523831401982\n",
      "train loss:0.0004431781645350529\n",
      "train loss:0.0004440844055374915\n",
      "train loss:0.020623291132487197\n",
      "train loss:0.0005945062705204226\n",
      "train loss:0.0006112617037736785\n",
      "train loss:0.0010327330205917248\n",
      "train loss:0.0013862120436143844\n",
      "train loss:0.0003531829959247804\n",
      "train loss:0.00453419495702075\n",
      "train loss:0.01089579735593872\n",
      "train loss:0.001162247312823326\n",
      "train loss:0.0008452183989074828\n",
      "train loss:0.002413666579988133\n",
      "train loss:0.01088949414599883\n",
      "train loss:0.010380138127800689\n",
      "train loss:0.001619101595156921\n",
      "train loss:0.02234037874022442\n",
      "train loss:0.0008447439780116778\n",
      "train loss:0.0025101087277684736\n",
      "train loss:0.0030518562563271456\n",
      "train loss:0.006388798184189484\n",
      "train loss:0.005570855949308266\n",
      "train loss:0.000704938050792246\n",
      "train loss:0.00437649956078896\n",
      "train loss:0.001490860070276457\n",
      "train loss:0.0019120154258073783\n",
      "train loss:0.005344166481312436\n",
      "train loss:0.005755401653997726\n",
      "train loss:0.0047570615760341405\n",
      "train loss:0.03928509535908989\n",
      "train loss:0.0005255404102397492\n",
      "train loss:0.007358598266281593\n",
      "train loss:0.0007904654635213935\n",
      "train loss:0.0020595455498805294\n",
      "train loss:0.0032738210367509023\n",
      "train loss:0.0006882686249162606\n",
      "train loss:0.0007544012365154589\n",
      "train loss:0.0014245562338167054\n",
      "train loss:0.009480961488384674\n",
      "train loss:0.002125162612090617\n",
      "train loss:0.0011720958481532247\n",
      "train loss:0.01058559717554763\n",
      "train loss:0.0007421673579179588\n",
      "train loss:0.008235095975045867\n",
      "train loss:0.025469825979263845\n",
      "train loss:0.0021032121678168088\n",
      "train loss:0.0016081248573574518\n",
      "train loss:0.0006924286987083094\n",
      "train loss:0.012989631867606728\n",
      "train loss:0.01098387389414439\n",
      "train loss:0.0014437968225483177\n",
      "train loss:0.0017516443410330632\n",
      "train loss:0.0008763376346741851\n",
      "train loss:0.002817721905810017\n",
      "train loss:0.0019096000778947128\n",
      "train loss:0.0052223864832398725\n",
      "train loss:0.008920514353652091\n",
      "train loss:0.0002128219370356018\n",
      "train loss:0.0007528627176890674\n",
      "train loss:0.0033832645078631794\n",
      "train loss:0.001024215314041579\n",
      "train loss:0.0010177520562770408\n",
      "train loss:0.005282789614104842\n",
      "train loss:0.002017059427695898\n",
      "train loss:0.0020177850059809274\n",
      "train loss:0.0024668495015714\n",
      "train loss:0.002514148081500279\n",
      "train loss:0.0005523178546964987\n",
      "train loss:0.0021219017086162736\n",
      "train loss:0.003881342193220408\n",
      "train loss:0.0012116027678078926\n",
      "train loss:0.0023395079244727716\n",
      "train loss:0.0022893691306414914\n",
      "train loss:0.001350875847706056\n",
      "train loss:0.0014586832266550614\n",
      "train loss:0.0017466267217243813\n",
      "train loss:0.0018098143690732402\n",
      "train loss:0.0006406299650859715\n",
      "train loss:0.0065137958562085435\n",
      "train loss:0.003433973570896693\n",
      "train loss:0.0007596177127224028\n",
      "train loss:0.0026154830464251376\n",
      "train loss:0.0048323765917307115\n",
      "train loss:0.006048686455451341\n",
      "train loss:0.002115916753674485\n",
      "train loss:0.007519299415642592\n",
      "train loss:0.005570039231960959\n",
      "train loss:0.00016193420201139903\n",
      "train loss:0.0018588106899142226\n",
      "train loss:0.0021456746945697916\n",
      "train loss:0.018812389149217405\n",
      "train loss:0.014854460234508813\n",
      "train loss:0.013135014409619767\n",
      "train loss:0.022842281913075302\n",
      "train loss:0.0006379383310354369\n",
      "train loss:0.0005456338435231298\n",
      "train loss:0.0033696644280574828\n",
      "train loss:0.001948383562526488\n",
      "train loss:0.00774723418861385\n",
      "train loss:0.004254983545935253\n",
      "train loss:0.0023597450488347447\n",
      "train loss:0.0005858177329215842\n",
      "train loss:0.006688362032850238\n",
      "train loss:0.0068565595598999215\n",
      "train loss:0.002761390477953075\n",
      "train loss:0.0009526486482746484\n",
      "train loss:0.0020256126840779514\n",
      "train loss:0.0020088240015582225\n",
      "train loss:0.013474620970325084\n",
      "train loss:0.0013382588440849152\n",
      "train loss:0.002416320652542297\n",
      "train loss:0.001208935426448359\n",
      "train loss:0.006365765181903452\n",
      "train loss:0.0025920310357911893\n",
      "train loss:0.011158649161583916\n",
      "train loss:0.001642673083235797\n",
      "train loss:0.013705220868221327\n",
      "train loss:0.045645462889267505\n",
      "train loss:0.003243784023496914\n",
      "train loss:0.005852392699325893\n",
      "train loss:0.001727736974188127\n",
      "train loss:0.0004679909772243755\n",
      "train loss:0.0017895777581215097\n",
      "train loss:0.0015773184711415156\n",
      "train loss:0.0023288578625300254\n",
      "train loss:0.001979425761834025\n",
      "train loss:0.009294608909143449\n",
      "train loss:0.0023965669480286883\n",
      "train loss:0.0040167732805383456\n",
      "train loss:0.0017488414955860814\n",
      "train loss:0.0029640360547911098\n",
      "train loss:0.010211866129150102\n",
      "train loss:0.010282609956021344\n",
      "train loss:0.002476522728176682\n",
      "train loss:0.006004449969671546\n",
      "train loss:0.00488036413247755\n",
      "train loss:0.03969901126630518\n",
      "train loss:0.008486927956640094\n",
      "train loss:0.006559551978258018\n",
      "train loss:0.003749005713748824\n",
      "train loss:0.016239687120890633\n",
      "train loss:0.0010960127539918951\n",
      "train loss:0.0025075946463883705\n",
      "train loss:0.0017433188019666957\n",
      "train loss:0.019869750908193214\n",
      "train loss:0.0017819558684162558\n",
      "train loss:0.003919157653781106\n",
      "train loss:0.010349071992458927\n",
      "train loss:0.0017162676284911858\n",
      "train loss:0.002063360132657999\n",
      "train loss:0.003261015451636499\n",
      "train loss:0.004519161265817373\n",
      "train loss:0.0052184903586192195\n",
      "train loss:0.0009129083645160416\n",
      "train loss:0.0036116696690074797\n",
      "train loss:0.00166391407869611\n",
      "train loss:0.006303927298497243\n",
      "train loss:0.0042661827664637105\n",
      "train loss:0.002005276715795258\n",
      "train loss:0.0070537019595094015\n",
      "train loss:0.0022777502937851076\n",
      "train loss:0.006948079635930288\n",
      "train loss:0.003450668257305932\n",
      "train loss:0.01396567227119544\n",
      "train loss:0.021164752070575183\n",
      "train loss:0.0010842511557766434\n",
      "train loss:0.0012409265997553394\n",
      "train loss:0.0013278824636608353\n",
      "train loss:0.0012679776897929808\n",
      "train loss:0.0030478291408343934\n",
      "train loss:0.006020139109820082\n",
      "train loss:0.001992631086425287\n",
      "train loss:0.016098443189452673\n",
      "train loss:0.0006525959644307459\n",
      "train loss:0.0013796242955167349\n",
      "train loss:0.0005428199961734349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005201587243854243\n",
      "train loss:0.00881422641878185\n",
      "train loss:0.002225028380059588\n",
      "train loss:0.0009197793411665628\n",
      "train loss:0.002549989267603021\n",
      "train loss:0.0006725312423967237\n",
      "train loss:0.0054208305829077175\n",
      "train loss:0.009830588276882902\n",
      "train loss:0.0013817075763367347\n",
      "train loss:0.0010891260352168294\n",
      "train loss:0.020313792976374513\n",
      "train loss:0.0010482587488074985\n",
      "train loss:0.0015438034676266371\n",
      "train loss:0.015014873516415546\n",
      "train loss:0.0037946964613079495\n",
      "train loss:0.0006392897556237953\n",
      "train loss:0.00920949405375407\n",
      "train loss:0.001485490523877493\n",
      "train loss:0.0019446814403198322\n",
      "train loss:0.001196508607676154\n",
      "train loss:0.020449646734179577\n",
      "train loss:0.0005959137114654835\n",
      "train loss:0.001534584028369245\n",
      "train loss:0.0018249944740673292\n",
      "train loss:0.0007785816274675187\n",
      "train loss:0.008070149535693039\n",
      "train loss:0.0038100462796533717\n",
      "train loss:0.004844125263733101\n",
      "train loss:0.0013176252900195574\n",
      "train loss:0.0020227510926486775\n",
      "train loss:0.0028648140662406647\n",
      "train loss:0.003409424182473646\n",
      "train loss:0.0007524992456160119\n",
      "train loss:0.0069342179837620106\n",
      "train loss:0.003077503632942443\n",
      "train loss:0.003754080881204424\n",
      "train loss:0.0031544519572903195\n",
      "train loss:0.009532936973354233\n",
      "train loss:0.0012950114849365516\n",
      "train loss:0.0053986648705354485\n",
      "train loss:0.0015067097437548138\n",
      "train loss:0.0016384700223390563\n",
      "train loss:0.002368386156154653\n",
      "train loss:0.0007130525974125823\n",
      "train loss:0.000977552756522087\n",
      "train loss:0.0023361623516523207\n",
      "train loss:0.0060550577641497304\n",
      "train loss:0.0011302064243837696\n",
      "train loss:0.0029914334068161723\n",
      "train loss:0.0006990119195829018\n",
      "train loss:0.005942795729206757\n",
      "train loss:0.0013115589363885346\n",
      "train loss:0.0027104165469470616\n",
      "train loss:0.003953111832373862\n",
      "train loss:0.0067991198313518955\n",
      "train loss:0.004153464188721946\n",
      "train loss:0.007115511933005818\n",
      "train loss:0.0009856698261033448\n",
      "train loss:0.004998658952582262\n",
      "train loss:0.0008687202589157946\n",
      "train loss:0.0023079280373124603\n",
      "train loss:0.0018521825842106063\n",
      "train loss:0.003375558093417949\n",
      "train loss:0.0003208098569358096\n",
      "train loss:0.003990561011897696\n",
      "train loss:0.0015201920092133081\n",
      "train loss:0.005778434410663154\n",
      "train loss:0.006851010810538907\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9871376811594202\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 멀티레이어넷(ch06)\n",
    "\n",
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.img_oxt import load_oxt\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_oxt()\n",
    "\n",
    "# 드롭아웃 사용 유무와 비울 설정 ========================\n",
    "use_dropout = True  # 드롭아웃을 쓰지 않을 때는 False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=3, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=120,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
    "\n",
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0966958448114241\n",
      "=== epoch:1, train acc:0.493, test acc:0.539 ===\n",
      "train loss:1.095397297495027\n",
      "train loss:1.09199623390004\n",
      "train loss:1.0870957632205873\n",
      "train loss:1.0824872973739166\n",
      "train loss:1.0750904571035071\n",
      "train loss:1.0582807511120123\n",
      "train loss:1.054332268574783\n",
      "train loss:1.0297485608186205\n",
      "train loss:1.0080241741712894\n",
      "train loss:1.0035017400498754\n",
      "train loss:0.9675935263228225\n",
      "train loss:0.9325234344855179\n",
      "train loss:0.8957971200729593\n",
      "train loss:0.898541775684192\n",
      "train loss:0.8696216480034246\n",
      "train loss:0.8550234480237203\n",
      "train loss:0.9271816046288497\n",
      "train loss:0.8651681309065378\n",
      "train loss:0.737629513462322\n",
      "train loss:0.7387806533225032\n",
      "train loss:0.756270561890266\n",
      "train loss:0.8922409568672867\n",
      "train loss:0.755210804038338\n",
      "train loss:0.7813907197892721\n",
      "train loss:0.690574369864433\n",
      "train loss:0.7119622450415939\n",
      "train loss:0.7961212841393266\n",
      "train loss:0.7959087495483814\n",
      "train loss:0.7078929365412951\n",
      "train loss:0.8242697740453362\n",
      "train loss:0.7400416695562536\n",
      "train loss:0.7698575647835059\n",
      "train loss:0.7510924665723958\n",
      "train loss:0.7855862458122448\n",
      "train loss:0.8068014186204877\n",
      "train loss:0.5776784480476671\n",
      "train loss:0.7338339309782796\n",
      "train loss:0.6724128987513593\n",
      "train loss:0.6592879799154729\n",
      "train loss:0.736004983812088\n",
      "train loss:0.6946710817000227\n",
      "train loss:0.7277570599277695\n",
      "train loss:0.6721171496437396\n",
      "train loss:0.7607152037972884\n",
      "train loss:0.6847896884643918\n",
      "train loss:0.626050480177476\n",
      "train loss:0.6011772406080428\n",
      "train loss:0.5967929354663885\n",
      "train loss:0.5877409363615604\n",
      "train loss:0.6632991465828082\n",
      "train loss:0.617126850390035\n",
      "train loss:0.6571192312002624\n",
      "train loss:0.6368754014201576\n",
      "train loss:0.5100893396673878\n",
      "train loss:0.49788115344784173\n",
      "train loss:0.5127176824733293\n",
      "train loss:0.5500763427113262\n",
      "train loss:0.5680483192420496\n",
      "train loss:0.5483423580555765\n",
      "train loss:0.5252146042533172\n",
      "train loss:0.45745209124629954\n",
      "train loss:0.45938643632750903\n",
      "train loss:0.5764454123297061\n",
      "train loss:0.5477884505235967\n",
      "train loss:0.4854541747011723\n",
      "train loss:0.43123938035619586\n",
      "train loss:0.5618695898701865\n",
      "train loss:0.5262153880519775\n",
      "train loss:0.4801354436948645\n",
      "train loss:0.4717138684307785\n",
      "train loss:0.43964514494205464\n",
      "train loss:0.4897839384642661\n",
      "train loss:0.3926104444198611\n",
      "train loss:0.4319363796804012\n",
      "train loss:0.5311884963277025\n",
      "train loss:0.45144432156390596\n",
      "train loss:0.4579253142607566\n",
      "train loss:0.3714568007541795\n",
      "train loss:0.3798156722885393\n",
      "train loss:0.41857219731859\n",
      "train loss:0.38125048313185533\n",
      "train loss:0.3782717400736111\n",
      "train loss:0.40096036965762105\n",
      "train loss:0.3789466724168057\n",
      "train loss:0.4431554186661862\n",
      "train loss:0.3939961223068362\n",
      "train loss:0.3055103084685523\n",
      "train loss:0.40934814620303295\n",
      "train loss:0.33151516502667805\n",
      "train loss:0.26944458383459097\n",
      "train loss:0.24594002372572765\n",
      "train loss:0.2475907431118429\n",
      "train loss:0.2658927268266547\n",
      "train loss:0.34613095360968155\n",
      "train loss:0.28079595371606453\n",
      "train loss:0.2936147617723792\n",
      "train loss:0.3527899954126195\n",
      "train loss:0.29799775554095853\n",
      "train loss:0.19940606417865953\n",
      "train loss:0.36501224553306355\n",
      "train loss:0.33145828231120533\n",
      "train loss:0.3094007178537963\n",
      "train loss:0.18907764664223603\n",
      "train loss:0.28744337289019495\n",
      "train loss:0.23388601198758993\n",
      "train loss:0.2557417516304418\n",
      "train loss:0.20164777087523073\n",
      "train loss:0.3117961641484739\n",
      "train loss:0.24619208668667478\n",
      "train loss:0.24721232824540457\n",
      "train loss:0.25917660420227256\n",
      "train loss:0.24422400455219542\n",
      "train loss:0.2228795662391633\n",
      "train loss:0.22953026159614254\n",
      "train loss:0.20799884080648648\n",
      "train loss:0.2711788169489063\n",
      "train loss:0.1825836095334705\n",
      "train loss:0.24087582006608638\n",
      "train loss:0.28050365493089874\n",
      "train loss:0.17430914216410856\n",
      "train loss:0.24389917029252756\n",
      "train loss:0.1729841812037975\n",
      "train loss:0.19867893480461238\n",
      "train loss:0.29089513189865107\n",
      "train loss:0.17759611037852654\n",
      "train loss:0.23275534284181318\n",
      "train loss:0.21439123475293131\n",
      "train loss:0.1504985802610512\n",
      "train loss:0.27278500383175186\n",
      "train loss:0.2674277415126634\n",
      "train loss:0.20978467211237598\n",
      "train loss:0.13395328126834827\n",
      "train loss:0.1791230883655743\n",
      "train loss:0.28029638101931587\n",
      "train loss:0.25809820331779026\n",
      "train loss:0.17491367653880902\n",
      "train loss:0.16135532458002297\n",
      "train loss:0.1965740432213966\n",
      "train loss:0.19225895723535225\n",
      "train loss:0.19211473549443808\n",
      "train loss:0.1629357250437627\n",
      "train loss:0.19488950270162633\n",
      "train loss:0.1593920103560653\n",
      "train loss:0.14073414904960446\n",
      "train loss:0.26977212349730817\n",
      "train loss:0.26468083090907635\n",
      "train loss:0.17435183785911992\n",
      "train loss:0.14156849661262014\n",
      "train loss:0.13436159591604813\n",
      "train loss:0.2658494182950396\n",
      "train loss:0.14422463947209477\n",
      "train loss:0.19022617202815292\n",
      "train loss:0.16420285591127068\n",
      "train loss:0.16747392610050138\n",
      "train loss:0.18956055428463373\n",
      "train loss:0.1561838855884881\n",
      "train loss:0.1780298533127165\n",
      "train loss:0.14616736668285188\n",
      "train loss:0.12122231229873842\n",
      "train loss:0.29440824990866493\n",
      "train loss:0.1779633096981143\n",
      "train loss:0.1412500153071218\n",
      "train loss:0.21388487338712234\n",
      "train loss:0.22193518231666282\n",
      "train loss:0.13928927531944266\n",
      "train loss:0.2086927334023267\n",
      "train loss:0.11200175372022404\n",
      "train loss:0.15447529191127948\n",
      "train loss:0.24108511947997266\n",
      "train loss:0.2544691443766732\n",
      "train loss:0.19358671638111305\n",
      "train loss:0.20620322443639186\n",
      "train loss:0.12817922559454156\n",
      "train loss:0.14262206112220327\n",
      "train loss:0.11370931896246288\n",
      "train loss:0.14751695341548535\n",
      "train loss:0.13264896896194434\n",
      "train loss:0.19276496040977478\n",
      "train loss:0.134305004962497\n",
      "train loss:0.12753584971630721\n",
      "train loss:0.14397024586683277\n",
      "train loss:0.09758541037936853\n",
      "train loss:0.1786700126765295\n",
      "train loss:0.1424689905273646\n",
      "train loss:0.1997365892940847\n",
      "train loss:0.16020196167713718\n",
      "train loss:0.19309946627977834\n",
      "train loss:0.11383069119305517\n",
      "train loss:0.14825437145760478\n",
      "train loss:0.15458961568856774\n",
      "train loss:0.18124777980038367\n",
      "train loss:0.10431576782173832\n",
      "train loss:0.19523354817090002\n",
      "train loss:0.14591666586945898\n",
      "train loss:0.1304592467515234\n",
      "train loss:0.20172460521521754\n",
      "train loss:0.1391553174289996\n",
      "train loss:0.14201141084139846\n",
      "train loss:0.15087593935430318\n",
      "train loss:0.1863992208567314\n",
      "train loss:0.18026720071025046\n",
      "train loss:0.08524424153068728\n",
      "train loss:0.20953637756930235\n",
      "train loss:0.12075362548593463\n",
      "train loss:0.19291589502195633\n",
      "train loss:0.12551980921568365\n",
      "train loss:0.13748324996438535\n",
      "train loss:0.15684958690071937\n",
      "train loss:0.13533365538953443\n",
      "train loss:0.1536013646268368\n",
      "train loss:0.15505802501736524\n",
      "train loss:0.12015088894271192\n",
      "train loss:0.1323445872496308\n",
      "train loss:0.1327663236887639\n",
      "train loss:0.23593956712201297\n",
      "train loss:0.13451764741676225\n",
      "train loss:0.18901926222978946\n",
      "train loss:0.14434673207980164\n",
      "train loss:0.10763445347040604\n",
      "train loss:0.10936822244638843\n",
      "train loss:0.13518079860045987\n",
      "train loss:0.09027954857977552\n",
      "train loss:0.21367962405634747\n",
      "train loss:0.12283366560647042\n",
      "train loss:0.1321367900044468\n",
      "train loss:0.12573976601384296\n",
      "train loss:0.07780222833746678\n",
      "train loss:0.0779390266056633\n",
      "train loss:0.15728928817826587\n",
      "train loss:0.08450832286338335\n",
      "train loss:0.1317910833309224\n",
      "train loss:0.12482653322281757\n",
      "train loss:0.1866042514032836\n",
      "train loss:0.14527513088414887\n",
      "train loss:0.14793187325300067\n",
      "train loss:0.16300837518577585\n",
      "train loss:0.17872203205270257\n",
      "train loss:0.12804475178423386\n",
      "train loss:0.13003473176410119\n",
      "train loss:0.13826192129718734\n",
      "train loss:0.08634342775322369\n",
      "train loss:0.14320769367729533\n",
      "train loss:0.14555499712894548\n",
      "train loss:0.10740813754196149\n",
      "train loss:0.15235759727368378\n",
      "train loss:0.14119999702378908\n",
      "train loss:0.1607652032274072\n",
      "train loss:0.11796684516515216\n",
      "train loss:0.16210449231532378\n",
      "train loss:0.10759912150239816\n",
      "train loss:0.11683303237228068\n",
      "train loss:0.12930095141859718\n",
      "train loss:0.1394460716228426\n",
      "train loss:0.07108312359667499\n",
      "train loss:0.11590921646572712\n",
      "train loss:0.09484086792264224\n",
      "train loss:0.0735894912119564\n",
      "train loss:0.06868828354741015\n",
      "train loss:0.08524829614918783\n",
      "train loss:0.09786671400375156\n",
      "train loss:0.15146382221672383\n",
      "train loss:0.09665930879336973\n",
      "train loss:0.1612386207434905\n",
      "train loss:0.13705994505604208\n",
      "train loss:0.11375195424453953\n",
      "train loss:0.0999977451658831\n",
      "train loss:0.11115455369721465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07706169617661177\n",
      "train loss:0.1034373618483771\n",
      "train loss:0.10332318840183058\n",
      "train loss:0.1657284925863749\n",
      "train loss:0.09118056053288552\n",
      "train loss:0.16218298714187274\n",
      "train loss:0.14527415293730306\n",
      "train loss:0.12235531162945623\n",
      "train loss:0.14044909274580805\n",
      "train loss:0.10797475105941663\n",
      "train loss:0.0774135677399715\n",
      "train loss:0.16099358755264498\n",
      "train loss:0.11162738783100395\n",
      "train loss:0.15700785296320108\n",
      "train loss:0.08558806754887359\n",
      "train loss:0.11422159732913319\n",
      "train loss:0.11302697631097856\n",
      "train loss:0.16534847619388077\n",
      "train loss:0.12994074411918913\n",
      "train loss:0.09042268868644462\n",
      "train loss:0.0771850245450407\n",
      "train loss:0.04989840669948166\n",
      "train loss:0.16256099436011423\n",
      "train loss:0.08094284353054657\n",
      "train loss:0.0812105341757139\n",
      "train loss:0.21125277171004192\n",
      "train loss:0.10885412036301627\n",
      "train loss:0.14629313120317639\n",
      "train loss:0.09000704947625546\n",
      "train loss:0.11040906531458373\n",
      "train loss:0.08183650367874969\n",
      "train loss:0.07179836737179165\n",
      "train loss:0.07348705401284589\n",
      "train loss:0.166811943832148\n",
      "train loss:0.07958692222353975\n",
      "train loss:0.0838540649337847\n",
      "train loss:0.06595783602037267\n",
      "train loss:0.1251753093341241\n",
      "train loss:0.03845701297326154\n",
      "train loss:0.12934815560609092\n",
      "train loss:0.13622054771880546\n",
      "train loss:0.09575315938797001\n",
      "train loss:0.08996396778995716\n",
      "train loss:0.06081325225023144\n",
      "train loss:0.10343904193459404\n",
      "train loss:0.08394411662919866\n",
      "train loss:0.058418977176563636\n",
      "train loss:0.07552145165179949\n",
      "train loss:0.13533226041916316\n",
      "train loss:0.05621302696631781\n",
      "train loss:0.10353278883979362\n",
      "train loss:0.05859403548536159\n",
      "train loss:0.10331198273952502\n",
      "train loss:0.05561821204455851\n",
      "train loss:0.1161192612598568\n",
      "train loss:0.09058185789771289\n",
      "train loss:0.0387499902203257\n",
      "train loss:0.08329132311409704\n",
      "train loss:0.09094347982734671\n",
      "train loss:0.04803808232687253\n",
      "train loss:0.07951873727542848\n",
      "train loss:0.11201533899444259\n",
      "train loss:0.08485221801260506\n",
      "train loss:0.178866624394978\n",
      "train loss:0.08604885781038624\n",
      "train loss:0.09265390172795838\n",
      "train loss:0.10296955258835888\n",
      "train loss:0.10207198010813233\n",
      "train loss:0.0918834915832372\n",
      "train loss:0.0674287234059141\n",
      "train loss:0.10782347860466064\n",
      "train loss:0.11386448972480569\n",
      "train loss:0.13809720376074316\n",
      "train loss:0.08720978503089861\n",
      "train loss:0.07448732482035113\n",
      "train loss:0.05867694616902789\n",
      "train loss:0.07056989671581432\n",
      "train loss:0.11773303807415234\n",
      "train loss:0.09583305997644521\n",
      "train loss:0.044657648508798845\n",
      "train loss:0.07009279758132324\n",
      "train loss:0.05796661039750681\n",
      "train loss:0.08613553968011309\n",
      "train loss:0.13923329526283548\n",
      "train loss:0.05442966628554929\n",
      "train loss:0.11619680067230083\n",
      "train loss:0.08309449413828589\n",
      "train loss:0.04786022401101529\n",
      "train loss:0.03957775708020982\n",
      "train loss:0.08419612223194213\n",
      "train loss:0.05660313001731545\n",
      "train loss:0.09680408611891435\n",
      "train loss:0.05867222293507156\n",
      "train loss:0.08757197855103982\n",
      "train loss:0.09009130969657939\n",
      "train loss:0.08998852320060502\n",
      "train loss:0.09705514097157966\n",
      "train loss:0.042963586131204004\n",
      "train loss:0.036155475218525815\n",
      "train loss:0.05788225558268452\n",
      "train loss:0.08480548956723814\n",
      "=== epoch:2, train acc:0.958, test acc:0.964 ===\n",
      "train loss:0.07479208587161355\n",
      "train loss:0.11334972996102027\n",
      "train loss:0.10754892155513875\n",
      "train loss:0.054950117156771346\n",
      "train loss:0.04874005670038852\n",
      "train loss:0.10415976795050087\n",
      "train loss:0.06917071983508556\n",
      "train loss:0.0824385033400859\n",
      "train loss:0.06836174053677195\n",
      "train loss:0.11884113491913739\n",
      "train loss:0.037793788067129415\n",
      "train loss:0.05389787878444406\n",
      "train loss:0.0879131505277568\n",
      "train loss:0.10663799327754164\n",
      "train loss:0.0678895337979478\n",
      "train loss:0.07071262013151237\n",
      "train loss:0.08301026401070805\n",
      "train loss:0.13603100229248283\n",
      "train loss:0.05322335857948908\n",
      "train loss:0.05283277542452455\n",
      "train loss:0.05861186601282811\n",
      "train loss:0.029070090243539338\n",
      "train loss:0.06419669744054834\n",
      "train loss:0.11424117388546208\n",
      "train loss:0.05047647474737722\n",
      "train loss:0.05252297897994385\n",
      "train loss:0.045382751074634166\n",
      "train loss:0.05134363825392992\n",
      "train loss:0.12325230668756713\n",
      "train loss:0.04143746501538075\n",
      "train loss:0.09358088532311507\n",
      "train loss:0.15158691443703082\n",
      "train loss:0.11582188767821083\n",
      "train loss:0.10711967656260322\n",
      "train loss:0.08189241789851762\n",
      "train loss:0.07100142800338623\n",
      "train loss:0.0738267406367494\n",
      "train loss:0.07447803293213531\n",
      "train loss:0.09835037491639274\n",
      "train loss:0.06985724726132596\n",
      "train loss:0.05380811312482246\n",
      "train loss:0.08152038363420949\n",
      "train loss:0.10822908889164715\n",
      "train loss:0.04920428846775528\n",
      "train loss:0.10696224274046268\n",
      "train loss:0.08155574621435265\n",
      "train loss:0.06341979633279579\n",
      "train loss:0.07280454059799375\n",
      "train loss:0.07311430581025605\n",
      "train loss:0.05427660440094772\n",
      "train loss:0.046188702395207386\n",
      "train loss:0.056477302425447844\n",
      "train loss:0.03664489805184154\n",
      "train loss:0.05117422789259459\n",
      "train loss:0.07035708881996822\n",
      "train loss:0.08313992602333858\n",
      "train loss:0.03994314961887759\n",
      "train loss:0.09337359664806807\n",
      "train loss:0.16199507505375701\n",
      "train loss:0.07394283931724073\n",
      "train loss:0.08384341047122433\n",
      "train loss:0.024278360830751262\n",
      "train loss:0.06574725339859969\n",
      "train loss:0.02855068431995994\n",
      "train loss:0.04332477697615846\n",
      "train loss:0.17189779798356333\n",
      "train loss:0.06756571234079099\n",
      "train loss:0.15868481154960262\n",
      "train loss:0.048133454351777766\n",
      "train loss:0.04974235608797746\n",
      "train loss:0.04289687486576681\n",
      "train loss:0.10358991203395969\n",
      "train loss:0.11480589997513822\n",
      "train loss:0.0469418795820517\n",
      "train loss:0.06857581674717587\n",
      "train loss:0.04663699118569346\n",
      "train loss:0.034936478673398226\n",
      "train loss:0.06497886950517912\n",
      "train loss:0.07753991992420156\n",
      "train loss:0.031398950000686585\n",
      "train loss:0.08566460901330458\n",
      "train loss:0.09533975973354708\n",
      "train loss:0.10555490389357841\n",
      "train loss:0.07136423301630396\n",
      "train loss:0.10944827426425958\n",
      "train loss:0.13134521989986997\n",
      "train loss:0.039748488976056845\n",
      "train loss:0.0895045164616813\n",
      "train loss:0.06472334220000121\n",
      "train loss:0.06377286922568222\n",
      "train loss:0.056236113514810955\n",
      "train loss:0.12193636851581567\n",
      "train loss:0.04048525827738837\n",
      "train loss:0.09749173336573236\n",
      "train loss:0.11347191811661055\n",
      "train loss:0.06398788525187724\n",
      "train loss:0.07204076880583449\n",
      "train loss:0.12311509201077823\n",
      "train loss:0.031374035773149886\n",
      "train loss:0.09136309923352938\n",
      "train loss:0.04361595621775823\n",
      "train loss:0.06777976166769273\n",
      "train loss:0.06119437310785504\n",
      "train loss:0.10320844198743659\n",
      "train loss:0.06132894896587616\n",
      "train loss:0.032292935105810196\n",
      "train loss:0.03939277031242598\n",
      "train loss:0.07797946087822118\n",
      "train loss:0.08219949894950744\n",
      "train loss:0.045581620291115586\n",
      "train loss:0.09754381662612496\n",
      "train loss:0.12047674944298378\n",
      "train loss:0.09599862045785894\n",
      "train loss:0.10180575392295893\n",
      "train loss:0.05065450955390014\n",
      "train loss:0.056313965850341444\n",
      "train loss:0.0847070115538103\n",
      "train loss:0.054573873623520425\n",
      "train loss:0.04245661842501776\n",
      "train loss:0.0800478622165315\n",
      "train loss:0.06770038988611599\n",
      "train loss:0.07129797971144222\n",
      "train loss:0.07493657961514069\n",
      "train loss:0.039208693363640724\n",
      "train loss:0.061354018925054\n",
      "train loss:0.04029884546036475\n",
      "train loss:0.05811934594677989\n",
      "train loss:0.08371802287215067\n",
      "train loss:0.08083970629864216\n",
      "train loss:0.08882025587042387\n",
      "train loss:0.01811036897938713\n",
      "train loss:0.023862605829931792\n",
      "train loss:0.09892936831124276\n",
      "train loss:0.1285184147365051\n",
      "train loss:0.0935149735097102\n",
      "train loss:0.07634751770997845\n",
      "train loss:0.10037046342107422\n",
      "train loss:0.08007628544127614\n",
      "train loss:0.04796062617883742\n",
      "train loss:0.0501257063383705\n",
      "train loss:0.06731363932866079\n",
      "train loss:0.04687939853282348\n",
      "train loss:0.0711027215501572\n",
      "train loss:0.07086526242307248\n",
      "train loss:0.0696424133135399\n",
      "train loss:0.04714066985135646\n",
      "train loss:0.062496382534789986\n",
      "train loss:0.07141664339156509\n",
      "train loss:0.03763266435453047\n",
      "train loss:0.09558698986139826\n",
      "train loss:0.02831287174236104\n",
      "train loss:0.12034695093922032\n",
      "train loss:0.036228973872664307\n",
      "train loss:0.09654517884078799\n",
      "train loss:0.044768764966974885\n",
      "train loss:0.06849272482176673\n",
      "train loss:0.02867677651126903\n",
      "train loss:0.06151283539221931\n",
      "train loss:0.07706333840937286\n",
      "train loss:0.034943789188948776\n",
      "train loss:0.07139472297784447\n",
      "train loss:0.05739605391202691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12052706733723767\n",
      "train loss:0.07601734655988898\n",
      "train loss:0.11554524937290325\n",
      "train loss:0.09493607669834545\n",
      "train loss:0.08009346127202124\n",
      "train loss:0.09645281872074116\n",
      "train loss:0.1222265627637663\n",
      "train loss:0.056875295967369704\n",
      "train loss:0.05984878567325466\n",
      "train loss:0.06013791869354711\n",
      "train loss:0.06442241300416597\n",
      "train loss:0.06172845641338035\n",
      "train loss:0.047592378741595984\n",
      "train loss:0.023703757879392474\n",
      "train loss:0.06341994423919124\n",
      "train loss:0.07284907601727131\n",
      "train loss:0.015339923518078264\n",
      "train loss:0.05900828800887322\n",
      "train loss:0.03021813880777978\n",
      "train loss:0.025392013056304275\n",
      "train loss:0.07239659030365685\n",
      "train loss:0.08597444147568215\n",
      "train loss:0.05438136856184542\n",
      "train loss:0.0735046670837367\n",
      "train loss:0.07810608324342369\n",
      "train loss:0.04558708190822973\n",
      "train loss:0.07538762789876724\n",
      "train loss:0.03193060892261501\n",
      "train loss:0.0933046441236714\n",
      "train loss:0.06902940929015343\n",
      "train loss:0.12707628006294935\n",
      "train loss:0.06931241616694361\n",
      "train loss:0.10347648463131949\n",
      "train loss:0.06531937687204296\n",
      "train loss:0.06621905140656802\n",
      "train loss:0.04207209695014022\n",
      "train loss:0.06946587820848982\n",
      "train loss:0.08218505266041869\n",
      "train loss:0.06593952670745705\n",
      "train loss:0.06807570621325135\n",
      "train loss:0.07754067423169095\n",
      "train loss:0.04280435845425775\n",
      "train loss:0.06691840226153449\n",
      "train loss:0.052759805530516304\n",
      "train loss:0.061321620432820634\n",
      "train loss:0.07354539565857125\n",
      "train loss:0.03593686133332028\n",
      "train loss:0.020985219143580144\n",
      "train loss:0.027120387916267526\n",
      "train loss:0.03752589662920943\n",
      "train loss:0.055614677884563396\n",
      "train loss:0.050865400180716266\n",
      "train loss:0.03040085084291288\n",
      "train loss:0.06268852849007832\n",
      "train loss:0.05623304986463489\n",
      "train loss:0.04827342998419385\n",
      "train loss:0.07355476887298651\n",
      "train loss:0.10305133405343694\n",
      "train loss:0.05565965755663869\n",
      "train loss:0.02777824182932152\n",
      "train loss:0.06577604794370256\n",
      "train loss:0.04540593863411866\n",
      "train loss:0.0486771698142073\n",
      "train loss:0.04694776848147943\n",
      "train loss:0.06627130970734765\n",
      "train loss:0.030139141326045716\n",
      "train loss:0.024693419780367033\n",
      "train loss:0.06382726993850578\n",
      "train loss:0.07524408428772442\n",
      "train loss:0.023134220101638184\n",
      "train loss:0.05909141925517864\n",
      "train loss:0.05539954768193236\n",
      "train loss:0.017791240837645488\n",
      "train loss:0.04033464869288213\n",
      "train loss:0.04639620175007571\n",
      "train loss:0.04192109908205784\n",
      "train loss:0.03150758109068045\n",
      "train loss:0.042496992342277745\n",
      "train loss:0.05395375657046961\n",
      "train loss:0.018130966139670048\n",
      "train loss:0.06244386327277631\n",
      "train loss:0.051410489028246874\n",
      "train loss:0.03773137518209208\n",
      "train loss:0.05436241512216171\n",
      "train loss:0.04821339562715507\n",
      "train loss:0.0171516939898087\n",
      "train loss:0.024241964260541114\n",
      "train loss:0.0693817179218261\n",
      "train loss:0.05284430032756996\n",
      "train loss:0.05865251383458482\n",
      "train loss:0.04702082581528248\n",
      "train loss:0.04091328778962553\n",
      "train loss:0.018672856896456095\n",
      "train loss:0.016570387772151425\n",
      "train loss:0.12385580790977543\n",
      "train loss:0.06491035014735583\n",
      "train loss:0.03689691426539816\n",
      "train loss:0.04146489749524139\n",
      "train loss:0.035210908218892625\n",
      "train loss:0.07671492775423731\n",
      "train loss:0.013545480242857262\n",
      "train loss:0.051584301298442416\n",
      "train loss:0.02800103147825261\n",
      "train loss:0.06717676191287539\n",
      "train loss:0.05291488186591352\n",
      "train loss:0.05347603736035705\n",
      "train loss:0.026180758502110567\n",
      "train loss:0.02475167499517778\n",
      "train loss:0.056929855097852824\n",
      "train loss:0.06413976747998193\n",
      "train loss:0.04411307482477305\n",
      "train loss:0.036594258338268036\n",
      "train loss:0.05808491123287561\n",
      "train loss:0.03420298145384536\n",
      "train loss:0.06395250081690598\n",
      "train loss:0.038814543336112346\n",
      "train loss:0.07326553793102644\n",
      "train loss:0.04488568992011763\n",
      "train loss:0.049567326159806184\n",
      "train loss:0.035676601140088325\n",
      "train loss:0.06482450033879751\n",
      "train loss:0.02713237888645488\n",
      "train loss:0.025528288699239097\n",
      "train loss:0.045156999083095443\n",
      "train loss:0.08202372156634116\n",
      "train loss:0.05740340736407199\n",
      "train loss:0.05640057815090376\n",
      "train loss:0.025807767184211614\n",
      "train loss:0.041891983692433285\n",
      "train loss:0.030030821395926367\n",
      "train loss:0.080723801811215\n",
      "train loss:0.06511751746010251\n",
      "train loss:0.02443227826682916\n",
      "train loss:0.017321754295948788\n",
      "train loss:0.01942863401866752\n",
      "train loss:0.024931521617470618\n",
      "train loss:0.06412183976213158\n",
      "train loss:0.050543069915085594\n",
      "train loss:0.028703484836898753\n",
      "train loss:0.02055908164863785\n",
      "train loss:0.04075216053060845\n",
      "train loss:0.03494644440336206\n",
      "train loss:0.038418531419244985\n",
      "train loss:0.02536888882481707\n",
      "train loss:0.07052164105116014\n",
      "train loss:0.036569952632295566\n",
      "train loss:0.028472116269765393\n",
      "train loss:0.09422956192935282\n",
      "train loss:0.05359716725445509\n",
      "train loss:0.036798419432868136\n",
      "train loss:0.056830076733555876\n",
      "train loss:0.05205779349694665\n",
      "train loss:0.12937019130379826\n",
      "train loss:0.028507273768102373\n",
      "train loss:0.05972401698116243\n",
      "train loss:0.07375294035524475\n",
      "train loss:0.022493412979547583\n",
      "train loss:0.03955892338942492\n",
      "train loss:0.02926440503473703\n",
      "train loss:0.022566130894163046\n",
      "train loss:0.06055036012357706\n",
      "train loss:0.042535590194547994\n",
      "train loss:0.06689836608090251\n",
      "train loss:0.016301769036648286\n",
      "train loss:0.03892653067324533\n",
      "train loss:0.03688459591080126\n",
      "train loss:0.02990032378002212\n",
      "train loss:0.06604948752340133\n",
      "train loss:0.08156425144117643\n",
      "train loss:0.03125051472228283\n",
      "train loss:0.028508457188405667\n",
      "train loss:0.04212239244546625\n",
      "train loss:0.0502428012338518\n",
      "train loss:0.031394701573725335\n",
      "train loss:0.061934877114499895\n",
      "train loss:0.0654275690270247\n",
      "train loss:0.04244095785565475\n",
      "train loss:0.009485650789826902\n",
      "train loss:0.05673063531220945\n",
      "train loss:0.02515666102201592\n",
      "train loss:0.018146525327506453\n",
      "train loss:0.03464446344598307\n",
      "train loss:0.06146935157255116\n",
      "train loss:0.03327292370562525\n",
      "train loss:0.05759486208084139\n",
      "train loss:0.039229482859466966\n",
      "train loss:0.0637681366800107\n",
      "train loss:0.04419879527675509\n",
      "train loss:0.07892680652962583\n",
      "train loss:0.010116755148778495\n",
      "train loss:0.030359891154009232\n",
      "train loss:0.05212130072650809\n",
      "train loss:0.06795567520950306\n",
      "train loss:0.056421829712932345\n",
      "train loss:0.04287007379211225\n",
      "train loss:0.02216998080418771\n",
      "train loss:0.04170867846180157\n",
      "train loss:0.05430682304746262\n",
      "train loss:0.013596755946861354\n",
      "train loss:0.0208490673215792\n",
      "train loss:0.03178889515034408\n",
      "train loss:0.0798303220361076\n",
      "train loss:0.03864079672827869\n",
      "train loss:0.027123712271340087\n",
      "train loss:0.04885348153823239\n",
      "train loss:0.027295507187656103\n",
      "=== epoch:3, train acc:0.98, test acc:0.982 ===\n",
      "train loss:0.03436142844223536\n",
      "train loss:0.00922358622439582\n",
      "train loss:0.026948264630973627\n",
      "train loss:0.019207502030509492\n",
      "train loss:0.01323142714283538\n",
      "train loss:0.026541126900920826\n",
      "train loss:0.03765021648695687\n",
      "train loss:0.04285690695813703\n",
      "train loss:0.00755495921983802\n",
      "train loss:0.07148574203133139\n",
      "train loss:0.04076904440677179\n",
      "train loss:0.0206921312829804\n",
      "train loss:0.02076464176443075\n",
      "train loss:0.03514687237302864\n",
      "train loss:0.026685397950403908\n",
      "train loss:0.0943811323892377\n",
      "train loss:0.01876860496923109\n",
      "train loss:0.01668446575133762\n",
      "train loss:0.05402762623682035\n",
      "train loss:0.03758118226070092\n",
      "train loss:0.040570357320256406\n",
      "train loss:0.060098284288438476\n",
      "train loss:0.05984925064268379\n",
      "train loss:0.028850707487483696\n",
      "train loss:0.01809152267327267\n",
      "train loss:0.03426844392943778\n",
      "train loss:0.057342560830261013\n",
      "train loss:0.025989784325485783\n",
      "train loss:0.0365930026223233\n",
      "train loss:0.029349531952666787\n",
      "train loss:0.022075996044511225\n",
      "train loss:0.07131302008859589\n",
      "train loss:0.017148730781907564\n",
      "train loss:0.03038367016594375\n",
      "train loss:0.03313686478844352\n",
      "train loss:0.046556231463599884\n",
      "train loss:0.05823188561010168\n",
      "train loss:0.029299533324141976\n",
      "train loss:0.029849984310249256\n",
      "train loss:0.023635386992466995\n",
      "train loss:0.0177267251137028\n",
      "train loss:0.026647216546448645\n",
      "train loss:0.060719271591771\n",
      "train loss:0.036402822603760446\n",
      "train loss:0.03663269986300574\n",
      "train loss:0.028580815825351946\n",
      "train loss:0.02415358465712007\n",
      "train loss:0.04759719114136832\n",
      "train loss:0.03331026180466943\n",
      "train loss:0.02513098772040092\n",
      "train loss:0.033658974032714124\n",
      "train loss:0.04978937327544294\n",
      "train loss:0.03766052672988519\n",
      "train loss:0.0485028617879149\n",
      "train loss:0.011395852450321462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.017085365791974498\n",
      "train loss:0.04177757368613041\n",
      "train loss:0.06756648081326158\n",
      "train loss:0.04590281403794247\n",
      "train loss:0.02237993360578829\n",
      "train loss:0.03147915759741127\n",
      "train loss:0.021158320342705976\n",
      "train loss:0.018452835249774924\n",
      "train loss:0.024023559520874076\n",
      "train loss:0.04920027387710595\n",
      "train loss:0.053413914366233085\n",
      "train loss:0.03061852110866965\n",
      "train loss:0.018603548299167657\n",
      "train loss:0.0379767105389648\n",
      "train loss:0.055103030065312496\n",
      "train loss:0.035167184618133916\n",
      "train loss:0.027353803722488048\n",
      "train loss:0.014789109568188817\n",
      "train loss:0.03608685103734085\n",
      "train loss:0.043021375200621007\n",
      "train loss:0.025491068622238384\n",
      "train loss:0.03855298017150171\n",
      "train loss:0.02414791003762779\n",
      "train loss:0.037703166678688955\n",
      "train loss:0.07183861841583668\n",
      "train loss:0.04184861355881342\n",
      "train loss:0.018507679610785786\n",
      "train loss:0.03508463448763819\n",
      "train loss:0.0286807315296732\n",
      "train loss:0.017084507074987473\n",
      "train loss:0.04791095159036026\n",
      "train loss:0.11087336719086407\n",
      "train loss:0.0239330538224615\n",
      "train loss:0.029528862633936337\n",
      "train loss:0.04757878410482196\n",
      "train loss:0.04331865040799334\n",
      "train loss:0.038643268738306\n",
      "train loss:0.026040138254472097\n",
      "train loss:0.023927226430924552\n",
      "train loss:0.023676564459408266\n",
      "train loss:0.027756059596617155\n",
      "train loss:0.018633956762537054\n",
      "train loss:0.028154494552538125\n",
      "train loss:0.04228560056856015\n",
      "train loss:0.06361313679138635\n",
      "train loss:0.04487982749510162\n",
      "train loss:0.016030874063362104\n",
      "train loss:0.07291761793634266\n",
      "train loss:0.032357042936554496\n",
      "train loss:0.01764381593871023\n",
      "train loss:0.07800738012665716\n",
      "train loss:0.029316396938212648\n",
      "train loss:0.05774631404332406\n",
      "train loss:0.022160031954348573\n",
      "train loss:0.04565326493875088\n",
      "train loss:0.02479064622581657\n",
      "train loss:0.017765093048957178\n",
      "train loss:0.027834773220185\n",
      "train loss:0.0418313599073965\n",
      "train loss:0.02357469573139065\n",
      "train loss:0.06969829284510999\n",
      "train loss:0.04248238040578811\n",
      "train loss:0.020625808638295894\n",
      "train loss:0.013714804702416308\n",
      "train loss:0.025560495950325002\n",
      "train loss:0.036635577838222015\n",
      "train loss:0.05258496501190253\n",
      "train loss:0.045158679968095444\n",
      "train loss:0.0483496043128003\n",
      "train loss:0.0325124668834239\n",
      "train loss:0.07797056782513419\n",
      "train loss:0.032138935037546966\n",
      "train loss:0.013217909870885702\n",
      "train loss:0.040889404973295816\n",
      "train loss:0.04658838205410231\n",
      "train loss:0.03328738469860456\n",
      "train loss:0.03497365752480679\n",
      "train loss:0.022504877790458407\n",
      "train loss:0.05389877620979746\n",
      "train loss:0.011510256637001814\n",
      "train loss:0.02829683156161509\n",
      "train loss:0.08470052093673681\n",
      "train loss:0.06798198543628627\n",
      "train loss:0.051799386373553656\n",
      "train loss:0.05656401345066023\n",
      "train loss:0.08324845991076503\n",
      "train loss:0.028879045908482493\n",
      "train loss:0.027447571568171736\n",
      "train loss:0.05069776559635825\n",
      "train loss:0.031245905232640325\n",
      "train loss:0.09293873328091223\n",
      "train loss:0.03679678283323198\n",
      "train loss:0.03379483472260871\n",
      "train loss:0.04904994775101746\n",
      "train loss:0.045767216116513666\n",
      "train loss:0.0312517321891388\n",
      "train loss:0.043302217010999004\n",
      "train loss:0.013774562601327044\n",
      "train loss:0.020631643977286236\n",
      "train loss:0.08929860648636187\n",
      "train loss:0.04403586021302857\n",
      "train loss:0.020853543288558218\n",
      "train loss:0.012062587590608402\n",
      "train loss:0.040693740741834815\n",
      "train loss:0.05339896102645764\n",
      "train loss:0.03799136205823398\n",
      "train loss:0.05137563837697867\n",
      "train loss:0.050101385393442256\n",
      "train loss:0.052223476206969294\n",
      "train loss:0.025140273581304416\n",
      "train loss:0.0818099851073253\n",
      "train loss:0.009665543928953862\n",
      "train loss:0.043827969709619316\n",
      "train loss:0.05392660654302115\n",
      "train loss:0.033074348549681706\n",
      "train loss:0.04023655362899692\n",
      "train loss:0.018710501390998627\n",
      "train loss:0.026634093866687143\n",
      "train loss:0.019350043744038835\n",
      "train loss:0.03707219538720918\n",
      "train loss:0.02806405898560078\n",
      "train loss:0.0045147420105251185\n",
      "train loss:0.04137025474598517\n",
      "train loss:0.036032233961709535\n",
      "train loss:0.01807649812515642\n",
      "train loss:0.021420103370904185\n",
      "train loss:0.03429265777512671\n",
      "train loss:0.03113068601724631\n",
      "train loss:0.03795523385732839\n",
      "train loss:0.03313993976590208\n",
      "train loss:0.049628727787308424\n",
      "train loss:0.014939377693165867\n",
      "train loss:0.02294672737697101\n",
      "train loss:0.012588692833996972\n",
      "train loss:0.012178480045791118\n",
      "train loss:0.06231223008160214\n",
      "train loss:0.01549927307318911\n",
      "train loss:0.010144116011607841\n",
      "train loss:0.049495041846513176\n",
      "train loss:0.029186581217519773\n",
      "train loss:0.0625046769460517\n",
      "train loss:0.05153896294948151\n",
      "train loss:0.023264888007124954\n",
      "train loss:0.02186796232667917\n",
      "train loss:0.015338611004687667\n",
      "train loss:0.038718121198435956\n",
      "train loss:0.021520085991306764\n",
      "train loss:0.035614150749417\n",
      "train loss:0.020330339282105366\n",
      "train loss:0.023313941024457458\n",
      "train loss:0.023103136086021332\n",
      "train loss:0.02947590766874726\n",
      "train loss:0.030426839525707034\n",
      "train loss:0.028288282066820488\n",
      "train loss:0.009886820731476563\n",
      "train loss:0.018017372187540313\n",
      "train loss:0.033307289726010096\n",
      "train loss:0.03979514009470675\n",
      "train loss:0.021237625778804347\n",
      "train loss:0.017974479976588686\n",
      "train loss:0.01867357349960744\n",
      "train loss:0.033989274191133\n",
      "train loss:0.023812969690410336\n",
      "train loss:0.012275081523720395\n",
      "train loss:0.05270013508641124\n",
      "train loss:0.018814282694789877\n",
      "train loss:0.032000247359761674\n",
      "train loss:0.029412858696467963\n",
      "train loss:0.013197192246707777\n",
      "train loss:0.008564641631317083\n",
      "train loss:0.023284199495322684\n",
      "train loss:0.03326396416504799\n",
      "train loss:0.019188991913042398\n",
      "train loss:0.021999700659002794\n",
      "train loss:0.04522661242655593\n",
      "train loss:0.023610550601042415\n",
      "train loss:0.032810663570693864\n",
      "train loss:0.01692749769752908\n",
      "train loss:0.01674837415466225\n",
      "train loss:0.03287279289853341\n",
      "train loss:0.03860582975876294\n",
      "train loss:0.011390347518004617\n",
      "train loss:0.017031290170592153\n",
      "train loss:0.03531636344059148\n",
      "train loss:0.020869123079977497\n",
      "train loss:0.013322728861287037\n",
      "train loss:0.03318846223305916\n",
      "train loss:0.022797198900115046\n",
      "train loss:0.016935074750902522\n",
      "train loss:0.010556144330764383\n",
      "train loss:0.014108694529887231\n",
      "train loss:0.032585062405875574\n",
      "train loss:0.07521674681733434\n",
      "train loss:0.006994306303463756\n",
      "train loss:0.01881928649376293\n",
      "train loss:0.006542172650285784\n",
      "train loss:0.01712711269082929\n",
      "train loss:0.02369493726579853\n",
      "train loss:0.0271054683955794\n",
      "train loss:0.026482344906958298\n",
      "train loss:0.018832826733380697\n",
      "train loss:0.08517292512736478\n",
      "train loss:0.05013260723935664\n",
      "train loss:0.00859444099417584\n",
      "train loss:0.018019976241027743\n",
      "train loss:0.015797559123681446\n",
      "train loss:0.07213895214892653\n",
      "train loss:0.029237155097002792\n",
      "train loss:0.02149504482333867\n",
      "train loss:0.04002748020585376\n",
      "train loss:0.014067362502691801\n",
      "train loss:0.021455727127894727\n",
      "train loss:0.015597296887743025\n",
      "train loss:0.06654343541653111\n",
      "train loss:0.03692619575005898\n",
      "train loss:0.023600898913154755\n",
      "train loss:0.010244072088925249\n",
      "train loss:0.043415244470115986\n",
      "train loss:0.05683623828044941\n",
      "train loss:0.018725687362630184\n",
      "train loss:0.03082172913582092\n",
      "train loss:0.02323153523363056\n",
      "train loss:0.021814901250369903\n",
      "train loss:0.011439306428391334\n",
      "train loss:0.0062979556232087685\n",
      "train loss:0.03515718864125231\n",
      "train loss:0.06224522998806639\n",
      "train loss:0.016738299239996594\n",
      "train loss:0.02656723116168492\n",
      "train loss:0.009557843011560553\n",
      "train loss:0.014650108312191778\n",
      "train loss:0.04391260893611283\n",
      "train loss:0.012838435519334989\n",
      "train loss:0.03200384328466643\n",
      "train loss:0.014413851670911084\n",
      "train loss:0.01008851961488884\n",
      "train loss:0.026703214823348996\n",
      "train loss:0.00785787010913509\n",
      "train loss:0.01039037268307652\n",
      "train loss:0.022586083723434226\n",
      "train loss:0.010498918543344275\n",
      "train loss:0.02225196204572657\n",
      "train loss:0.011118611301690213\n",
      "train loss:0.022128960074981694\n",
      "train loss:0.10321263104339226\n",
      "train loss:0.016728575323540152\n",
      "train loss:0.004845418131387744\n",
      "train loss:0.03188823011388132\n",
      "train loss:0.008405322291037477\n",
      "train loss:0.01666282322599268\n",
      "train loss:0.027040071306930764\n",
      "train loss:0.010648598019833895\n",
      "train loss:0.026193785268272644\n",
      "train loss:0.009247622744669495\n",
      "train loss:0.006031543308463994\n",
      "train loss:0.015918731113456267\n",
      "train loss:0.04437224512078597\n",
      "train loss:0.0353672985468109\n",
      "train loss:0.06825627700568775\n",
      "train loss:0.035360813717935174\n",
      "train loss:0.008964919396550357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015773100836610966\n",
      "train loss:0.02795557324474388\n",
      "train loss:0.05289779608409136\n",
      "train loss:0.014504290471059696\n",
      "train loss:0.01952241217802313\n",
      "train loss:0.012802100411204158\n",
      "train loss:0.01388337239126612\n",
      "train loss:0.02543069911002645\n",
      "train loss:0.011856223503703502\n",
      "train loss:0.023370822018303018\n",
      "train loss:0.02220889490747225\n",
      "train loss:0.027282802368812094\n",
      "train loss:0.039536718329068056\n",
      "train loss:0.00963782379938302\n",
      "train loss:0.01802752003417058\n",
      "train loss:0.012403449088096758\n",
      "train loss:0.011699733487397586\n",
      "train loss:0.03868142968923743\n",
      "train loss:0.018892689810312734\n",
      "train loss:0.032944025710182366\n",
      "train loss:0.017335191137632846\n",
      "train loss:0.013019009439146278\n",
      "train loss:0.043416610280075714\n",
      "train loss:0.022201231352301065\n",
      "train loss:0.016587764430566577\n",
      "train loss:0.0113150449544156\n",
      "train loss:0.01075007762188059\n",
      "train loss:0.013142341063994407\n",
      "train loss:0.03142632259777057\n",
      "train loss:0.027804793928781213\n",
      "train loss:0.032230665847967854\n",
      "train loss:0.02003925955726058\n",
      "train loss:0.03056737175773933\n",
      "train loss:0.004538201413442907\n",
      "train loss:0.009892314850508973\n",
      "train loss:0.021988286163948656\n",
      "train loss:0.018657310458703506\n",
      "train loss:0.05159351448142324\n",
      "train loss:0.023078866740749732\n",
      "train loss:0.024401218074436883\n",
      "train loss:0.010566537617774981\n",
      "train loss:0.02042179561578617\n",
      "train loss:0.011978149087402317\n",
      "train loss:0.013058847990472678\n",
      "train loss:0.009322568579689319\n",
      "train loss:0.017027664994648358\n",
      "train loss:0.033892688133045835\n",
      "train loss:0.023753999753115332\n",
      "train loss:0.014146688286483947\n",
      "train loss:0.013703276574394267\n",
      "train loss:0.02588793679465987\n",
      "train loss:0.022726424465164968\n",
      "=== epoch:4, train acc:0.989, test acc:0.987 ===\n",
      "train loss:0.029510175418399856\n",
      "train loss:0.018314328608945253\n",
      "train loss:0.004851631434012506\n",
      "train loss:0.01192375303029364\n",
      "train loss:0.013958664552021383\n",
      "train loss:0.014616790958553207\n",
      "train loss:0.04947356507266414\n",
      "train loss:0.01421414847863477\n",
      "train loss:0.01318949265099614\n",
      "train loss:0.03104668990462973\n",
      "train loss:0.025841397616561304\n",
      "train loss:0.014265986627885908\n",
      "train loss:0.04322477322045835\n",
      "train loss:0.011773321071391677\n",
      "train loss:0.011441613713976558\n",
      "train loss:0.015312683820545741\n",
      "train loss:0.004117028350490654\n",
      "train loss:0.04201531923209245\n",
      "train loss:0.021562828664025344\n",
      "train loss:0.007893634493860557\n",
      "train loss:0.009144546827011945\n",
      "train loss:0.021064884027287227\n",
      "train loss:0.01317190483073501\n",
      "train loss:0.055575182146356976\n",
      "train loss:0.01692074537905306\n",
      "train loss:0.00987776815050129\n",
      "train loss:0.01134283623943234\n",
      "train loss:0.0064168458813121335\n",
      "train loss:0.03964085123976021\n",
      "train loss:0.038418485832167226\n",
      "train loss:0.02301170856614556\n",
      "train loss:0.009171929391959136\n",
      "train loss:0.027528675132092388\n",
      "train loss:0.0069047581042461946\n",
      "train loss:0.015818138006383674\n",
      "train loss:0.019472489996059817\n",
      "train loss:0.023748066807190136\n",
      "train loss:0.037342282181635475\n",
      "train loss:0.015190914445176744\n",
      "train loss:0.012216361060806582\n",
      "train loss:0.011320455381298528\n",
      "train loss:0.029283406065976757\n",
      "train loss:0.011117405965818747\n",
      "train loss:0.006442377588419848\n",
      "train loss:0.023560397291321082\n",
      "train loss:0.01276654997766569\n",
      "train loss:0.046542203284209285\n",
      "train loss:0.03278328447144266\n",
      "train loss:0.01187417741695986\n",
      "train loss:0.010054638453727578\n",
      "train loss:0.01802096656554418\n",
      "train loss:0.008167036353184285\n",
      "train loss:0.011437596128136744\n",
      "train loss:0.010722657928920066\n",
      "train loss:0.020647139428160325\n",
      "train loss:0.007332786368821789\n",
      "train loss:0.015646708601213595\n",
      "train loss:0.017203928086894964\n",
      "train loss:0.034458565159173594\n",
      "train loss:0.039648638662927733\n",
      "train loss:0.016321833101487996\n",
      "train loss:0.00844596081073078\n",
      "train loss:0.014326254871772182\n",
      "train loss:0.014091164299251956\n",
      "train loss:0.013077587282597624\n",
      "train loss:0.012516612476331715\n",
      "train loss:0.004856904368081405\n",
      "train loss:0.018072505148363983\n",
      "train loss:0.018919607476488083\n",
      "train loss:0.008835852887013185\n",
      "train loss:0.014973146100033028\n",
      "train loss:0.025886976318585393\n",
      "train loss:0.0074834157769873245\n",
      "train loss:0.004919580547926367\n",
      "train loss:0.023557542639490437\n",
      "train loss:0.012505487090780618\n",
      "train loss:0.016749830215087733\n",
      "train loss:0.03355301844652914\n",
      "train loss:0.007391498951693459\n",
      "train loss:0.011204483248568032\n",
      "train loss:0.01730727650757177\n",
      "train loss:0.026719841742087292\n",
      "train loss:0.013803219329599574\n",
      "train loss:0.009455966330443828\n",
      "train loss:0.013427129903541455\n",
      "train loss:0.016107567393071908\n",
      "train loss:0.027305491154059242\n",
      "train loss:0.052422864816420285\n",
      "train loss:0.018226342258018682\n",
      "train loss:0.004875438929149569\n",
      "train loss:0.014477629558646787\n",
      "train loss:0.026266386455278956\n",
      "train loss:0.0197682759679542\n",
      "train loss:0.006197906686794185\n",
      "train loss:0.01458222507845677\n",
      "train loss:0.030738159217333836\n",
      "train loss:0.0030771156253017206\n",
      "train loss:0.027292649172010273\n",
      "train loss:0.03680733056460705\n",
      "train loss:0.004392738092034648\n",
      "train loss:0.02620314684282255\n",
      "train loss:0.020623842618813944\n",
      "train loss:0.011686514457122535\n",
      "train loss:0.011376137453850936\n",
      "train loss:0.0589480364443937\n",
      "train loss:0.004730306312173491\n",
      "train loss:0.014948849658720807\n",
      "train loss:0.06239224127931116\n",
      "train loss:0.055388128866359056\n",
      "train loss:0.018389997271473647\n",
      "train loss:0.021373241973233266\n",
      "train loss:0.010473534721505612\n",
      "train loss:0.016263087761945086\n",
      "train loss:0.00707458515705258\n",
      "train loss:0.004913140166406925\n",
      "train loss:0.028823581440942467\n",
      "train loss:0.02184793328145939\n",
      "train loss:0.005900359550910001\n",
      "train loss:0.01995355709764163\n",
      "train loss:0.010778782775059876\n",
      "train loss:0.013276776599317329\n",
      "train loss:0.016462078783937097\n",
      "train loss:0.023612779069504646\n",
      "train loss:0.01486081849117135\n",
      "train loss:0.007534013502435186\n",
      "train loss:0.022932268382551524\n",
      "train loss:0.01313982024450933\n",
      "train loss:0.008880135830135706\n",
      "train loss:0.017439255319299705\n",
      "train loss:0.008007488113851118\n",
      "train loss:0.04356944590484546\n",
      "train loss:0.04466151958819315\n",
      "train loss:0.01017620643169617\n",
      "train loss:0.03490322298352541\n",
      "train loss:0.01965729851484297\n",
      "train loss:0.01760079324221099\n",
      "train loss:0.010402092224907296\n",
      "train loss:0.016685284060947884\n",
      "train loss:0.013602840198674164\n",
      "train loss:0.009728146577360297\n",
      "train loss:0.0062326560273548055\n",
      "train loss:0.00627573121415775\n",
      "train loss:0.03301642836433095\n",
      "train loss:0.010630306555707755\n",
      "train loss:0.01869981817603944\n",
      "train loss:0.009512221620394912\n",
      "train loss:0.016111093607142763\n",
      "train loss:0.023656431079876673\n",
      "train loss:0.008413170793415942\n",
      "train loss:0.016695693638644236\n",
      "train loss:0.02080301504129955\n",
      "train loss:0.006199416378407276\n",
      "train loss:0.022847453098074972\n",
      "train loss:0.09096452600949881\n",
      "train loss:0.03435460253344051\n",
      "train loss:0.013486009541233034\n",
      "train loss:0.018966817692996442\n",
      "train loss:0.018853111034855916\n",
      "train loss:0.014814652947095667\n",
      "train loss:0.003777391212783826\n",
      "train loss:0.017018555379029774\n",
      "train loss:0.05979218833214641\n",
      "train loss:0.01869311711518228\n",
      "train loss:0.02363163967484558\n",
      "train loss:0.014407196226669755\n",
      "train loss:0.017033451030190345\n",
      "train loss:0.021502741766024677\n",
      "train loss:0.035532260404973745\n",
      "train loss:0.002972199033763183\n",
      "train loss:0.01390391029962028\n",
      "train loss:0.008993247279003755\n",
      "train loss:0.0033148855732925827\n",
      "train loss:0.020768583627005077\n",
      "train loss:0.016236532584825006\n",
      "train loss:0.006830711008586033\n",
      "train loss:0.03177564913232652\n",
      "train loss:0.007825358195323913\n",
      "train loss:0.014666559322191918\n",
      "train loss:0.014037254781243808\n",
      "train loss:0.007098865515033839\n",
      "train loss:0.013240744127701268\n",
      "train loss:0.023722814899708528\n",
      "train loss:0.038407601273862085\n",
      "train loss:0.010774338993005885\n",
      "train loss:0.030978379430142183\n",
      "train loss:0.011761541067814407\n",
      "train loss:0.018821739370765377\n",
      "train loss:0.01524719929819172\n",
      "train loss:0.010521032287787316\n",
      "train loss:0.015968075293870353\n",
      "train loss:0.015602221350728982\n",
      "train loss:0.04140797597458081\n",
      "train loss:0.016397305005138616\n",
      "train loss:0.009006694929303834\n",
      "train loss:0.008397402853037831\n",
      "train loss:0.00819444834905875\n",
      "train loss:0.056876318588217\n",
      "train loss:0.017215604134563193\n",
      "train loss:0.03571096550851759\n",
      "train loss:0.016559217794864693\n",
      "train loss:0.015244133413606848\n",
      "train loss:0.04754229650251044\n",
      "train loss:0.007765930545480036\n",
      "train loss:0.0036111516452008285\n",
      "train loss:0.04665339354287289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.013417354997794229\n",
      "train loss:0.02866759314965134\n",
      "train loss:0.019819547011237098\n",
      "train loss:0.009002046109707966\n",
      "train loss:0.010121721799713535\n",
      "train loss:0.011087792961811668\n",
      "train loss:0.014881287101959925\n",
      "train loss:0.03156951179831061\n",
      "train loss:0.04672534555810892\n",
      "train loss:0.020268678150531468\n",
      "train loss:0.010206299138877373\n",
      "train loss:0.009173354997954101\n",
      "train loss:0.025871132564091667\n",
      "train loss:0.033193108054145846\n",
      "train loss:0.011160560373194798\n",
      "train loss:0.006385296805130433\n",
      "train loss:0.009890517690142049\n",
      "train loss:0.01823764862432438\n",
      "train loss:0.01152206420106127\n",
      "train loss:0.014602946188078383\n",
      "train loss:0.05075664776408841\n",
      "train loss:0.015053249945186345\n",
      "train loss:0.017050069419238485\n",
      "train loss:0.012449811482687995\n",
      "train loss:0.017808389917845148\n",
      "train loss:0.04668498768031853\n",
      "train loss:0.020252624642236036\n",
      "train loss:0.011180916386881491\n",
      "train loss:0.009247551485233005\n",
      "train loss:0.0874283350516253\n",
      "train loss:0.00943691682458048\n",
      "train loss:0.009074632573041412\n",
      "train loss:0.023944677347847745\n",
      "train loss:0.0032986311222364534\n",
      "train loss:0.021651546978274466\n",
      "train loss:0.016726242334333744\n",
      "train loss:0.012953690348505605\n",
      "train loss:0.00424541338101412\n",
      "train loss:0.046199230825995904\n",
      "train loss:0.012807726103604998\n",
      "train loss:0.014539549638851717\n",
      "train loss:0.010367496579392206\n",
      "train loss:0.040443503521410885\n",
      "train loss:0.026770720368435988\n",
      "train loss:0.016351977323869733\n",
      "train loss:0.029698897426001396\n",
      "train loss:0.006728584040911955\n",
      "train loss:0.004657495237282883\n",
      "train loss:0.025816583047508692\n",
      "train loss:0.004639282356258171\n",
      "train loss:0.028122224795671606\n",
      "train loss:0.011955348834377521\n",
      "train loss:0.027696020348171233\n",
      "train loss:0.008825215053246866\n",
      "train loss:0.006470594330145404\n",
      "train loss:0.019662607094603372\n",
      "train loss:0.011352500220418652\n",
      "train loss:0.037403500762596756\n",
      "train loss:0.004835280944433658\n",
      "train loss:0.016948461577781425\n",
      "train loss:0.025660694219633285\n",
      "train loss:0.010917985204742138\n",
      "train loss:0.023350303349885502\n",
      "train loss:0.014487549025812735\n",
      "train loss:0.005983262163479205\n",
      "train loss:0.013239777778720044\n",
      "train loss:0.013117554959575685\n",
      "train loss:0.015392544341221847\n",
      "train loss:0.01616804683270274\n",
      "train loss:0.0012848114894135378\n",
      "train loss:0.027681944258281396\n",
      "train loss:0.008621736571925573\n",
      "train loss:0.014804738177972144\n",
      "train loss:0.01076567084015926\n",
      "train loss:0.01302179846625231\n",
      "train loss:0.049039959942981076\n",
      "train loss:0.006998249495970765\n",
      "train loss:0.0246947232161279\n",
      "train loss:0.02243894857199431\n",
      "train loss:0.008456823587978893\n",
      "train loss:0.024106862187684524\n",
      "train loss:0.00655700824516039\n",
      "train loss:0.022217724122080437\n",
      "train loss:0.005784759937642465\n",
      "train loss:0.02646481454058802\n",
      "train loss:0.00999062484334905\n",
      "train loss:0.014861987100899095\n",
      "train loss:0.010142040355346323\n",
      "train loss:0.008967604130337127\n",
      "train loss:0.008632093588286198\n",
      "train loss:0.005041324812105179\n",
      "train loss:0.008377786702988287\n",
      "train loss:0.05670178065217987\n",
      "train loss:0.004023176964689671\n",
      "train loss:0.03906807544231745\n",
      "train loss:0.013850816263950261\n",
      "train loss:0.012056304680342904\n",
      "train loss:0.004121502787155528\n",
      "train loss:0.0220930370081723\n",
      "train loss:0.012681150567984729\n",
      "train loss:0.007683986768294563\n",
      "train loss:0.00987687037743602\n",
      "train loss:0.018925809207057658\n",
      "train loss:0.021504237791854175\n",
      "train loss:0.01753936840420607\n",
      "train loss:0.011612015631624987\n",
      "train loss:0.015607216067418859\n",
      "train loss:0.06596040961770806\n",
      "train loss:0.015150051729090985\n",
      "train loss:0.011761209836837016\n",
      "train loss:0.003554989262763983\n",
      "train loss:0.053084698635088245\n",
      "train loss:0.008470456575033331\n",
      "train loss:0.014200982077867134\n",
      "train loss:0.019416164106448138\n",
      "train loss:0.02472763568698696\n",
      "train loss:0.011370224204764346\n",
      "train loss:0.006886947891735858\n",
      "train loss:0.032406991417001756\n",
      "train loss:0.023738562838182577\n",
      "train loss:0.013440698787394052\n",
      "train loss:0.015856356139965912\n",
      "train loss:0.009203540334416015\n",
      "train loss:0.020557216007006055\n",
      "train loss:0.012614143710770973\n",
      "train loss:0.020379173119393287\n",
      "train loss:0.016145051957315356\n",
      "train loss:0.010071109414027798\n",
      "train loss:0.004387285642043445\n",
      "train loss:0.008346639171088943\n",
      "train loss:0.006400231515092279\n",
      "train loss:0.02004511386515859\n",
      "train loss:0.011505086648505783\n",
      "train loss:0.010970065817709417\n",
      "train loss:0.021180440840378605\n",
      "train loss:0.012679715907738231\n",
      "train loss:0.0048566216599309955\n",
      "train loss:0.010011020855319512\n",
      "train loss:0.04920152807002534\n",
      "train loss:0.03626969073545987\n",
      "train loss:0.006796530938610568\n",
      "train loss:0.007965130287664494\n",
      "train loss:0.010379034736990948\n",
      "train loss:0.04912616119492723\n",
      "train loss:0.011664920337032803\n",
      "train loss:0.006278110514529223\n",
      "train loss:0.019017725789141227\n",
      "train loss:0.01402732090416736\n",
      "train loss:0.02826546905207532\n",
      "train loss:0.015961941788773356\n",
      "train loss:0.009781184618021936\n",
      "train loss:0.006540672726600575\n",
      "train loss:0.007233878906957457\n",
      "train loss:0.003355758692416196\n",
      "train loss:0.0123353820716953\n",
      "train loss:0.006790509143863353\n",
      "train loss:0.008826424527707065\n",
      "train loss:0.05546055374738506\n",
      "train loss:0.02019104190713903\n",
      "train loss:0.002954275629374842\n",
      "train loss:0.006237773916847432\n",
      "train loss:0.025359435466459263\n",
      "train loss:0.021441819573125628\n",
      "=== epoch:5, train acc:0.994, test acc:0.992 ===\n",
      "train loss:0.016020438592070384\n",
      "train loss:0.02323024871018024\n",
      "train loss:0.013428843316871074\n",
      "train loss:0.026933610941242626\n",
      "train loss:0.011553476155856042\n",
      "train loss:0.00958557946612706\n",
      "train loss:0.015619215111277266\n",
      "train loss:0.007081802555196359\n",
      "train loss:0.05214031130831135\n",
      "train loss:0.012465472475775735\n",
      "train loss:0.017867160496132888\n",
      "train loss:0.01017360699604124\n",
      "train loss:0.011507471398073392\n",
      "train loss:0.025018947268950213\n",
      "train loss:0.009570439500833158\n",
      "train loss:0.009114179786808856\n",
      "train loss:0.019281633307042377\n",
      "train loss:0.011638069625333444\n",
      "train loss:0.007662961808523686\n",
      "train loss:0.025696761603602927\n",
      "train loss:0.0029954778481701685\n",
      "train loss:0.00590162757255896\n",
      "train loss:0.008489854827142141\n",
      "train loss:0.012118916757801867\n",
      "train loss:0.005800647237196221\n",
      "train loss:0.004015605504567364\n",
      "train loss:0.017925469134341888\n",
      "train loss:0.008062209113609635\n",
      "train loss:0.012849249309671466\n",
      "train loss:0.006711010875382382\n",
      "train loss:0.014523698213446104\n",
      "train loss:0.03381920347416193\n",
      "train loss:0.003010914711527636\n",
      "train loss:0.01459701587211369\n",
      "train loss:0.013362859733406039\n",
      "train loss:0.017345763239515956\n",
      "train loss:0.013335475587308028\n",
      "train loss:0.007752902254249548\n",
      "train loss:0.004118395160892457\n",
      "train loss:0.021468292898639527\n",
      "train loss:0.013227537828322023\n",
      "train loss:0.017661199102590914\n",
      "train loss:0.011840353756203738\n",
      "train loss:0.006558478935732675\n",
      "train loss:0.005563530492888795\n",
      "train loss:0.004587735332228648\n",
      "train loss:0.022909670523487427\n",
      "train loss:0.012010482029398212\n",
      "train loss:0.02543721429967239\n",
      "train loss:0.017373172101993097\n",
      "train loss:0.04068675236869478\n",
      "train loss:0.008978052665793376\n",
      "train loss:0.0036981579167222915\n",
      "train loss:0.019544768623046414\n",
      "train loss:0.007846115515771163\n",
      "train loss:0.01773890369566636\n",
      "train loss:0.007801714186893366\n",
      "train loss:0.02559232022692002\n",
      "train loss:0.00650162391151722\n",
      "train loss:0.014937052966503824\n",
      "train loss:0.01856038203114844\n",
      "train loss:0.005763956366586983\n",
      "train loss:0.0054187610008678356\n",
      "train loss:0.009990096070011913\n",
      "train loss:0.0070557462225438496\n",
      "train loss:0.004437798904949366\n",
      "train loss:0.028550163218037335\n",
      "train loss:0.009315587652748794\n",
      "train loss:0.008288949772411753\n",
      "train loss:0.009538628856933237\n",
      "train loss:0.013945241846656043\n",
      "train loss:0.05658943995248109\n",
      "train loss:0.012023128589369578\n",
      "train loss:0.01202844839123484\n",
      "train loss:0.0030082973618229705\n",
      "train loss:0.01371991837084967\n",
      "train loss:0.006608311133396829\n",
      "train loss:0.0037327570413855904\n",
      "train loss:0.00820913681046187\n",
      "train loss:0.023473825432473346\n",
      "train loss:0.016873043424218814\n",
      "train loss:0.01153675577357286\n",
      "train loss:0.009135233534251752\n",
      "train loss:0.06459129024031557\n",
      "train loss:0.0023993299630280934\n",
      "train loss:0.017526158857501337\n",
      "train loss:0.004964814631469214\n",
      "train loss:0.013585630086360604\n",
      "train loss:0.007833597874034487\n",
      "train loss:0.0320073828878022\n",
      "train loss:0.009387356055898114\n",
      "train loss:0.0077610843426232255\n",
      "train loss:0.01138212589296999\n",
      "train loss:0.014594591760935662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00905165122698428\n",
      "train loss:0.007820600110086508\n",
      "train loss:0.00853452152795424\n",
      "train loss:0.004764150514192031\n",
      "train loss:0.016879574179072508\n",
      "train loss:0.007854048741531889\n",
      "train loss:0.008152069656480632\n",
      "train loss:0.0037307745404317654\n",
      "train loss:0.05938964462404066\n",
      "train loss:0.006710749513168592\n",
      "train loss:0.013720755136992658\n",
      "train loss:0.008887323652628308\n",
      "train loss:0.012743154795129634\n",
      "train loss:0.0143891072820043\n",
      "train loss:0.00905335394512941\n",
      "train loss:0.00619219934665116\n",
      "train loss:0.007249435484520368\n",
      "train loss:0.03686535938529773\n",
      "train loss:0.003479254424014961\n",
      "train loss:0.010505365174282003\n",
      "train loss:0.00216126242003075\n",
      "train loss:0.0065890488477785645\n",
      "train loss:0.008276775199738066\n",
      "train loss:0.00588979698064824\n",
      "train loss:0.00437194679097629\n",
      "train loss:0.01115356407176028\n",
      "train loss:0.034700480842299784\n",
      "train loss:0.015288834123216482\n",
      "train loss:0.009019037424865591\n",
      "train loss:0.00814342043161289\n",
      "train loss:0.011998885657605762\n",
      "train loss:0.017020013824768008\n",
      "train loss:0.0044003098634429645\n",
      "train loss:0.010183438060819632\n",
      "train loss:0.011177047467884869\n",
      "train loss:0.004820539467002321\n",
      "train loss:0.040521881150827097\n",
      "train loss:0.01905569142717131\n",
      "train loss:0.0071393074959008335\n",
      "train loss:0.030818442287414465\n",
      "train loss:0.012075288628143423\n",
      "train loss:0.032577564990451745\n",
      "train loss:0.034537288687916085\n",
      "train loss:0.010008038278851682\n",
      "train loss:0.0263741964826005\n",
      "train loss:0.0026919434914937095\n",
      "train loss:0.0009411322080512429\n",
      "train loss:0.03934506950271389\n",
      "train loss:0.017547224115499298\n",
      "train loss:0.007220179109173843\n",
      "train loss:0.01102093954915806\n",
      "train loss:0.051679541616769145\n",
      "train loss:0.031349030661086214\n",
      "train loss:0.0062522134728948036\n",
      "train loss:0.00413136962865772\n",
      "train loss:0.01174247605842359\n",
      "train loss:0.02042131915090945\n",
      "train loss:0.013133913926379411\n",
      "train loss:0.015230220831777297\n",
      "train loss:0.009956427965401327\n",
      "train loss:0.00601835219706987\n",
      "train loss:0.01126662354517258\n",
      "train loss:0.012689517492346722\n",
      "train loss:0.0038810094798483238\n",
      "train loss:0.008074452722395006\n",
      "train loss:0.010269996717144089\n",
      "train loss:0.002815515690837286\n",
      "train loss:0.020964521901009805\n",
      "train loss:0.009265950121684097\n",
      "train loss:0.01816815163718936\n",
      "train loss:0.006588764943841058\n",
      "train loss:0.006535139391947576\n",
      "train loss:0.005416644940589731\n",
      "train loss:0.004447793888122589\n",
      "train loss:0.004044449448749856\n",
      "train loss:0.0033856500785351138\n",
      "train loss:0.006509148637345019\n",
      "train loss:0.00418516842696299\n",
      "train loss:0.006245319248965792\n",
      "train loss:0.013940288209371347\n",
      "train loss:0.030855599912311814\n",
      "train loss:0.004590784509308635\n",
      "train loss:0.008958587688771873\n",
      "train loss:0.017594347003134194\n",
      "train loss:0.003828610648880337\n",
      "train loss:0.00512425835575757\n",
      "train loss:0.022008090704377415\n",
      "train loss:0.011296076290915705\n",
      "train loss:0.006717227177365799\n",
      "train loss:0.013559836449592765\n",
      "train loss:0.012459554717592617\n",
      "train loss:0.003393993798248042\n",
      "train loss:0.008674747518100732\n",
      "train loss:0.01174854034522259\n",
      "train loss:0.0110567028342345\n",
      "train loss:0.01761316914831527\n",
      "train loss:0.007804605899602183\n",
      "train loss:0.0033250159571662483\n",
      "train loss:0.008493707934780067\n",
      "train loss:0.016027661681501847\n",
      "train loss:0.012272036741061585\n",
      "train loss:0.023818179760067115\n",
      "train loss:0.007364722327376211\n",
      "train loss:0.007457030374961317\n",
      "train loss:0.02929150483569431\n",
      "train loss:0.01680938367238109\n",
      "train loss:0.020249865759027142\n",
      "train loss:0.015699561965282532\n",
      "train loss:0.012061437447065622\n",
      "train loss:0.01882159130590848\n",
      "train loss:0.01861656079738644\n",
      "train loss:0.007699971805719767\n",
      "train loss:0.008246010777904362\n",
      "train loss:0.007077888301359246\n",
      "train loss:0.009457435567883202\n",
      "train loss:0.01233167970115213\n",
      "train loss:0.015167017877026274\n",
      "train loss:0.004027120451711723\n",
      "train loss:0.00633853689551547\n",
      "train loss:0.015387255072511475\n",
      "train loss:0.011931212111776019\n",
      "train loss:0.004658440716019804\n",
      "train loss:0.00920702167604042\n",
      "train loss:0.030201322921706887\n",
      "train loss:0.005897090200436233\n",
      "train loss:0.019345146002407772\n",
      "train loss:0.013453447745376042\n",
      "train loss:0.01509153935383469\n",
      "train loss:0.006292810230931142\n",
      "train loss:0.012375763335671374\n",
      "train loss:0.029576720198045265\n",
      "train loss:0.029209370841920934\n",
      "train loss:0.010013532166471956\n",
      "train loss:0.01912101141856074\n",
      "train loss:0.010589851275792362\n",
      "train loss:0.006450265559028774\n",
      "train loss:0.04729283300561095\n",
      "train loss:0.0067977034936880605\n",
      "train loss:0.004931803567352888\n",
      "train loss:0.0016282365962227742\n",
      "train loss:0.010492230355687837\n",
      "train loss:0.004780395368504098\n",
      "train loss:0.010758559798211432\n",
      "train loss:0.007181876782800977\n",
      "train loss:0.01025055024737298\n",
      "train loss:0.004246383232389922\n",
      "train loss:0.01237075033378397\n",
      "train loss:0.009319911205410921\n",
      "train loss:0.033762324312878976\n",
      "train loss:0.005811233016651949\n",
      "train loss:0.0137267265695512\n",
      "train loss:0.012929010745919433\n",
      "train loss:0.0032562231476754295\n",
      "train loss:0.005641022725691277\n",
      "train loss:0.016487661769086153\n",
      "train loss:0.02274112329793012\n",
      "train loss:0.011695495302222757\n",
      "train loss:0.002958242696395725\n",
      "train loss:0.004314351649084557\n",
      "train loss:0.004646184659746861\n",
      "train loss:0.006780446558470377\n",
      "train loss:0.01623695157909779\n",
      "train loss:0.015013086453365857\n",
      "train loss:0.012108990187873151\n",
      "train loss:0.005146282426790847\n",
      "train loss:0.010209588740432374\n",
      "train loss:0.002210562014198689\n",
      "train loss:0.030931966313706864\n",
      "train loss:0.005773640318422244\n",
      "train loss:0.011627814533151795\n",
      "train loss:0.004163077501233921\n",
      "train loss:0.008474338490134892\n",
      "train loss:0.02029063810751229\n",
      "train loss:0.010539017865589407\n",
      "train loss:0.012035478749108855\n",
      "train loss:0.01443597349894183\n",
      "train loss:0.010002934210402709\n",
      "train loss:0.004662204296170657\n",
      "train loss:0.009154271189516106\n",
      "train loss:0.006444881011323327\n",
      "train loss:0.012575889621180168\n",
      "train loss:0.01023077559162335\n",
      "train loss:0.00627096557714223\n",
      "train loss:0.006746437421027008\n",
      "train loss:0.015064507708562401\n",
      "train loss:0.003238945912579742\n",
      "train loss:0.006470646750682906\n",
      "train loss:0.005063618627914592\n",
      "train loss:0.04075086451664666\n",
      "train loss:0.005284071456743506\n",
      "train loss:0.009302042193101889\n",
      "train loss:0.00546280328067542\n",
      "train loss:0.009516938557265424\n",
      "train loss:0.004235213174829061\n",
      "train loss:0.005808881823101578\n",
      "train loss:0.004786229492824359\n",
      "train loss:0.0018846135934390365\n",
      "train loss:0.012736011208800902\n",
      "train loss:0.011781697135713982\n",
      "train loss:0.009240907477917122\n",
      "train loss:0.011463354825723117\n",
      "train loss:0.006119021579304653\n",
      "train loss:0.007993528760732355\n",
      "train loss:0.004637702489346651\n",
      "train loss:0.006670730382183218\n",
      "train loss:0.006269996214856256\n",
      "train loss:0.007984702283980627\n",
      "train loss:0.010505662077932866\n",
      "train loss:0.0025763728812913233\n",
      "train loss:0.008123669866365368\n",
      "train loss:0.012824010583435923\n",
      "train loss:0.0037624147363375824\n",
      "train loss:0.010013477565319057\n",
      "train loss:0.006023445535112327\n",
      "train loss:0.006248962291926243\n",
      "train loss:0.0034008719866670156\n",
      "train loss:0.006011119885992358\n",
      "train loss:0.0033551911050485167\n",
      "train loss:0.02835851054078094\n",
      "train loss:0.010928086652686882\n",
      "train loss:0.0055509721141605295\n",
      "train loss:0.00843942804442533\n",
      "train loss:0.020352615801520185\n",
      "train loss:0.011568151475960386\n",
      "train loss:0.009448258127683747\n",
      "train loss:0.007406293884683771\n",
      "train loss:0.015598900756878819\n",
      "train loss:0.0124827250946174\n",
      "train loss:0.027795383130737938\n",
      "train loss:0.007620917927170045\n",
      "train loss:0.007830019455350857\n",
      "train loss:0.004597470909508247\n",
      "train loss:0.007106448184573285\n",
      "train loss:0.007388623005740345\n",
      "train loss:0.0011516885398571916\n",
      "train loss:0.022997382319297748\n",
      "train loss:0.011903449025834312\n",
      "train loss:0.009915785254856905\n",
      "train loss:0.011511046413496404\n",
      "train loss:0.008909143073808135\n",
      "train loss:0.01809620964084877\n",
      "train loss:0.007795921733456523\n",
      "train loss:0.009545802962085908\n",
      "train loss:0.007817395829785807\n",
      "train loss:0.0016241176969086135\n",
      "train loss:0.0037570121517130008\n",
      "train loss:0.02430870256870863\n",
      "train loss:0.006322284391574824\n",
      "train loss:0.011701530910799124\n",
      "train loss:0.005650892756724188\n",
      "train loss:0.028173931395609118\n",
      "train loss:0.01119483717891047\n",
      "train loss:0.024530663171643853\n",
      "train loss:0.0019997979223915297\n",
      "train loss:0.01687398611565347\n",
      "train loss:0.00324075524899493\n",
      "train loss:0.050607925353477815\n",
      "train loss:0.004912382372473755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006366214976648345\n",
      "train loss:0.0031089087597821344\n",
      "train loss:0.00970882481481063\n",
      "train loss:0.014837543719338368\n",
      "train loss:0.004734224763396241\n",
      "train loss:0.03095799812829998\n",
      "train loss:0.007585398798695825\n",
      "train loss:0.0035904504359370927\n",
      "train loss:0.002194209957191878\n",
      "train loss:0.008747905673149625\n",
      "train loss:0.010813945472576683\n",
      "train loss:0.008385993436987463\n",
      "train loss:0.004024275310835318\n",
      "train loss:0.012994643863875732\n",
      "train loss:0.0037855712784763663\n",
      "train loss:0.0024274345947190154\n",
      "=== epoch:6, train acc:0.996, test acc:0.992 ===\n",
      "train loss:0.0072420032755985166\n",
      "train loss:0.012394952827691146\n",
      "train loss:0.0018458408116583751\n",
      "train loss:0.008227808917231183\n",
      "train loss:0.021247270216508032\n",
      "train loss:0.018519097026480143\n",
      "train loss:0.00754706123573075\n",
      "train loss:0.011888966767024124\n",
      "train loss:0.007574407548663352\n",
      "train loss:0.005212316372305292\n",
      "train loss:0.01550125029139271\n",
      "train loss:0.012006310999107643\n",
      "train loss:0.007874646992883287\n",
      "train loss:0.013006740303562843\n",
      "train loss:0.004479378750702285\n",
      "train loss:0.040239437251144504\n",
      "train loss:0.010197717950027524\n",
      "train loss:0.009642731686754343\n",
      "train loss:0.03211179340375953\n",
      "train loss:0.024059135750041823\n",
      "train loss:0.01223565431446605\n",
      "train loss:0.0051521057390883\n",
      "train loss:0.006662540770407748\n",
      "train loss:0.01473552195647006\n",
      "train loss:0.006024745135654641\n",
      "train loss:0.0026258558064346286\n",
      "train loss:0.0013159852516308336\n",
      "train loss:0.0011659183217373463\n",
      "train loss:0.010839984172229995\n",
      "train loss:0.01655091942662505\n",
      "train loss:0.001771363139539349\n",
      "train loss:0.005532274759424347\n",
      "train loss:0.0012994171294719225\n",
      "train loss:0.006312948874482182\n",
      "train loss:0.00831670187736726\n",
      "train loss:0.012628551894627558\n",
      "train loss:0.009063243500660293\n",
      "train loss:0.02095046755058195\n",
      "train loss:0.012104275149363497\n",
      "train loss:0.012168051440186633\n",
      "train loss:0.006930411238556371\n",
      "train loss:0.011020971876284275\n",
      "train loss:0.010603591394477004\n",
      "train loss:0.004355520780474021\n",
      "train loss:0.0032520179817478816\n",
      "train loss:0.025866226756439015\n",
      "train loss:0.0032156392260356717\n",
      "train loss:0.00852382445010658\n",
      "train loss:0.0005737926012582028\n",
      "train loss:0.01302844858684092\n",
      "train loss:0.005081497611222975\n",
      "train loss:0.01110140528094478\n",
      "train loss:0.004073282188625124\n",
      "train loss:0.009779415267617171\n",
      "train loss:0.015801070669654714\n",
      "train loss:0.002420437855585115\n",
      "train loss:0.005561959936689311\n",
      "train loss:0.014538225534356039\n",
      "train loss:0.007382807328804873\n",
      "train loss:0.0053477425039279\n",
      "train loss:0.0018397421665293813\n",
      "train loss:0.009191836058145917\n",
      "train loss:0.0023515216088632073\n",
      "train loss:0.0031784030051688807\n",
      "train loss:0.003427976252026829\n",
      "train loss:0.006858032168125988\n",
      "train loss:0.008352971168112486\n",
      "train loss:0.020900919133670235\n",
      "train loss:0.021008111875464905\n",
      "train loss:0.009479933712730818\n",
      "train loss:0.002234896039902419\n",
      "train loss:0.0023241061951921023\n",
      "train loss:0.0044486657028601625\n",
      "train loss:0.02258262917885743\n",
      "train loss:0.005937821783185601\n",
      "train loss:0.010538705323504283\n",
      "train loss:0.00986677370936278\n",
      "train loss:0.0016023147258602275\n",
      "train loss:0.01008174366001525\n",
      "train loss:0.005237693537601821\n",
      "train loss:0.04904815848621244\n",
      "train loss:0.011457774041096293\n",
      "train loss:0.017810015109448022\n",
      "train loss:0.013977336472672873\n",
      "train loss:0.014312624706116325\n",
      "train loss:0.015092331584019762\n",
      "train loss:0.010212183391963147\n",
      "train loss:0.019965130456977412\n",
      "train loss:0.02931664080413985\n",
      "train loss:0.009399123066148098\n",
      "train loss:0.027100902045324855\n",
      "train loss:0.0037289363918598384\n",
      "train loss:0.008439814206224026\n",
      "train loss:0.002879584010277374\n",
      "train loss:0.0038663450641970567\n",
      "train loss:0.005534221733676054\n",
      "train loss:0.016723116374627638\n",
      "train loss:0.01943498001324055\n",
      "train loss:0.015498698114763065\n",
      "train loss:0.016210899335427194\n",
      "train loss:0.0038754796893492884\n",
      "train loss:0.010219723159233638\n",
      "train loss:0.008361009870744888\n",
      "train loss:0.018906814446097608\n",
      "train loss:0.012369240760800041\n",
      "train loss:0.007150162525817526\n",
      "train loss:0.0033124083612975264\n",
      "train loss:0.03273473525114785\n",
      "train loss:0.0036658424299224435\n",
      "train loss:0.011442804239361306\n",
      "train loss:0.01137199636542675\n",
      "train loss:0.005077939851652907\n",
      "train loss:0.0016050890793626717\n",
      "train loss:0.03704091006410575\n",
      "train loss:0.002610317738416686\n",
      "train loss:0.0036487279747479126\n",
      "train loss:0.00449507023208884\n",
      "train loss:0.006939831496838399\n",
      "train loss:0.01965707359272263\n",
      "train loss:0.0047444070885611376\n",
      "train loss:0.005261497788063674\n",
      "train loss:0.007021439820578734\n",
      "train loss:0.006797111897504639\n",
      "train loss:0.0035142005397419754\n",
      "train loss:0.027020988137869704\n",
      "train loss:0.005874859257687912\n",
      "train loss:0.004566586732909271\n",
      "train loss:0.0055100101812546026\n",
      "train loss:0.007276684576328432\n",
      "train loss:0.007236502211398032\n",
      "train loss:0.010532718229684802\n",
      "train loss:0.008505811447003834\n",
      "train loss:0.009385532227804715\n",
      "train loss:0.003655611286523941\n",
      "train loss:0.0034686539343944307\n",
      "train loss:0.012087423019565799\n",
      "train loss:0.00796820306439811\n",
      "train loss:0.0009037718572052268\n",
      "train loss:0.008175707159897136\n",
      "train loss:0.021241446677334984\n",
      "train loss:0.005253725787977693\n",
      "train loss:0.006871904361540835\n",
      "train loss:0.013783780264917117\n",
      "train loss:0.0018811565175118707\n",
      "train loss:0.006007537455693778\n",
      "train loss:0.042334925664361124\n",
      "train loss:0.02053027093978342\n",
      "train loss:0.006212315760311973\n",
      "train loss:0.010698566959421367\n",
      "train loss:0.026832067442406356\n",
      "train loss:0.023902411105048878\n",
      "train loss:0.02497262033604808\n",
      "train loss:0.005958106079751052\n",
      "train loss:0.020426068978974053\n",
      "train loss:0.004055110488176427\n",
      "train loss:0.00884262095919334\n",
      "train loss:0.02701021017819275\n",
      "train loss:0.004052705432238462\n",
      "train loss:0.005627497211788913\n",
      "train loss:0.0026109842833564405\n",
      "train loss:0.00234676823721608\n",
      "train loss:0.00627515009411127\n",
      "train loss:0.0016999889964030596\n",
      "train loss:0.011859577840181565\n",
      "train loss:0.016106013743515942\n",
      "train loss:0.012779479269670943\n",
      "train loss:0.006364756626817765\n",
      "train loss:0.007487585361117658\n",
      "train loss:0.002654857148367541\n",
      "train loss:0.002996032476988493\n",
      "train loss:0.011986177626051914\n",
      "train loss:0.010174133852288778\n",
      "train loss:0.004173939832469013\n",
      "train loss:0.002626337558371652\n",
      "train loss:0.012008804500653282\n",
      "train loss:0.007441881752069155\n",
      "train loss:0.0027089944569407614\n",
      "train loss:0.0036552913389531067\n",
      "train loss:0.008113287424527969\n",
      "train loss:0.014818904995404078\n",
      "train loss:0.003210009076861781\n",
      "train loss:0.006411667242567278\n",
      "train loss:0.0011654256557641748\n",
      "train loss:0.003720688422689126\n",
      "train loss:0.011645649560451252\n",
      "train loss:0.02070669180669177\n",
      "train loss:0.001987647823867724\n",
      "train loss:0.004227852343108024\n",
      "train loss:0.005974541342088479\n",
      "train loss:0.008459054287832724\n",
      "train loss:0.008633098523094396\n",
      "train loss:0.007557195821733837\n",
      "train loss:0.004866062564346626\n",
      "train loss:0.003015961823140047\n",
      "train loss:0.005067836888744846\n",
      "train loss:0.0036686332172448325\n",
      "train loss:0.001526704655809092\n",
      "train loss:0.011922171975944732\n",
      "train loss:0.003036675450293109\n",
      "train loss:0.005524521226085227\n",
      "train loss:0.00327716083167247\n",
      "train loss:0.0018265667160070516\n",
      "train loss:0.003950115497039432\n",
      "train loss:0.00479182124706797\n",
      "train loss:0.0019084533107278057\n",
      "train loss:0.0021612023762351195\n",
      "train loss:0.004618910539189603\n",
      "train loss:0.0013798082006198954\n",
      "train loss:0.0037809808182711715\n",
      "train loss:0.0038490404065666768\n",
      "train loss:0.01064577571232986\n",
      "train loss:0.008170553504696873\n",
      "train loss:0.0070554032090868945\n",
      "train loss:0.006106139808085259\n",
      "train loss:0.0036852881633397403\n",
      "train loss:0.003301066755389139\n",
      "train loss:0.008465199175281646\n",
      "train loss:0.017261828871297673\n",
      "train loss:0.0034507246632814155\n",
      "train loss:0.0035158634394294387\n",
      "train loss:0.019291027370245458\n",
      "train loss:0.006214225170233085\n",
      "train loss:0.003211810225969185\n",
      "train loss:0.008328713080547374\n",
      "train loss:0.002262350310389119\n",
      "train loss:0.0023447432908646343\n",
      "train loss:0.03241467436188572\n",
      "train loss:0.007677474187730406\n",
      "train loss:0.008766792340448887\n",
      "train loss:0.011055614140071439\n",
      "train loss:0.027358152319384377\n",
      "train loss:0.0022981841445118742\n",
      "train loss:0.010942974141114984\n",
      "train loss:0.026000856398215522\n",
      "train loss:0.015894582528005404\n",
      "train loss:0.0070203167261094195\n",
      "train loss:0.03342943764291218\n",
      "train loss:0.005014911311556374\n",
      "train loss:0.0027197208404645687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0064795754519291265\n",
      "train loss:0.010724359689525008\n",
      "train loss:0.0029096667013446616\n",
      "train loss:0.0013170252344463674\n",
      "train loss:0.005096006699043502\n",
      "train loss:0.0034187700508504838\n",
      "train loss:0.0009530879525700317\n",
      "train loss:0.0064051388810572275\n",
      "train loss:0.011980873793913027\n",
      "train loss:0.007773162009221555\n",
      "train loss:0.003109888361139854\n",
      "train loss:0.00673952912467667\n",
      "train loss:0.0034741165609534137\n",
      "train loss:0.017823565797920493\n",
      "train loss:0.0064036987873604565\n",
      "train loss:0.00499601620655739\n",
      "train loss:0.0032277626068843842\n",
      "train loss:0.002233148716840645\n",
      "train loss:0.004456055145508784\n",
      "train loss:0.012520813488448192\n",
      "train loss:0.0029300630078646704\n",
      "train loss:0.015048062187885701\n",
      "train loss:0.01064153333718282\n",
      "train loss:0.009386980225561123\n",
      "train loss:0.004539055170639422\n",
      "train loss:0.015405356089795662\n",
      "train loss:0.006155170671849647\n",
      "train loss:0.003115186574536599\n",
      "train loss:0.0058560726371762375\n",
      "train loss:0.003817928386405418\n",
      "train loss:0.005980826459799916\n",
      "train loss:0.019094798107393597\n",
      "train loss:0.044807442545170446\n",
      "train loss:0.012210637601148874\n",
      "train loss:0.0014278680309880094\n",
      "train loss:0.005533490302685587\n",
      "train loss:0.0020914071130159043\n",
      "train loss:0.00664674342257969\n",
      "train loss:0.013505156307707997\n",
      "train loss:0.014374562910941599\n",
      "train loss:0.014942884188116878\n",
      "train loss:0.005798953084945295\n",
      "train loss:0.013331952202515521\n",
      "train loss:0.002393476190757805\n",
      "train loss:0.002316303297641184\n",
      "train loss:0.004878612768272597\n",
      "train loss:0.005880724366929354\n",
      "train loss:0.005641278078497491\n",
      "train loss:0.007817188769493891\n",
      "train loss:0.006225441824697681\n",
      "train loss:0.0046613007976702685\n",
      "train loss:0.006173093303239113\n",
      "train loss:0.004628958425584555\n",
      "train loss:0.0017851592509157963\n",
      "train loss:0.013284618295360916\n",
      "train loss:0.003957496652722726\n",
      "train loss:0.002799601061226455\n",
      "train loss:0.008155688541576398\n",
      "train loss:0.0047222200129025576\n",
      "train loss:0.002978988902248508\n",
      "train loss:0.01239293884898517\n",
      "train loss:0.0026570537856164273\n",
      "train loss:0.002675858484618875\n",
      "train loss:0.005835880541420487\n",
      "train loss:0.005633280635238406\n",
      "train loss:0.0014863931863801122\n",
      "train loss:0.0032663815589637113\n",
      "train loss:0.0025146165912558064\n",
      "train loss:0.002918981145898469\n",
      "train loss:0.0062308162761727905\n",
      "train loss:0.002391357247939666\n",
      "train loss:0.0047136744147023586\n",
      "train loss:0.001747478060936227\n",
      "train loss:0.004407234486097306\n",
      "train loss:0.009340414030359716\n",
      "train loss:0.004261074393946482\n",
      "train loss:0.005900658059344186\n",
      "train loss:0.004172762886330139\n",
      "train loss:0.0038286545799110614\n",
      "train loss:0.004417865942323772\n",
      "train loss:0.0006217422445577258\n",
      "train loss:0.005880885150857109\n",
      "train loss:0.005101645486101247\n",
      "train loss:0.0015334316921222755\n",
      "train loss:0.017385261423092872\n",
      "train loss:0.012080302396329463\n",
      "train loss:0.008826408439069863\n",
      "train loss:0.006462506680060469\n",
      "train loss:0.01792969823902625\n",
      "train loss:0.005437189235270575\n",
      "train loss:0.0039121533156224715\n",
      "train loss:0.005696427424789214\n",
      "train loss:0.0130937242716133\n",
      "train loss:0.0035799495250133447\n",
      "train loss:0.015578640105817958\n",
      "train loss:0.006044278120117225\n",
      "train loss:0.012990754545504173\n",
      "train loss:0.0030104082646121074\n",
      "train loss:0.0034698949552141502\n",
      "train loss:0.0031520391997116315\n",
      "train loss:0.011347126020825679\n",
      "train loss:0.0010819737946055055\n",
      "train loss:0.01745801371505368\n",
      "train loss:0.026396337567355953\n",
      "train loss:0.004667575254036751\n",
      "train loss:0.00403762690376401\n",
      "train loss:0.0019700820749015513\n",
      "train loss:0.0006178693988254535\n",
      "train loss:0.00450876847835945\n",
      "train loss:0.0023413910931248745\n",
      "train loss:0.009641704186738964\n",
      "train loss:0.004955333440746669\n",
      "train loss:0.0015817466793182366\n",
      "train loss:0.006742065808572689\n",
      "train loss:0.01564364850588973\n",
      "train loss:0.0014305606579222232\n",
      "train loss:0.00529148794438617\n",
      "train loss:0.008243451627819559\n",
      "train loss:0.0017772755043866364\n",
      "train loss:0.005740491671325092\n",
      "train loss:0.0021956694296599594\n",
      "train loss:0.006268663503420178\n",
      "train loss:0.008547380617511778\n",
      "train loss:0.012612244342236229\n",
      "train loss:0.0020628310619568756\n",
      "train loss:0.0052793235946546535\n",
      "train loss:0.0011832299994192052\n",
      "train loss:0.01435602082205162\n",
      "train loss:0.00495943722672307\n",
      "=== epoch:7, train acc:0.999, test acc:0.996 ===\n",
      "train loss:0.002304760308974373\n",
      "train loss:0.0012032053866978315\n",
      "train loss:0.00291665184200639\n",
      "train loss:0.0017242678896731342\n",
      "train loss:0.0037514261120929608\n",
      "train loss:0.002134062091939126\n",
      "train loss:0.005458468797333573\n",
      "train loss:0.018106538975989957\n",
      "train loss:0.005392846659377319\n",
      "train loss:0.0018210741747133456\n",
      "train loss:0.0016212131076543286\n",
      "train loss:0.0024468504437035322\n",
      "train loss:0.003857279722932189\n",
      "train loss:0.004072644946868469\n",
      "train loss:0.0007607513266416958\n",
      "train loss:0.0049886765452562595\n",
      "train loss:0.018228735066109843\n",
      "train loss:0.0027643931450743397\n",
      "train loss:0.007303047252479928\n",
      "train loss:0.03379746539561198\n",
      "train loss:0.015682396410192933\n",
      "train loss:0.004076890836583059\n",
      "train loss:0.009405260885929728\n",
      "train loss:0.003296963937354741\n",
      "train loss:0.002396331762083754\n",
      "train loss:0.013446435358114553\n",
      "train loss:0.010960851754987514\n",
      "train loss:0.008764025919365188\n",
      "train loss:0.008515251824001535\n",
      "train loss:0.014433540926349074\n",
      "train loss:0.004337879936382246\n",
      "train loss:0.002259974947876499\n",
      "train loss:0.0034950451770127803\n",
      "train loss:0.003656118435060704\n",
      "train loss:0.005570254737626362\n",
      "train loss:0.005977910687037903\n",
      "train loss:0.011652042749253022\n",
      "train loss:0.00909923858481227\n",
      "train loss:0.00869417201804733\n",
      "train loss:0.001863233319377463\n",
      "train loss:0.006237897534809976\n",
      "train loss:0.004046784851330427\n",
      "train loss:0.0016158287088291778\n",
      "train loss:0.0012395012778460188\n",
      "train loss:0.004479596292542091\n",
      "train loss:0.025668553820982338\n",
      "train loss:0.02391749637049544\n",
      "train loss:0.0034776387284872184\n",
      "train loss:0.007770508400007539\n",
      "train loss:0.009498703461748685\n",
      "train loss:0.004764875779888194\n",
      "train loss:0.01679043513992788\n",
      "train loss:0.002896393709262729\n",
      "train loss:0.0025709054939776254\n",
      "train loss:0.01150123948725923\n",
      "train loss:0.0007374165347834515\n",
      "train loss:0.0027091536945497443\n",
      "train loss:0.013658036313392552\n",
      "train loss:0.0031851094790740064\n",
      "train loss:0.0014840257677096772\n",
      "train loss:0.012696542412216563\n",
      "train loss:0.0035162053339437382\n",
      "train loss:0.012884427640032855\n",
      "train loss:0.02064614019416221\n",
      "train loss:0.0008889385761339963\n",
      "train loss:0.007657400051782128\n",
      "train loss:0.015933433383988775\n",
      "train loss:0.0027353497474921678\n",
      "train loss:0.011302723925531949\n",
      "train loss:0.028562499853232705\n",
      "train loss:0.006728992537098902\n",
      "train loss:0.006474855630472894\n",
      "train loss:0.002484616420931089\n",
      "train loss:0.007516260109685979\n",
      "train loss:0.0027294477754816124\n",
      "train loss:0.004692891287607369\n",
      "train loss:0.004108027980167763\n",
      "train loss:0.0025607017986228634\n",
      "train loss:0.012819146448822098\n",
      "train loss:0.0036427597032448068\n",
      "train loss:0.006209929609043935\n",
      "train loss:0.0070382798149664595\n",
      "train loss:0.010753032997464612\n",
      "train loss:0.01530928218097033\n",
      "train loss:0.0033890317512386818\n",
      "train loss:0.003300850001034981\n",
      "train loss:0.0013587005795731148\n",
      "train loss:0.019743959633761875\n",
      "train loss:0.0021995813002219002\n",
      "train loss:0.0061991344346839375\n",
      "train loss:0.0013273371057362727\n",
      "train loss:0.012186365239363943\n",
      "train loss:0.0047967842679634025\n",
      "train loss:0.02142847266995934\n",
      "train loss:0.01936256971390397\n",
      "train loss:0.004697320805722399\n",
      "train loss:0.002020334953058057\n",
      "train loss:0.012163273391398407\n",
      "train loss:0.004375241270334507\n",
      "train loss:0.0061982881515757725\n",
      "train loss:0.0027364276489429793\n",
      "train loss:0.002010522445385503\n",
      "train loss:0.004847338608291911\n",
      "train loss:0.007871861624305778\n",
      "train loss:0.0022502120104003986\n",
      "train loss:0.006606804189174539\n",
      "train loss:0.0010481228252834324\n",
      "train loss:0.0035102334274765916\n",
      "train loss:0.000895334752752687\n",
      "train loss:0.0015319178374025954\n",
      "train loss:0.03300062086754931\n",
      "train loss:0.0025536663013206954\n",
      "train loss:0.0024998793912106554\n",
      "train loss:0.005469405141031606\n",
      "train loss:0.005647442730325932\n",
      "train loss:0.02509523923605157\n",
      "train loss:0.002117049424412454\n",
      "train loss:0.0017598525636301557\n",
      "train loss:0.0044547791026873385\n",
      "train loss:0.0012644115684115151\n",
      "train loss:0.0017981834587121178\n",
      "train loss:0.003837538390901516\n",
      "train loss:0.0070555941877770475\n",
      "train loss:0.002314442897237715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002123393196343832\n",
      "train loss:0.0037992218064811165\n",
      "train loss:0.002882642213810192\n",
      "train loss:0.0019015036789112128\n",
      "train loss:0.0019885266937682156\n",
      "train loss:0.0019594232168657463\n",
      "train loss:0.0021540310546426206\n",
      "train loss:0.03778678209822308\n",
      "train loss:0.0019997617492544277\n",
      "train loss:0.005271372822536605\n",
      "train loss:0.0023659130583817732\n",
      "train loss:0.0017691629716260755\n",
      "train loss:0.0030300863660559416\n",
      "train loss:0.003790402420929934\n",
      "train loss:0.0021354416248746855\n",
      "train loss:0.0031684053245645766\n",
      "train loss:0.0014017230805405808\n",
      "train loss:0.0057229068828468415\n",
      "train loss:0.005819910631561382\n",
      "train loss:0.0034358002211420198\n",
      "train loss:0.004984329534919163\n",
      "train loss:0.005274308643672043\n",
      "train loss:0.008362475864940492\n",
      "train loss:0.007548676251787523\n",
      "train loss:0.0012010201282439564\n",
      "train loss:0.016863472258222007\n",
      "train loss:0.005013187908852481\n",
      "train loss:0.0008792265068352147\n",
      "train loss:0.0008597843755377731\n",
      "train loss:0.0025943046697440623\n",
      "train loss:0.003810747697873007\n",
      "train loss:0.004849959057949302\n",
      "train loss:0.00181464388262816\n",
      "train loss:0.0031802145949713506\n",
      "train loss:0.0124535661935538\n",
      "train loss:0.0038835606391502\n",
      "train loss:0.003901628388570872\n",
      "train loss:0.0016026990280187101\n",
      "train loss:0.036227506533566385\n",
      "train loss:0.0025085364895507203\n",
      "train loss:0.0010261941021798583\n",
      "train loss:0.003231177497059405\n",
      "train loss:0.00469566110155176\n",
      "train loss:0.006900581839582245\n",
      "train loss:0.0033031104162384163\n",
      "train loss:0.010460119602139693\n",
      "train loss:0.0133146736416023\n",
      "train loss:0.007058854532721702\n",
      "train loss:0.011782771988962298\n",
      "train loss:0.0025904150552879036\n",
      "train loss:0.001797760142149554\n",
      "train loss:0.000528669738130997\n",
      "train loss:0.002730845372829593\n",
      "train loss:0.004588349074078875\n",
      "train loss:0.00232391825877819\n",
      "train loss:0.011588329389387106\n",
      "train loss:0.05311915484508774\n",
      "train loss:0.001897392818399697\n",
      "train loss:0.0030766845264690815\n",
      "train loss:0.00166686319081047\n",
      "train loss:0.001814424067257861\n",
      "train loss:0.01690615902351372\n",
      "train loss:0.0022525185900763856\n",
      "train loss:0.006006122358613623\n",
      "train loss:0.009574635988273869\n",
      "train loss:0.0034902172677207218\n",
      "train loss:0.004678260380252492\n",
      "train loss:0.0036418626236780307\n",
      "train loss:0.001402378655035451\n",
      "train loss:0.006449845660122151\n",
      "train loss:0.001227638102282757\n",
      "train loss:0.008505797020993867\n",
      "train loss:0.014155229517355527\n",
      "train loss:0.0020266713489384696\n",
      "train loss:0.007055742472460648\n",
      "train loss:0.007470037716176056\n",
      "train loss:0.0014790513226967757\n",
      "train loss:0.0033800149016231336\n",
      "train loss:0.001852232176684743\n",
      "train loss:0.0020379443118356383\n",
      "train loss:0.021483688140641735\n",
      "train loss:0.00856036057289162\n",
      "train loss:0.015617628698160102\n",
      "train loss:0.004215905868838072\n",
      "train loss:0.0039184062591911175\n",
      "train loss:0.008764542048301554\n",
      "train loss:0.0035501349630739764\n",
      "train loss:0.004539327231374162\n",
      "train loss:0.005070966540849491\n",
      "train loss:0.004543159842418704\n",
      "train loss:0.011356707263657295\n",
      "train loss:0.0060977456599723475\n",
      "train loss:0.00298754259638421\n",
      "train loss:0.0026277727341267607\n",
      "train loss:0.006345437992603851\n",
      "train loss:0.010230271918612777\n",
      "train loss:0.006522899437519594\n",
      "train loss:0.002387237356374715\n",
      "train loss:0.005473104305295787\n",
      "train loss:0.005507077235060589\n",
      "train loss:0.0038883272629358233\n",
      "train loss:0.003026896537669661\n",
      "train loss:0.0008296024241172819\n",
      "train loss:0.012201986039064557\n",
      "train loss:0.0027148522562106935\n",
      "train loss:0.0007680786197171464\n",
      "train loss:0.0013743468132703524\n",
      "train loss:0.03924433596258527\n",
      "train loss:0.014871317924327474\n",
      "train loss:0.006569182623945117\n",
      "train loss:0.001022997605233683\n",
      "train loss:0.006783560336726332\n",
      "train loss:0.005467892595388533\n",
      "train loss:0.0023651937135806293\n",
      "train loss:0.003855747915368744\n",
      "train loss:0.004258122224528677\n",
      "train loss:0.002903268591201649\n",
      "train loss:0.007612211028462628\n",
      "train loss:0.002280709190286459\n",
      "train loss:0.00505252297175927\n",
      "train loss:0.006662401415728063\n",
      "train loss:0.005001477067316369\n",
      "train loss:0.001345775292725459\n",
      "train loss:0.00452594656102785\n",
      "train loss:0.010491017462212303\n",
      "train loss:0.0028154338593581476\n",
      "train loss:0.008253729660089512\n",
      "train loss:0.010598052437727493\n",
      "train loss:0.010110782252657196\n",
      "train loss:0.002385263981979622\n",
      "train loss:0.014866143696382521\n",
      "train loss:0.002532034677046662\n",
      "train loss:0.0035618197009518416\n",
      "train loss:0.0020857753774724173\n",
      "train loss:0.0012376723186033494\n",
      "train loss:0.0018409103351217876\n",
      "train loss:0.004824390413292291\n",
      "train loss:0.0019785524012824515\n",
      "train loss:0.0047644818571915765\n",
      "train loss:0.0023764206678771813\n",
      "train loss:0.004261684937187455\n",
      "train loss:0.0036956747510079814\n",
      "train loss:0.004358863296906322\n",
      "train loss:0.003437153352461609\n",
      "train loss:0.0035168777673416714\n",
      "train loss:0.0013053463595193403\n",
      "train loss:0.006173044560381315\n",
      "train loss:0.0008224523001505358\n",
      "train loss:0.003926464903291407\n",
      "train loss:0.001730398024104569\n",
      "train loss:0.003781487289039252\n",
      "train loss:0.003534828213735195\n",
      "train loss:0.002632404723506206\n",
      "train loss:0.003160353702207244\n",
      "train loss:0.010823286664381494\n",
      "train loss:0.0015759505363033407\n",
      "train loss:0.003707761833774391\n",
      "train loss:0.006190426156545934\n",
      "train loss:0.0036806770076707267\n",
      "train loss:0.008965935832567872\n",
      "train loss:0.001390711029614806\n",
      "train loss:0.0026873279219432095\n",
      "train loss:0.0033060049064835514\n",
      "train loss:0.002084521577064982\n",
      "train loss:0.005303602217668343\n",
      "train loss:0.0012205333024446693\n",
      "train loss:0.0021878537716484075\n",
      "train loss:0.004934841326034962\n",
      "train loss:0.0014263100086014612\n",
      "train loss:0.0023963438028327694\n",
      "train loss:0.001223859125849575\n",
      "train loss:0.0028989838267417956\n",
      "train loss:0.0025191016921766573\n",
      "train loss:0.01067756956385881\n",
      "train loss:0.0016587010214170034\n",
      "train loss:0.004043988840094321\n",
      "train loss:0.00311965772696878\n",
      "train loss:0.0029730433929311562\n",
      "train loss:0.0030534623023925392\n",
      "train loss:0.01370354841089086\n",
      "train loss:0.0033467498503018276\n",
      "train loss:0.029544119397131686\n",
      "train loss:0.0010793542654157996\n",
      "train loss:0.004406314574035177\n",
      "train loss:0.004380295293584759\n",
      "train loss:0.0030856165966631124\n",
      "train loss:0.0019823290234235796\n",
      "train loss:0.0012215424912214556\n",
      "train loss:0.0012644595009954499\n",
      "train loss:0.0045612690993228865\n",
      "train loss:0.0049546735909159695\n",
      "train loss:0.0035893491285370516\n",
      "train loss:0.009622238742738671\n",
      "train loss:0.0005034157492853577\n",
      "train loss:0.002735983280913309\n",
      "train loss:0.0021355618186543355\n",
      "train loss:0.0006576854741945231\n",
      "train loss:0.002113490756874388\n",
      "train loss:0.002053707932342696\n",
      "train loss:0.011045029697827658\n",
      "train loss:0.000767831390623995\n",
      "train loss:0.004864949506388802\n",
      "train loss:0.006508026425929684\n",
      "train loss:0.006990419636288563\n",
      "train loss:0.0024904014095675866\n",
      "train loss:0.003901557258585495\n",
      "train loss:0.00087716869865419\n",
      "train loss:0.006675326121673589\n",
      "train loss:0.0007236377283942032\n",
      "train loss:0.0009058826678975787\n",
      "train loss:0.00033985204789876376\n",
      "train loss:0.002395796634680999\n",
      "train loss:0.0029694505383542355\n",
      "train loss:0.006779709017979222\n",
      "train loss:0.01486491707861964\n",
      "train loss:0.0012296815316807249\n",
      "train loss:0.001319200029560493\n",
      "train loss:0.0014140043514255334\n",
      "train loss:0.013876306579176509\n",
      "train loss:0.0014840240931548064\n",
      "train loss:0.0025976719250882774\n",
      "train loss:0.001107372534805185\n",
      "train loss:0.007444325514219404\n",
      "train loss:0.0010910687732679685\n",
      "train loss:0.0017879925537542857\n",
      "train loss:0.0012749274871247667\n",
      "train loss:0.000783745215653877\n",
      "train loss:0.0008661625848146089\n",
      "train loss:0.0034153628431254144\n",
      "train loss:0.0033146529908983447\n",
      "train loss:0.00046816650906238405\n",
      "train loss:0.0011237152324759766\n",
      "train loss:0.0023529975070542167\n",
      "train loss:0.001583308389810384\n",
      "train loss:0.0018882329955418771\n",
      "train loss:0.005037849306336076\n",
      "train loss:0.0012652830468522665\n",
      "train loss:0.0075948447958340565\n",
      "train loss:0.006696499349895945\n",
      "train loss:0.007418817192177794\n",
      "train loss:0.003904454043167496\n",
      "train loss:0.003048358931198464\n",
      "train loss:0.001585414525868791\n",
      "train loss:0.002543323707757006\n",
      "=== epoch:8, train acc:0.999, test acc:0.998 ===\n",
      "train loss:0.0017858130103400917\n",
      "train loss:0.0047272090204910746\n",
      "train loss:0.0025594594754866423\n",
      "train loss:0.007265082422985961\n",
      "train loss:0.0022031987389556284\n",
      "train loss:0.001726391264006412\n",
      "train loss:0.002913406635156072\n",
      "train loss:0.002240801880070038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0013053315366052508\n",
      "train loss:0.0021592954308380817\n",
      "train loss:0.011034963326045968\n",
      "train loss:0.0013214896164369077\n",
      "train loss:0.0005218704727933957\n",
      "train loss:0.0013753112355634088\n",
      "train loss:0.0068262477375681235\n",
      "train loss:0.0049370700805457645\n",
      "train loss:0.0005529937050699591\n",
      "train loss:0.009559962069667234\n",
      "train loss:0.014708125262647892\n",
      "train loss:0.0009016386469281062\n",
      "train loss:0.003300561390030175\n",
      "train loss:0.006600265554383895\n",
      "train loss:0.001661907039356085\n",
      "train loss:0.001227890944552675\n",
      "train loss:0.0029431611503136913\n",
      "train loss:0.0008350523424294497\n",
      "train loss:0.019040385290050386\n",
      "train loss:0.0018865520412586468\n",
      "train loss:0.006247844918295529\n",
      "train loss:0.0023909407118472307\n",
      "train loss:0.0017050986622343543\n",
      "train loss:0.002503491272753898\n",
      "train loss:0.014399359237118093\n",
      "train loss:0.0023767537141062304\n",
      "train loss:0.0023362049338556874\n",
      "train loss:0.0026548330860115383\n",
      "train loss:0.0002973203054542921\n",
      "train loss:0.0015263681639395763\n",
      "train loss:0.003535752902664039\n",
      "train loss:0.004651879303136979\n",
      "train loss:0.002683498556613974\n",
      "train loss:0.0030008284076339935\n",
      "train loss:0.0016043592184084889\n",
      "train loss:0.005371264547734924\n",
      "train loss:0.006216437633766375\n",
      "train loss:0.017061695673481894\n",
      "train loss:0.003997819907061295\n",
      "train loss:0.000829666125746914\n",
      "train loss:0.009171025500260633\n",
      "train loss:0.002222875021656407\n",
      "train loss:0.0004942596532945375\n",
      "train loss:0.002199280134855952\n",
      "train loss:0.0005571348447125799\n",
      "train loss:0.0005423324635274983\n",
      "train loss:0.004508437479803059\n",
      "train loss:0.0024543197491203148\n",
      "train loss:0.0018484121274660406\n",
      "train loss:0.00908024724368674\n",
      "train loss:0.0010666480203726611\n",
      "train loss:0.0019087089066395313\n",
      "train loss:0.0036423541030324645\n",
      "train loss:0.006226725244272267\n",
      "train loss:0.0017785215598939313\n",
      "train loss:0.001379351336601528\n",
      "train loss:0.004727518375570228\n",
      "train loss:0.010656715421602096\n",
      "train loss:0.009319024887729952\n",
      "train loss:0.0058920892012900745\n",
      "train loss:0.005310938665197129\n",
      "train loss:0.00176973918092346\n",
      "train loss:0.001423783968977555\n",
      "train loss:0.0011827463566718318\n",
      "train loss:0.012127549512174613\n",
      "train loss:0.0026783994871887634\n",
      "train loss:0.00465200353032942\n",
      "train loss:0.004417019197673944\n",
      "train loss:0.010851418224304306\n",
      "train loss:0.00715360920363471\n",
      "train loss:0.0030167871998204995\n",
      "train loss:0.014328736305399707\n",
      "train loss:0.016201819905862492\n",
      "train loss:0.0032547753066667928\n",
      "train loss:0.004813819804431906\n",
      "train loss:0.005886437674460559\n",
      "train loss:0.0007043841507255002\n",
      "train loss:0.0008496679146225999\n",
      "train loss:0.010395757062463136\n",
      "train loss:0.026087630827304874\n",
      "train loss:0.0002971849964669011\n",
      "train loss:0.0008694464935070579\n",
      "train loss:0.003595222946075638\n",
      "train loss:0.005267698387765898\n",
      "train loss:0.0013097989250975635\n",
      "train loss:0.0013219399025072131\n",
      "train loss:0.0024513833418817964\n",
      "train loss:0.013086827487084339\n",
      "train loss:0.008951634558378366\n",
      "train loss:0.01576607692668297\n",
      "train loss:0.0021528729278844664\n",
      "train loss:0.013755396218886268\n",
      "train loss:0.0013239917187855793\n",
      "train loss:0.004527784091913347\n",
      "train loss:0.001266258417294536\n",
      "train loss:0.002011645382955096\n",
      "train loss:0.0032428519022022952\n",
      "train loss:0.005790675399823451\n",
      "train loss:0.0014812735266145917\n",
      "train loss:0.008571910537446383\n",
      "train loss:0.0018072003418519236\n",
      "train loss:0.0029160843545421636\n",
      "train loss:0.004037581793839086\n",
      "train loss:0.003318797559708991\n",
      "train loss:0.0013378976500892199\n",
      "train loss:0.0039754455026396\n",
      "train loss:0.002089603575026783\n",
      "train loss:0.00384737175316448\n",
      "train loss:0.0033477484256121343\n",
      "train loss:0.0022422061541840553\n",
      "train loss:0.0031468859295927186\n",
      "train loss:0.002984468182329503\n",
      "train loss:0.0021509396653149513\n",
      "train loss:0.0027407901208792106\n",
      "train loss:0.0036653248332737254\n",
      "train loss:0.001962022953938888\n",
      "train loss:0.005159436108826855\n",
      "train loss:0.001017952726584081\n",
      "train loss:0.0024745822143297947\n",
      "train loss:0.0013725768581362597\n",
      "train loss:0.0008387595380135523\n",
      "train loss:0.0013730014707256997\n",
      "train loss:0.0008350363169194243\n",
      "train loss:0.00625514676180971\n",
      "train loss:0.0011867926956332477\n",
      "train loss:0.0033178116103148745\n",
      "train loss:0.00580058213936716\n",
      "train loss:0.004413158526272425\n",
      "train loss:0.0014696158049109554\n",
      "train loss:0.005489899978950348\n",
      "train loss:0.0016120643803650167\n",
      "train loss:0.003403171382254021\n",
      "train loss:0.0029570701599112995\n",
      "train loss:0.00460922154588673\n",
      "train loss:0.001974300862541112\n",
      "train loss:0.0007799590172285128\n",
      "train loss:0.0008737779212939155\n",
      "train loss:0.004396927574984928\n",
      "train loss:0.0021991799466957655\n",
      "train loss:0.001375739967391204\n",
      "train loss:0.017255301655158945\n",
      "train loss:0.0020747776089820496\n",
      "train loss:0.0014942284842081649\n",
      "train loss:0.0004997396290977518\n",
      "train loss:0.005741839809115497\n",
      "train loss:0.0005423304777273764\n",
      "train loss:0.006055645054644624\n",
      "train loss:0.006340439606920616\n",
      "train loss:0.0011622826087084397\n",
      "train loss:0.004463968857512655\n",
      "train loss:0.010240653208698595\n",
      "train loss:0.01493891854773957\n",
      "train loss:0.045938156521256386\n",
      "train loss:0.0034546298216592375\n",
      "train loss:0.0026934056133713505\n",
      "train loss:0.0013712085668491634\n",
      "train loss:0.003147072832043761\n",
      "train loss:0.003884431881816852\n",
      "train loss:0.005593998024299439\n",
      "train loss:0.0029282811578852925\n",
      "train loss:0.005879644680579055\n",
      "train loss:0.0036578016846452507\n",
      "train loss:0.004247288021267869\n",
      "train loss:0.0072784099152111426\n",
      "train loss:0.0037596766614816897\n",
      "train loss:0.0149189745051364\n",
      "train loss:0.003378422917243293\n",
      "train loss:0.0024546255545025895\n",
      "train loss:0.003102283989323604\n",
      "train loss:0.005869930365944265\n",
      "train loss:0.0023203119777760526\n",
      "train loss:0.0003222292391609008\n",
      "train loss:0.002281653225021237\n",
      "train loss:0.008675282202444417\n",
      "train loss:0.0016115992365444722\n",
      "train loss:0.0011375940311900352\n",
      "train loss:0.004104576023352776\n",
      "train loss:0.004506893947658323\n",
      "train loss:0.006816853680361408\n",
      "train loss:0.008029674446174905\n",
      "train loss:0.0010952206637218015\n",
      "train loss:0.0030616926615335337\n",
      "train loss:0.0044360206176319895\n",
      "train loss:0.008226629409569003\n",
      "train loss:0.0059665623231529635\n",
      "train loss:0.0069492184592987866\n",
      "train loss:0.003763701321816913\n",
      "train loss:0.0018306795352105222\n",
      "train loss:0.002791718813231291\n",
      "train loss:0.010169231442420844\n",
      "train loss:0.0016744979154030685\n",
      "train loss:0.006122583514631723\n",
      "train loss:0.02418849265034805\n",
      "train loss:0.005287248077200804\n",
      "train loss:0.006240232142116158\n",
      "train loss:0.0032407637760773537\n",
      "train loss:0.0036311191459765958\n",
      "train loss:0.002950886020985627\n",
      "train loss:0.0197777024840859\n",
      "train loss:0.0021309945112420767\n",
      "train loss:0.013652059108334457\n",
      "train loss:0.005798894559227918\n",
      "train loss:0.004473310098804859\n",
      "train loss:0.003783138889321446\n",
      "train loss:0.0010921785867472984\n",
      "train loss:0.0021047150690674324\n",
      "train loss:0.001420366852191457\n",
      "train loss:0.0020491546618099875\n",
      "train loss:0.005864413768249353\n",
      "train loss:0.002580194116828236\n",
      "train loss:0.00046990355739340246\n",
      "train loss:0.0023170348511669476\n",
      "train loss:0.005067758421035526\n",
      "train loss:0.00045967618504934315\n",
      "train loss:0.0030427749412725276\n",
      "train loss:0.0006386323151455255\n",
      "train loss:0.0009416086353200419\n",
      "train loss:0.0017254364899857535\n",
      "train loss:0.0005956406060662054\n",
      "train loss:0.003192993025344089\n",
      "train loss:0.0015960921029326105\n",
      "train loss:0.0023345409676322807\n",
      "train loss:0.0007618073946328546\n",
      "train loss:0.005466252804187621\n",
      "train loss:0.0056605729039834055\n",
      "train loss:0.0022777986590275206\n",
      "train loss:0.0018153514207417422\n",
      "train loss:0.0016796568033790405\n",
      "train loss:0.0027391706341514175\n",
      "train loss:0.002413045705472023\n",
      "train loss:0.0019132220733747124\n",
      "train loss:0.0038935172389430897\n",
      "train loss:0.00585679726049709\n",
      "train loss:0.0017382441845164942\n",
      "train loss:0.0006455342827591262\n",
      "train loss:0.0034343347609256743\n",
      "train loss:0.0008943063436463778\n",
      "train loss:0.0006326809225669852\n",
      "train loss:0.0066289404005585115\n",
      "train loss:0.0061477160380097404\n",
      "train loss:0.00042038950009668814\n",
      "train loss:0.001952699789546312\n",
      "train loss:0.0002570833984128752\n",
      "train loss:0.004748015439435982\n",
      "train loss:0.012809629393203409\n",
      "train loss:0.002909776999602576\n",
      "train loss:0.021979573743439906\n",
      "train loss:0.008416071031892637\n",
      "train loss:0.0009782512028910495\n",
      "train loss:0.0015706369373475202\n",
      "train loss:0.0159449941696159\n",
      "train loss:0.0017961588027795876\n",
      "train loss:0.0033255534399429638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0023831707187064012\n",
      "train loss:0.001951317014701471\n",
      "train loss:0.0017039677642298537\n",
      "train loss:0.019023212618542434\n",
      "train loss:0.0034549108976095638\n",
      "train loss:0.0037992514983915425\n",
      "train loss:0.005695748149892389\n",
      "train loss:0.001157083933251825\n",
      "train loss:0.0014093476829348894\n",
      "train loss:0.0021356131552011564\n",
      "train loss:0.009595929335121151\n",
      "train loss:0.0040058393681741645\n",
      "train loss:0.007343461362242527\n",
      "train loss:0.003150639342959608\n",
      "train loss:0.005641040399847851\n",
      "train loss:0.004423720076082859\n",
      "train loss:0.017206161677229204\n",
      "train loss:0.00490937693075592\n",
      "train loss:0.002111072527456374\n",
      "train loss:0.001912793459439063\n",
      "train loss:0.001588546799790266\n",
      "train loss:0.0035123577090495233\n",
      "train loss:0.018099825971331994\n",
      "train loss:0.0057341270412014506\n",
      "train loss:0.006812577171867733\n",
      "train loss:0.0010983854654648291\n",
      "train loss:0.016024118040172827\n",
      "train loss:0.0006947341481673315\n",
      "train loss:0.0056923370601195955\n",
      "train loss:0.0015294238115993648\n",
      "train loss:0.0044132300032982165\n",
      "train loss:0.002007207917793983\n",
      "train loss:0.0032356482540316874\n",
      "train loss:0.005926250064359764\n",
      "train loss:0.0007529093774023046\n",
      "train loss:0.0009680284640330391\n",
      "train loss:0.005404642993794849\n",
      "train loss:0.004284361317793192\n",
      "train loss:0.002503918117351516\n",
      "train loss:0.0010096849500488049\n",
      "train loss:0.0008577962442164617\n",
      "train loss:0.0029921080144559315\n",
      "train loss:0.0021443854458832543\n",
      "train loss:0.003192769549670319\n",
      "train loss:0.0009171558233602385\n",
      "train loss:0.0009729011851896495\n",
      "train loss:0.002123060986484439\n",
      "train loss:0.0027942815427482144\n",
      "train loss:0.0013689909552366947\n",
      "train loss:0.0037858605683400498\n",
      "train loss:0.0025302476073394272\n",
      "train loss:0.0042042634161746474\n",
      "train loss:0.0016936726748653591\n",
      "train loss:0.005841124504375054\n",
      "train loss:0.0030423473084964453\n",
      "train loss:0.0011263353728557307\n",
      "train loss:0.002602356813340315\n",
      "train loss:0.00234284889606918\n",
      "train loss:0.0024320961090906782\n",
      "train loss:0.00014013036591173144\n",
      "train loss:0.003228521682016211\n",
      "train loss:0.0024299758444375095\n",
      "train loss:0.0013148391107155018\n",
      "train loss:0.0021215322349998956\n",
      "train loss:0.003863855837984823\n",
      "train loss:0.0009813306642982834\n",
      "train loss:0.0007243398754473863\n",
      "train loss:0.027553981052586725\n",
      "train loss:0.002813469677903827\n",
      "train loss:0.005094793634020432\n",
      "train loss:0.002081388345747237\n",
      "train loss:0.012375246106835236\n",
      "train loss:0.0009763701833441233\n",
      "train loss:0.0024905794511117007\n",
      "train loss:0.009201823040354605\n",
      "train loss:0.0014836278338339831\n",
      "train loss:0.004097112123241571\n",
      "train loss:0.003474502694389073\n",
      "train loss:0.003446937426470722\n",
      "train loss:0.011877580781496257\n",
      "train loss:0.0007291482382371351\n",
      "train loss:0.003769614764516532\n",
      "train loss:0.0005251507635594183\n",
      "train loss:0.004255324737951349\n",
      "train loss:0.010618221008435182\n",
      "train loss:0.0007501854571151581\n",
      "train loss:0.0012947464906228898\n",
      "train loss:0.003225938843258872\n",
      "train loss:0.002840561276563468\n",
      "train loss:0.004130436205316976\n",
      "train loss:0.007948180490980226\n",
      "train loss:0.006840202470215257\n",
      "train loss:0.008459698865125388\n",
      "train loss:0.0011591115319862187\n",
      "train loss:0.0009005235925341946\n",
      "train loss:0.0020456635179963672\n",
      "train loss:0.0023745968130498007\n",
      "train loss:0.00295261990165542\n",
      "train loss:0.0010075311644550582\n",
      "train loss:0.0011504131461668279\n",
      "train loss:0.005108997144360686\n",
      "train loss:0.0021128201008610713\n",
      "train loss:0.000793905840852635\n",
      "train loss:0.0024665210109296315\n",
      "train loss:0.003098409476717488\n",
      "train loss:0.002527764739621144\n",
      "train loss:0.001630130781410878\n",
      "=== epoch:9, train acc:0.998, test acc:0.997 ===\n",
      "train loss:0.0016856940153921315\n",
      "train loss:0.002478670912459633\n",
      "train loss:0.0006043503950797379\n",
      "train loss:0.004247370631076683\n",
      "train loss:0.0024198471005786137\n",
      "train loss:0.0021138522637788016\n",
      "train loss:0.002395893720532005\n",
      "train loss:0.0018694179683932828\n",
      "train loss:0.018544094491313997\n",
      "train loss:0.004224510683214566\n",
      "train loss:0.004256912053127579\n",
      "train loss:0.0017398559645286694\n",
      "train loss:0.009299801922842639\n",
      "train loss:0.012860909653161383\n",
      "train loss:0.001358873419311017\n",
      "train loss:0.0037917108380337737\n",
      "train loss:0.0009358163129425122\n",
      "train loss:0.001132144918770062\n",
      "train loss:0.0015459722415321383\n",
      "train loss:0.000531047367908405\n",
      "train loss:0.005077468477478864\n",
      "train loss:0.0018652245975243926\n",
      "train loss:0.0034183347673602143\n",
      "train loss:0.0021856967931102515\n",
      "train loss:0.0006591203417842472\n",
      "train loss:0.016889581939895305\n",
      "train loss:0.0020713249402753244\n",
      "train loss:0.004237480292063542\n",
      "train loss:0.0007005268126782487\n",
      "train loss:0.0013752921221887528\n",
      "train loss:0.003744927620545758\n",
      "train loss:0.0005189492634682735\n",
      "train loss:0.0037156440131808632\n",
      "train loss:0.004315520955957925\n",
      "train loss:0.0010482908562851549\n",
      "train loss:0.005460316570109484\n",
      "train loss:0.0009319416529893582\n",
      "train loss:0.003031570169903442\n",
      "train loss:0.006458407877358016\n",
      "train loss:0.0008134270153079343\n",
      "train loss:0.0006525036049947028\n",
      "train loss:0.002261955488875212\n",
      "train loss:0.001521249685974779\n",
      "train loss:0.00561197554284725\n",
      "train loss:0.0010072264570154907\n",
      "train loss:0.0013539464106676474\n",
      "train loss:0.004540439810989531\n",
      "train loss:0.0021940754355939955\n",
      "train loss:0.003443019033754846\n",
      "train loss:0.005157844701410563\n",
      "train loss:0.009168728255814643\n",
      "train loss:0.0033234445814904617\n",
      "train loss:0.001728266497837531\n",
      "train loss:0.0023382683314689874\n",
      "train loss:0.0011825981249003884\n",
      "train loss:0.001596108058017617\n",
      "train loss:0.0011064127290136574\n",
      "train loss:0.0019468669579430012\n",
      "train loss:0.005223433028845595\n",
      "train loss:0.006157120662710873\n",
      "train loss:0.0022493162861279337\n",
      "train loss:0.011103142623940519\n",
      "train loss:0.0035535286955273256\n",
      "train loss:0.0008433683766171949\n",
      "train loss:0.0011268637858327032\n",
      "train loss:0.014360843099912184\n",
      "train loss:0.002581438556871983\n",
      "train loss:0.009088103524271172\n",
      "train loss:0.002291629436805857\n",
      "train loss:0.00022532221250890318\n",
      "train loss:0.00020845221030035358\n",
      "train loss:0.003823129776497836\n",
      "train loss:0.0005500970477674301\n",
      "train loss:0.0033765076406112944\n",
      "train loss:0.001822679233771147\n",
      "train loss:0.0009502632342641273\n",
      "train loss:0.001979810129922683\n",
      "train loss:0.0021282204185114626\n",
      "train loss:0.007705855286807139\n",
      "train loss:0.0005175701113828382\n",
      "train loss:0.0006996559595471156\n",
      "train loss:0.0036081931120885663\n",
      "train loss:0.0008544112829553675\n",
      "train loss:0.0005347784007455638\n",
      "train loss:0.0030704104303672483\n",
      "train loss:0.0009420989289546031\n",
      "train loss:0.0006760391961531893\n",
      "train loss:0.00827378449426042\n",
      "train loss:0.0008801917527151179\n",
      "train loss:0.004917668101992803\n",
      "train loss:0.000758796779960625\n",
      "train loss:0.0017122343385040188\n",
      "train loss:0.001429386597115347\n",
      "train loss:0.002224792595680756\n",
      "train loss:0.0016274023383611599\n",
      "train loss:0.003776842560050074\n",
      "train loss:0.004993908697978509\n",
      "train loss:0.0031171753973758386\n",
      "train loss:0.0006528168520377773\n",
      "train loss:0.002036987162225409\n",
      "train loss:0.0004528819045311439\n",
      "train loss:0.009761034161009976\n",
      "train loss:0.0003541280140104963\n",
      "train loss:0.0019362530663964463\n",
      "train loss:0.0006783775347927632\n",
      "train loss:0.0016320647377609046\n",
      "train loss:0.009984652609521586\n",
      "train loss:0.0022835366175011553\n",
      "train loss:0.0029687796928516558\n",
      "train loss:0.0011004891440770427\n",
      "train loss:0.0039964824393204845\n",
      "train loss:0.0023593781984186917\n",
      "train loss:0.0029837024794235572\n",
      "train loss:0.005206883163410616\n",
      "train loss:0.0009395446140433223\n",
      "train loss:0.002935245793221372\n",
      "train loss:0.0040489157270996645\n",
      "train loss:0.003367782893573448\n",
      "train loss:0.000869938761450703\n",
      "train loss:0.0019006131620530398\n",
      "train loss:0.0018751087638323436\n",
      "train loss:0.0051079943680401784\n",
      "train loss:0.0023227018018466034\n",
      "train loss:0.00019100022760692165\n",
      "train loss:0.0015044975721281368\n",
      "train loss:0.00018761324295044543\n",
      "train loss:0.004100906637511475\n",
      "train loss:0.0023214382803671183\n",
      "train loss:0.002025429329929223\n",
      "train loss:0.0009333560229502994\n",
      "train loss:0.002788531494102226\n",
      "train loss:0.0005510589117235644\n",
      "train loss:0.0006074381112878667\n",
      "train loss:0.0006598169546424009\n",
      "train loss:0.0007259691532611194\n",
      "train loss:0.0073728854182535525\n",
      "train loss:0.0024790553742958365\n",
      "train loss:0.0024081528602714146\n",
      "train loss:0.003499373116450479\n",
      "train loss:0.0005299494426590376\n",
      "train loss:0.002471928531030826\n",
      "train loss:0.00232120363360569\n",
      "train loss:0.002104456688723224\n",
      "train loss:0.001830330132882544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001879607904126999\n",
      "train loss:0.0025050122671303075\n",
      "train loss:0.0006419907444058653\n",
      "train loss:0.006827728279247213\n",
      "train loss:0.0026812225452504087\n",
      "train loss:0.001049795177950911\n",
      "train loss:0.008585810455663336\n",
      "train loss:0.014066118145871831\n",
      "train loss:0.002947328901797612\n",
      "train loss:0.004051322488678867\n",
      "train loss:0.0012511885559336432\n",
      "train loss:0.0012655679484185776\n",
      "train loss:0.0025084931094467855\n",
      "train loss:0.017841519966057665\n",
      "train loss:0.00043791960868580504\n",
      "train loss:0.0009752618944965347\n",
      "train loss:0.0009518146673456571\n",
      "train loss:0.004272234208163835\n",
      "train loss:0.0005551344685714103\n",
      "train loss:0.0017570198232042698\n",
      "train loss:0.0041955750154878575\n",
      "train loss:0.002085672262038434\n",
      "train loss:0.0020271808398681745\n",
      "train loss:0.0013407779862632922\n",
      "train loss:0.0017302046653262448\n",
      "train loss:0.0020278361585948797\n",
      "train loss:0.0009221864685598655\n",
      "train loss:0.0003993614891901128\n",
      "train loss:0.0009583372291768355\n",
      "train loss:0.001728807081382218\n",
      "train loss:0.0011034806917995762\n",
      "train loss:0.0014004395642613022\n",
      "train loss:0.0012375674846152795\n",
      "train loss:0.0020688192317348357\n",
      "train loss:0.0017662665320654447\n",
      "train loss:0.0005558889401906767\n",
      "train loss:0.0014069171834322587\n",
      "train loss:0.001282150756003641\n",
      "train loss:0.0017198329723688765\n",
      "train loss:0.003445085432385552\n",
      "train loss:0.0012101616088952165\n",
      "train loss:0.0007779026607087747\n",
      "train loss:0.0006759267583577501\n",
      "train loss:0.0021557035093137658\n",
      "train loss:0.0006497847143027237\n",
      "train loss:0.0013690564750636937\n",
      "train loss:0.00443937692088953\n",
      "train loss:0.0022813109533498304\n",
      "train loss:0.005346589730642363\n",
      "train loss:0.00333339440367599\n",
      "train loss:0.0014490580373277128\n",
      "train loss:0.002806692442213261\n",
      "train loss:0.0013202619607604706\n",
      "train loss:0.0003762154691986393\n",
      "train loss:0.0010407306657191874\n",
      "train loss:0.003583340871763448\n",
      "train loss:0.0007162534952495705\n",
      "train loss:0.0023541946454594944\n",
      "train loss:0.0016206408845586264\n",
      "train loss:0.0013011761061575437\n",
      "train loss:0.0022223760277519555\n",
      "train loss:0.0011834344240115996\n",
      "train loss:0.000392864521199308\n",
      "train loss:0.00324932610347695\n",
      "train loss:0.0002286100910380563\n",
      "train loss:0.001610391664553194\n",
      "train loss:0.0019852612895613236\n",
      "train loss:0.0005525169242521704\n",
      "train loss:0.0020157146346632933\n",
      "train loss:0.002684786575284118\n",
      "train loss:0.0007366063875865299\n",
      "train loss:0.0014876161899963992\n",
      "train loss:0.0008000053056361197\n",
      "train loss:0.005154455348787409\n",
      "train loss:0.005785251991266097\n",
      "train loss:0.0007090693356207542\n",
      "train loss:0.015765955855659188\n",
      "train loss:0.005151743677055212\n",
      "train loss:0.006258473807608454\n",
      "train loss:0.006143447202073119\n",
      "train loss:0.013334817809155778\n",
      "train loss:0.0009346984761355841\n",
      "train loss:0.0008614190233505592\n",
      "train loss:0.003850441227968102\n",
      "train loss:0.0009808913476086055\n",
      "train loss:0.0005100266632125788\n",
      "train loss:0.005943292641925341\n",
      "train loss:0.005651688274467371\n",
      "train loss:0.01667939972472151\n",
      "train loss:0.004543412709022191\n",
      "train loss:0.002317463412228874\n",
      "train loss:0.034211510460744006\n",
      "train loss:0.011622245362444727\n",
      "train loss:0.005646133104413645\n",
      "train loss:0.001120798542069787\n",
      "train loss:0.002664429697901248\n",
      "train loss:0.008246117632680605\n",
      "train loss:0.01604438345332174\n",
      "train loss:0.005153992837146021\n",
      "train loss:0.0018614816473747086\n",
      "train loss:0.0010572880365883463\n",
      "train loss:0.0007557087341481742\n",
      "train loss:0.003255471954796023\n",
      "train loss:0.0031021181531943934\n",
      "train loss:0.0011197439981667943\n",
      "train loss:0.0026483401566858677\n",
      "train loss:0.0007852787762555374\n",
      "train loss:0.008618821290635532\n",
      "train loss:0.0013839252771246113\n",
      "train loss:0.003535433029020041\n",
      "train loss:0.004302555903299348\n",
      "train loss:0.012859624387497862\n",
      "train loss:0.0034635456099038676\n",
      "train loss:0.005999059101202161\n",
      "train loss:0.0030896432997542284\n",
      "train loss:0.0030943004928577875\n",
      "train loss:0.002670777324236\n",
      "train loss:0.008080178986760911\n",
      "train loss:0.005869217204281898\n",
      "train loss:0.0018567990109187415\n",
      "train loss:0.0030216018071327526\n",
      "train loss:0.002434989152857551\n",
      "train loss:0.0038923649699479325\n",
      "train loss:0.0016580269288523806\n",
      "train loss:0.009951543977556548\n",
      "train loss:0.0065570064643965115\n",
      "train loss:0.001837159169796497\n",
      "train loss:0.008145847330315616\n",
      "train loss:0.0037530768117191773\n",
      "train loss:0.0013813399314328671\n",
      "train loss:0.001865441245012071\n",
      "train loss:0.004571724784543431\n",
      "train loss:0.002196415097248454\n",
      "train loss:0.0014240700615274137\n",
      "train loss:0.001206491261473002\n",
      "train loss:0.0009337955535340168\n",
      "train loss:0.017788457496221835\n",
      "train loss:0.001855823206649599\n",
      "train loss:0.005299910979740251\n",
      "train loss:0.00195622933006647\n",
      "train loss:0.0014680035423773447\n",
      "train loss:0.0025729165433838407\n",
      "train loss:0.0006275477618877147\n",
      "train loss:0.000809359688650702\n",
      "train loss:0.006281449911724529\n",
      "train loss:0.0030972300583524456\n",
      "train loss:0.003112439403756271\n",
      "train loss:0.0028813948587128875\n",
      "train loss:0.0014574661744087196\n",
      "train loss:0.00181194678043798\n",
      "train loss:0.0006444076122530712\n",
      "train loss:0.0034990539791991504\n",
      "train loss:0.006406331663280749\n",
      "train loss:0.0032944526129704155\n",
      "train loss:0.0017200657485219521\n",
      "train loss:0.019834425407501972\n",
      "train loss:0.004101685162924655\n",
      "train loss:0.0014049707010693599\n",
      "train loss:0.0017610835742728921\n",
      "train loss:0.0024330626789725606\n",
      "train loss:0.009772280679375266\n",
      "train loss:0.002354778022803135\n",
      "train loss:0.001508379193808797\n",
      "train loss:0.0017195694016754403\n",
      "train loss:0.0011183828531980803\n",
      "train loss:0.000996878028842278\n",
      "train loss:0.00046389496743376755\n",
      "train loss:0.006785381976612475\n",
      "train loss:0.004136772416688598\n",
      "train loss:0.00040277613017409354\n",
      "train loss:0.0012425719956685975\n",
      "train loss:0.002349301881100244\n",
      "train loss:0.013518850417964273\n",
      "train loss:0.0038085205733022895\n",
      "train loss:0.0037186558770233203\n",
      "train loss:0.008820078564147177\n",
      "train loss:0.0018267011552442077\n",
      "train loss:0.0021687696201599664\n",
      "train loss:0.0016403342034491406\n",
      "train loss:0.0016505319197763412\n",
      "train loss:0.005984129405265989\n",
      "train loss:0.0020299840392999863\n",
      "train loss:0.0019290624119072054\n",
      "train loss:0.0009067070371783954\n",
      "train loss:0.0015794896496521187\n",
      "train loss:0.0035374909388388776\n",
      "train loss:0.007367249554372717\n",
      "train loss:0.0011335838597784187\n",
      "train loss:0.0035313870146314497\n",
      "train loss:0.01630089754053492\n",
      "train loss:0.00453311331224337\n",
      "train loss:0.00037339569540015385\n",
      "train loss:0.0015765273223520564\n",
      "train loss:0.0010690844629286792\n",
      "train loss:0.00020003676696314792\n",
      "train loss:0.0011382449092240472\n",
      "train loss:0.012855245475894839\n",
      "train loss:0.00032959112989831737\n",
      "train loss:0.002351544084281401\n",
      "train loss:0.004051354733577794\n",
      "train loss:0.0018587636511351417\n",
      "train loss:0.009322439531711628\n",
      "train loss:0.0005236043495901028\n",
      "train loss:0.0011899335257316323\n",
      "train loss:0.0008145987861760043\n",
      "train loss:0.0005381016975157459\n",
      "train loss:0.0018237913398304892\n",
      "train loss:0.0053886712248646775\n",
      "train loss:0.004922596973567056\n",
      "train loss:0.001553339649450483\n",
      "train loss:0.0017422759404453223\n",
      "train loss:0.0007141605423961001\n",
      "train loss:0.0034300050194145193\n",
      "train loss:0.0015992450988284287\n",
      "train loss:0.0005370577343648813\n",
      "train loss:0.0051888680991964515\n",
      "train loss:0.006344710022769251\n",
      "train loss:0.0004212479971891024\n",
      "train loss:0.0007875292708490768\n",
      "train loss:0.003428069967238047\n",
      "train loss:0.002845788732787162\n",
      "train loss:0.0007943170990170903\n",
      "train loss:0.02741621096081664\n",
      "train loss:0.0020246771384031066\n",
      "=== epoch:10, train acc:1.0, test acc:0.994 ===\n",
      "train loss:0.002428613907735231\n",
      "train loss:0.0016745197540812679\n",
      "train loss:0.0021180575384251166\n",
      "train loss:0.001673812556432545\n",
      "train loss:0.0031233199553377315\n",
      "train loss:0.0029397212728831186\n",
      "train loss:0.0032402531193285503\n",
      "train loss:0.0010411115852824266\n",
      "train loss:0.0014836311211366853\n",
      "train loss:0.0038139426503275317\n",
      "train loss:0.002599935840308271\n",
      "train loss:0.004576203274614009\n",
      "train loss:0.0015415673353172095\n",
      "train loss:0.0015750256050073705\n",
      "train loss:0.0011612388965681465\n",
      "train loss:0.0016662271828462355\n",
      "train loss:0.0016507282806248983\n",
      "train loss:0.0011860253469687556\n",
      "train loss:0.0004807776733248712\n",
      "train loss:0.0004107688281849676\n",
      "train loss:0.0007989433046893341\n",
      "train loss:0.0007377368110946674\n",
      "train loss:0.002624530970195119\n",
      "train loss:0.002468699230383382\n",
      "train loss:0.0012165584325612442\n",
      "train loss:0.00026996258476665546\n",
      "train loss:0.002158465081722892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016058737078489768\n",
      "train loss:0.0010815484179808063\n",
      "train loss:0.0016964345613351012\n",
      "train loss:0.0015876777433353425\n",
      "train loss:0.002377082002892991\n",
      "train loss:0.002229220550402956\n",
      "train loss:0.0010411358291911497\n",
      "train loss:0.0007485614877132388\n",
      "train loss:0.0002787173935632758\n",
      "train loss:0.0006036904355195098\n",
      "train loss:0.0010447833187120358\n",
      "train loss:0.0006151476845361938\n",
      "train loss:0.002057138755448481\n",
      "train loss:0.001456833001412412\n",
      "train loss:0.0023066186869644856\n",
      "train loss:0.0009858855051860227\n",
      "train loss:0.0009933232516390444\n",
      "train loss:0.0006060334322820669\n",
      "train loss:0.0002908154624947286\n",
      "train loss:0.001171082710399391\n",
      "train loss:0.0015387162814539724\n",
      "train loss:0.0003499556018368752\n",
      "train loss:0.003660265660035721\n",
      "train loss:0.00034300199935361945\n",
      "train loss:0.002692506588557484\n",
      "train loss:0.0005692868084950322\n",
      "train loss:0.0001722494833477343\n",
      "train loss:0.001048958138500818\n",
      "train loss:0.0006143722253563549\n",
      "train loss:0.0022853448543757233\n",
      "train loss:0.004695384986058145\n",
      "train loss:0.0010096072323376995\n",
      "train loss:0.0007780353823303377\n",
      "train loss:0.002630919201567849\n",
      "train loss:0.0007272255660612892\n",
      "train loss:0.0015260491933621603\n",
      "train loss:0.00018146228574082737\n",
      "train loss:0.00027675478668123316\n",
      "train loss:0.0020103740488416045\n",
      "train loss:0.0010550346785769952\n",
      "train loss:0.0017872619871639388\n",
      "train loss:0.0007013112761861232\n",
      "train loss:0.0010744916232730132\n",
      "train loss:0.0024843419644886592\n",
      "train loss:0.0004257719841382748\n",
      "train loss:0.0007208674887481549\n",
      "train loss:0.0005513982215862887\n",
      "train loss:0.005587782902978323\n",
      "train loss:0.004307544358312876\n",
      "train loss:0.0005416506159574875\n",
      "train loss:0.001129486189346039\n",
      "train loss:0.0006781840195323694\n",
      "train loss:0.001271058772809808\n",
      "train loss:0.0005063740327752021\n",
      "train loss:0.0010348489943880178\n",
      "train loss:0.0014319192982319112\n",
      "train loss:0.0007209166585356409\n",
      "train loss:0.0008043449573146998\n",
      "train loss:0.0018596179462850547\n",
      "train loss:0.0016786751019533834\n",
      "train loss:0.0013682043190101402\n",
      "train loss:0.0003757587263474399\n",
      "train loss:0.0014121309631098357\n",
      "train loss:0.0020837188449549303\n",
      "train loss:0.0024357764121055218\n",
      "train loss:0.0014262339238638243\n",
      "train loss:0.0021973751177139845\n",
      "train loss:0.0010409855191949673\n",
      "train loss:0.0009848595738600721\n",
      "train loss:0.0030002270550595687\n",
      "train loss:0.0009737867797751261\n",
      "train loss:0.001881099029419806\n",
      "train loss:0.0010908905046795256\n",
      "train loss:0.0019923540035659245\n",
      "train loss:0.0008707810132347692\n",
      "train loss:0.0074132756284879565\n",
      "train loss:0.0047582279140157\n",
      "train loss:0.000689569102890212\n",
      "train loss:0.00019187907226854244\n",
      "train loss:0.00045842480346877505\n",
      "train loss:0.000233301332351076\n",
      "train loss:0.0021175032585863626\n",
      "train loss:0.0020072375339061396\n",
      "train loss:0.0047082290858187605\n",
      "train loss:0.0005236805391732289\n",
      "train loss:0.001697282983991705\n",
      "train loss:0.0003918514276564491\n",
      "train loss:0.000798197462711502\n",
      "train loss:0.0005350634343497599\n",
      "train loss:0.0008764050708865763\n",
      "train loss:0.0027906025751816893\n",
      "train loss:0.0012592793301316315\n",
      "train loss:0.002263823209773411\n",
      "train loss:0.0007211084297619789\n",
      "train loss:0.002109730886091308\n",
      "train loss:0.0003596429790146048\n",
      "train loss:0.0025923533992230504\n",
      "train loss:0.0010505153375885785\n",
      "train loss:0.00021250448060069848\n",
      "train loss:0.0297280323902997\n",
      "train loss:0.0007451128603012142\n",
      "train loss:0.009414524736547556\n",
      "train loss:0.005560195443270982\n",
      "train loss:0.0025800889204810515\n",
      "train loss:0.000657997111389561\n",
      "train loss:0.0015099338426287725\n",
      "train loss:0.006047063692066601\n",
      "train loss:0.002945636122319432\n",
      "train loss:0.0018588587092565542\n",
      "train loss:0.0026569202250897764\n",
      "train loss:0.0018967471478682242\n",
      "train loss:0.0021568229501361643\n",
      "train loss:0.001230817711703379\n",
      "train loss:0.00148341470864956\n",
      "train loss:0.0015534240721999193\n",
      "train loss:0.000701521986128802\n",
      "train loss:0.0012640567451666876\n",
      "train loss:0.0007021314294333499\n",
      "train loss:0.0005008860305446714\n",
      "train loss:0.0011038270905660529\n",
      "train loss:0.0011282318388148574\n",
      "train loss:0.0036501967074384894\n",
      "train loss:0.0008509457878400218\n",
      "train loss:0.0004053436924082724\n",
      "train loss:0.0011676852169449608\n",
      "train loss:0.001584054023738453\n",
      "train loss:0.0036083156415173947\n",
      "train loss:0.0015779413985873888\n",
      "train loss:0.0012351395219763887\n",
      "train loss:0.0007590563969220751\n",
      "train loss:0.003959676531276824\n",
      "train loss:0.0015656133964790898\n",
      "train loss:0.0008656158811667843\n",
      "train loss:0.0004708351144302889\n",
      "train loss:0.007569578257358537\n",
      "train loss:0.002481830772240371\n",
      "train loss:0.0020661749119459468\n",
      "train loss:0.0016883250689318093\n",
      "train loss:0.0010921246608104724\n",
      "train loss:0.00041541022655440063\n",
      "train loss:0.0008021935304778654\n",
      "train loss:0.0003080770585219721\n",
      "train loss:0.0031304503534862888\n",
      "train loss:0.002546913660601336\n",
      "train loss:0.0017500535406186728\n",
      "train loss:0.0065334943768238785\n",
      "train loss:0.002131708648568281\n",
      "train loss:0.0009333649650962573\n",
      "train loss:0.0017476824037562174\n",
      "train loss:0.0020972252912070965\n",
      "train loss:0.001950138947429591\n",
      "train loss:0.001966066041708624\n",
      "train loss:0.0011120883265480935\n",
      "train loss:0.001289492376481804\n",
      "train loss:0.0007518360035767325\n",
      "train loss:0.0019253647425064606\n",
      "train loss:0.0004348276909652385\n",
      "train loss:0.00035968087907320374\n",
      "train loss:0.0003856374927756439\n",
      "train loss:0.0007285767526539171\n",
      "train loss:0.0009301023146356432\n",
      "train loss:0.0019144359052450262\n",
      "train loss:0.0005112180301465565\n",
      "train loss:0.0011406459062601618\n",
      "train loss:0.00046104818693451776\n",
      "train loss:0.0017563392336776933\n",
      "train loss:0.0003999988966130494\n",
      "train loss:0.001182273460787606\n",
      "train loss:0.0003823637461394569\n",
      "train loss:0.0038833356830571086\n",
      "train loss:0.00024501160556699526\n",
      "train loss:0.00010689049473657339\n",
      "train loss:0.0021053197069358085\n",
      "train loss:0.0014799609436500567\n",
      "train loss:0.00043773449081639784\n",
      "train loss:0.00035576911827962565\n",
      "train loss:0.0007388555228558648\n",
      "train loss:0.0018783814027702656\n",
      "train loss:0.000798949567235212\n",
      "train loss:0.004421379395914502\n",
      "train loss:0.0004274367366602123\n",
      "train loss:0.005709226606686623\n",
      "train loss:0.0038048170965740576\n",
      "train loss:0.002292798572185554\n",
      "train loss:0.004150775273590746\n",
      "train loss:0.001423089786031749\n",
      "train loss:0.00023065703625870394\n",
      "train loss:0.0003918522740729846\n",
      "train loss:0.0008170000452201027\n",
      "train loss:0.0002462668755367323\n",
      "train loss:0.0005194433889388506\n",
      "train loss:0.0007225718861903829\n",
      "train loss:0.007872883719564043\n",
      "train loss:0.0049407763791596655\n",
      "train loss:0.0011116206588524808\n",
      "train loss:0.0016860028449529546\n",
      "train loss:0.0020448807013693053\n",
      "train loss:0.00025318442103712226\n",
      "train loss:0.001382775357086609\n",
      "train loss:0.0007014036234124962\n",
      "train loss:0.0011521910056344962\n",
      "train loss:0.0032229830762797456\n",
      "train loss:0.0009024184496164037\n",
      "train loss:0.0009428541710671634\n",
      "train loss:0.002894894456714733\n",
      "train loss:0.0033049265250539527\n",
      "train loss:0.002057709578223787\n",
      "train loss:0.0002871260695121262\n",
      "train loss:0.0010233035833824879\n",
      "train loss:0.001421935871252535\n",
      "train loss:0.0013944209897687047\n",
      "train loss:0.002835244087084451\n",
      "train loss:0.0006368949666360269\n",
      "train loss:0.0003484295055611953\n",
      "train loss:0.0014699324647158402\n",
      "train loss:0.0013470128735516484\n",
      "train loss:0.0014148232431036383\n",
      "train loss:0.0011213983192489073\n",
      "train loss:0.0017635772482134165\n",
      "train loss:0.00043981853098195624\n",
      "train loss:0.0005492110255282473\n",
      "train loss:0.01964758563366546\n",
      "train loss:0.0019407768473971283\n",
      "train loss:0.0006846329194375673\n",
      "train loss:0.00045097653063876157\n",
      "train loss:0.007738216152008579\n",
      "train loss:0.001584215218754328\n",
      "train loss:0.001510139414764147\n",
      "train loss:0.003953729982807899\n",
      "train loss:0.0008210189674273761\n",
      "train loss:0.0036233602821927253\n",
      "train loss:0.0009769566589753862\n",
      "train loss:0.0009510152822913627\n",
      "train loss:0.0011192823431885048\n",
      "train loss:0.002678688708189165\n",
      "train loss:0.0007696183388623707\n",
      "train loss:0.0001557827234737628\n",
      "train loss:0.00017712874336576538\n",
      "train loss:0.0007024484719464698\n",
      "train loss:0.0005950832278624107\n",
      "train loss:0.0008987415644962144\n",
      "train loss:0.0021304911870885786\n",
      "train loss:0.0020058439684211235\n",
      "train loss:0.0024175202998710393\n",
      "train loss:0.000559414085081465\n",
      "train loss:0.00040533399741634403\n",
      "train loss:0.0010933689688210142\n",
      "train loss:0.00360454432633214\n",
      "train loss:0.0007308055873988604\n",
      "train loss:0.00039429841725361383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003718829566719625\n",
      "train loss:0.0005061127598885545\n",
      "train loss:0.001744327373611736\n",
      "train loss:0.0012206170434537534\n",
      "train loss:0.000300788322831131\n",
      "train loss:0.0010050563481404833\n",
      "train loss:0.0005402449278691983\n",
      "train loss:0.0022032862861303486\n",
      "train loss:0.0010667657868594369\n",
      "train loss:0.00024162288644317235\n",
      "train loss:0.0012483655885954766\n",
      "train loss:0.0004188148895501905\n",
      "train loss:0.0002633090801757296\n",
      "train loss:0.002520426396402014\n",
      "train loss:0.0010051271500251071\n",
      "train loss:0.002087270016449674\n",
      "train loss:0.0010246547032599185\n",
      "train loss:0.00038123659509138065\n",
      "train loss:0.0015079282836347344\n",
      "train loss:0.0013858363446914595\n",
      "train loss:0.0026691171534829828\n",
      "train loss:0.0007896170748425909\n",
      "train loss:0.0003791146602116394\n",
      "train loss:0.0015176010380687694\n",
      "train loss:0.0003140930681404108\n",
      "train loss:0.0014363834392937304\n",
      "train loss:0.00034750228120117104\n",
      "train loss:0.0008787928715894542\n",
      "train loss:0.002879784350118292\n",
      "train loss:0.00037562064610785836\n",
      "train loss:0.0002739698679287958\n",
      "train loss:0.0038581002518605543\n",
      "train loss:0.001326999577654639\n",
      "train loss:0.000993459382783325\n",
      "train loss:0.0010057750352696173\n",
      "train loss:0.0005817040907819605\n",
      "train loss:0.0006560190286184473\n",
      "train loss:0.0008432139482001398\n",
      "train loss:0.0009890917472530798\n",
      "train loss:0.009756404838111708\n",
      "train loss:0.004476330410073349\n",
      "train loss:0.001187058067043338\n",
      "train loss:0.002543827456024686\n",
      "train loss:0.0003659412022473934\n",
      "train loss:0.00037255643373614115\n",
      "train loss:0.0026164789937453024\n",
      "train loss:0.000445513893050999\n",
      "train loss:0.04858575321221461\n",
      "train loss:0.00031134078993923117\n",
      "train loss:0.00211856031670015\n",
      "train loss:0.0012977755054094135\n",
      "train loss:0.0018098929206731619\n",
      "train loss:0.0002445039468180035\n",
      "train loss:0.0037536033675936178\n",
      "train loss:0.0007732807145775532\n",
      "train loss:0.0013370165918355002\n",
      "train loss:0.004257080428746911\n",
      "train loss:0.0010182078908939165\n",
      "train loss:0.0008012027975633065\n",
      "train loss:0.0001655019240259948\n",
      "train loss:0.0016411952906846298\n",
      "train loss:0.004111834748295189\n",
      "train loss:0.001142737708451373\n",
      "train loss:0.0019048847194681486\n",
      "train loss:0.0023297011666909796\n",
      "train loss:0.0028756135510808194\n",
      "train loss:0.0008535641319658476\n",
      "train loss:0.003895794479137678\n",
      "train loss:0.0009496463225754897\n",
      "train loss:0.0013524681185773549\n",
      "train loss:0.0003255822134132059\n",
      "train loss:0.004121213560045957\n",
      "train loss:0.0008136061214613596\n",
      "train loss:0.0019356526949303875\n",
      "train loss:0.0005636450035929411\n",
      "train loss:0.0009857693014971912\n",
      "train loss:0.0006172089708078636\n",
      "train loss:0.0010774322418122561\n",
      "train loss:0.0007351138247182245\n",
      "train loss:0.00040771339683699364\n",
      "train loss:0.00032128533147242875\n",
      "train loss:0.0005581202517290003\n",
      "train loss:0.0014717679556392681\n",
      "train loss:0.0020618648646646013\n",
      "train loss:0.0015932172939788771\n",
      "train loss:0.0017200630183269925\n",
      "train loss:0.0009132897155747569\n",
      "train loss:0.0022871142153530265\n",
      "train loss:0.0009652048428940183\n",
      "train loss:0.0029425418181852005\n",
      "train loss:0.0029051034887954187\n",
      "=== epoch:11, train acc:0.999, test acc:0.994 ===\n",
      "train loss:0.0017814385056194382\n",
      "train loss:0.00179492406939973\n",
      "train loss:0.014503537191725452\n",
      "train loss:0.002662792588897019\n",
      "train loss:0.002999363941206779\n",
      "train loss:0.0015398142002929739\n",
      "train loss:0.0017670855561146214\n",
      "train loss:0.0003463451016516386\n",
      "train loss:0.0008816977593157092\n",
      "train loss:0.007090733540722196\n",
      "train loss:0.001911887126933079\n",
      "train loss:0.0009435792736595246\n",
      "train loss:0.019773373871513185\n",
      "train loss:0.001442301443304901\n",
      "train loss:0.0009121142672015706\n",
      "train loss:0.005586723826184488\n",
      "train loss:0.0019165854004961425\n",
      "train loss:0.0033067732220719115\n",
      "train loss:0.0004822060783696267\n",
      "train loss:0.0010888527173119702\n",
      "train loss:0.0007644184984626057\n",
      "train loss:0.0018237310193590082\n",
      "train loss:0.0015474559098036125\n",
      "train loss:0.004664031770530706\n",
      "train loss:0.001386073351871558\n",
      "train loss:0.001517301582877935\n",
      "train loss:0.00038245792667590545\n",
      "train loss:0.003824515380082064\n",
      "train loss:0.0033794673688208993\n",
      "train loss:0.000797081940350209\n",
      "train loss:0.0008780444982901428\n",
      "train loss:0.004024528896108046\n",
      "train loss:0.002778379079316331\n",
      "train loss:0.0006249390134866762\n",
      "train loss:0.00030711256280773413\n",
      "train loss:0.00022828963694029883\n",
      "train loss:0.0038544621279129193\n",
      "train loss:0.002237019014602944\n",
      "train loss:0.000886279333123958\n",
      "train loss:0.000816917617185433\n",
      "train loss:0.002617815469618911\n",
      "train loss:0.00029928762200146473\n",
      "train loss:0.002600428998128638\n",
      "train loss:0.001478652542582722\n",
      "train loss:0.0009783200380569421\n",
      "train loss:0.0009493100614080455\n",
      "train loss:0.0003755440833425479\n",
      "train loss:0.0013732084863787577\n",
      "train loss:0.0008683185601129527\n",
      "train loss:0.0015300818353092339\n",
      "train loss:0.0021717166698610366\n",
      "train loss:0.0016324931257421919\n",
      "train loss:0.0018828445467933906\n",
      "train loss:0.0009491726373073693\n",
      "train loss:0.0015173081737120684\n",
      "train loss:0.0026132689759975143\n",
      "train loss:0.0022865770023479323\n",
      "train loss:0.0012194788710981558\n",
      "train loss:0.003647339013962176\n",
      "train loss:0.0019103728396040423\n",
      "train loss:0.005492860689630589\n",
      "train loss:0.0008965905023492892\n",
      "train loss:0.0012022106905459394\n",
      "train loss:0.0002388270328952076\n",
      "train loss:0.0009496326878257848\n",
      "train loss:0.0013749352716849927\n",
      "train loss:0.003147567931169176\n",
      "train loss:0.0010542571241687275\n",
      "train loss:0.003752193994758102\n",
      "train loss:0.0033748290924851113\n",
      "train loss:0.0026379350940713103\n",
      "train loss:0.0005536729840174098\n",
      "train loss:0.0013274036577526538\n",
      "train loss:0.0020221775643081545\n",
      "train loss:0.0004254466366996481\n",
      "train loss:0.00036493321555232296\n",
      "train loss:0.0003875868257452788\n",
      "train loss:0.00043623558697771127\n",
      "train loss:0.0005017308383411815\n",
      "train loss:0.0014766762870399963\n",
      "train loss:0.002241954361621822\n",
      "train loss:0.003469491449934163\n",
      "train loss:0.0008623281220011076\n",
      "train loss:0.0009612938298145145\n",
      "train loss:0.003098052233910999\n",
      "train loss:0.00013233134027225692\n",
      "train loss:0.0007091557736794981\n",
      "train loss:0.00033182591840333743\n",
      "train loss:0.00042393955017130654\n",
      "train loss:0.0008437384919109362\n",
      "train loss:0.002727342891625068\n",
      "train loss:0.0009831667819658106\n",
      "train loss:0.0005622202770491374\n",
      "train loss:0.0006055931834872447\n",
      "train loss:0.0006996647354274407\n",
      "train loss:0.0003853289518223247\n",
      "train loss:0.0009471768291053934\n",
      "train loss:0.0010338467753722436\n",
      "train loss:0.0006060412765920485\n",
      "train loss:0.00036036799531247594\n",
      "train loss:0.0012345019303037852\n",
      "train loss:0.0009384109104127998\n",
      "train loss:0.0004526914073235458\n",
      "train loss:0.0007715848593918775\n",
      "train loss:0.0027330630405292124\n",
      "train loss:0.001434509709122127\n",
      "train loss:0.0005389423720159286\n",
      "train loss:0.00024331141548580618\n",
      "train loss:0.0005130401318432959\n",
      "train loss:0.0003703652215458607\n",
      "train loss:0.00021298359813513195\n",
      "train loss:0.00037514264563921507\n",
      "train loss:0.0005741639131085131\n",
      "train loss:0.00013251082806085604\n",
      "train loss:0.0008467431219647194\n",
      "train loss:0.0024390986629598604\n",
      "train loss:0.0016794964942038009\n",
      "train loss:0.0009521246311502945\n",
      "train loss:0.000554600275764516\n",
      "train loss:0.0018796821168885066\n",
      "train loss:0.00026444005476073594\n",
      "train loss:0.00035865830299007696\n",
      "train loss:0.0018549859132599336\n",
      "train loss:0.0006231983503607615\n",
      "train loss:0.0009861597095482811\n",
      "train loss:0.00021950439686752317\n",
      "train loss:0.0017740319412942606\n",
      "train loss:0.0008265494628254944\n",
      "train loss:0.001005001672723159\n",
      "train loss:0.00036454948886551576\n",
      "train loss:0.000203634365895275\n",
      "train loss:0.00012871787418633238\n",
      "train loss:0.0006730820783373349\n",
      "train loss:0.0006427162371437052\n",
      "train loss:0.0002895915054949935\n",
      "train loss:0.0007258100734714299\n",
      "train loss:0.00014693859747136578\n",
      "train loss:0.0007794683544343375\n",
      "train loss:0.0005549663104093272\n",
      "train loss:0.0004902539650388785\n",
      "train loss:0.0005860352313863178\n",
      "train loss:0.001109215600792081\n",
      "train loss:0.0021649995656844103\n",
      "train loss:0.0006079528077479072\n",
      "train loss:0.00044785366300432463\n",
      "train loss:0.0020353249253319996\n",
      "train loss:0.0011617482664476905\n",
      "train loss:0.0006076908606961219\n",
      "train loss:0.0009456486477162504\n",
      "train loss:0.0004553204027840912\n",
      "train loss:0.00020777537538814241\n",
      "train loss:0.0005546831905091156\n",
      "train loss:0.00028185731876896093\n",
      "train loss:0.006063508155076455\n",
      "train loss:0.0007292212651414787\n",
      "train loss:0.0009834975720506938\n",
      "train loss:0.0009894456859293977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004187652933996591\n",
      "train loss:0.0027195038331881286\n",
      "train loss:0.00048198632875431463\n",
      "train loss:0.0004115689968314536\n",
      "train loss:0.0009695294713911197\n",
      "train loss:0.002097373521511861\n",
      "train loss:0.00018175416524917248\n",
      "train loss:0.0007743796187327734\n",
      "train loss:0.0006891822017975766\n",
      "train loss:0.0005737633134217508\n",
      "train loss:0.0005291191051894425\n",
      "train loss:0.0033644278094063524\n",
      "train loss:0.0006031299808520632\n",
      "train loss:0.0014279974752840028\n",
      "train loss:0.002410593999936052\n",
      "train loss:0.0006744292532222915\n",
      "train loss:0.002628043012527613\n",
      "train loss:0.00044890980487563033\n",
      "train loss:0.0005734827534802887\n",
      "train loss:0.00479147034278147\n",
      "train loss:0.00033473813011591387\n",
      "train loss:0.0005065225247491364\n",
      "train loss:0.0016170273506996373\n",
      "train loss:0.0017624511159822775\n",
      "train loss:0.0011680670397348708\n",
      "train loss:0.0047528720222316054\n",
      "train loss:0.011506201365577264\n",
      "train loss:0.001972917223770762\n",
      "train loss:0.0003698443066828373\n",
      "train loss:0.003770973552168638\n",
      "train loss:0.0037874904008995446\n",
      "train loss:0.0009610208227962762\n",
      "train loss:0.002074518708900015\n",
      "train loss:0.0017605075757224494\n",
      "train loss:0.004822596523009968\n",
      "train loss:0.002777816546263888\n",
      "train loss:0.0010699063946571334\n",
      "train loss:0.0010249426427220835\n",
      "train loss:0.0020526865467017275\n",
      "train loss:0.0026106974794353377\n",
      "train loss:0.0002144727905355331\n",
      "train loss:0.0007737106892868473\n",
      "train loss:0.0018434094544838016\n",
      "train loss:0.001191921844341626\n",
      "train loss:0.0007982954209198312\n",
      "train loss:0.0016719949421983389\n",
      "train loss:0.001890988256036077\n",
      "train loss:0.00033622162760697897\n",
      "train loss:0.0005217317628818816\n",
      "train loss:0.0018719727306528526\n",
      "train loss:0.0007390158668676481\n",
      "train loss:0.004368956861553237\n",
      "train loss:0.000644902255248514\n",
      "train loss:0.01355168356379328\n",
      "train loss:0.0020304517021326306\n",
      "train loss:0.0032613147300646094\n",
      "train loss:0.00444849315040294\n",
      "train loss:0.0014547810215229855\n",
      "train loss:0.00046322605981347575\n",
      "train loss:0.0034497371308680317\n",
      "train loss:0.0019064995198943327\n",
      "train loss:0.0046065706905308425\n",
      "train loss:0.0006785412920046495\n",
      "train loss:0.001694938603700204\n",
      "train loss:0.0018743638235548027\n",
      "train loss:0.0023992179811761958\n",
      "train loss:0.0012568339096759743\n",
      "train loss:0.004078000530221965\n",
      "train loss:0.0003129742148654467\n",
      "train loss:0.0011752293285781387\n",
      "train loss:0.0005957462005534745\n",
      "train loss:0.0008405625584173012\n",
      "train loss:0.0011673180276917552\n",
      "train loss:0.002424316740653372\n",
      "train loss:0.0004843298740228387\n",
      "train loss:0.0008560376359535388\n",
      "train loss:0.000252845839094399\n",
      "train loss:0.0025655347132768273\n",
      "train loss:0.0032402954449232335\n",
      "train loss:0.0009277634430430361\n",
      "train loss:0.0017682750768600616\n",
      "train loss:0.003605148300985435\n",
      "train loss:0.003981822017826984\n",
      "train loss:0.0006461682053329303\n",
      "train loss:0.0006803445268902026\n",
      "train loss:0.0018257327032401027\n",
      "train loss:0.00238308208523187\n",
      "train loss:0.001242552196861132\n",
      "train loss:0.0012560415592342826\n",
      "train loss:0.0024619276751807377\n",
      "train loss:0.0018227466956778496\n",
      "train loss:0.0009125225499562455\n",
      "train loss:0.0006104266240409687\n",
      "train loss:0.0030812807104225962\n",
      "train loss:0.00346226726761078\n",
      "train loss:0.0022557535033916826\n",
      "train loss:0.0006532879473505757\n",
      "train loss:0.0003863536234592673\n",
      "train loss:0.00056767484147514\n",
      "train loss:0.0011836578655653887\n",
      "train loss:0.005415098866711504\n",
      "train loss:0.0013982687508345627\n",
      "train loss:0.0031045067396060716\n",
      "train loss:0.0002554984982139427\n",
      "train loss:0.0017333135423324602\n",
      "train loss:0.0020743036865604175\n",
      "train loss:0.0005987779807753029\n",
      "train loss:0.001387826515857014\n",
      "train loss:0.0014453390708161012\n",
      "train loss:0.0016063445182241927\n",
      "train loss:0.00032871884132224823\n",
      "train loss:0.002252581599574243\n",
      "train loss:0.0037805631440630113\n",
      "train loss:0.0015108178231143905\n",
      "train loss:0.0023304643576092148\n",
      "train loss:0.000970020886107048\n",
      "train loss:0.0027757827182674473\n",
      "train loss:0.0019046839930881483\n",
      "train loss:0.00045849668864552686\n",
      "train loss:0.001129604736721544\n",
      "train loss:0.004001098560791924\n",
      "train loss:0.0005877050050619952\n",
      "train loss:0.0006528282963736145\n",
      "train loss:0.00036928508690534296\n",
      "train loss:0.004744348031278217\n",
      "train loss:0.0013274819002740282\n",
      "train loss:0.0005140120308007506\n",
      "train loss:0.0005035951308166709\n",
      "train loss:0.001497766172240632\n",
      "train loss:0.00243558571126006\n",
      "train loss:0.003919290419509929\n",
      "train loss:0.0014815971937353367\n",
      "train loss:0.0004712470284276932\n",
      "train loss:0.0038945658310712856\n",
      "train loss:0.0036330243926058934\n",
      "train loss:0.000780733897435907\n",
      "train loss:0.0012133819525863689\n",
      "train loss:0.002926335859218934\n",
      "train loss:0.005245202191228526\n",
      "train loss:0.0010859508529662415\n",
      "train loss:0.0025294698542563765\n",
      "train loss:0.028845502940596277\n",
      "train loss:0.0016115221694626104\n",
      "train loss:0.0018924181963108154\n",
      "train loss:0.0007037419384651969\n",
      "train loss:0.0005920899326184348\n",
      "train loss:0.0014624586418096421\n",
      "train loss:0.0012016164773499532\n",
      "train loss:0.002903385756776796\n",
      "train loss:0.0003972481503556682\n",
      "train loss:0.0006758551666040969\n",
      "train loss:0.0006606459886720006\n",
      "train loss:0.001320770935757199\n",
      "train loss:0.0007202710565586515\n",
      "train loss:0.0003699589138385264\n",
      "train loss:0.0008330533837597779\n",
      "train loss:0.0009870838578271903\n",
      "train loss:0.0018863117397010449\n",
      "train loss:0.0011647805882823085\n",
      "train loss:0.004976033615499949\n",
      "train loss:0.001024006189298972\n",
      "train loss:0.0012701282563591565\n",
      "train loss:0.0028584332074752454\n",
      "train loss:0.003935435621625951\n",
      "train loss:0.021633569943156537\n",
      "train loss:0.00365676191677011\n",
      "train loss:0.001809302162231093\n",
      "train loss:0.0007732064468526469\n",
      "train loss:0.013560777753058363\n",
      "train loss:0.002417424011368406\n",
      "train loss:0.0016572544278709161\n",
      "train loss:0.002158741815300164\n",
      "train loss:0.019225059005319598\n",
      "train loss:0.0024032855316942154\n",
      "train loss:0.001782144304124392\n",
      "train loss:0.0009976611170135778\n",
      "train loss:0.003590251797870634\n",
      "train loss:0.001056367044116285\n",
      "train loss:0.004117142387742324\n",
      "train loss:0.0019370862759420936\n",
      "train loss:0.0032384126549020813\n",
      "train loss:0.0017927021530004324\n",
      "train loss:0.00045612187724961126\n",
      "train loss:0.0006960691934106592\n",
      "train loss:0.00851894954151181\n",
      "train loss:0.0024376290710462476\n",
      "train loss:0.0019646512293432423\n",
      "train loss:0.0034413619813824267\n",
      "train loss:0.006578876966103831\n",
      "train loss:0.0032168645699008074\n",
      "train loss:0.0019942545308826547\n",
      "train loss:0.002256869085608901\n",
      "train loss:0.0010421259188125272\n",
      "train loss:0.0008524480711422391\n",
      "train loss:0.0005039839961061401\n",
      "train loss:0.0017216539781516984\n",
      "train loss:0.002001600389649314\n",
      "train loss:0.002093537031165827\n",
      "train loss:0.0018158709301263926\n",
      "train loss:0.0016398388760246838\n",
      "train loss:0.001292185748152466\n",
      "train loss:0.005142365690305503\n",
      "train loss:0.0022392981521718075\n",
      "train loss:0.001882714859632892\n",
      "train loss:0.002956856069490595\n",
      "train loss:0.00158819456881596\n",
      "train loss:0.00785319418430751\n",
      "train loss:0.0011110776167329972\n",
      "train loss:0.0014220143559263445\n",
      "train loss:0.00022870407815612614\n",
      "train loss:0.00035154898472295766\n",
      "=== epoch:12, train acc:0.999, test acc:0.991 ===\n",
      "train loss:0.0019958815718812022\n",
      "train loss:0.0009972897755284864\n",
      "train loss:0.002956808105354337\n",
      "train loss:0.0046448072309964745\n",
      "train loss:0.0016866017255793247\n",
      "train loss:0.003323790880215708\n",
      "train loss:0.0013450870973126226\n",
      "train loss:0.00502250003241649\n",
      "train loss:0.003991402275790524\n",
      "train loss:0.00047575226047942093\n",
      "train loss:0.004764076116751888\n",
      "train loss:0.0019855604710474818\n",
      "train loss:0.0020641271624786614\n",
      "train loss:0.005469205281563968\n",
      "train loss:0.004960950512694709\n",
      "train loss:0.0024221268885924554\n",
      "train loss:0.0005916948879107018\n",
      "train loss:0.0006417901548869388\n",
      "train loss:0.0016322687833282977\n",
      "train loss:0.0058070311995346\n",
      "train loss:0.0005159092361958045\n",
      "train loss:0.000104884789820439\n",
      "train loss:0.0018183957432994127\n",
      "train loss:0.002851425491816569\n",
      "train loss:0.001192071254327638\n",
      "train loss:0.0009505606210957098\n",
      "train loss:0.001175451660089387\n",
      "train loss:0.0015060998346700526\n",
      "train loss:0.002939359171993816\n",
      "train loss:0.012927829670352298\n",
      "train loss:0.0015699973605608258\n",
      "train loss:0.0016462136857778944\n",
      "train loss:0.0076261716047264635\n",
      "train loss:0.00012930646309369478\n",
      "train loss:0.0013282718209087824\n",
      "train loss:0.0012592266377397352\n",
      "train loss:0.007368245834245475\n",
      "train loss:0.0002885122886997308\n",
      "train loss:0.0030867935227816517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003991733029744607\n",
      "train loss:0.001803401110437767\n",
      "train loss:0.0019807447337692402\n",
      "train loss:0.0019261912758351417\n",
      "train loss:0.002425232003523556\n",
      "train loss:0.0004932973363691352\n",
      "train loss:0.0008554277876709771\n",
      "train loss:0.0017185852816861595\n",
      "train loss:0.001085359940831875\n",
      "train loss:0.00035425729902416336\n",
      "train loss:0.0001964154840670323\n",
      "train loss:0.0011214966454245248\n",
      "train loss:0.0017281557796389898\n",
      "train loss:0.0011356939988609828\n",
      "train loss:0.0012747172302152883\n",
      "train loss:0.0003748456375397685\n",
      "train loss:0.00023719024035424505\n",
      "train loss:0.0014709140967385237\n",
      "train loss:0.0001575874901670444\n",
      "train loss:0.0005232800669779991\n",
      "train loss:0.0024731163956319734\n",
      "train loss:0.0007204347637070236\n",
      "train loss:0.0016317115777431084\n",
      "train loss:0.00021254664495339595\n",
      "train loss:0.001473568928864226\n",
      "train loss:0.0011411002526562012\n",
      "train loss:0.0007288873195175813\n",
      "train loss:0.0017059623516922809\n",
      "train loss:0.0037327999395669123\n",
      "train loss:0.0006309532995851068\n",
      "train loss:0.00035570379596577156\n",
      "train loss:0.0005621459651436782\n",
      "train loss:0.004943909464542948\n",
      "train loss:0.0006951400740791257\n",
      "train loss:0.0005714756223241067\n",
      "train loss:0.0016644769503993447\n",
      "train loss:0.0009119377274147408\n",
      "train loss:0.0003200052764541073\n",
      "train loss:0.0012593507965830684\n",
      "train loss:0.0005283922484146302\n",
      "train loss:0.00038032771448640235\n",
      "train loss:0.0001235908348361922\n",
      "train loss:9.983778994373342e-05\n",
      "train loss:0.0005477254855390858\n",
      "train loss:0.0008884158721832327\n",
      "train loss:0.00046571842591594867\n",
      "train loss:0.0002806548867793441\n",
      "train loss:0.0008485003334835535\n",
      "train loss:0.0019038388158648014\n",
      "train loss:2.4054733685587724e-05\n",
      "train loss:0.0006245789838462345\n",
      "train loss:0.00017755688974076646\n",
      "train loss:0.002347289538316986\n",
      "train loss:0.0010324516239634033\n",
      "train loss:0.001033700380119614\n",
      "train loss:0.002026659690539941\n",
      "train loss:0.0015115421464214772\n",
      "train loss:0.0002335965477189788\n",
      "train loss:0.0009060854338530192\n",
      "train loss:0.0013967517287983772\n",
      "train loss:0.0019582636423610147\n",
      "train loss:0.002159636228505443\n",
      "train loss:0.0005164663967879601\n",
      "train loss:0.0009545598028174855\n",
      "train loss:0.00027259230125870824\n",
      "train loss:0.004161810208725741\n",
      "train loss:0.0017433271899895792\n",
      "train loss:0.001095429617467731\n",
      "train loss:0.00015146005549717745\n",
      "train loss:0.00018775399082047493\n",
      "train loss:0.0005165790784601308\n",
      "train loss:0.001094903190571689\n",
      "train loss:0.00023465325884685582\n",
      "train loss:0.0023552663398762794\n",
      "train loss:0.0011023484556568735\n",
      "train loss:0.00022386741621440467\n",
      "train loss:5.391267186198828e-05\n",
      "train loss:0.000209077424312163\n",
      "train loss:0.0006532156825569769\n",
      "train loss:0.00040490832231465386\n",
      "train loss:0.0007948527812335815\n",
      "train loss:0.000335547856145446\n",
      "train loss:0.0003470145918630201\n",
      "train loss:0.00030706083364632147\n",
      "train loss:0.0006127314370214045\n",
      "train loss:0.0009115709536410123\n",
      "train loss:0.00047493152336541865\n",
      "train loss:0.0008439080451802414\n",
      "train loss:0.0006409888223495659\n",
      "train loss:0.0016489181993684092\n",
      "train loss:0.0005579911855127024\n",
      "train loss:0.0003715670224732858\n",
      "train loss:0.0009181401846543455\n",
      "train loss:0.0006616897935302358\n",
      "train loss:9.159169381997468e-05\n",
      "train loss:0.0011239764641325898\n",
      "train loss:0.0004435133619329622\n",
      "train loss:0.0005458253892829467\n",
      "train loss:0.00166657502010589\n",
      "train loss:6.9142667472815e-05\n",
      "train loss:0.0009698408361015503\n",
      "train loss:0.0011822890090941785\n",
      "train loss:0.0010501646397804215\n",
      "train loss:0.0013816112908968184\n",
      "train loss:0.0010800031369371074\n",
      "train loss:0.0014947146445314283\n",
      "train loss:0.0005434353151259746\n",
      "train loss:0.0004169959485098024\n",
      "train loss:0.0007275280174688417\n",
      "train loss:0.0005128311820988097\n",
      "train loss:0.0007693511250772685\n",
      "train loss:0.0009272178096975831\n",
      "train loss:0.002213578506717675\n",
      "train loss:0.00018170741427708052\n",
      "train loss:8.875376093091764e-05\n",
      "train loss:0.0004976799783635339\n",
      "train loss:0.00029645907813536667\n",
      "train loss:0.00042443042768087043\n",
      "train loss:8.470924559907147e-05\n",
      "train loss:0.0002146497528158428\n",
      "train loss:0.0009990967506638892\n",
      "train loss:0.0004734761337408036\n",
      "train loss:0.0006969327712568603\n",
      "train loss:0.00038373238779877033\n",
      "train loss:0.00042393990016709453\n",
      "train loss:0.00012126470957829466\n",
      "train loss:0.00041728068169932765\n",
      "train loss:0.000295870030535765\n",
      "train loss:0.0011374061550768763\n",
      "train loss:0.0007769279243602952\n",
      "train loss:0.0008320610727403212\n",
      "train loss:0.001006084628585806\n",
      "train loss:0.0002976869377464606\n",
      "train loss:0.0006840093447052411\n",
      "train loss:0.0002561963477362082\n",
      "train loss:0.0004982501306641375\n",
      "train loss:0.0002749563078130562\n",
      "train loss:0.0008981904088467905\n",
      "train loss:0.0017823849568682556\n",
      "train loss:0.00048187681152549503\n",
      "train loss:0.0006375289634111494\n",
      "train loss:0.0007990055315972907\n",
      "train loss:0.00013089610214112198\n",
      "train loss:0.0005277886994283796\n",
      "train loss:0.0003533425736157485\n",
      "train loss:0.0006428885708742047\n",
      "train loss:0.0013677009156837774\n",
      "train loss:0.00044208969446968375\n",
      "train loss:0.0001478914298737463\n",
      "train loss:0.0009416058634811533\n",
      "train loss:0.0003621425913657099\n",
      "train loss:0.0004970067015836176\n",
      "train loss:0.003378393416451991\n",
      "train loss:0.0004540780352363438\n",
      "train loss:0.0015176130773080115\n",
      "train loss:0.0003125287363598924\n",
      "train loss:0.00027495111218835155\n",
      "train loss:0.0006999024221909175\n",
      "train loss:0.0013603065754770177\n",
      "train loss:0.0002654402237908894\n",
      "train loss:0.00012575743895317404\n",
      "train loss:0.0006764487231505832\n",
      "train loss:0.0014498199848371866\n",
      "train loss:0.0008653822964917576\n",
      "train loss:0.0006486425765482513\n",
      "train loss:0.0004811218778666848\n",
      "train loss:0.0009670295323701543\n",
      "train loss:0.0010271604786047195\n",
      "train loss:0.001394626134058597\n",
      "train loss:0.0013128607481844125\n",
      "train loss:0.0060098921339920815\n",
      "train loss:0.0008365074048743594\n",
      "train loss:0.0004795295613471321\n",
      "train loss:0.00014603651247410362\n",
      "train loss:0.00013974876742540987\n",
      "train loss:0.00011820126766629371\n",
      "train loss:0.0006590324422604193\n",
      "train loss:0.0012285610425021576\n",
      "train loss:0.0004657621306998065\n",
      "train loss:0.00011281588316311082\n",
      "train loss:0.00028076218927904225\n",
      "train loss:0.0007890858712186075\n",
      "train loss:0.000816663749393978\n",
      "train loss:0.0002673144167497536\n",
      "train loss:0.0016365627800337722\n",
      "train loss:0.0004991899784585032\n",
      "train loss:0.0003209168371808222\n",
      "train loss:0.0009883324543508043\n",
      "train loss:0.0009674074764400884\n",
      "train loss:0.0005581513822717849\n",
      "train loss:0.0004935822696741389\n",
      "train loss:0.0015531281151498683\n",
      "train loss:0.0005075453905712755\n",
      "train loss:0.0001470305694110894\n",
      "train loss:0.0006386718654074076\n",
      "train loss:0.0004273322346879072\n",
      "train loss:0.00019323079240981706\n",
      "train loss:0.0002322290928359752\n",
      "train loss:0.00015663851164960876\n",
      "train loss:0.0002196528446070791\n",
      "train loss:0.0008189335802801461\n",
      "train loss:0.001134297737978571\n",
      "train loss:0.0003191902812424227\n",
      "train loss:0.0028956935684283504\n",
      "train loss:0.0003648763396442679\n",
      "train loss:0.00042331892955881203\n",
      "train loss:0.00021706077267171693\n",
      "train loss:0.00012912611385880007\n",
      "train loss:0.0010261494789165226\n",
      "train loss:0.0013712637788059455\n",
      "train loss:0.0005632244610402076\n",
      "train loss:0.0011036261108745048\n",
      "train loss:0.0001625978171083447\n",
      "train loss:0.00123899400257467\n",
      "train loss:0.0021822758098733307\n",
      "train loss:0.00032937505167076085\n",
      "train loss:0.0005434969041532599\n",
      "train loss:0.0005847664789872257\n",
      "train loss:0.0005275049132478227\n",
      "train loss:0.0010123067393859098\n",
      "train loss:0.0003158301059447484\n",
      "train loss:0.001112475102310659\n",
      "train loss:0.000548486863482851\n",
      "train loss:0.004137376711423509\n",
      "train loss:0.0007719376708227697\n",
      "train loss:0.00035072035245758764\n",
      "train loss:0.0004394489541653674\n",
      "train loss:0.00022114881058229145\n",
      "train loss:0.0005458781663105589\n",
      "train loss:0.0009964530386411957\n",
      "train loss:9.10836553342099e-05\n",
      "train loss:0.000479504413167041\n",
      "train loss:0.0008158133501612682\n",
      "train loss:0.0002635951504556322\n",
      "train loss:0.0001567161121879205\n",
      "train loss:0.000304433081114964\n",
      "train loss:0.0011384468023247342\n",
      "train loss:0.0001563272194337535\n",
      "train loss:0.0006802516874403193\n",
      "train loss:0.001284628188324255\n",
      "train loss:0.0006041567827509748\n",
      "train loss:0.000823167654981378\n",
      "train loss:0.0001364978343030905\n",
      "train loss:0.0005456321747979449\n",
      "train loss:0.001397555224512722\n",
      "train loss:0.00045145230391530625\n",
      "train loss:4.008375345464827e-05\n",
      "train loss:0.00014174422038173737\n",
      "train loss:0.0002852957086073416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006758136312094259\n",
      "train loss:6.256497945286887e-05\n",
      "train loss:0.0003864312908052788\n",
      "train loss:0.00035118199320115554\n",
      "train loss:0.0005865796277959184\n",
      "train loss:0.0003167562338923718\n",
      "train loss:0.001404252226513096\n",
      "train loss:0.0024944786537056487\n",
      "train loss:0.0001162038507792575\n",
      "train loss:0.00024566282245510435\n",
      "train loss:0.0006475870661755499\n",
      "train loss:0.0002102780015393221\n",
      "train loss:0.0009152063191744304\n",
      "train loss:0.0022253222728465735\n",
      "train loss:0.001910583166714073\n",
      "train loss:0.00045191492712822335\n",
      "train loss:0.0002626474813304933\n",
      "train loss:0.0014797302232562029\n",
      "train loss:0.0009633726684838674\n",
      "train loss:8.573731262346189e-05\n",
      "train loss:0.00022244927506430133\n",
      "train loss:0.001107785741653935\n",
      "train loss:0.0005404814400056737\n",
      "train loss:0.000618027208453361\n",
      "train loss:0.000752585366517414\n",
      "train loss:0.00044016167310743676\n",
      "train loss:1.766011081242296e-05\n",
      "train loss:0.0014010554279011787\n",
      "train loss:0.0003084894947554307\n",
      "train loss:0.0017382792378718604\n",
      "train loss:0.0006665372598226752\n",
      "train loss:0.0014140939564363153\n",
      "train loss:0.001290456524529788\n",
      "train loss:0.0008379201372296171\n",
      "train loss:0.001191170943048515\n",
      "train loss:0.0002232016084784529\n",
      "train loss:0.0016161917228196291\n",
      "train loss:0.002083247713778982\n",
      "train loss:0.0007608731457766033\n",
      "train loss:0.0005696170349908005\n",
      "train loss:0.00048307043277718523\n",
      "train loss:0.0004055697556057881\n",
      "train loss:0.0034502010467754906\n",
      "train loss:0.0009444550904031628\n",
      "train loss:0.0007954872936503124\n",
      "train loss:0.0010348473786172064\n",
      "train loss:0.001560882573839729\n",
      "train loss:0.0009431401546699219\n",
      "train loss:0.002350566565295113\n",
      "train loss:0.0008715007075684426\n",
      "train loss:0.00018088275413826921\n",
      "train loss:0.0001258038884030259\n",
      "train loss:0.00014596250148420575\n",
      "train loss:4.246530161447469e-05\n",
      "train loss:0.0003790739971534859\n",
      "train loss:0.00038038413029786613\n",
      "train loss:0.0010290218131296348\n",
      "train loss:0.00014276076203605998\n",
      "train loss:0.0015794191044378038\n",
      "train loss:7.341781200604969e-05\n",
      "train loss:0.0007030310607587848\n",
      "train loss:0.00047148125827447114\n",
      "train loss:0.00017224251336887136\n",
      "train loss:0.0008379707781362402\n",
      "train loss:0.0009959409856560375\n",
      "train loss:0.0016987080085234772\n",
      "train loss:0.0002901619806198514\n",
      "train loss:0.001592943262417972\n",
      "train loss:0.0005856480382206851\n",
      "train loss:0.0025817429775453252\n",
      "train loss:0.001687512864859898\n",
      "train loss:0.002153558603495913\n",
      "train loss:0.00036846387978441494\n",
      "train loss:0.00026474780383461423\n",
      "train loss:0.00018817833333868708\n",
      "train loss:0.0006606063163705422\n",
      "train loss:0.00039319087218507386\n",
      "train loss:0.0008364026771303921\n",
      "train loss:0.000247638727296304\n",
      "train loss:0.0008971537055697534\n",
      "=== epoch:13, train acc:1.0, test acc:0.996 ===\n",
      "train loss:0.00034528967724828705\n",
      "train loss:0.004627766719862266\n",
      "train loss:0.00022106848902189784\n",
      "train loss:0.0006379878828733117\n",
      "train loss:0.0005268829992306545\n",
      "train loss:0.0017381291656039452\n",
      "train loss:0.0002719100651743033\n",
      "train loss:0.0016704215187496201\n",
      "train loss:0.002241032025105931\n",
      "train loss:0.0014885510620574955\n",
      "train loss:0.0011074784937856945\n",
      "train loss:0.00036248941713664534\n",
      "train loss:0.004106474712739988\n",
      "train loss:0.00016082208158128876\n",
      "train loss:0.0008570163312863029\n",
      "train loss:7.794617288572886e-05\n",
      "train loss:0.00038005594487372057\n",
      "train loss:0.0005634487263527443\n",
      "train loss:0.00016126124895233414\n",
      "train loss:0.002860442107945129\n",
      "train loss:0.0012878878921197161\n",
      "train loss:0.0001900535675557712\n",
      "train loss:0.00018564717312909463\n",
      "train loss:0.00010000496149776591\n",
      "train loss:0.0010589761205368647\n",
      "train loss:0.0006378251646172811\n",
      "train loss:0.002212390687058402\n",
      "train loss:0.0006019391957965298\n",
      "train loss:0.00011506148357337865\n",
      "train loss:0.00035160624778165643\n",
      "train loss:0.0014328052518846354\n",
      "train loss:0.0030890591622389136\n",
      "train loss:0.0014778118703581782\n",
      "train loss:0.00106398507792151\n",
      "train loss:0.0013172124902978432\n",
      "train loss:0.0005804008292911514\n",
      "train loss:0.00044412660541029436\n",
      "train loss:0.0009485028414148531\n",
      "train loss:0.002273230322166128\n",
      "train loss:0.0007705811267217781\n",
      "train loss:0.0005861773635795611\n",
      "train loss:0.00012469933673920277\n",
      "train loss:0.0002948064734062153\n",
      "train loss:0.0001590122793450154\n",
      "train loss:0.00030221510150039613\n",
      "train loss:8.50408763752543e-05\n",
      "train loss:0.00019918580179785738\n",
      "train loss:0.0006476977095384545\n",
      "train loss:0.0011934010388914647\n",
      "train loss:0.00014875422995204123\n",
      "train loss:0.001034979403802169\n",
      "train loss:0.0005092827106240881\n",
      "train loss:0.004687880694751777\n",
      "train loss:0.0007968712494377993\n",
      "train loss:0.00026423458253517566\n",
      "train loss:0.0005654890944332063\n",
      "train loss:0.0007396069177605505\n",
      "train loss:0.0010672311072235402\n",
      "train loss:0.004174710869428665\n",
      "train loss:0.0019510688789890435\n",
      "train loss:0.004148983817305151\n",
      "train loss:0.001590663186588486\n",
      "train loss:0.00028373730521024325\n",
      "train loss:0.0013417962837155692\n",
      "train loss:0.0010411584217456834\n",
      "train loss:0.00016771718554943192\n",
      "train loss:0.0003278687938237876\n",
      "train loss:0.00016393374511637908\n",
      "train loss:0.002052704371648923\n",
      "train loss:0.00026963185565233907\n",
      "train loss:0.0011252685872711323\n",
      "train loss:0.0014397278141689517\n",
      "train loss:0.00010409088271103037\n",
      "train loss:0.0014008444114653924\n",
      "train loss:0.0011622278859054693\n",
      "train loss:0.0005145086929448095\n",
      "train loss:0.00019353155531600375\n",
      "train loss:0.0007246852979810282\n",
      "train loss:0.00018681133853064657\n",
      "train loss:0.0035364748964586204\n",
      "train loss:0.0004174861419590944\n",
      "train loss:0.00014546091140803444\n",
      "train loss:0.0006327097758204462\n",
      "train loss:0.002135236625620642\n",
      "train loss:0.0015103223688831236\n",
      "train loss:0.00047815520654711136\n",
      "train loss:0.001714876394821183\n",
      "train loss:0.00227330509820408\n",
      "train loss:0.0001590191162043103\n",
      "train loss:0.0005937695622179733\n",
      "train loss:0.0008641935514970902\n",
      "train loss:0.0013591629482157719\n",
      "train loss:0.003301915281877918\n",
      "train loss:0.0009412162086793484\n",
      "train loss:0.0002440648430690361\n",
      "train loss:0.00042950166214530283\n",
      "train loss:0.0008121337133353494\n",
      "train loss:0.0011966361228785422\n",
      "train loss:0.00047133464708386534\n",
      "train loss:0.0002842324538524057\n",
      "train loss:0.0017963619013050959\n",
      "train loss:0.0013797228340786442\n",
      "train loss:0.0003918211032009319\n",
      "train loss:0.0001662812378095174\n",
      "train loss:0.0001992593373141643\n",
      "train loss:0.0001274593302611012\n",
      "train loss:6.626039007477205e-05\n",
      "train loss:0.00017254459928717423\n",
      "train loss:0.00020490721459131306\n",
      "train loss:0.00020841248233823188\n",
      "train loss:0.00048645898538812504\n",
      "train loss:0.00011717172262387448\n",
      "train loss:0.0002287421271998457\n",
      "train loss:0.0011810306312027641\n",
      "train loss:0.0004588814663809942\n",
      "train loss:0.0002031807591896492\n",
      "train loss:0.0006168833144972886\n",
      "train loss:0.0004753112110728142\n",
      "train loss:0.0004627580398108335\n",
      "train loss:0.0001858358454679897\n",
      "train loss:0.00027102343630290283\n",
      "train loss:0.000511568927135463\n",
      "train loss:0.000620686995656957\n",
      "train loss:0.00031300910609001215\n",
      "train loss:0.0002396766839960876\n",
      "train loss:0.0004140731907859832\n",
      "train loss:5.3820056843247695e-05\n",
      "train loss:5.815675660489716e-05\n",
      "train loss:0.00041029103434166663\n",
      "train loss:0.00036158146872095114\n",
      "train loss:0.0002515240491615811\n",
      "train loss:9.93570212625065e-05\n",
      "train loss:0.001117687337211928\n",
      "train loss:0.0006831064222779039\n",
      "train loss:0.000642726981244558\n",
      "train loss:0.00024259696411299856\n",
      "train loss:0.0007552773319971782\n",
      "train loss:0.0007347769522213194\n",
      "train loss:0.00047167509272002877\n",
      "train loss:0.0011494022698373722\n",
      "train loss:0.00020795760206132006\n",
      "train loss:0.0006254286201708629\n",
      "train loss:0.00014183047184420386\n",
      "train loss:0.0002954487814667823\n",
      "train loss:0.000765907736501007\n",
      "train loss:0.0007625116144186608\n",
      "train loss:9.451719998814545e-05\n",
      "train loss:0.0005296728596512287\n",
      "train loss:0.00013870598100584747\n",
      "train loss:0.0005181753540250744\n",
      "train loss:5.575343309478299e-05\n",
      "train loss:1.6299149239226135e-05\n",
      "train loss:0.00012114192650354246\n",
      "train loss:0.0003261678898018031\n",
      "train loss:0.0005646113736341318\n",
      "train loss:0.00026890603593472245\n",
      "train loss:0.00025910369318990717\n",
      "train loss:0.00042420617943012435\n",
      "train loss:0.001054298443054008\n",
      "train loss:0.0001820064383229455\n",
      "train loss:0.00097821973635794\n",
      "train loss:0.00037767050046898953\n",
      "train loss:0.00036498586382831326\n",
      "train loss:0.0017704431468928586\n",
      "train loss:0.00014449406710067395\n",
      "train loss:0.00013733544197359624\n",
      "train loss:0.00017851034929859056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00016038800224409065\n",
      "train loss:0.0001621365689391177\n",
      "train loss:0.0005331220216069893\n",
      "train loss:0.00030439809636229856\n",
      "train loss:9.252130579929186e-05\n",
      "train loss:0.0003939015798145127\n",
      "train loss:0.00046668514011875963\n",
      "train loss:0.00019133457821609513\n",
      "train loss:0.0002451038472870001\n",
      "train loss:0.00012356636102598325\n",
      "train loss:0.00047751524244931743\n",
      "train loss:0.00011617010285613596\n",
      "train loss:0.00020067849507603936\n",
      "train loss:0.0002701866029759952\n",
      "train loss:0.0002659627889857323\n",
      "train loss:0.000740095923102728\n",
      "train loss:0.00027403941452222737\n",
      "train loss:0.0004883536387234751\n",
      "train loss:0.0006681555139794261\n",
      "train loss:0.0005844837061835646\n",
      "train loss:0.00024321731210183046\n",
      "train loss:0.0005592614496607214\n",
      "train loss:0.00459373190093781\n",
      "train loss:0.0006106436176419476\n",
      "train loss:0.00044167153834895405\n",
      "train loss:0.0016675684815631675\n",
      "train loss:0.00045908663886797956\n",
      "train loss:0.0008949088683296187\n",
      "train loss:0.0016835175458372602\n",
      "train loss:0.00044027376525293185\n",
      "train loss:0.0007750211233132599\n",
      "train loss:0.0031526000740232886\n",
      "train loss:0.000349961604601972\n",
      "train loss:0.0010885742058091704\n",
      "train loss:0.0020162468562017364\n",
      "train loss:0.001070335569150924\n",
      "train loss:0.0004871132128824491\n",
      "train loss:0.00015948104566722795\n",
      "train loss:0.0006504644887092607\n",
      "train loss:0.0006781038541634266\n",
      "train loss:0.0006503651072679119\n",
      "train loss:0.0005245850044837919\n",
      "train loss:0.0003065207550885619\n",
      "train loss:0.0007876168206491108\n",
      "train loss:0.0011896045131862408\n",
      "train loss:0.00010324693024334975\n",
      "train loss:0.00010474012459593088\n",
      "train loss:0.004601926523699818\n",
      "train loss:7.875197696059156e-05\n",
      "train loss:0.00027063204367751997\n",
      "train loss:0.0012037231359759396\n",
      "train loss:0.003075658893282914\n",
      "train loss:0.0010018153420764501\n",
      "train loss:9.379467249529485e-05\n",
      "train loss:0.00014857984707366132\n",
      "train loss:0.0005935825705156293\n",
      "train loss:0.007488852471694258\n",
      "train loss:0.0003689368624671802\n",
      "train loss:0.000729599343388218\n",
      "train loss:0.00033689669512047853\n",
      "train loss:0.00043168758405001895\n",
      "train loss:0.0027720217836312163\n",
      "train loss:0.002195056668874441\n",
      "train loss:0.0003194125260143815\n",
      "train loss:0.002560288346682553\n",
      "train loss:0.00097762730238693\n",
      "train loss:0.00332533942576608\n",
      "train loss:0.00041323507678055676\n",
      "train loss:0.0007655668890065961\n",
      "train loss:0.0009345210272514291\n",
      "train loss:0.003036186126096704\n",
      "train loss:0.004172527641675002\n",
      "train loss:0.0032745948723900287\n",
      "train loss:0.0015027503230160626\n",
      "train loss:0.0005351307909038364\n",
      "train loss:0.001577811338140752\n",
      "train loss:0.001235769125623087\n",
      "train loss:0.002472689055808051\n",
      "train loss:0.0017781826423024102\n",
      "train loss:0.0012890197571670645\n",
      "train loss:0.00042845401354238\n",
      "train loss:0.000270098520422139\n",
      "train loss:0.03389336856510428\n",
      "train loss:0.0007887217644552766\n",
      "train loss:0.008378448013398284\n",
      "train loss:0.001262498309346517\n",
      "train loss:0.001353946514352225\n",
      "train loss:0.0005708687443946721\n",
      "train loss:0.006601955043837831\n",
      "train loss:0.0016944485482730334\n",
      "train loss:0.0007762704654050855\n",
      "train loss:0.001760450722992379\n",
      "train loss:0.0006536234298121975\n",
      "train loss:0.0026677398790584993\n",
      "train loss:0.00016569550066210438\n",
      "train loss:0.006348092197260471\n",
      "train loss:0.0011455567755651647\n",
      "train loss:0.0032861053856113142\n",
      "train loss:0.0010215622002221327\n",
      "train loss:0.0017167958570911972\n",
      "train loss:0.002391325360015184\n",
      "train loss:0.00340468872497814\n",
      "train loss:0.0014139983045196145\n",
      "train loss:0.0014410891714340074\n",
      "train loss:0.0003671688991550077\n",
      "train loss:0.001332726950489221\n",
      "train loss:0.0013395274323384568\n",
      "train loss:0.0011161752760693706\n",
      "train loss:0.00029028223975527737\n",
      "train loss:0.0028065453575046033\n",
      "train loss:0.003385774519993118\n",
      "train loss:0.0023470131405790963\n",
      "train loss:0.005364282217976992\n",
      "train loss:0.0036159577837716335\n",
      "train loss:0.007023445653043829\n",
      "train loss:0.002729607140222146\n",
      "train loss:0.0030862546913479217\n",
      "train loss:0.0023507329706010994\n",
      "train loss:0.00043043542662718286\n",
      "train loss:0.006253068766593301\n",
      "train loss:0.0002591542077713338\n",
      "train loss:0.0033387355466405217\n",
      "train loss:0.0033152007818855705\n",
      "train loss:0.0006672358612154989\n",
      "train loss:0.0028062962268127884\n",
      "train loss:0.004828332654911992\n",
      "train loss:0.010556031749995533\n",
      "train loss:0.0012320325515994166\n",
      "train loss:0.0010809699203988567\n",
      "train loss:0.0016980625729633577\n",
      "train loss:0.03624127617079767\n",
      "train loss:0.005554262760135779\n",
      "train loss:0.0010472088789557318\n",
      "train loss:0.002198509154332602\n",
      "train loss:0.0018437466337088845\n",
      "train loss:0.009888753904491572\n",
      "train loss:0.000321154769132731\n",
      "train loss:0.003292323992975889\n",
      "train loss:0.0019475502975867635\n",
      "train loss:0.002724089540999816\n",
      "train loss:0.0017147520999312214\n",
      "train loss:0.0019391586524411986\n",
      "train loss:0.0009519743096478933\n",
      "train loss:0.0018153821035570194\n",
      "train loss:0.0001008814200723962\n",
      "train loss:0.004345143540662332\n",
      "train loss:0.0046737460415114266\n",
      "train loss:0.003474147646048864\n",
      "train loss:0.0008196800561355176\n",
      "train loss:5.667231042637655e-05\n",
      "train loss:0.004927571498012201\n",
      "train loss:0.00011847460447787645\n",
      "train loss:0.0018886247708944255\n",
      "train loss:0.0018345575540472433\n",
      "train loss:0.0004649958872869942\n",
      "train loss:0.0002685567771549814\n",
      "train loss:0.0021915758367112292\n",
      "train loss:0.001402658643276688\n",
      "train loss:0.0015311723397796134\n",
      "train loss:0.0021748730850961544\n",
      "train loss:0.001398344040400843\n",
      "train loss:0.0008678516071313876\n",
      "train loss:0.000954105492438857\n",
      "train loss:0.0019551611978487595\n",
      "train loss:0.00040451732972925715\n",
      "train loss:0.0008959491475602655\n",
      "train loss:0.0019254121080145175\n",
      "train loss:0.0009322109854739313\n",
      "train loss:0.0008859866150074804\n",
      "train loss:0.0007774334965865586\n",
      "train loss:0.0005612055284136447\n",
      "train loss:0.013287264227562608\n",
      "train loss:0.0002752953510005969\n",
      "train loss:0.0003361685381125552\n",
      "train loss:0.0004295547663271746\n",
      "train loss:0.0017144969211681424\n",
      "train loss:0.0014192858658226705\n",
      "train loss:0.0006591708489807005\n",
      "train loss:0.0010696755696819019\n",
      "train loss:0.00394399539709912\n",
      "train loss:0.0031977919555050247\n",
      "train loss:0.0013318762461930129\n",
      "train loss:0.0011646900796645784\n",
      "train loss:0.0016557563108107916\n",
      "train loss:0.0022258162934568884\n",
      "train loss:0.003159580293672951\n",
      "train loss:0.0002485870541525536\n",
      "train loss:0.0010080997924899041\n",
      "train loss:4.880005087408931e-05\n",
      "train loss:0.0016700303193663204\n",
      "train loss:0.0002477815704450133\n",
      "train loss:0.0014241921370545996\n",
      "train loss:0.003948601382946783\n",
      "train loss:0.0013352978742017683\n",
      "train loss:9.832852182861748e-05\n",
      "train loss:0.0020583237656946166\n",
      "train loss:0.0010015622886511383\n",
      "train loss:0.0003538439620867274\n",
      "train loss:0.00048758765580650144\n",
      "train loss:0.007245672655254499\n",
      "train loss:0.000611248946305417\n",
      "=== epoch:14, train acc:0.997, test acc:0.996 ===\n",
      "train loss:0.0003674323620450436\n",
      "train loss:0.00025054004883850133\n",
      "train loss:0.0071377792914429404\n",
      "train loss:0.005017901441918753\n",
      "train loss:0.0013744081529519427\n",
      "train loss:0.001315951368212997\n",
      "train loss:0.0023875401808304384\n",
      "train loss:0.0016103298624919173\n",
      "train loss:0.0010439286097518486\n",
      "train loss:0.0006492740008281012\n",
      "train loss:0.0009664047015722292\n",
      "train loss:0.0011760532408052807\n",
      "train loss:0.0025695899086920953\n",
      "train loss:0.0004174910306035238\n",
      "train loss:0.0018879020723673145\n",
      "train loss:0.0006969633054419204\n",
      "train loss:0.0010367714429330224\n",
      "train loss:0.0017274664662121804\n",
      "train loss:0.0002041658004149278\n",
      "train loss:0.0009311424573866644\n",
      "train loss:0.0005983064660680268\n",
      "train loss:0.014153159465909998\n",
      "train loss:0.0015584792854135767\n",
      "train loss:0.0027331973622799683\n",
      "train loss:0.0017779413733784717\n",
      "train loss:0.0012897482914141659\n",
      "train loss:0.007189829342888464\n",
      "train loss:0.002022934414123866\n",
      "train loss:0.001053803923010988\n",
      "train loss:0.013150063325969743\n",
      "train loss:0.014336417227159427\n",
      "train loss:0.0002680520899991785\n",
      "train loss:0.0010281162567756966\n",
      "train loss:0.004072611455298713\n",
      "train loss:0.005829797862735489\n",
      "train loss:0.0033803568794376526\n",
      "train loss:0.02009868978079227\n",
      "train loss:0.0021159206308506554\n",
      "train loss:0.003815459726096574\n",
      "train loss:0.002586020540443809\n",
      "train loss:0.004952830223117834\n",
      "train loss:0.003927940461773898\n",
      "train loss:0.0017727248749243507\n",
      "train loss:0.006809259071454536\n",
      "train loss:0.0015903026946011555\n",
      "train loss:0.007408161504047949\n",
      "train loss:0.005172384586805108\n",
      "train loss:0.0076458857991956305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003674483314092379\n",
      "train loss:0.004413997160437205\n",
      "train loss:0.0021773386743267177\n",
      "train loss:0.0007230296017729603\n",
      "train loss:0.0025687103327154005\n",
      "train loss:0.0003198868797968542\n",
      "train loss:0.0018097880957005286\n",
      "train loss:0.0007140921359662935\n",
      "train loss:0.004682726676957841\n",
      "train loss:0.00691312613558838\n",
      "train loss:0.000424072434537167\n",
      "train loss:0.000851070132914283\n",
      "train loss:0.0006406597575437889\n",
      "train loss:0.000367808841730842\n",
      "train loss:0.0003726910122421651\n",
      "train loss:0.0010368613590122657\n",
      "train loss:0.0012532132622789234\n",
      "train loss:0.0012521404487368948\n",
      "train loss:0.0026731756851331645\n",
      "train loss:0.0011362092813701251\n",
      "train loss:0.002255786629204028\n",
      "train loss:0.00036136083345571695\n",
      "train loss:0.00037623370915968786\n",
      "train loss:0.0003291511802054111\n",
      "train loss:0.0028120585644166485\n",
      "train loss:0.0008722841743920519\n",
      "train loss:0.0025901998185967156\n",
      "train loss:0.00045879641251661546\n",
      "train loss:0.0021193513732973503\n",
      "train loss:0.00034415846920865463\n",
      "train loss:0.0036888305007571134\n",
      "train loss:0.003883069022727808\n",
      "train loss:0.0027177675156418927\n",
      "train loss:0.0016525380749287072\n",
      "train loss:0.0026023484902558533\n",
      "train loss:0.0011826696263333722\n",
      "train loss:0.0010609311713584743\n",
      "train loss:0.003928020271478\n",
      "train loss:0.0025633530576358744\n",
      "train loss:0.0042666184818769435\n",
      "train loss:0.0022713176472381985\n",
      "train loss:0.0022959184836697276\n",
      "train loss:0.0010933618409639943\n",
      "train loss:0.0011851706317859971\n",
      "train loss:0.0011199164599541612\n",
      "train loss:0.0015404130071010463\n",
      "train loss:0.001155707198563266\n",
      "train loss:0.0015461126349966292\n",
      "train loss:0.005046341439481913\n",
      "train loss:0.004267358361413256\n",
      "train loss:0.0008857661876757746\n",
      "train loss:0.006222279292138009\n",
      "train loss:0.0007081900202015178\n",
      "train loss:0.004290538381565109\n",
      "train loss:0.0036683285099272777\n",
      "train loss:0.005865723833468301\n",
      "train loss:0.0002862671501366413\n",
      "train loss:0.0008098911027116369\n",
      "train loss:0.002977690139615874\n",
      "train loss:0.0028919293823115033\n",
      "train loss:0.015071201828423844\n",
      "train loss:0.015679762894234152\n",
      "train loss:0.0014907198626405674\n",
      "train loss:0.002354257543829838\n",
      "train loss:0.002338401910462584\n",
      "train loss:0.0031311390412119794\n",
      "train loss:0.0018290634385053984\n",
      "train loss:0.0020279616140462856\n",
      "train loss:0.0008795506443377367\n",
      "train loss:0.0010591010591998783\n",
      "train loss:0.0013905345294833978\n",
      "train loss:0.001477765325409497\n",
      "train loss:0.0008795876920836839\n",
      "train loss:0.00485925857072362\n",
      "train loss:0.001510700670404596\n",
      "train loss:0.005060648084017933\n",
      "train loss:0.003478252534262977\n",
      "train loss:0.00447153489028258\n",
      "train loss:0.0012191656691960787\n",
      "train loss:0.012306514189961792\n",
      "train loss:0.0006479554568121474\n",
      "train loss:0.013009042569062039\n",
      "train loss:0.002429648420010604\n",
      "train loss:0.002257729121130919\n",
      "train loss:0.04146567443665388\n",
      "train loss:0.0028652667411873623\n",
      "train loss:0.0008911449144566856\n",
      "train loss:0.001203130672811435\n",
      "train loss:0.0006266662066882796\n",
      "train loss:0.0012197587871128717\n",
      "train loss:0.00230628865165809\n",
      "train loss:0.000714654302652205\n",
      "train loss:0.0023366138788080628\n",
      "train loss:0.0006498893204052208\n",
      "train loss:0.0017793866970528158\n",
      "train loss:0.00260069695750368\n",
      "train loss:0.0009205051483472167\n",
      "train loss:0.000980294294056222\n",
      "train loss:0.00013952333234632455\n",
      "train loss:0.003069311012698318\n",
      "train loss:0.0027274234903569487\n",
      "train loss:0.004261509117347229\n",
      "train loss:0.006333950920159773\n",
      "train loss:0.00016995071873113793\n",
      "train loss:0.0018734367240694318\n",
      "train loss:0.001644738102582224\n",
      "train loss:0.0008894118116268393\n",
      "train loss:0.0012733854779738384\n",
      "train loss:0.0006900629447143367\n",
      "train loss:0.004512673064820896\n",
      "train loss:0.00272627066903806\n",
      "train loss:0.0006779343718809792\n",
      "train loss:0.0010352407659775414\n",
      "train loss:0.0013109954700587742\n",
      "train loss:0.003197810417828336\n",
      "train loss:0.0020129938880381684\n",
      "train loss:0.00046986343696553526\n",
      "train loss:0.0002750721577399839\n",
      "train loss:0.0019567504241708206\n",
      "train loss:0.0030620788657516437\n",
      "train loss:0.0017269677747144808\n",
      "train loss:0.0017536538337912906\n",
      "train loss:0.0014745549114601876\n",
      "train loss:0.0010977762547294372\n",
      "train loss:0.003674584592897725\n",
      "train loss:0.0012222139290199684\n",
      "train loss:0.0015007543949949527\n",
      "train loss:0.0003986593113377495\n",
      "train loss:0.0006002846784474663\n",
      "train loss:0.0005034204529855768\n",
      "train loss:0.0015578265248830264\n",
      "train loss:0.0003408773307952135\n",
      "train loss:0.0004394958934051749\n",
      "train loss:0.0006735722615167435\n",
      "train loss:0.0002056164325603984\n",
      "train loss:0.00031545473098261364\n",
      "train loss:0.00028790555587890945\n",
      "train loss:0.00031037840070644815\n",
      "train loss:0.00024694951776555287\n",
      "train loss:0.00022556220303047425\n",
      "train loss:0.001107934495575711\n",
      "train loss:0.0006746852342889454\n",
      "train loss:0.0003291078482719777\n",
      "train loss:0.00027831636664562746\n",
      "train loss:0.0007890535522370674\n",
      "train loss:0.012934736563374875\n",
      "train loss:0.0033398168318068645\n",
      "train loss:0.0004528576882004734\n",
      "train loss:0.0005654491522709036\n",
      "train loss:0.0027939258594315212\n",
      "train loss:0.00021433826247969665\n",
      "train loss:0.0013025584802679117\n",
      "train loss:0.0009059323841020734\n",
      "train loss:0.0011859983838944676\n",
      "train loss:0.001467890081428413\n",
      "train loss:0.0018648700829336962\n",
      "train loss:0.005122475245619841\n",
      "train loss:7.7346924341698e-05\n",
      "train loss:0.0005872650062669554\n",
      "train loss:0.00037445171266437796\n",
      "train loss:0.00021926911718451593\n",
      "train loss:0.009043179750815674\n",
      "train loss:0.0015149521884299337\n",
      "train loss:0.0006979465555659039\n",
      "train loss:0.001762053009017985\n",
      "train loss:0.007491744115630509\n",
      "train loss:0.0025450468358257216\n",
      "train loss:0.0018592912458910565\n",
      "train loss:0.0014172664282327268\n",
      "train loss:0.004084312947526382\n",
      "train loss:0.001028920620359611\n",
      "train loss:0.003467333151025162\n",
      "train loss:0.002461440488823145\n",
      "train loss:0.0022249678163134222\n",
      "train loss:0.0009472915152936786\n",
      "train loss:0.0022197714912877975\n",
      "train loss:0.0021958990877128702\n",
      "train loss:0.0017432282210978237\n",
      "train loss:0.0004019949722509041\n",
      "train loss:0.00018406606625862306\n",
      "train loss:0.0010679612184107212\n",
      "train loss:0.0025784214379650445\n",
      "train loss:0.0006782488288618712\n",
      "train loss:0.0012624172336499035\n",
      "train loss:0.0008316621936133923\n",
      "train loss:0.0005631517757230351\n",
      "train loss:0.00016357629701123667\n",
      "train loss:0.0001419015617659689\n",
      "train loss:0.0006384280158365914\n",
      "train loss:0.0013700958996824238\n",
      "train loss:0.00046472563039873525\n",
      "train loss:0.00138399343067038\n",
      "train loss:9.282380402758332e-05\n",
      "train loss:0.0012251837917417962\n",
      "train loss:0.00230757084397443\n",
      "train loss:0.0002919200975520247\n",
      "train loss:0.00021705236226156552\n",
      "train loss:0.0011184018482459396\n",
      "train loss:0.00012625516760560366\n",
      "train loss:0.0002975857545860175\n",
      "train loss:0.005637653211672529\n",
      "train loss:0.000913550588951558\n",
      "train loss:0.001955796959920614\n",
      "train loss:0.0006969664283950915\n",
      "train loss:0.0020960270983953876\n",
      "train loss:0.0004650363386990746\n",
      "train loss:0.0003911521952490682\n",
      "train loss:0.004238526929046796\n",
      "train loss:0.0004060193298454562\n",
      "train loss:0.0018527421873419192\n",
      "train loss:0.0002809166462406497\n",
      "train loss:8.300503537855791e-05\n",
      "train loss:0.001028890005330561\n",
      "train loss:0.0007306852630169401\n",
      "train loss:0.0004636320271399\n",
      "train loss:0.0005182591775297771\n",
      "train loss:0.0005478314223955676\n",
      "train loss:0.002392632336080887\n",
      "train loss:0.0004032791473635102\n",
      "train loss:8.46859119982345e-05\n",
      "train loss:0.00045912160399371116\n",
      "train loss:0.004155945096082552\n",
      "train loss:0.003914227646612479\n",
      "train loss:0.00234788929840269\n",
      "train loss:0.012698993624883852\n",
      "train loss:0.0006671435136907957\n",
      "train loss:0.00541271091169815\n",
      "train loss:0.00026405087546929606\n",
      "train loss:0.0008542940921025088\n",
      "train loss:0.0003817889593513665\n",
      "train loss:0.0014668757135805285\n",
      "train loss:0.004041296716174183\n",
      "train loss:0.0017348736170770718\n",
      "train loss:0.001134825254581811\n",
      "train loss:0.0013367920151067172\n",
      "train loss:0.0013375253720429156\n",
      "train loss:0.0023418883677839217\n",
      "train loss:0.003156103260964273\n",
      "train loss:0.002387635584172591\n",
      "train loss:0.00037914681581256205\n",
      "train loss:0.0024063151101056143\n",
      "train loss:0.0013487844163940451\n",
      "train loss:0.0006895460033167249\n",
      "train loss:0.002987875659793254\n",
      "train loss:0.0010021178455097454\n",
      "train loss:0.000736688867812489\n",
      "train loss:0.004551219396928561\n",
      "train loss:0.0029276974072870564\n",
      "train loss:0.0015851419269936112\n",
      "train loss:0.0011422182860929492\n",
      "train loss:0.0023347806029571944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0027710388960514123\n",
      "train loss:0.0012906825874183555\n",
      "train loss:0.008152488023995872\n",
      "train loss:0.002023021891503642\n",
      "train loss:0.0006861928604565068\n",
      "train loss:0.0021511994661220684\n",
      "train loss:0.0008162839585943424\n",
      "train loss:0.0014521231061671582\n",
      "train loss:0.001267234339453234\n",
      "train loss:0.0038590494854723253\n",
      "train loss:0.0011757793093324393\n",
      "train loss:0.0034307017991183028\n",
      "train loss:0.016918358514772316\n",
      "train loss:0.00042985739570314485\n",
      "train loss:0.0009527026832881817\n",
      "train loss:0.004912555916265154\n",
      "train loss:0.0015194332054391554\n",
      "train loss:0.000889075533047646\n",
      "train loss:0.0019882966138695343\n",
      "train loss:0.0011755466420369251\n",
      "train loss:0.00025212762602422914\n",
      "train loss:0.0032656988448934296\n",
      "train loss:0.0001117278850642303\n",
      "train loss:0.002483812798368568\n",
      "train loss:0.002116927524594326\n",
      "train loss:0.0004146274364919405\n",
      "train loss:0.002420738066015968\n",
      "train loss:0.0012404026769755187\n",
      "train loss:0.00035189613038374995\n",
      "train loss:0.0004960594642289586\n",
      "train loss:7.637493268446506e-05\n",
      "train loss:0.0012506385443860793\n",
      "train loss:0.0002794602088821923\n",
      "train loss:0.0007039290533940192\n",
      "train loss:0.00027536746545683995\n",
      "train loss:0.00023936425630432333\n",
      "train loss:0.00201640756118945\n",
      "train loss:0.00042794689747606326\n",
      "train loss:0.0007631244796705987\n",
      "train loss:0.00036786067696706353\n",
      "train loss:0.0013178834814573201\n",
      "train loss:0.0014323305574935603\n",
      "train loss:0.0014069511113560423\n",
      "train loss:0.0007414143670554916\n",
      "train loss:0.0007543019024141676\n",
      "train loss:0.0003009740554861161\n",
      "train loss:0.00060771442669444\n",
      "train loss:0.00040826019227931733\n",
      "train loss:0.00042395882590634586\n",
      "train loss:0.001716848999314516\n",
      "train loss:0.0004168758514612878\n",
      "train loss:0.00012670206441330186\n",
      "train loss:0.001019916497080183\n",
      "train loss:0.00029028612732214106\n",
      "train loss:0.0006343166242314382\n",
      "train loss:0.00027166567480869317\n",
      "train loss:0.0014422863234502517\n",
      "train loss:0.0006528232277208154\n",
      "train loss:0.0003013395655852087\n",
      "train loss:0.00161861981041937\n",
      "train loss:0.0013032744144472177\n",
      "train loss:0.0006134938374766553\n",
      "train loss:0.0009394458196470052\n",
      "train loss:0.0005689183431851134\n",
      "train loss:0.00018854826018441524\n",
      "train loss:0.002221738901298099\n",
      "train loss:0.0005696348704550811\n",
      "train loss:0.001029475358140394\n",
      "train loss:0.0007782655139115202\n",
      "=== epoch:15, train acc:0.999, test acc:0.996 ===\n",
      "train loss:0.00038627524075017007\n",
      "train loss:0.0009628712537639023\n",
      "train loss:4.018886344593125e-05\n",
      "train loss:0.0003569264281396267\n",
      "train loss:0.00032313704177292966\n",
      "train loss:0.0008151055581329657\n",
      "train loss:0.005953713849920728\n",
      "train loss:0.000154959300238924\n",
      "train loss:0.0004688745821954419\n",
      "train loss:0.0016118925984164993\n",
      "train loss:0.00021476171350124536\n",
      "train loss:0.0002606227273152614\n",
      "train loss:0.0007169934370514265\n",
      "train loss:0.0032009205035599558\n",
      "train loss:0.00091967102829101\n",
      "train loss:0.001195070236804119\n",
      "train loss:0.0011172898854158694\n",
      "train loss:0.001025013808687699\n",
      "train loss:8.546349156881242e-05\n",
      "train loss:0.00010493712900153778\n",
      "train loss:0.0005702753558700333\n",
      "train loss:0.0007241879471962716\n",
      "train loss:4.672240882644053e-05\n",
      "train loss:0.00015815522933731733\n",
      "train loss:0.003409425903394209\n",
      "train loss:0.001437565544982553\n",
      "train loss:0.002656607045305598\n",
      "train loss:0.0025013405860137027\n",
      "train loss:0.003792464633189831\n",
      "train loss:0.000481464928999787\n",
      "train loss:0.001098311812178962\n",
      "train loss:0.003075582467641698\n",
      "train loss:0.003008142738231548\n",
      "train loss:0.0006537958179675445\n",
      "train loss:0.0007530356443365233\n",
      "train loss:0.0009865698745413769\n",
      "train loss:0.0008675986036226789\n",
      "train loss:0.0018621497873085179\n",
      "train loss:0.0006417263261460109\n",
      "train loss:0.0001013302203310456\n",
      "train loss:0.00020753104461847843\n",
      "train loss:0.00019404445751822409\n",
      "train loss:0.0010275790604862478\n",
      "train loss:0.004472849078427854\n",
      "train loss:0.009102084428220216\n",
      "train loss:0.004288706403961887\n",
      "train loss:0.0016189130606131868\n",
      "train loss:0.0005715816453657241\n",
      "train loss:0.0013686367605398307\n",
      "train loss:0.0032191937426966567\n",
      "train loss:0.0005070325784487102\n",
      "train loss:0.0063288430808800256\n",
      "train loss:0.0013372794097227683\n",
      "train loss:0.001531431330403256\n",
      "train loss:0.00046696969275277357\n",
      "train loss:0.0005018752864564997\n",
      "train loss:0.00027511870891033633\n",
      "train loss:0.0003840307029645407\n",
      "train loss:0.000996317165546131\n",
      "train loss:0.000210921006760056\n",
      "train loss:0.0015419796605303903\n",
      "train loss:0.0005789215248987568\n",
      "train loss:0.004504735114854607\n",
      "train loss:0.003265532403374417\n",
      "train loss:0.0007763154186350373\n",
      "train loss:0.0016637394820381369\n",
      "train loss:0.001477420453295919\n",
      "train loss:0.00044025839300794803\n",
      "train loss:0.0003053711007833637\n",
      "train loss:0.0007256175261125613\n",
      "train loss:0.01052127429377083\n",
      "train loss:0.0013443133412406215\n",
      "train loss:6.748659828470177e-05\n",
      "train loss:0.0021906412324075863\n",
      "train loss:0.00109036536987758\n",
      "train loss:0.004423582449961607\n",
      "train loss:0.0008728706071390276\n",
      "train loss:0.0019172196845304375\n",
      "train loss:0.0011336397987396884\n",
      "train loss:0.0008487821505329139\n",
      "train loss:0.0010002174218028605\n",
      "train loss:0.0008962191623984333\n",
      "train loss:0.0001722029141291481\n",
      "train loss:0.00048061511646140675\n",
      "train loss:0.00022497068248752134\n",
      "train loss:0.0012587980674728804\n",
      "train loss:0.0009908004486699669\n",
      "train loss:0.000455022068867946\n",
      "train loss:0.0004149335840314366\n",
      "train loss:0.0003563370640756083\n",
      "train loss:0.0006145293774334804\n",
      "train loss:0.0015568084202788567\n",
      "train loss:0.00141135226009956\n",
      "train loss:0.0009749136637416441\n",
      "train loss:0.00039656742286763003\n",
      "train loss:0.0002836355997753089\n",
      "train loss:0.003014399924786782\n",
      "train loss:0.0036960477345626378\n",
      "train loss:0.0015620234767367628\n",
      "train loss:0.008401662073733652\n",
      "train loss:0.005606748489486861\n",
      "train loss:0.0019868367025967734\n",
      "train loss:0.0016363170809390016\n",
      "train loss:0.0022668952603703014\n",
      "train loss:0.0010683674478578144\n",
      "train loss:0.016931004556160915\n",
      "train loss:0.0005855892293783779\n",
      "train loss:0.003755907962846637\n",
      "train loss:0.0017726126950746706\n",
      "train loss:0.0005223133722943886\n",
      "train loss:0.0016120110149358351\n",
      "train loss:0.001045199834504328\n",
      "train loss:0.0016129458419410223\n",
      "train loss:0.004902538598905099\n",
      "train loss:0.0010909629388251396\n",
      "train loss:0.0012871702028327272\n",
      "train loss:0.0016540963698922675\n",
      "train loss:0.007832406108779359\n",
      "train loss:0.002607943705809365\n",
      "train loss:0.00036935119736043406\n",
      "train loss:0.0007050513126724531\n",
      "train loss:0.0010801626964861957\n",
      "train loss:0.0012718715306689126\n",
      "train loss:0.005083049069277993\n",
      "train loss:0.0021666926841758297\n",
      "train loss:0.0032848373541804576\n",
      "train loss:0.0012255725733407985\n",
      "train loss:0.0009186279420569284\n",
      "train loss:0.0007000901892448168\n",
      "train loss:0.0008722201914990519\n",
      "train loss:0.0003677667748870912\n",
      "train loss:0.0018862786078170555\n",
      "train loss:0.0009148397763885073\n",
      "train loss:0.0004056062260938349\n",
      "train loss:0.0014450603567469971\n",
      "train loss:0.000439946051558743\n",
      "train loss:0.002376503198860966\n",
      "train loss:0.00048629786350146256\n",
      "train loss:0.0008698077725270509\n",
      "train loss:0.0028519299948122135\n",
      "train loss:0.005926513084313856\n",
      "train loss:0.002891021522291468\n",
      "train loss:0.0024963140940672725\n",
      "train loss:0.00022935152668635312\n",
      "train loss:0.00047454420994879747\n",
      "train loss:0.0010376282779614395\n",
      "train loss:0.0008340958298466441\n",
      "train loss:0.0011373783586083792\n",
      "train loss:0.0014557271954203663\n",
      "train loss:0.0001823817415240039\n",
      "train loss:0.0012053470186119007\n",
      "train loss:0.001324802871966255\n",
      "train loss:0.0009803864041669544\n",
      "train loss:0.0005645609545859873\n",
      "train loss:0.0003569424027574204\n",
      "train loss:0.000726511139408666\n",
      "train loss:0.0003460868363117453\n",
      "train loss:0.0013911571490551784\n",
      "train loss:0.0024231352071465975\n",
      "train loss:0.001072256582748174\n",
      "train loss:0.0004663496286251743\n",
      "train loss:0.001034262153897886\n",
      "train loss:0.0005637476409337947\n",
      "train loss:0.0015945315978126101\n",
      "train loss:0.0006862599589470176\n",
      "train loss:0.002833806295195901\n",
      "train loss:0.0004582295735070843\n",
      "train loss:0.0022940080417099664\n",
      "train loss:0.0026148756186633376\n",
      "train loss:0.000186985268293426\n",
      "train loss:0.003157071813779558\n",
      "train loss:0.002175829570226086\n",
      "train loss:0.0013008764587994562\n",
      "train loss:0.0012982216189153552\n",
      "train loss:0.001104173986736182\n",
      "train loss:0.0001263766479028338\n",
      "train loss:0.00045420042926881877\n",
      "train loss:0.0022178689504358017\n",
      "train loss:0.0003300306946391761\n",
      "train loss:0.0022663190987597926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00010994985457441023\n",
      "train loss:0.0007946161141643579\n",
      "train loss:0.0022408917714445164\n",
      "train loss:0.0019203358527951854\n",
      "train loss:0.002301766856385191\n",
      "train loss:0.0007491430250788182\n",
      "train loss:0.0016722748096496469\n",
      "train loss:0.0009999884629424407\n",
      "train loss:0.0007011011171492721\n",
      "train loss:0.0016952861965039239\n",
      "train loss:0.0013144015841650891\n",
      "train loss:0.00029847671163615706\n",
      "train loss:0.001824674215665589\n",
      "train loss:0.0005667722382069475\n",
      "train loss:0.0002769868787293099\n",
      "train loss:0.0004507245703472333\n",
      "train loss:0.0007459226005312558\n",
      "train loss:0.0004229523824169536\n",
      "train loss:0.00011312401794578437\n",
      "train loss:0.0047155893052199796\n",
      "train loss:0.0002989100402321143\n",
      "train loss:0.0003837127992594857\n",
      "train loss:0.0005698418726786905\n",
      "train loss:0.00021001302344506105\n",
      "train loss:0.00021807501830207015\n",
      "train loss:0.0025412466583285558\n",
      "train loss:0.000492383506597979\n",
      "train loss:0.00019472725162765207\n",
      "train loss:0.000989615458326988\n",
      "train loss:0.0015142213147639658\n",
      "train loss:0.00017949191442763216\n",
      "train loss:0.0006769046006261453\n",
      "train loss:0.000905927939679118\n",
      "train loss:0.00019612937475601934\n",
      "train loss:0.0017395554978492155\n",
      "train loss:2.8946865433911082e-05\n",
      "train loss:0.0007549319274333328\n",
      "train loss:0.007852762125918915\n",
      "train loss:0.0009075713729197953\n",
      "train loss:0.001514302552036315\n",
      "train loss:0.0009355378405089595\n",
      "train loss:0.00029521078408531844\n",
      "train loss:0.000553011764198855\n",
      "train loss:0.0008389600778211801\n",
      "train loss:0.0014823080485139304\n",
      "train loss:0.0030985809201915957\n",
      "train loss:0.001011857279157611\n",
      "train loss:0.0007571942642824459\n",
      "train loss:0.0005390749314142722\n",
      "train loss:0.0005323653224330802\n",
      "train loss:0.0003825670430830583\n",
      "train loss:0.0030882884370733695\n",
      "train loss:6.836298732600357e-05\n",
      "train loss:0.0005102544484748258\n",
      "train loss:0.0008314751296893665\n",
      "train loss:0.00012859064391957046\n",
      "train loss:0.00040267293548432696\n",
      "train loss:0.0010470012913909585\n",
      "train loss:0.0008917682876369561\n",
      "train loss:0.0001102817393763679\n",
      "train loss:0.0008094709969920069\n",
      "train loss:0.00010770857887930519\n",
      "train loss:0.0002984869240955425\n",
      "train loss:0.00024827234545962153\n",
      "train loss:0.0001708810732779992\n",
      "train loss:0.0002900562495961191\n",
      "train loss:0.0029779134593922968\n",
      "train loss:0.0010204846703418368\n",
      "train loss:0.0010243694455785712\n",
      "train loss:0.002409571736154559\n",
      "train loss:0.0001673051425075384\n",
      "train loss:0.0003074202599347666\n",
      "train loss:0.0012354995508747884\n",
      "train loss:0.00012016407977445796\n",
      "train loss:9.889745293260276e-05\n",
      "train loss:0.0012017711814653854\n",
      "train loss:0.000716037794384266\n",
      "train loss:0.0018375775975527887\n",
      "train loss:0.0006944747853609944\n",
      "train loss:0.0010257449659930244\n",
      "train loss:0.0006939228760898089\n",
      "train loss:0.0002927767708167348\n",
      "train loss:0.00013782415076975236\n",
      "train loss:0.0006970329807652422\n",
      "train loss:0.005106366829588371\n",
      "train loss:0.001027395316219311\n",
      "train loss:0.0011319579182273798\n",
      "train loss:0.0014289551452453843\n",
      "train loss:0.00039161252687023505\n",
      "train loss:0.0012489884268698838\n",
      "train loss:0.0002567594589356959\n",
      "train loss:0.00042274385144479656\n",
      "train loss:0.00037819179110341563\n",
      "train loss:0.0018633800530292325\n",
      "train loss:0.0012470282885092456\n",
      "train loss:0.00040776073284095444\n",
      "train loss:0.001046837844552347\n",
      "train loss:0.0005804092427870339\n",
      "train loss:0.00014250199732326657\n",
      "train loss:0.00017073354582409605\n",
      "train loss:0.001959922700828966\n",
      "train loss:0.00033013026886665007\n",
      "train loss:0.0007370899165049688\n",
      "train loss:0.00047937165016023395\n",
      "train loss:0.0002990500786469606\n",
      "train loss:0.0014565046390177428\n",
      "train loss:0.0003770311187255237\n",
      "train loss:0.0027409286907361706\n",
      "train loss:0.0009066839649746551\n",
      "train loss:0.0006871230831309389\n",
      "train loss:0.00012582928001741132\n",
      "train loss:0.0026339491538633626\n",
      "train loss:0.00010734121935849682\n",
      "train loss:0.0032043080921375627\n",
      "train loss:0.0006239099712946162\n",
      "train loss:0.001687433673120381\n",
      "train loss:0.0009398790015707595\n",
      "train loss:0.0014901604734676845\n",
      "train loss:4.8807225832713324e-05\n",
      "train loss:0.00012801381702937125\n",
      "train loss:0.001631649104511905\n",
      "train loss:0.0012751344339201258\n",
      "train loss:0.001480702982920002\n",
      "train loss:0.0012890336893786514\n",
      "train loss:0.00114031176450843\n",
      "train loss:0.00036130679924151193\n",
      "train loss:8.513011927829633e-05\n",
      "train loss:0.0013850296387494284\n",
      "train loss:0.00017943771931007527\n",
      "train loss:0.00029915583987379123\n",
      "train loss:0.0007819457300693944\n",
      "train loss:0.0008692247491778611\n",
      "train loss:0.001097803914744854\n",
      "train loss:0.0020822202129907276\n",
      "train loss:0.0007836605894723581\n",
      "train loss:0.001066808080733384\n",
      "train loss:0.0016404654802278282\n",
      "train loss:0.0014952641147406931\n",
      "train loss:0.00013117495922905606\n",
      "train loss:0.00034249445936809244\n",
      "train loss:0.00031190894183701594\n",
      "train loss:0.0019436427295386619\n",
      "train loss:0.0034600067376796303\n",
      "train loss:0.0003799696207328537\n",
      "train loss:0.00024379111870349642\n",
      "train loss:0.0009203094626023044\n",
      "train loss:0.0009798127919492332\n",
      "train loss:0.00024057541839413618\n",
      "train loss:0.0019461338643868423\n",
      "train loss:0.0016288311370796157\n",
      "train loss:0.0012412451501193206\n",
      "train loss:0.0005945274986567884\n",
      "train loss:0.00254483509000235\n",
      "train loss:7.345940905619303e-05\n",
      "train loss:0.00034196020208287993\n",
      "train loss:0.0011891514106053345\n",
      "train loss:0.0011251101426834676\n",
      "train loss:0.0017294621479846885\n",
      "train loss:0.0016102623082893265\n",
      "train loss:0.001192608987577663\n",
      "train loss:0.004347150926040869\n",
      "train loss:0.004055829015542527\n",
      "train loss:0.0012354413232547642\n",
      "train loss:0.0003947664099635568\n",
      "train loss:0.0011660436239102807\n",
      "train loss:0.00014047754631401726\n",
      "train loss:0.012091156719482165\n",
      "train loss:0.004157595472117051\n",
      "train loss:0.004315172626934414\n",
      "train loss:0.0002782704266877739\n",
      "train loss:0.0008383503255927567\n",
      "train loss:0.000314250379554907\n",
      "train loss:0.0008569185606683479\n",
      "train loss:0.00010577385744793887\n",
      "train loss:0.012652280304911624\n",
      "train loss:0.0017263342492504958\n",
      "train loss:0.00032620262459286966\n",
      "train loss:0.00045695796216824414\n",
      "train loss:0.0014066559449504097\n",
      "train loss:0.00032068296003005304\n",
      "train loss:0.012418826797633948\n",
      "train loss:0.006187711301303509\n",
      "train loss:0.0022449392421582145\n",
      "train loss:0.0067395233884457225\n",
      "train loss:0.0012869380124511812\n",
      "train loss:0.0030897138266728417\n",
      "train loss:4.073050208972823e-05\n",
      "train loss:0.0006215196808515899\n",
      "=== epoch:16, train acc:1.0, test acc:0.995 ===\n",
      "train loss:0.0006233048408798939\n",
      "train loss:0.0025047023729726932\n",
      "train loss:0.0018453001885057841\n",
      "train loss:0.0003432047665680917\n",
      "train loss:0.0004664315808755802\n",
      "train loss:0.0002680419488417577\n",
      "train loss:4.5419173621458715e-05\n",
      "train loss:4.335713565128575e-05\n",
      "train loss:0.0014956848497878826\n",
      "train loss:0.0005619125770182571\n",
      "train loss:0.00025602305651268285\n",
      "train loss:0.0014528462432721134\n",
      "train loss:0.004813644791581403\n",
      "train loss:0.001457928674578267\n",
      "train loss:0.00030768120498028077\n",
      "train loss:0.00023807108743026547\n",
      "train loss:0.0019015921540763796\n",
      "train loss:0.0016673271794220208\n",
      "train loss:0.005404464482729155\n",
      "train loss:0.002972200116812845\n",
      "train loss:0.0008666310476411551\n",
      "train loss:0.0010299688654229048\n",
      "train loss:0.0016761467071392362\n",
      "train loss:0.000628106847782945\n",
      "train loss:0.006432612327161123\n",
      "train loss:0.0002650418682238626\n",
      "train loss:0.0013088897460921483\n",
      "train loss:0.0011531529091366726\n",
      "train loss:0.0009708554257146923\n",
      "train loss:6.891056193328936e-05\n",
      "train loss:0.0005402302939604418\n",
      "train loss:0.0005991140047981184\n",
      "train loss:0.005450215526586015\n",
      "train loss:0.0002543425122140266\n",
      "train loss:0.002619187121470035\n",
      "train loss:0.00033994939355803624\n",
      "train loss:0.0007691743317204208\n",
      "train loss:0.00027885448317214973\n",
      "train loss:0.0025738419117960257\n",
      "train loss:0.00113201322935754\n",
      "train loss:0.0006889962328139175\n",
      "train loss:0.0025640027926970787\n",
      "train loss:0.0006557727849604908\n",
      "train loss:0.0010368223006902804\n",
      "train loss:0.0004472249587032757\n",
      "train loss:0.0006821191831515993\n",
      "train loss:0.00010523385112004979\n",
      "train loss:0.0010637310977730735\n",
      "train loss:0.0001794768424452886\n",
      "train loss:0.0014316968038818815\n",
      "train loss:0.001620197058702589\n",
      "train loss:0.00026685427475513674\n",
      "train loss:0.000920809702896401\n",
      "train loss:0.00044099095353389246\n",
      "train loss:0.0003417066657974519\n",
      "train loss:0.0009494527258193478\n",
      "train loss:0.00014643681627992937\n",
      "train loss:0.0010863461733302585\n",
      "train loss:0.0021985277839761926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0015109936359966787\n",
      "train loss:0.00022047569272881773\n",
      "train loss:0.0008980396719230465\n",
      "train loss:0.001355505851566608\n",
      "train loss:0.0006921000085772552\n",
      "train loss:0.00042834027152525316\n",
      "train loss:0.0012701078508515235\n",
      "train loss:0.0005133076741737403\n",
      "train loss:0.0008721408630419995\n",
      "train loss:0.00032481124041755413\n",
      "train loss:0.00023483466936795552\n",
      "train loss:0.00014324162627850056\n",
      "train loss:0.003500033014003693\n",
      "train loss:0.0010852478206093078\n",
      "train loss:0.004710691998848382\n",
      "train loss:0.0017101640450906557\n",
      "train loss:0.0013998255078171375\n",
      "train loss:0.0009761137485521119\n",
      "train loss:0.001087155349089805\n",
      "train loss:6.156870899838827e-05\n",
      "train loss:9.355678171322643e-05\n",
      "train loss:0.00135086869359931\n",
      "train loss:0.00013626458017431347\n",
      "train loss:0.0011054147885253417\n",
      "train loss:0.00023713574516741415\n",
      "train loss:0.0008242121364367347\n",
      "train loss:0.0005738875930002079\n",
      "train loss:0.0005436932656836852\n",
      "train loss:0.003578718162660579\n",
      "train loss:3.834006657974015e-05\n",
      "train loss:0.0009574748561043252\n",
      "train loss:0.00027346771530157833\n",
      "train loss:0.0017896819033697581\n",
      "train loss:0.0006967356506981719\n",
      "train loss:0.0006572357558796108\n",
      "train loss:0.009620683072655926\n",
      "train loss:0.0014258203671523495\n",
      "train loss:0.0014630026363206428\n",
      "train loss:0.00011601855614676837\n",
      "train loss:0.0004181834860353266\n",
      "train loss:0.0009673009076919065\n",
      "train loss:0.002246122301644934\n",
      "train loss:0.000586691465384998\n",
      "train loss:0.001019899743178978\n",
      "train loss:0.0001670006815633311\n",
      "train loss:0.00603310265190761\n",
      "train loss:0.00023143734183431067\n",
      "train loss:0.004064678376720465\n",
      "train loss:0.0007167714943525391\n",
      "train loss:0.003044945624458698\n",
      "train loss:0.001055552016348045\n",
      "train loss:0.00015672002942769957\n",
      "train loss:0.0015131362316228312\n",
      "train loss:4.48312574185722e-05\n",
      "train loss:0.001772861332423404\n",
      "train loss:0.0014750142370692503\n",
      "train loss:9.676907133715836e-05\n",
      "train loss:0.0002944810046719696\n",
      "train loss:0.00037638611417388257\n",
      "train loss:0.0003330295220754455\n",
      "train loss:0.0005090389051490537\n",
      "train loss:0.0006240292946229603\n",
      "train loss:4.761095666335067e-05\n",
      "train loss:0.00022638534222986997\n",
      "train loss:0.0004582645869603625\n",
      "train loss:0.0013325777775915946\n",
      "train loss:0.011732437435677099\n",
      "train loss:1.766916627696411e-05\n",
      "train loss:0.0002551676389737125\n",
      "train loss:0.0013280249273347783\n",
      "train loss:0.0002707503418605062\n",
      "train loss:0.0007234037235892946\n",
      "train loss:0.0014376304516992597\n",
      "train loss:0.00021948224095619332\n",
      "train loss:0.00011930849726311703\n",
      "train loss:0.0003939310439008966\n",
      "train loss:0.0001213763986590798\n",
      "train loss:0.0007815410842076039\n",
      "train loss:7.558362650989993e-05\n",
      "train loss:0.002114323928621138\n",
      "train loss:0.0009141322945240341\n",
      "train loss:0.0006330042261188533\n",
      "train loss:0.00013329845897063405\n",
      "train loss:0.00032373495354044414\n",
      "train loss:0.0007024073337179958\n",
      "train loss:0.002038825040509145\n",
      "train loss:0.00034994477098984736\n",
      "train loss:0.003881081882858471\n",
      "train loss:0.0005532597267955717\n",
      "train loss:0.0003522844760998786\n",
      "train loss:0.000470788821977182\n",
      "train loss:0.00046633764813847983\n",
      "train loss:0.0013642106890426114\n",
      "train loss:0.001286857991793321\n",
      "train loss:0.0036476739472181244\n",
      "train loss:0.0011219142098207737\n",
      "train loss:0.00132634409311978\n",
      "train loss:7.726440475939413e-05\n",
      "train loss:0.0005820485187439569\n",
      "train loss:2.90168191113891e-05\n",
      "train loss:0.00026992271579477395\n",
      "train loss:0.00044433552317987244\n",
      "train loss:0.002165510368909108\n",
      "train loss:3.275580195873561e-05\n",
      "train loss:0.014815266155777001\n",
      "train loss:0.0034579933927949363\n",
      "train loss:0.00040006802526768893\n",
      "train loss:0.0011675467311565088\n",
      "train loss:0.0007254623434795851\n",
      "train loss:0.000455492579992032\n",
      "train loss:0.0007852724191002567\n",
      "train loss:0.001516605720806272\n",
      "train loss:0.00306590318441461\n",
      "train loss:0.0014888401927761028\n",
      "train loss:0.0005283992558958391\n",
      "train loss:0.0024101345306173473\n",
      "train loss:0.000866642811770139\n",
      "train loss:0.0010526150036376568\n",
      "train loss:0.00042896061144737904\n",
      "train loss:0.001133585951070158\n",
      "train loss:0.0007114608036519449\n",
      "train loss:0.00023760341700538475\n",
      "train loss:0.0009404070896107022\n",
      "train loss:0.001832700140062111\n",
      "train loss:0.0001943722041369485\n",
      "train loss:0.00043938931649118953\n",
      "train loss:0.004878801043529615\n",
      "train loss:0.0010643945410956114\n",
      "train loss:0.0009609662444235532\n",
      "train loss:0.00128557301365505\n",
      "train loss:0.00037402481180660635\n",
      "train loss:0.001130301468053247\n",
      "train loss:0.0003538033910707724\n",
      "train loss:0.00024066592357481706\n",
      "train loss:0.00036058128764736617\n",
      "train loss:8.389075671026662e-05\n",
      "train loss:0.0005893641724102976\n",
      "train loss:0.0006745111716583383\n",
      "train loss:0.0007929314482370331\n",
      "train loss:0.00044446186899082987\n",
      "train loss:0.0028584649750281787\n",
      "train loss:0.002273410935819875\n",
      "train loss:0.0015235500232594413\n",
      "train loss:0.000689354258317426\n",
      "train loss:9.443075942776226e-05\n",
      "train loss:9.096517648992794e-05\n",
      "train loss:0.001045946447672958\n",
      "train loss:6.821930074647746e-05\n",
      "train loss:9.524587587978179e-05\n",
      "train loss:0.0010206362120828865\n",
      "train loss:0.0003249816482421793\n",
      "train loss:0.000393882609295653\n",
      "train loss:0.0011763966122459357\n",
      "train loss:0.0005639391336421817\n",
      "train loss:7.944833071125239e-05\n",
      "train loss:0.0007011329273211762\n",
      "train loss:0.0033890338562607538\n",
      "train loss:0.0002693068122844833\n",
      "train loss:8.47447314651614e-05\n",
      "train loss:0.00042783267281811904\n",
      "train loss:0.00023721213686105284\n",
      "train loss:5.8222642283505135e-05\n",
      "train loss:0.0008062254200619947\n",
      "train loss:0.0008157639402102102\n",
      "train loss:0.0003554478101589733\n",
      "train loss:0.0015866991650027465\n",
      "train loss:0.0003337481169473893\n",
      "train loss:3.875376275492472e-05\n",
      "train loss:0.00017925011643464542\n",
      "train loss:0.0001415891098702907\n",
      "train loss:0.00021821910885967618\n",
      "train loss:0.0019319681766588228\n",
      "train loss:0.00029965913063597304\n",
      "train loss:6.490002084197587e-05\n",
      "train loss:0.00016829352760892955\n",
      "train loss:0.00028746122483611173\n",
      "train loss:0.0007558603721108891\n",
      "train loss:2.4556618685238593e-05\n",
      "train loss:0.0004470050755263651\n",
      "train loss:0.0010828648215711536\n",
      "train loss:9.112327945291079e-05\n",
      "train loss:0.0005627917748361281\n",
      "train loss:0.00013535421349404253\n",
      "train loss:0.0020409316807267104\n",
      "train loss:0.0005973030405643578\n",
      "train loss:0.0003519206308478038\n",
      "train loss:0.001428543108514609\n",
      "train loss:7.726615401201072e-05\n",
      "train loss:0.00048329813619515705\n",
      "train loss:2.141891737087515e-05\n",
      "train loss:0.00011635576133083603\n",
      "train loss:0.00012157176134644552\n",
      "train loss:0.001112786201229073\n",
      "train loss:0.00033612542375493836\n",
      "train loss:3.903027214999653e-05\n",
      "train loss:0.00014332724986753848\n",
      "train loss:0.0015734692888252288\n",
      "train loss:0.0025699340808725975\n",
      "train loss:0.0019060855014837877\n",
      "train loss:0.0010859626725138564\n",
      "train loss:0.0005570014601225822\n",
      "train loss:0.0007739188353175206\n",
      "train loss:0.0004024191299262981\n",
      "train loss:0.00017693310114418054\n",
      "train loss:8.017329441754015e-05\n",
      "train loss:0.0008965827404543817\n",
      "train loss:0.00038481705770795953\n",
      "train loss:0.0006550932411343494\n",
      "train loss:1.3976267267325265e-05\n",
      "train loss:0.001132724864934081\n",
      "train loss:0.00020735562054128553\n",
      "train loss:0.0003680069091356906\n",
      "train loss:0.000228839378462213\n",
      "train loss:0.00016765121338597179\n",
      "train loss:0.00207823687075846\n",
      "train loss:0.0008669619437796245\n",
      "train loss:0.00017296331819562937\n",
      "train loss:0.00023701771177681054\n",
      "train loss:0.00032297818028872944\n",
      "train loss:0.000270928804980749\n",
      "train loss:0.0003398398014480303\n",
      "train loss:0.00023049214264842527\n",
      "train loss:0.0006817370210109208\n",
      "train loss:7.73004661548966e-05\n",
      "train loss:0.0008831878647077966\n",
      "train loss:0.00028409512164912604\n",
      "train loss:0.00010735774252617243\n",
      "train loss:0.00026626564411318874\n",
      "train loss:0.00027380644724704065\n",
      "train loss:0.0002228410733039195\n",
      "train loss:0.0004943990008582927\n",
      "train loss:0.00037538475618432933\n",
      "train loss:0.0002402980192168186\n",
      "train loss:0.00012728457575901625\n",
      "train loss:0.006433252145067662\n",
      "train loss:0.000762254650982801\n",
      "train loss:7.04358856503461e-05\n",
      "train loss:0.0004658213675085563\n",
      "train loss:5.250062012910912e-05\n",
      "train loss:0.0001257826767714877\n",
      "train loss:0.00011575034602251749\n",
      "train loss:0.0003172912253710887\n",
      "train loss:0.0003146532748208886\n",
      "train loss:0.00036634963554276585\n",
      "train loss:8.522512829082864e-05\n",
      "train loss:0.0001609243425641619\n",
      "train loss:0.00014131608329667552\n",
      "train loss:0.0009724245267535718\n",
      "train loss:0.00023298006422055732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0018439722192121935\n",
      "train loss:0.00036451998576152525\n",
      "train loss:0.00047729489214792516\n",
      "train loss:9.694473256504541e-05\n",
      "train loss:6.142014940587644e-05\n",
      "train loss:0.000192259065261418\n",
      "train loss:5.40288627612889e-05\n",
      "train loss:0.0012586194296079424\n",
      "train loss:0.00010570395792285934\n",
      "train loss:0.00024252427719205006\n",
      "train loss:0.00017125849451852133\n",
      "train loss:0.00028385021749217075\n",
      "train loss:0.0005944087599124164\n",
      "train loss:0.0006077520968897042\n",
      "train loss:0.0018421466386438093\n",
      "train loss:0.00014691722722801244\n",
      "train loss:0.00047366828575054015\n",
      "train loss:0.0008622982921446999\n",
      "train loss:0.0006806716465695121\n",
      "train loss:0.00044280741426093125\n",
      "train loss:0.0006265512840507822\n",
      "train loss:0.0033574347853372512\n",
      "train loss:0.0007817852896910106\n",
      "train loss:0.0006469408173311651\n",
      "train loss:0.0003343896619248214\n",
      "train loss:0.0019107258718000833\n",
      "train loss:0.0006002148669435487\n",
      "train loss:0.000163382424308992\n",
      "train loss:0.00023444214703079313\n",
      "train loss:0.00010850081332919578\n",
      "train loss:3.421768571189339e-05\n",
      "train loss:0.00032747671226855836\n",
      "train loss:9.95632672516602e-05\n",
      "train loss:0.0001595376991955741\n",
      "train loss:7.8588059448191e-05\n",
      "train loss:0.00021881701000830994\n",
      "train loss:9.695765217754144e-05\n",
      "train loss:0.00042795586366169554\n",
      "train loss:0.0002706840528628193\n",
      "train loss:0.0006666383291546501\n",
      "train loss:0.0007287633294287069\n",
      "train loss:0.0002716228901926833\n",
      "train loss:0.00024073241560382386\n",
      "train loss:0.0006713771801984732\n",
      "train loss:0.00012346253544059954\n",
      "train loss:9.720214234430763e-05\n",
      "train loss:8.263130452834013e-05\n",
      "train loss:0.00014250861074226328\n",
      "train loss:0.0001335116991429637\n",
      "train loss:0.0005890630299705001\n",
      "train loss:0.00018503098354544003\n",
      "train loss:0.00021101935484333005\n",
      "train loss:0.0010892004735543678\n",
      "train loss:5.3229421867192785e-05\n",
      "train loss:0.00018695063020187676\n",
      "train loss:0.00013308567808421998\n",
      "train loss:0.0002657581484661028\n",
      "train loss:0.0003034076003339036\n",
      "train loss:0.0009484354218156306\n",
      "train loss:0.00020122211007092525\n",
      "=== epoch:17, train acc:1.0, test acc:0.997 ===\n",
      "train loss:0.0006625616050384497\n",
      "train loss:0.0004013563934522046\n",
      "train loss:0.002455454157678853\n",
      "train loss:8.914110872470017e-05\n",
      "train loss:4.871773797666943e-05\n",
      "train loss:0.00027763820852841386\n",
      "train loss:0.0007997807141036611\n",
      "train loss:0.0014875044834026445\n",
      "train loss:0.00030778368403790694\n",
      "train loss:0.0002385906216201469\n",
      "train loss:6.0612437622283e-05\n",
      "train loss:7.464969241515902e-05\n",
      "train loss:0.00012057853728822839\n",
      "train loss:0.0005088966791169047\n",
      "train loss:0.00030639257933903774\n",
      "train loss:0.0007089002080842027\n",
      "train loss:1.5175460868862414e-05\n",
      "train loss:0.00019058999060620155\n",
      "train loss:0.00033938651489994463\n",
      "train loss:0.0001087688006196873\n",
      "train loss:6.659478774489764e-05\n",
      "train loss:0.00018003399307064914\n",
      "train loss:8.286826638926267e-05\n",
      "train loss:0.0009482206470634452\n",
      "train loss:0.0002540041928537967\n",
      "train loss:0.0005968764099690992\n",
      "train loss:5.2593934311622735e-05\n",
      "train loss:0.0002452863258425059\n",
      "train loss:0.0013707444472343018\n",
      "train loss:0.0002161647508803761\n",
      "train loss:0.00010826936634367666\n",
      "train loss:2.7717967232954526e-05\n",
      "train loss:0.00029567753704866546\n",
      "train loss:0.0004820543300421311\n",
      "train loss:2.3480826772572827e-05\n",
      "train loss:7.978509779829131e-05\n",
      "train loss:0.00015722885150033759\n",
      "train loss:0.00018925820043481922\n",
      "train loss:6.760247336021086e-05\n",
      "train loss:0.0001281283526469999\n",
      "train loss:7.51189877745159e-05\n",
      "train loss:4.99905715067382e-05\n",
      "train loss:0.001313384188466702\n",
      "train loss:5.4246951275642936e-05\n",
      "train loss:5.999704856655327e-05\n",
      "train loss:0.00014507079249598267\n",
      "train loss:0.0006558052560940575\n",
      "train loss:0.00015773983742267103\n",
      "train loss:0.0013275005768002416\n",
      "train loss:5.6533525311735004e-05\n",
      "train loss:0.00023969635815949522\n",
      "train loss:0.0005195133283813193\n",
      "train loss:0.0022926594766893332\n",
      "train loss:0.00023656391992144454\n",
      "train loss:0.0001127283141820411\n",
      "train loss:0.0008154752859465131\n",
      "train loss:0.0011675279250276053\n",
      "train loss:0.00010661229815777217\n",
      "train loss:0.00015203112942527774\n",
      "train loss:0.000546839543821264\n",
      "train loss:0.0008824544582879984\n",
      "train loss:0.0006806823083370165\n",
      "train loss:0.001381882584243829\n",
      "train loss:0.00018019926269571745\n",
      "train loss:0.0002506027273637085\n",
      "train loss:0.002352255418506892\n",
      "train loss:0.0006098164125606448\n",
      "train loss:0.00010956894197483935\n",
      "train loss:0.0004945186100801905\n",
      "train loss:0.0004003069311084529\n",
      "train loss:0.0005112142106337206\n",
      "train loss:0.00024583380766707774\n",
      "train loss:0.00017241830500974403\n",
      "train loss:0.0008026922315934263\n",
      "train loss:0.00017189511584042092\n",
      "train loss:6.346234115800477e-05\n",
      "train loss:8.5498550669266e-05\n",
      "train loss:0.00017999697862271886\n",
      "train loss:0.000368518645622021\n",
      "train loss:0.00019564248528128878\n",
      "train loss:0.0004951781942007764\n",
      "train loss:0.00015390709716493867\n",
      "train loss:0.00023283473226438017\n",
      "train loss:0.00015219907342594626\n",
      "train loss:0.0001489377656557638\n",
      "train loss:0.000378755063909333\n",
      "train loss:6.786371842233994e-05\n",
      "train loss:7.476272599324736e-05\n",
      "train loss:0.0007478926807173096\n",
      "train loss:0.0005831977951929644\n",
      "train loss:0.00026329280847505664\n",
      "train loss:4.0807622733956975e-05\n",
      "train loss:0.0002344736873932432\n",
      "train loss:0.0010062291434448705\n",
      "train loss:0.0004492794124276559\n",
      "train loss:0.0008441231109064207\n",
      "train loss:5.6778414427093545e-05\n",
      "train loss:0.00011546447822726819\n",
      "train loss:0.00017338417992200666\n",
      "train loss:0.00011918546476060644\n",
      "train loss:0.00012459172566024472\n",
      "train loss:4.7209798074667655e-06\n",
      "train loss:0.00024847897699890653\n",
      "train loss:4.8678169636908975e-05\n",
      "train loss:0.0006003598385300519\n",
      "train loss:0.003020598745609396\n",
      "train loss:6.474970847859079e-05\n",
      "train loss:4.282238238330988e-05\n",
      "train loss:0.0003092722493868098\n",
      "train loss:0.00011751363367759566\n",
      "train loss:3.2290275320128774e-05\n",
      "train loss:0.0008380479279472646\n",
      "train loss:0.0001082274182308335\n",
      "train loss:0.00018513050598368823\n",
      "train loss:0.00011564944280583588\n",
      "train loss:0.0008147552757314878\n",
      "train loss:5.762441503451083e-05\n",
      "train loss:3.307375163333125e-05\n",
      "train loss:3.7508777635283777e-05\n",
      "train loss:0.00010923356803738323\n",
      "train loss:3.2574303967351645e-05\n",
      "train loss:0.00014513494884524957\n",
      "train loss:0.00017324389966382614\n",
      "train loss:0.0002875476804664644\n",
      "train loss:6.222007064891491e-06\n",
      "train loss:8.736974306395616e-05\n",
      "train loss:0.00036130848604139264\n",
      "train loss:8.572838574673798e-05\n",
      "train loss:0.00011827350469553456\n",
      "train loss:6.614112505953341e-05\n",
      "train loss:0.00040837090183250014\n",
      "train loss:0.0010977216312908396\n",
      "train loss:0.0005272229498672123\n",
      "train loss:9.170692705118642e-05\n",
      "train loss:0.00012860572918147465\n",
      "train loss:0.0005665905728832164\n",
      "train loss:0.00031959308928760223\n",
      "train loss:4.043195288572417e-05\n",
      "train loss:4.393342603818856e-05\n",
      "train loss:0.00013393897408546743\n",
      "train loss:0.00029261846329314866\n",
      "train loss:0.00020605552483790365\n",
      "train loss:0.00015263969758067916\n",
      "train loss:0.0005678683566312574\n",
      "train loss:0.0001462111149382715\n",
      "train loss:0.000359289144609599\n",
      "train loss:0.0002265602456331338\n",
      "train loss:4.360747282097951e-05\n",
      "train loss:0.000269689122364525\n",
      "train loss:9.370719288767308e-05\n",
      "train loss:7.867673839451219e-05\n",
      "train loss:0.0002606257214827183\n",
      "train loss:0.0002013186459828674\n",
      "train loss:4.6603902233958355e-05\n",
      "train loss:0.00022627859997910308\n",
      "train loss:5.6405704132803015e-05\n",
      "train loss:2.052596923892307e-05\n",
      "train loss:8.623650508680031e-05\n",
      "train loss:0.0004944471286530478\n",
      "train loss:0.0001885045066762226\n",
      "train loss:0.0001529710308774531\n",
      "train loss:4.9455129287541176e-05\n",
      "train loss:2.1753752127657755e-05\n",
      "train loss:0.0006922060034639793\n",
      "train loss:9.913903148070314e-05\n",
      "train loss:7.125887817788232e-05\n",
      "train loss:0.00012748700719434936\n",
      "train loss:0.0003448313449768684\n",
      "train loss:6.973847346062439e-05\n",
      "train loss:3.836561785701338e-05\n",
      "train loss:6.460740247573774e-05\n",
      "train loss:0.00010230149983473974\n",
      "train loss:0.0001073323400736904\n",
      "train loss:5.866662256367657e-05\n",
      "train loss:8.646093017225996e-05\n",
      "train loss:0.002293171671644199\n",
      "train loss:3.349923242265832e-05\n",
      "train loss:1.13866775996297e-05\n",
      "train loss:0.0002143204565041741\n",
      "train loss:0.0001965680894778855\n",
      "train loss:4.3184236363834706e-05\n",
      "train loss:0.0002733004044059051\n",
      "train loss:0.0004287787582982183\n",
      "train loss:0.000869927002973286\n",
      "train loss:0.0016461150664498429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0019993421019424956\n",
      "train loss:0.0007042645379208262\n",
      "train loss:0.0002520998235390048\n",
      "train loss:0.00025036326365765834\n",
      "train loss:8.568760496189671e-05\n",
      "train loss:7.964637451726935e-05\n",
      "train loss:0.00013081829667017377\n",
      "train loss:0.0001583078416865097\n",
      "train loss:0.00027091450407596275\n",
      "train loss:1.1431656174143883e-05\n",
      "train loss:0.00015146241805698613\n",
      "train loss:0.00016691252767478537\n",
      "train loss:0.0001768325113058463\n",
      "train loss:0.00016443889519160098\n",
      "train loss:0.0005217797003837964\n",
      "train loss:4.4479918601040536e-05\n",
      "train loss:0.0015234847976704627\n",
      "train loss:0.001822213478123145\n",
      "train loss:6.480447187904968e-05\n",
      "train loss:0.00012441465784985564\n",
      "train loss:6.754170972282349e-05\n",
      "train loss:0.00012095945860817699\n",
      "train loss:4.238240829505848e-05\n",
      "train loss:0.0002927883933422212\n",
      "train loss:0.00038773172753240524\n",
      "train loss:7.199816687003057e-05\n",
      "train loss:0.00019440629447674442\n",
      "train loss:0.00017258737184623656\n",
      "train loss:0.0005568609223051363\n",
      "train loss:0.0005684956728796621\n",
      "train loss:0.00027748134416071934\n",
      "train loss:0.0012350257066259158\n",
      "train loss:0.0003831450110130973\n",
      "train loss:0.00015393334846076768\n",
      "train loss:0.00014367913280751929\n",
      "train loss:5.594868897792779e-05\n",
      "train loss:0.0003854927927487253\n",
      "train loss:0.00011840883486391564\n",
      "train loss:6.715779394280844e-05\n",
      "train loss:0.00013361620345322159\n",
      "train loss:0.0006884227708614057\n",
      "train loss:0.00022264035488448556\n",
      "train loss:0.0003691114706674498\n",
      "train loss:6.976851565062731e-05\n",
      "train loss:0.00011423142733235327\n",
      "train loss:0.00014324716452835063\n",
      "train loss:2.281891301545431e-05\n",
      "train loss:0.0004582999206124951\n",
      "train loss:0.0003917431661118326\n",
      "train loss:8.803429942788376e-05\n",
      "train loss:9.471161935638537e-05\n",
      "train loss:6.05978305819767e-05\n",
      "train loss:0.00043110247584367847\n",
      "train loss:0.00011843567361397962\n",
      "train loss:6.721574448143132e-05\n",
      "train loss:2.635769583523228e-05\n",
      "train loss:0.00020285719589163592\n",
      "train loss:5.262755143118563e-05\n",
      "train loss:9.451787394967777e-05\n",
      "train loss:1.3092664390645821e-05\n",
      "train loss:8.314130171710506e-05\n",
      "train loss:3.986092418447044e-05\n",
      "train loss:0.0002535564579047538\n",
      "train loss:6.399198978553748e-05\n",
      "train loss:3.628776902307888e-05\n",
      "train loss:0.00017145070486744774\n",
      "train loss:0.000390222430597549\n",
      "train loss:8.748100966304009e-05\n",
      "train loss:2.9781987942735634e-05\n",
      "train loss:7.305752388551397e-05\n",
      "train loss:0.0006920979417816193\n",
      "train loss:9.040213675602826e-06\n",
      "train loss:2.2723745402829266e-05\n",
      "train loss:0.0012510189221343168\n",
      "train loss:0.0001009095939314184\n",
      "train loss:0.00011311367425410148\n",
      "train loss:0.0001750275047400228\n",
      "train loss:0.0001078815085235273\n",
      "train loss:0.00014309166151091587\n",
      "train loss:0.0009831591174427896\n",
      "train loss:0.00014114333040335806\n",
      "train loss:0.00046623930573510994\n",
      "train loss:0.0002737764072419889\n",
      "train loss:0.00017915286576991796\n",
      "train loss:5.3585731074344464e-05\n",
      "train loss:9.66754746884387e-05\n",
      "train loss:0.00046806641509061065\n",
      "train loss:0.00017383550636612994\n",
      "train loss:0.0005711231149659845\n",
      "train loss:7.82901678475726e-05\n",
      "train loss:0.00019621655415646367\n",
      "train loss:7.702150814908854e-05\n",
      "train loss:0.00016969552317072658\n",
      "train loss:7.418481897823632e-05\n",
      "train loss:3.5872789378255915e-05\n",
      "train loss:0.0001179280346272226\n",
      "train loss:0.0004449376197407817\n",
      "train loss:0.00010074468086215731\n",
      "train loss:0.00016058459410193005\n",
      "train loss:0.0001953717437576268\n",
      "train loss:0.0002945985928870445\n",
      "train loss:0.00016973801188928432\n",
      "train loss:0.00021049365516780143\n",
      "train loss:0.00011205661013160949\n",
      "train loss:1.3856383985458963e-05\n",
      "train loss:4.360253452115692e-05\n",
      "train loss:2.0609273336302376e-05\n",
      "train loss:0.00018067688006574457\n",
      "train loss:0.0001646072342196117\n",
      "train loss:7.781257210922156e-05\n",
      "train loss:0.00047529353082799067\n",
      "train loss:8.483739934016027e-05\n",
      "train loss:8.480193364934608e-05\n",
      "train loss:0.0003045633100938892\n",
      "train loss:2.8492229644351835e-05\n",
      "train loss:0.00011335613725704917\n",
      "train loss:2.1634426514584752e-05\n",
      "train loss:9.627091484357123e-05\n",
      "train loss:0.00015851055495212765\n",
      "train loss:3.429517761864337e-05\n",
      "train loss:0.000240160932283684\n",
      "train loss:0.00014124749296131397\n",
      "train loss:0.0001215389590309591\n",
      "train loss:0.00021792611163557862\n",
      "train loss:0.0001618639311814206\n",
      "train loss:0.000149267012463403\n",
      "train loss:0.00010259441602674474\n",
      "train loss:0.00015536052049945287\n",
      "train loss:0.00014305623297780192\n",
      "train loss:0.00014794668811157516\n",
      "train loss:0.00011734153011202471\n",
      "train loss:0.00015033957190512245\n",
      "train loss:6.204274521192349e-05\n",
      "train loss:0.0005008211112348869\n",
      "train loss:0.00010665023389255592\n",
      "train loss:9.810453064784315e-05\n",
      "train loss:0.00013888802777491221\n",
      "train loss:9.484878393187575e-05\n",
      "train loss:0.000548005926863741\n",
      "train loss:0.00013903244558168825\n",
      "train loss:9.639603260963137e-05\n",
      "train loss:1.52188853918941e-05\n",
      "train loss:0.0003833380238407554\n",
      "train loss:0.0005069924326424134\n",
      "train loss:9.653342930901346e-05\n",
      "train loss:4.03740449424302e-05\n",
      "train loss:0.00013301888177709147\n",
      "train loss:5.9083802742427994e-05\n",
      "train loss:0.00017656941725844195\n",
      "train loss:0.00014077261790024247\n",
      "train loss:0.0002068490174774653\n",
      "train loss:4.039919660520021e-05\n",
      "train loss:0.0001276530171532018\n",
      "train loss:0.00044313244436602916\n",
      "train loss:6.914389431586816e-05\n",
      "train loss:4.810132870951007e-05\n",
      "train loss:3.3037720093800515e-05\n",
      "train loss:9.172634579726355e-05\n",
      "train loss:0.000185696958800451\n",
      "train loss:0.0004986901733185493\n",
      "train loss:0.0005462060646166036\n",
      "train loss:7.706798574116023e-05\n",
      "train loss:4.8251505333204083e-05\n",
      "train loss:0.00021403987967345077\n",
      "train loss:0.0002968313377116188\n",
      "train loss:8.593979939787387e-05\n",
      "train loss:0.00015996250938916291\n",
      "train loss:6.301224087979312e-05\n",
      "train loss:9.931364893758232e-05\n",
      "train loss:2.4420532866123466e-05\n",
      "train loss:0.00029194959294207815\n",
      "train loss:7.931540033208695e-05\n",
      "train loss:1.251592278437617e-05\n",
      "train loss:0.0003759917015980338\n",
      "train loss:0.0003807452315085568\n",
      "train loss:2.78433599625342e-05\n",
      "train loss:0.00013227309759007624\n",
      "train loss:0.00015218039404923817\n",
      "train loss:3.862963251574293e-05\n",
      "train loss:0.0001042811180383598\n",
      "train loss:0.0002661187537510468\n",
      "train loss:9.821093815366777e-05\n",
      "train loss:7.842457315137542e-05\n",
      "=== epoch:18, train acc:1.0, test acc:0.996 ===\n",
      "train loss:0.00018113254758339017\n",
      "train loss:0.00012087115989488972\n",
      "train loss:0.0001320579142617611\n",
      "train loss:0.00014187603594778352\n",
      "train loss:9.203393508457678e-05\n",
      "train loss:3.541541963448617e-05\n",
      "train loss:0.0002754212595040415\n",
      "train loss:2.148170336914596e-05\n",
      "train loss:2.8780876054411687e-05\n",
      "train loss:0.00013668959766769797\n",
      "train loss:0.00010315614830976364\n",
      "train loss:0.000366952253576376\n",
      "train loss:0.0003073189876298561\n",
      "train loss:0.0003850557901751258\n",
      "train loss:0.00011937328249834427\n",
      "train loss:0.000122202941666622\n",
      "train loss:5.981529166760784e-05\n",
      "train loss:4.46820118407367e-05\n",
      "train loss:4.3905894696278375e-05\n",
      "train loss:2.6913381000695045e-05\n",
      "train loss:0.00011786660901870596\n",
      "train loss:0.000202581663745597\n",
      "train loss:0.00012804196309238423\n",
      "train loss:0.00013590185313677768\n",
      "train loss:9.349463155197024e-05\n",
      "train loss:3.125695680886313e-05\n",
      "train loss:0.0002263802550911113\n",
      "train loss:0.0006852329049433398\n",
      "train loss:0.00012100796126485735\n",
      "train loss:0.0005701771153022692\n",
      "train loss:0.00011647301351851788\n",
      "train loss:3.945245061049959e-05\n",
      "train loss:0.00010547270629490648\n",
      "train loss:0.00018098972970352782\n",
      "train loss:1.7524914068494923e-05\n",
      "train loss:7.445729485647323e-05\n",
      "train loss:6.211346601120415e-05\n",
      "train loss:0.00031191434541034095\n",
      "train loss:8.45450582440075e-05\n",
      "train loss:0.00020519511737585196\n",
      "train loss:8.825793337732662e-05\n",
      "train loss:3.790685271678519e-05\n",
      "train loss:6.423658167647409e-05\n",
      "train loss:5.301907987720515e-05\n",
      "train loss:0.0004640559839195202\n",
      "train loss:0.00028722713878677947\n",
      "train loss:0.00011145419633730174\n",
      "train loss:0.000150320559968325\n",
      "train loss:1.1486084939121608e-05\n",
      "train loss:8.315197395280456e-05\n",
      "train loss:2.535733813567009e-05\n",
      "train loss:0.0002600265141430403\n",
      "train loss:1.1209833470183802e-05\n",
      "train loss:4.179348387581807e-05\n",
      "train loss:3.557750022047861e-05\n",
      "train loss:0.00022898505956575672\n",
      "train loss:0.0001609461472988435\n",
      "train loss:9.448043709005008e-05\n",
      "train loss:5.744461158642981e-05\n",
      "train loss:8.862792394661211e-05\n",
      "train loss:1.72158996438509e-05\n",
      "train loss:0.00020991207524262214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00010400970290228611\n",
      "train loss:7.155431113279883e-05\n",
      "train loss:0.0002832307606887393\n",
      "train loss:3.387892251926914e-05\n",
      "train loss:3.9218689674561556e-05\n",
      "train loss:8.437430476975677e-05\n",
      "train loss:0.0010748581461144\n",
      "train loss:7.784648875728851e-05\n",
      "train loss:0.00010305067704419216\n",
      "train loss:6.12389560513476e-05\n",
      "train loss:3.0213757070147018e-05\n",
      "train loss:0.00020680559271158804\n",
      "train loss:9.141099996366381e-05\n",
      "train loss:7.960014944968572e-05\n",
      "train loss:0.00020004424599192466\n",
      "train loss:0.0008883147052594053\n",
      "train loss:5.970528065831815e-05\n",
      "train loss:1.965692993660043e-05\n",
      "train loss:3.984749705731787e-05\n",
      "train loss:0.0002522222562051942\n",
      "train loss:6.144492470098713e-05\n",
      "train loss:3.0418226238652818e-05\n",
      "train loss:1.0751607011037747e-05\n",
      "train loss:0.00015414374885846903\n",
      "train loss:4.492752387320392e-05\n",
      "train loss:0.0003213912862868232\n",
      "train loss:2.1590042001652476e-05\n",
      "train loss:0.0002295052906103115\n",
      "train loss:0.0001120409668261064\n",
      "train loss:0.00024199614748547185\n",
      "train loss:7.678814481357388e-05\n",
      "train loss:0.0001842700614669654\n",
      "train loss:0.00019041546290334506\n",
      "train loss:0.0002144213183664199\n",
      "train loss:0.00011093346869633411\n",
      "train loss:9.24325808524434e-05\n",
      "train loss:5.2668733199600146e-05\n",
      "train loss:3.35538859914518e-05\n",
      "train loss:0.00014090227855077648\n",
      "train loss:5.651587539706283e-05\n",
      "train loss:0.0001276379327659178\n",
      "train loss:0.00023766986628352503\n",
      "train loss:8.744367044261662e-05\n",
      "train loss:4.588130082341169e-05\n",
      "train loss:9.903968385715978e-05\n",
      "train loss:5.785607476151228e-05\n",
      "train loss:0.00012190095741750394\n",
      "train loss:3.5173907694942975e-05\n",
      "train loss:5.041216787019498e-05\n",
      "train loss:0.00029919113453634043\n",
      "train loss:0.0004713734177933283\n",
      "train loss:0.00010506182435021716\n",
      "train loss:1.703517447413874e-05\n",
      "train loss:5.637900513787198e-05\n",
      "train loss:0.00018025819147937124\n",
      "train loss:0.00014231949105378907\n",
      "train loss:0.0003085019553099246\n",
      "train loss:2.631578788499297e-05\n",
      "train loss:6.566643436864144e-05\n",
      "train loss:3.7316990138925494e-05\n",
      "train loss:7.861686838365246e-05\n",
      "train loss:0.0002068351020778086\n",
      "train loss:6.285639668949467e-05\n",
      "train loss:3.889263090643394e-05\n",
      "train loss:6.569170027836465e-05\n",
      "train loss:0.00010391874104367715\n",
      "train loss:7.809911755039785e-05\n",
      "train loss:0.00026677352104665086\n",
      "train loss:3.6550199377386766e-05\n",
      "train loss:0.0003502936572507415\n",
      "train loss:4.2283864871913386e-05\n",
      "train loss:0.00013095927173693655\n",
      "train loss:5.89483860678335e-05\n",
      "train loss:4.813574427475375e-05\n",
      "train loss:2.7439980749430506e-05\n",
      "train loss:1.4167755348982496e-05\n",
      "train loss:0.00011213158566465801\n",
      "train loss:2.8701563890047542e-05\n",
      "train loss:6.281506775348128e-05\n",
      "train loss:6.143834420277422e-05\n",
      "train loss:0.00021451190811438522\n",
      "train loss:2.3861918552866647e-05\n",
      "train loss:0.00013503794889859944\n",
      "train loss:2.8424630322519698e-05\n",
      "train loss:6.274165162863213e-05\n",
      "train loss:1.956221045197e-05\n",
      "train loss:6.977557758986983e-05\n",
      "train loss:0.000293997777287874\n",
      "train loss:0.0009084844419450222\n",
      "train loss:3.0024296896365693e-05\n",
      "train loss:9.115263236658147e-05\n",
      "train loss:0.00011078963133791233\n",
      "train loss:0.0017256386293064603\n",
      "train loss:9.290456620732216e-05\n",
      "train loss:5.8148195910465815e-05\n",
      "train loss:7.020989229191209e-05\n",
      "train loss:0.00015682427825991786\n",
      "train loss:7.021413485926102e-06\n",
      "train loss:9.109082147416575e-05\n",
      "train loss:0.0004797416672103501\n",
      "train loss:4.2788916837216794e-05\n",
      "train loss:6.838663721609046e-05\n",
      "train loss:0.00017200174117816392\n",
      "train loss:0.0002618210977411832\n",
      "train loss:0.00011630799728973648\n",
      "train loss:0.00011616207768049464\n",
      "train loss:0.00012260463983549243\n",
      "train loss:9.512367658797428e-05\n",
      "train loss:1.3600453805090462e-05\n",
      "train loss:5.781385893431256e-05\n",
      "train loss:5.176736837248611e-05\n",
      "train loss:0.0001612614569883231\n",
      "train loss:0.000126099580783033\n",
      "train loss:0.00011227252918729834\n",
      "train loss:0.00012988129730331932\n",
      "train loss:9.769928365725413e-05\n",
      "train loss:9.608503671039877e-05\n",
      "train loss:2.5152578788616737e-05\n",
      "train loss:0.00017032126485217833\n",
      "train loss:3.0435529612831257e-05\n",
      "train loss:5.167033745850395e-05\n",
      "train loss:4.934750343622424e-05\n",
      "train loss:6.949331491018358e-05\n",
      "train loss:7.711253930502959e-05\n",
      "train loss:9.958590932010422e-05\n",
      "train loss:0.0003101861244207332\n",
      "train loss:8.380888778894156e-05\n",
      "train loss:0.00016773015113704306\n",
      "train loss:8.877618987419932e-05\n",
      "train loss:2.3762013647105924e-05\n",
      "train loss:0.0006186280795246625\n",
      "train loss:0.0008824333913273491\n",
      "train loss:0.00019573938514569857\n",
      "train loss:9.657735469497594e-05\n",
      "train loss:2.453934857497921e-05\n",
      "train loss:0.00024178512375406264\n",
      "train loss:3.3850999025844455e-05\n",
      "train loss:0.00022705806054822947\n",
      "train loss:0.00023721715023722955\n",
      "train loss:7.020722064506492e-05\n",
      "train loss:0.0010024193479017632\n",
      "train loss:6.571542894140574e-05\n",
      "train loss:0.00027252059287077174\n",
      "train loss:6.844953603635382e-05\n",
      "train loss:4.6199655015074145e-05\n",
      "train loss:4.4241542506309284e-05\n",
      "train loss:9.202729005306514e-05\n",
      "train loss:5.985364873142751e-05\n",
      "train loss:3.6411273257632546e-05\n",
      "train loss:0.0001448381551595975\n",
      "train loss:6.660012468310492e-05\n",
      "train loss:7.86353177412034e-05\n",
      "train loss:0.00033786058737620626\n",
      "train loss:0.0002487517491020455\n",
      "train loss:0.0001432041639484367\n",
      "train loss:6.81266270395338e-05\n",
      "train loss:0.00010743728798791055\n",
      "train loss:0.00013763736152088338\n",
      "train loss:0.0005182230062195343\n",
      "train loss:0.00010019887979567688\n",
      "train loss:0.00041550159765210194\n",
      "train loss:0.0001560547653517607\n",
      "train loss:8.662868474231462e-06\n",
      "train loss:4.201860388315239e-05\n",
      "train loss:9.212949163788267e-05\n",
      "train loss:3.476750266462555e-05\n",
      "train loss:0.00024653331660569376\n",
      "train loss:0.00011577967307581846\n",
      "train loss:9.716657126488596e-06\n",
      "train loss:0.00013247574786917152\n",
      "train loss:0.00010525440881467147\n",
      "train loss:8.385929070366447e-05\n",
      "train loss:3.1015916692219746e-05\n",
      "train loss:3.919794807366891e-05\n",
      "train loss:0.00038746972037522474\n",
      "train loss:0.00013786086520669596\n",
      "train loss:1.3884698194681308e-05\n",
      "train loss:3.488652595697059e-05\n",
      "train loss:0.0001746817425061115\n",
      "train loss:4.051722539293378e-05\n",
      "train loss:2.0974899433395218e-05\n",
      "train loss:0.00025866839317351505\n",
      "train loss:8.12793232809234e-05\n",
      "train loss:6.57820489842143e-05\n",
      "train loss:0.0001201655623485733\n",
      "train loss:0.00035774307011698497\n",
      "train loss:0.00010001114012198873\n",
      "train loss:3.2347450223364274e-05\n",
      "train loss:4.3315041774762124e-05\n",
      "train loss:3.241910425269113e-05\n",
      "train loss:0.00010050151054581136\n",
      "train loss:5.921418100582698e-05\n",
      "train loss:0.0002617427014125281\n",
      "train loss:0.0002806193690005939\n",
      "train loss:0.00011620015819326414\n",
      "train loss:1.0188488605645955e-05\n",
      "train loss:5.824731698886064e-05\n",
      "train loss:3.589370874460689e-05\n",
      "train loss:0.00021913910789644263\n",
      "train loss:0.0001400729603111823\n",
      "train loss:0.0008224532983966143\n",
      "train loss:9.14001225275072e-05\n",
      "train loss:0.00034931990163189773\n",
      "train loss:5.3325986684653295e-05\n",
      "train loss:5.3844624443549096e-05\n",
      "train loss:5.958408104740683e-05\n",
      "train loss:0.00020173041230417502\n",
      "train loss:7.199692034228083e-05\n",
      "train loss:8.34978139284826e-05\n",
      "train loss:0.00015820840949442845\n",
      "train loss:3.6408282393692205e-05\n",
      "train loss:4.814529778499259e-05\n",
      "train loss:0.0001430199206590577\n",
      "train loss:0.0001305336510863558\n",
      "train loss:9.354270213778705e-05\n",
      "train loss:4.550914488537679e-05\n",
      "train loss:2.6008464418507925e-05\n",
      "train loss:5.761265711367647e-05\n",
      "train loss:7.862376710153886e-05\n",
      "train loss:8.41023644905696e-05\n",
      "train loss:5.6768198182055825e-05\n",
      "train loss:0.00012708751670903703\n",
      "train loss:0.000206787150069551\n",
      "train loss:8.279630534918779e-05\n",
      "train loss:8.86293936047384e-05\n",
      "train loss:0.00027375132697197356\n",
      "train loss:7.400339697829146e-05\n",
      "train loss:0.00020358721697699925\n",
      "train loss:0.00023380906658916742\n",
      "train loss:0.00032759047900797207\n",
      "train loss:4.032163610896766e-05\n",
      "train loss:6.814060759280348e-05\n",
      "train loss:0.0001462311052623944\n",
      "train loss:2.78025638087202e-05\n",
      "train loss:6.934123756538449e-05\n",
      "train loss:0.0007369606094970793\n",
      "train loss:8.27921530385137e-05\n",
      "train loss:0.00012898453649592354\n",
      "train loss:0.00027176102506759126\n",
      "train loss:4.030863125840823e-05\n",
      "train loss:4.269544184189859e-05\n",
      "train loss:0.00018197409476075933\n",
      "train loss:3.0302613361100624e-05\n",
      "train loss:9.725608163744792e-05\n",
      "train loss:0.0001096080843752487\n",
      "train loss:9.581693279959738e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.9568532804275016e-05\n",
      "train loss:9.039747379165404e-05\n",
      "train loss:2.4911034359415896e-05\n",
      "train loss:1.2200005737786353e-05\n",
      "train loss:0.00032876561562858117\n",
      "train loss:0.0001040902549153696\n",
      "train loss:7.783065693241997e-05\n",
      "train loss:0.0004450660813665643\n",
      "train loss:0.0003603478566790658\n",
      "train loss:4.259499498555471e-05\n",
      "train loss:1.52909031431035e-05\n",
      "train loss:0.00017132958187628117\n",
      "train loss:7.485634412677047e-06\n",
      "train loss:2.9412103524562074e-05\n",
      "train loss:6.72800998960424e-05\n",
      "train loss:0.00018931957015806979\n",
      "train loss:0.0002692598865322103\n",
      "train loss:0.00014027581890569215\n",
      "train loss:5.535137619355092e-05\n",
      "train loss:0.00018972685819789142\n",
      "train loss:9.311207565415869e-05\n",
      "train loss:3.48287127972864e-05\n",
      "train loss:3.275706171763212e-05\n",
      "train loss:3.260946936573087e-05\n",
      "train loss:6.622859598490047e-05\n",
      "train loss:6.862539815784432e-05\n",
      "train loss:0.00032056994506084944\n",
      "train loss:1.2778042652381656e-05\n",
      "train loss:2.5511262330084752e-05\n",
      "train loss:2.2049361832656016e-05\n",
      "train loss:0.00012437208995564074\n",
      "train loss:0.0001904094192833104\n",
      "train loss:0.00013501490953209157\n",
      "train loss:4.3379130231844764e-05\n",
      "train loss:1.029874770370816e-05\n",
      "train loss:9.314340712648077e-05\n",
      "train loss:9.086708909866326e-05\n",
      "train loss:9.735257852425274e-05\n",
      "train loss:0.00018145914847896407\n",
      "train loss:2.4657657385282523e-05\n",
      "train loss:6.588749714267117e-05\n",
      "train loss:0.00012482494678292167\n",
      "train loss:2.6676876729431187e-05\n",
      "train loss:4.145462853069376e-05\n",
      "train loss:5.514376933383319e-05\n",
      "train loss:4.8183840855587825e-05\n",
      "train loss:0.00013765805547504475\n",
      "train loss:0.00011938080836342204\n",
      "train loss:0.00022180633792030565\n",
      "train loss:5.950192274251792e-05\n",
      "train loss:0.0007384065116586382\n",
      "train loss:8.596633444466666e-05\n",
      "train loss:3.202347886016365e-05\n",
      "train loss:3.816146297977809e-05\n",
      "train loss:2.3054039948560444e-05\n",
      "train loss:2.05635634647857e-05\n",
      "train loss:0.00012076157259373393\n",
      "train loss:6.820218239911785e-05\n",
      "train loss:3.875983336455033e-05\n",
      "train loss:7.868590335477362e-05\n",
      "=== epoch:19, train acc:1.0, test acc:0.996 ===\n",
      "train loss:7.590637160154573e-05\n",
      "train loss:2.194015821218244e-05\n",
      "train loss:9.267311558921094e-06\n",
      "train loss:0.00015534115285422779\n",
      "train loss:2.1344421549956184e-05\n",
      "train loss:0.00018122458681031617\n",
      "train loss:0.0007688383258037484\n",
      "train loss:2.2718756284801774e-05\n",
      "train loss:4.66134720108342e-05\n",
      "train loss:0.0001375398929613712\n",
      "train loss:9.142879088949947e-05\n",
      "train loss:5.2113100655900675e-05\n",
      "train loss:0.0003533545752888542\n",
      "train loss:0.0002687112452388973\n",
      "train loss:0.0001428871903656013\n",
      "train loss:5.516451874834826e-05\n",
      "train loss:9.3427664508006e-05\n",
      "train loss:2.7660369669237376e-05\n",
      "train loss:2.213484720148084e-05\n",
      "train loss:0.00012453289411576166\n",
      "train loss:3.702418426819766e-05\n",
      "train loss:5.1447680442685606e-05\n",
      "train loss:3.552264423554875e-05\n",
      "train loss:0.00012818007211418358\n",
      "train loss:5.293006996739568e-05\n",
      "train loss:8.723413106430058e-05\n",
      "train loss:4.637720707593948e-05\n",
      "train loss:0.0003063740820895354\n",
      "train loss:3.657984612417724e-05\n",
      "train loss:4.271333610732289e-05\n",
      "train loss:0.00015508137126020593\n",
      "train loss:3.8304468446628884e-05\n",
      "train loss:0.00015750801074703902\n",
      "train loss:0.00029151800845410536\n",
      "train loss:0.0001882273013146456\n",
      "train loss:8.959510827125696e-05\n",
      "train loss:0.00011976396947350692\n",
      "train loss:0.00030877663841091406\n",
      "train loss:2.98186807879518e-05\n",
      "train loss:6.635538551460727e-05\n",
      "train loss:7.992146159271247e-05\n",
      "train loss:2.121825002389711e-05\n",
      "train loss:0.00011916874213903434\n",
      "train loss:9.727377943311629e-05\n",
      "train loss:0.0007219120965264975\n",
      "train loss:0.00011195008444676785\n",
      "train loss:6.237988040100322e-05\n",
      "train loss:9.368198389883059e-05\n",
      "train loss:0.00025074428610167687\n",
      "train loss:4.436889610534255e-05\n",
      "train loss:0.00015685138943806383\n",
      "train loss:1.9187613973395272e-05\n",
      "train loss:0.00025017068702888194\n",
      "train loss:0.0001064466321783735\n",
      "train loss:4.0161953339048706e-05\n",
      "train loss:7.98014635227088e-05\n",
      "train loss:4.49635838795759e-05\n",
      "train loss:0.00014517972924160094\n",
      "train loss:3.0348367262700694e-05\n",
      "train loss:5.832906955705093e-05\n",
      "train loss:5.9306467862772664e-05\n",
      "train loss:1.9761924427432226e-05\n",
      "train loss:0.00011243544767234108\n",
      "train loss:5.861424491913468e-06\n",
      "train loss:0.00033813578878518234\n",
      "train loss:0.00014210106957651482\n",
      "train loss:0.00016048791212381946\n",
      "train loss:7.560567748020128e-05\n",
      "train loss:7.385929366237545e-05\n",
      "train loss:0.00011365002159151276\n",
      "train loss:8.4388653554095e-06\n",
      "train loss:0.0003385748781853148\n",
      "train loss:4.118872034199972e-05\n",
      "train loss:0.0001269854898617325\n",
      "train loss:6.806462076328152e-05\n",
      "train loss:2.5177114851086367e-05\n",
      "train loss:0.00013917987627710325\n",
      "train loss:0.0002169718898704952\n",
      "train loss:1.2447161306288877e-05\n",
      "train loss:4.639460581357064e-05\n",
      "train loss:2.515199845699867e-05\n",
      "train loss:5.3707506698364947e-05\n",
      "train loss:5.4334337685779884e-05\n",
      "train loss:1.6512438688205788e-05\n",
      "train loss:0.0003684290325192053\n",
      "train loss:3.844319975716939e-05\n",
      "train loss:1.610214392415213e-05\n",
      "train loss:9.102005347108226e-05\n",
      "train loss:5.4907953291671345e-05\n",
      "train loss:8.066049210700074e-05\n",
      "train loss:7.254389374225682e-05\n",
      "train loss:1.438274152158568e-05\n",
      "train loss:2.7540475141567137e-05\n",
      "train loss:2.102620369513781e-05\n",
      "train loss:6.74923760318931e-05\n",
      "train loss:0.00011247727601097306\n",
      "train loss:8.271948652453228e-05\n",
      "train loss:7.854554130940955e-06\n",
      "train loss:5.745829839419515e-05\n",
      "train loss:5.490866473152938e-05\n",
      "train loss:5.0226635266309503e-05\n",
      "train loss:4.122405252503293e-05\n",
      "train loss:0.00010180267580677301\n",
      "train loss:7.007940719146863e-05\n",
      "train loss:3.0515632448652336e-05\n",
      "train loss:1.4951473896873591e-05\n",
      "train loss:9.94831844188045e-05\n",
      "train loss:0.00016029067306271987\n",
      "train loss:3.749698310744852e-05\n",
      "train loss:0.00011861274615381045\n",
      "train loss:0.0002204298560720677\n",
      "train loss:3.747943440960507e-05\n",
      "train loss:0.00016970554552824476\n",
      "train loss:3.8560355741844846e-05\n",
      "train loss:0.0002913331219393566\n",
      "train loss:8.17887379577731e-05\n",
      "train loss:0.00014310621529470122\n",
      "train loss:4.942735623238795e-05\n",
      "train loss:0.00010972163604601451\n",
      "train loss:0.00011573406117945454\n",
      "train loss:4.864590566669998e-05\n",
      "train loss:2.5248253708626075e-05\n",
      "train loss:8.625576393728743e-05\n",
      "train loss:4.950053976574675e-05\n",
      "train loss:0.00016088454790790587\n",
      "train loss:0.0003386467822595741\n",
      "train loss:3.398336342205104e-05\n",
      "train loss:0.00010464106759234064\n",
      "train loss:8.814623369416858e-05\n",
      "train loss:6.354741375475269e-05\n",
      "train loss:6.233398008005318e-05\n",
      "train loss:0.0002412589198177532\n",
      "train loss:2.62043609550736e-05\n",
      "train loss:9.344034255236847e-06\n",
      "train loss:7.664198174913815e-05\n",
      "train loss:1.9593350588644403e-05\n",
      "train loss:0.0006101936682660594\n",
      "train loss:1.8613337849247194e-05\n",
      "train loss:0.00011023696834959797\n",
      "train loss:7.000369528135812e-05\n",
      "train loss:0.00020016976109205295\n",
      "train loss:0.0002820187373574799\n",
      "train loss:2.4295167687846024e-05\n",
      "train loss:3.678062518789726e-05\n",
      "train loss:6.084140282853177e-05\n",
      "train loss:1.0514538888962123e-05\n",
      "train loss:4.584623173075195e-05\n",
      "train loss:8.173667321796738e-06\n",
      "train loss:2.1986757256601598e-05\n",
      "train loss:4.406245513643627e-05\n",
      "train loss:9.090021558493634e-06\n",
      "train loss:8.835271868322208e-06\n",
      "train loss:2.2153785931601882e-05\n",
      "train loss:0.00014956671966046602\n",
      "train loss:0.00016669203334124016\n",
      "train loss:5.69683634667258e-05\n",
      "train loss:1.4582198015205407e-05\n",
      "train loss:6.925588210434154e-05\n",
      "train loss:7.637388735554524e-05\n",
      "train loss:0.00018861742837684515\n",
      "train loss:7.479423852492177e-05\n",
      "train loss:5.344801276125551e-05\n",
      "train loss:3.8698409802837296e-05\n",
      "train loss:6.957612301953083e-05\n",
      "train loss:3.411576898568235e-05\n",
      "train loss:8.529088396207193e-05\n",
      "train loss:5.062805881150112e-05\n",
      "train loss:0.000125920829657228\n",
      "train loss:3.196627075251611e-05\n",
      "train loss:6.238729731762783e-06\n",
      "train loss:0.00030669560844990646\n",
      "train loss:0.0001139826865032895\n",
      "train loss:8.295083127429903e-06\n",
      "train loss:0.00016737325392055866\n",
      "train loss:5.0723914331991334e-05\n",
      "train loss:9.10279402425479e-05\n",
      "train loss:0.00010779927522410872\n",
      "train loss:0.00017265461349015454\n",
      "train loss:0.000455871567078588\n",
      "train loss:3.203123589498105e-05\n",
      "train loss:9.883370736035606e-06\n",
      "train loss:0.00019623827008971286\n",
      "train loss:6.457026022356035e-05\n",
      "train loss:0.00011317575145488264\n",
      "train loss:0.0001243305549334851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00015377423987460433\n",
      "train loss:6.525034561485279e-05\n",
      "train loss:9.226802076737251e-05\n",
      "train loss:1.287902554301965e-05\n",
      "train loss:0.00016914877447677813\n",
      "train loss:2.5702469855385107e-05\n",
      "train loss:3.4361198996948055e-05\n",
      "train loss:0.00014468386909851144\n",
      "train loss:8.457581549511956e-05\n",
      "train loss:0.00010289497133352305\n",
      "train loss:6.322437671889115e-05\n",
      "train loss:3.419108418696571e-05\n",
      "train loss:3.3811083961509436e-05\n",
      "train loss:0.00010483317699240023\n",
      "train loss:3.16056109618202e-05\n",
      "train loss:4.1625201207074265e-05\n",
      "train loss:2.8793353373632805e-05\n",
      "train loss:6.975350878531563e-05\n",
      "train loss:0.00015530757727121296\n",
      "train loss:0.00012721691106370615\n",
      "train loss:0.00011593170443250599\n",
      "train loss:0.00010964923906235953\n",
      "train loss:6.317007853960418e-05\n",
      "train loss:3.940296848756671e-05\n",
      "train loss:8.406469377634399e-05\n",
      "train loss:1.8067019372674568e-05\n",
      "train loss:4.645046522687664e-05\n",
      "train loss:4.099443724314126e-05\n",
      "train loss:7.146387672835195e-05\n",
      "train loss:4.903581200838586e-05\n",
      "train loss:0.00020351647709905102\n",
      "train loss:0.00011380648590381557\n",
      "train loss:6.304983258541512e-05\n",
      "train loss:3.590549764219962e-05\n",
      "train loss:0.000139324745703691\n",
      "train loss:3.85714581176528e-05\n",
      "train loss:2.597308362182466e-05\n",
      "train loss:1.0329520897033268e-05\n",
      "train loss:0.00015540329127758105\n",
      "train loss:5.109697797061511e-05\n",
      "train loss:8.178590549576165e-05\n",
      "train loss:0.00018957557204274112\n",
      "train loss:3.486855327092594e-05\n",
      "train loss:0.00010694514307684121\n",
      "train loss:2.4967944321387006e-05\n",
      "train loss:5.015710408167727e-05\n",
      "train loss:5.79192697921879e-05\n",
      "train loss:0.00020217386160676162\n",
      "train loss:6.385693412349594e-05\n",
      "train loss:5.400152509357502e-05\n",
      "train loss:2.061765034215969e-05\n",
      "train loss:1.9009203578024037e-05\n",
      "train loss:3.975739260126262e-05\n",
      "train loss:8.459332665531077e-05\n",
      "train loss:4.958051022410782e-05\n",
      "train loss:4.66501068884726e-05\n",
      "train loss:2.432136893052865e-05\n",
      "train loss:0.00020128272855701168\n",
      "train loss:5.5181524537953e-05\n",
      "train loss:6.33932318384639e-05\n",
      "train loss:5.501433897785132e-05\n",
      "train loss:3.430350378665076e-05\n",
      "train loss:1.298850604834019e-05\n",
      "train loss:3.346177819330413e-05\n",
      "train loss:0.00010161810102130181\n",
      "train loss:2.715238495347526e-05\n",
      "train loss:0.00011536497171714355\n",
      "train loss:1.4042946676549765e-05\n",
      "train loss:0.00010665847505654757\n",
      "train loss:7.852197831628285e-06\n",
      "train loss:4.6352491761769875e-05\n",
      "train loss:4.199098376821616e-05\n",
      "train loss:7.859794174942164e-06\n",
      "train loss:6.230677653925223e-06\n",
      "train loss:0.00015493591618053056\n",
      "train loss:1.9129294045401623e-05\n",
      "train loss:1.608485632105079e-05\n",
      "train loss:0.00018784508525305965\n",
      "train loss:1.893517062556861e-05\n",
      "train loss:4.054538804138703e-05\n",
      "train loss:6.421765047792626e-05\n",
      "train loss:1.7743661412574296e-05\n",
      "train loss:7.020948285735512e-05\n",
      "train loss:7.924829031186867e-05\n",
      "train loss:7.905211969885341e-05\n",
      "train loss:6.8976069100298525e-06\n",
      "train loss:2.8484256247266936e-05\n",
      "train loss:2.680115915622631e-05\n",
      "train loss:9.401012814465365e-05\n",
      "train loss:6.678735350105513e-06\n",
      "train loss:0.00012129302292033827\n",
      "train loss:6.641263267719868e-05\n",
      "train loss:1.0182896111812861e-05\n",
      "train loss:6.125410150683251e-05\n",
      "train loss:5.408335285576231e-05\n",
      "train loss:2.5772161583104952e-05\n",
      "train loss:5.728756901180357e-05\n",
      "train loss:3.259167409204283e-05\n",
      "train loss:6.860897252080058e-05\n",
      "train loss:0.00014025002618656967\n",
      "train loss:2.3520588398002517e-05\n",
      "train loss:0.00022068896759454268\n",
      "train loss:2.4122853401072605e-05\n",
      "train loss:0.00010786664399574478\n",
      "train loss:5.803917616885537e-06\n",
      "train loss:3.67904713821445e-05\n",
      "train loss:7.09529256846567e-05\n",
      "train loss:3.3321920308799256e-05\n",
      "train loss:8.339251726465316e-06\n",
      "train loss:1.2962748489449608e-05\n",
      "train loss:9.278249435920722e-05\n",
      "train loss:3.4672213174831875e-05\n",
      "train loss:5.648098693646546e-05\n",
      "train loss:9.830496313044795e-05\n",
      "train loss:9.280098116880177e-05\n",
      "train loss:9.970284136325435e-05\n",
      "train loss:8.42976092628401e-05\n",
      "train loss:1.494452358286668e-05\n",
      "train loss:5.846116243554576e-05\n",
      "train loss:3.194802419120423e-05\n",
      "train loss:1.891024170486355e-05\n",
      "train loss:8.113608854718725e-05\n",
      "train loss:7.647610782695742e-05\n",
      "train loss:7.98409570420618e-05\n",
      "train loss:6.059539898914566e-05\n",
      "train loss:1.1952731565626601e-05\n",
      "train loss:1.3446104559863824e-05\n",
      "train loss:1.995716240783237e-05\n",
      "train loss:1.2425870266902167e-05\n",
      "train loss:4.194474829703732e-05\n",
      "train loss:0.00022954571935640937\n",
      "train loss:1.2151217073397082e-05\n",
      "train loss:5.089730608286494e-05\n",
      "train loss:0.00019057405735117412\n",
      "train loss:5.1103574739474974e-05\n",
      "train loss:0.00024124449128724114\n",
      "train loss:1.0603033157942122e-05\n",
      "train loss:8.402648492749811e-05\n",
      "train loss:1.6058382091905436e-05\n",
      "train loss:9.512725050352557e-05\n",
      "train loss:3.3694048732331585e-05\n",
      "train loss:0.00042023668072914167\n",
      "train loss:4.2217111610559945e-05\n",
      "train loss:1.62528522395689e-05\n",
      "train loss:5.7917048322508634e-05\n",
      "train loss:5.1307595472372e-05\n",
      "train loss:0.00010153811483535913\n",
      "train loss:4.824120177450033e-05\n",
      "train loss:1.260204027842918e-05\n",
      "train loss:7.737031267883646e-05\n",
      "train loss:2.3437266349871174e-05\n",
      "train loss:4.7548155860666597e-05\n",
      "train loss:3.580194946019803e-05\n",
      "train loss:8.022689955482965e-05\n",
      "train loss:6.0279602447736266e-05\n",
      "train loss:0.00034600132676538913\n",
      "train loss:1.7905592950329e-05\n",
      "train loss:8.740993177741886e-05\n",
      "train loss:0.00018371008908461017\n",
      "train loss:1.61618891560026e-05\n",
      "train loss:2.5022836436259937e-05\n",
      "train loss:6.221694689585815e-05\n",
      "train loss:1.4202853496343005e-05\n",
      "train loss:0.00010923352249658626\n",
      "train loss:1.5762985023212122e-05\n",
      "train loss:0.00021079514735297797\n",
      "train loss:7.548954742140428e-05\n",
      "train loss:4.5296317099995284e-05\n",
      "train loss:4.121282323001604e-05\n",
      "train loss:8.818828068514013e-05\n",
      "train loss:6.528942717273525e-05\n",
      "train loss:2.4636104947259622e-05\n",
      "train loss:2.7231040369683945e-05\n",
      "train loss:3.822020371094747e-05\n",
      "train loss:3.151806329608306e-05\n",
      "train loss:4.717443492096196e-05\n",
      "train loss:8.401123829140885e-05\n",
      "train loss:0.00017875672265068698\n",
      "train loss:5.502091163655113e-05\n",
      "train loss:0.00022644516200549773\n",
      "train loss:1.7466794217569995e-05\n",
      "train loss:1.1253398607647253e-05\n",
      "train loss:9.433655062638863e-06\n",
      "=== epoch:20, train acc:1.0, test acc:0.997 ===\n",
      "train loss:7.210482570174977e-05\n",
      "train loss:5.260973997717505e-05\n",
      "train loss:8.465871025713051e-06\n",
      "train loss:3.429444210391247e-05\n",
      "train loss:8.965904412365723e-05\n",
      "train loss:0.0001688520383398818\n",
      "train loss:7.679729401001747e-05\n",
      "train loss:0.0001876386551546537\n",
      "train loss:0.0002854388864590616\n",
      "train loss:9.452849240569811e-06\n",
      "train loss:7.125793007806478e-05\n",
      "train loss:1.893727877973911e-05\n",
      "train loss:2.7040352779909067e-05\n",
      "train loss:4.389483806098488e-05\n",
      "train loss:4.0903925028355134e-05\n",
      "train loss:2.152815952769153e-05\n",
      "train loss:0.0007384009247378968\n",
      "train loss:3.088079947044589e-05\n",
      "train loss:4.260950836373241e-05\n",
      "train loss:4.381015057805709e-05\n",
      "train loss:0.0004080210289633369\n",
      "train loss:6.310898293980214e-05\n",
      "train loss:0.00020906698239427923\n",
      "train loss:2.7823331057501804e-05\n",
      "train loss:8.814159104170394e-05\n",
      "train loss:3.5370448081828134e-05\n",
      "train loss:8.295540389785267e-06\n",
      "train loss:0.00012191655211009491\n",
      "train loss:0.00017010310418876816\n",
      "train loss:0.00018468901249223758\n",
      "train loss:4.36168700952739e-05\n",
      "train loss:2.687711580731629e-05\n",
      "train loss:0.00011351641842832366\n",
      "train loss:1.4456289592336316e-05\n",
      "train loss:1.2460398946755366e-05\n",
      "train loss:9.143790185637877e-06\n",
      "train loss:4.1432301824068294e-05\n",
      "train loss:2.9493390457575723e-05\n",
      "train loss:5.336359384442042e-05\n",
      "train loss:2.1271645002342972e-05\n",
      "train loss:4.455410026400873e-05\n",
      "train loss:0.0002229857992546619\n",
      "train loss:0.00013288699078374558\n",
      "train loss:0.00013126933525710755\n",
      "train loss:5.798028784073701e-05\n",
      "train loss:2.5205557634536772e-05\n",
      "train loss:0.00011858997365444973\n",
      "train loss:2.062518506894508e-05\n",
      "train loss:0.00010423251238205611\n",
      "train loss:1.7568056889141098e-05\n",
      "train loss:2.0560359295251496e-05\n",
      "train loss:5.774071857295586e-05\n",
      "train loss:1.7500412778192515e-05\n",
      "train loss:2.832697512478832e-05\n",
      "train loss:2.7831143510219338e-05\n",
      "train loss:2.1716474241949483e-05\n",
      "train loss:8.924603356190757e-05\n",
      "train loss:6.803683288726686e-06\n",
      "train loss:3.826646760852201e-05\n",
      "train loss:0.00037227986476281105\n",
      "train loss:9.623850533080339e-05\n",
      "train loss:5.3109302114289704e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:4.074186092890584e-05\n",
      "train loss:7.896193668599533e-05\n",
      "train loss:1.5607601408499537e-05\n",
      "train loss:1.600739183025207e-05\n",
      "train loss:0.00021435533249450912\n",
      "train loss:9.616138708638163e-05\n",
      "train loss:4.0970754681803516e-05\n",
      "train loss:3.236394292479201e-05\n",
      "train loss:6.705370484295163e-05\n",
      "train loss:1.9956722134905384e-05\n",
      "train loss:0.00010453042290730465\n",
      "train loss:2.6995889583043403e-05\n",
      "train loss:3.602543525426522e-05\n",
      "train loss:0.00014858245288488174\n",
      "train loss:5.200977577987153e-05\n",
      "train loss:7.030103127226758e-05\n",
      "train loss:0.000120151667523609\n",
      "train loss:0.0003136679445762576\n",
      "train loss:6.0064227434492144e-05\n",
      "train loss:9.197983107457295e-05\n",
      "train loss:2.778901540606304e-05\n",
      "train loss:4.1466471130974625e-05\n",
      "train loss:2.695080310464781e-05\n",
      "train loss:7.92754141235408e-05\n",
      "train loss:1.5998262384505207e-05\n",
      "train loss:9.721341262702073e-06\n",
      "train loss:4.3708299953457006e-05\n",
      "train loss:0.00031608464126804496\n",
      "train loss:1.708194162378382e-05\n",
      "train loss:5.887782419447493e-05\n",
      "train loss:0.00021514537599019818\n",
      "train loss:6.158501579916193e-05\n",
      "train loss:8.67236595635226e-05\n",
      "train loss:0.0003024431549113676\n",
      "train loss:0.0002589258137902232\n",
      "train loss:0.00013340689150190802\n",
      "train loss:0.00024156968660279636\n",
      "train loss:0.00010886519259760022\n",
      "train loss:0.00010343292149992625\n",
      "train loss:2.8818202848301193e-05\n",
      "train loss:2.1388394420396404e-05\n",
      "train loss:0.0004323223793460316\n",
      "train loss:0.0005307459715691528\n",
      "train loss:4.342790623188766e-05\n",
      "train loss:1.4792152083907085e-05\n",
      "train loss:9.871706491756804e-05\n",
      "train loss:1.8077183093140414e-05\n",
      "train loss:3.807655121547379e-05\n",
      "train loss:5.417748429970396e-05\n",
      "train loss:3.333043746630655e-05\n",
      "train loss:0.00011711009529970771\n",
      "train loss:7.888295939824209e-06\n",
      "train loss:9.664626333632483e-05\n",
      "train loss:6.511147405806355e-05\n",
      "train loss:9.362474054527359e-05\n",
      "train loss:3.077380702870727e-05\n",
      "train loss:3.877312700699464e-05\n",
      "train loss:1.5706624713154557e-05\n",
      "train loss:4.430318547266837e-06\n",
      "train loss:6.401335277769013e-05\n",
      "train loss:5.105591618242045e-05\n",
      "train loss:4.154212528079023e-05\n",
      "train loss:0.00025529857397009627\n",
      "train loss:3.298831779818954e-05\n",
      "train loss:5.575686820229908e-05\n",
      "train loss:3.216613826369768e-05\n",
      "train loss:0.00014964185768187447\n",
      "train loss:7.343026776776248e-06\n",
      "train loss:0.0001373905682904808\n",
      "train loss:2.6143697009998438e-05\n",
      "train loss:5.7543659090163713e-05\n",
      "train loss:7.153213033751959e-05\n",
      "train loss:0.00010871988877107651\n",
      "train loss:8.595788781040088e-05\n",
      "train loss:2.6569049765819818e-05\n",
      "train loss:5.742575151125307e-05\n",
      "train loss:1.4180353868994296e-05\n",
      "train loss:0.000276550416858322\n",
      "train loss:5.7958698598332736e-05\n",
      "train loss:8.988532406252395e-06\n",
      "train loss:3.82901489919774e-05\n",
      "train loss:2.252820485042033e-05\n",
      "train loss:5.7405296662918796e-05\n",
      "train loss:3.0184805965391917e-05\n",
      "train loss:7.734675037197923e-05\n",
      "train loss:9.411370038379543e-05\n",
      "train loss:2.6537093597690318e-05\n",
      "train loss:5.837933498498947e-05\n",
      "train loss:4.8884022909696155e-05\n",
      "train loss:7.716777282938889e-06\n",
      "train loss:7.41010968547636e-05\n",
      "train loss:2.8950555861859087e-05\n",
      "train loss:2.1707136273144174e-05\n",
      "train loss:3.3844945954982765e-05\n",
      "train loss:2.315256525587038e-05\n",
      "train loss:2.1498867979457592e-05\n",
      "train loss:3.891558559936509e-05\n",
      "train loss:1.6534145981074347e-05\n",
      "train loss:3.647006608721246e-05\n",
      "train loss:4.029611351699469e-05\n",
      "train loss:9.269593545463612e-05\n",
      "train loss:7.462280787456995e-05\n",
      "train loss:9.036868393883745e-06\n",
      "train loss:3.618830822056483e-05\n",
      "train loss:4.061698769259413e-05\n",
      "train loss:7.705862339986358e-05\n",
      "train loss:5.1060666877204306e-05\n",
      "train loss:7.611596696680793e-05\n",
      "train loss:4.555867366177049e-05\n",
      "train loss:5.992074623812322e-05\n",
      "train loss:3.779591921143803e-05\n",
      "train loss:6.4427510181289e-05\n",
      "train loss:4.747508980230791e-05\n",
      "train loss:4.2039031508776235e-05\n",
      "train loss:3.530375326254524e-05\n",
      "train loss:6.702142087509853e-05\n",
      "train loss:1.4723470250496735e-05\n",
      "train loss:0.0002130968392126836\n",
      "train loss:4.959598488389278e-05\n",
      "train loss:1.1868099256235047e-05\n",
      "train loss:1.1517560921652442e-05\n",
      "train loss:5.3261758897750594e-05\n",
      "train loss:8.794481086827313e-05\n",
      "train loss:2.3077767232837672e-05\n",
      "train loss:4.683933167126065e-05\n",
      "train loss:0.00014442508106287844\n",
      "train loss:0.0005032058595629777\n",
      "train loss:1.610820547229998e-05\n",
      "train loss:2.863892399351049e-05\n",
      "train loss:6.1431928959744e-05\n",
      "train loss:4.536189603329751e-05\n",
      "train loss:2.2654184279005602e-05\n",
      "train loss:7.299994858833831e-05\n",
      "train loss:0.00014902752215796127\n",
      "train loss:2.708955101335255e-05\n",
      "train loss:9.561688594432013e-05\n",
      "train loss:1.914043317974181e-05\n",
      "train loss:9.037656860845675e-05\n",
      "train loss:7.46477788761606e-05\n",
      "train loss:3.678529018810315e-05\n",
      "train loss:8.972174945347266e-05\n",
      "train loss:2.033532532065479e-05\n",
      "train loss:6.875087960554688e-06\n",
      "train loss:1.3148564905096915e-05\n",
      "train loss:7.441278806996721e-05\n",
      "train loss:2.3004096259095155e-05\n",
      "train loss:0.00010926610963160189\n",
      "train loss:1.542939576019719e-05\n",
      "train loss:7.228630683582962e-05\n",
      "train loss:1.6632349987925972e-05\n",
      "train loss:6.988733928246644e-05\n",
      "train loss:3.167247056364683e-05\n",
      "train loss:0.00010654067863423387\n",
      "train loss:8.89848723699537e-05\n",
      "train loss:8.294719567233252e-06\n",
      "train loss:3.546124952516555e-05\n",
      "train loss:2.5363182194239012e-05\n",
      "train loss:4.792774073834841e-05\n",
      "train loss:3.226463350546163e-05\n",
      "train loss:3.3714115170526256e-05\n",
      "train loss:1.895521987337836e-05\n",
      "train loss:1.4748297595723099e-05\n",
      "train loss:0.00011512744735256642\n",
      "train loss:3.892815780691598e-05\n",
      "train loss:8.810787992425068e-05\n",
      "train loss:2.1313031225469985e-05\n",
      "train loss:5.836077529337821e-06\n",
      "train loss:1.998753609930706e-05\n",
      "train loss:8.775744665314598e-05\n",
      "train loss:6.850016801501696e-05\n",
      "train loss:2.126857190575899e-05\n",
      "train loss:7.829746019032526e-05\n",
      "train loss:0.0002259301089427569\n",
      "train loss:4.61073646167849e-05\n",
      "train loss:8.581475815458168e-05\n",
      "train loss:1.8376667736138312e-05\n",
      "train loss:0.00012426495295745672\n",
      "train loss:3.23008440209325e-05\n",
      "train loss:1.9308524288960217e-05\n",
      "train loss:5.147707114499551e-06\n",
      "train loss:0.00011803075469776622\n",
      "train loss:7.648858709906201e-06\n",
      "train loss:4.1441263113785044e-05\n",
      "train loss:4.495934216370749e-05\n",
      "train loss:4.036064970829519e-05\n",
      "train loss:6.973738774664599e-05\n",
      "train loss:4.054485870456583e-05\n",
      "train loss:3.1848691528780044e-05\n",
      "train loss:3.5288607794589714e-05\n",
      "train loss:2.9871075577194746e-05\n",
      "train loss:4.53628805293992e-05\n",
      "train loss:2.1928646671812318e-05\n",
      "train loss:2.8743910849080902e-05\n",
      "train loss:7.448174730889607e-05\n",
      "train loss:3.351154362487694e-05\n",
      "train loss:3.2349822140693894e-05\n",
      "train loss:9.955573274897034e-05\n",
      "train loss:6.810667040020986e-05\n",
      "train loss:4.938952865548626e-05\n",
      "train loss:2.2619547247934117e-05\n",
      "train loss:0.0001694648256809321\n",
      "train loss:2.06428113882586e-05\n",
      "train loss:8.11206383016395e-05\n",
      "train loss:3.786103053710775e-05\n",
      "train loss:9.400496707357166e-05\n",
      "train loss:3.4723347554002064e-05\n",
      "train loss:3.953616838002625e-05\n",
      "train loss:2.2407307567713578e-05\n",
      "train loss:2.2264966323642942e-05\n",
      "train loss:5.198154745175059e-05\n",
      "train loss:6.0310908731308935e-05\n",
      "train loss:7.792347946575136e-05\n",
      "train loss:4.1617777085410476e-05\n",
      "train loss:2.3055038589762332e-05\n",
      "train loss:5.757623567701791e-05\n",
      "train loss:2.753761299033445e-05\n",
      "train loss:4.630513142155167e-05\n",
      "train loss:2.7808436310722983e-05\n",
      "train loss:4.7911888380938965e-05\n",
      "train loss:1.8715956748518944e-05\n",
      "train loss:4.3774976732926084e-05\n",
      "train loss:6.034775462435018e-05\n",
      "train loss:6.386118974005303e-05\n",
      "train loss:5.2246331526658815e-05\n",
      "train loss:1.4515394841038472e-05\n",
      "train loss:7.409381395648659e-05\n",
      "train loss:6.066890292964903e-05\n",
      "train loss:9.130425031092728e-05\n",
      "train loss:1.5048474768445885e-05\n",
      "train loss:5.491566175825784e-05\n",
      "train loss:7.296928931035368e-05\n",
      "train loss:6.154668757988803e-05\n",
      "train loss:2.5275400260404937e-05\n",
      "train loss:1.365202155991265e-05\n",
      "train loss:3.779062085039644e-05\n",
      "train loss:0.00020431240786104762\n",
      "train loss:0.00011856745223774133\n",
      "train loss:2.162228216318964e-05\n",
      "train loss:2.9804409560086774e-05\n",
      "train loss:9.423534383424713e-05\n",
      "train loss:4.9437950961056186e-05\n",
      "train loss:5.9210845821588615e-05\n",
      "train loss:3.1909840286139575e-05\n",
      "train loss:4.503367267706127e-05\n",
      "train loss:3.51154250769105e-05\n",
      "train loss:6.250706468172114e-05\n",
      "train loss:8.881980721171265e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00012386608992208685\n",
      "train loss:1.2013232681401617e-05\n",
      "train loss:5.808618516812048e-05\n",
      "train loss:4.06772035656786e-05\n",
      "train loss:8.109279349357877e-05\n",
      "train loss:6.3699587742551015e-06\n",
      "train loss:1.4289918782377231e-05\n",
      "train loss:6.922127619815268e-06\n",
      "train loss:2.1553909296579095e-05\n",
      "train loss:8.285559652875732e-05\n",
      "train loss:0.00010587113185615902\n",
      "train loss:4.176983076382417e-05\n",
      "train loss:8.773294647138165e-05\n",
      "train loss:0.00012856872164391655\n",
      "train loss:2.1133493262104535e-05\n",
      "train loss:1.994000770426663e-05\n",
      "train loss:1.5196632591118199e-05\n",
      "train loss:8.797641133239012e-05\n",
      "train loss:1.142583918471258e-05\n",
      "train loss:2.5735578457138248e-05\n",
      "train loss:9.383144551506837e-06\n",
      "train loss:3.033008176695582e-05\n",
      "train loss:6.092631858336257e-05\n",
      "train loss:2.278937379647882e-05\n",
      "train loss:2.174088236713336e-05\n",
      "train loss:8.855708308806659e-05\n",
      "train loss:3.260452335089089e-05\n",
      "train loss:3.9059574333637384e-05\n",
      "train loss:6.987663594723441e-05\n",
      "train loss:0.00010876976110440795\n",
      "train loss:2.5334858710081024e-05\n",
      "train loss:3.8229284481893035e-05\n",
      "train loss:6.712101892408769e-05\n",
      "train loss:0.00015880210347265966\n",
      "train loss:2.86559800595014e-05\n",
      "train loss:2.178458376311262e-05\n",
      "train loss:3.342090858808456e-05\n",
      "train loss:4.7317527334402674e-05\n",
      "train loss:0.00013274862406853355\n",
      "train loss:3.401648514014147e-05\n",
      "train loss:0.00010723631004710048\n",
      "train loss:6.109362816630773e-05\n",
      "train loss:1.600567912117269e-05\n",
      "train loss:3.0732415629333274e-05\n",
      "train loss:0.0003577863379655583\n",
      "train loss:2.6644537528968857e-05\n",
      "train loss:1.0732340171181166e-05\n",
      "train loss:3.180896866519539e-05\n",
      "train loss:5.9163395393135214e-05\n",
      "train loss:4.4495942830462005e-05\n",
      "train loss:7.728723033992605e-05\n",
      "train loss:5.214192125393602e-05\n",
      "train loss:2.7748940938615055e-05\n",
      "train loss:8.031640361833895e-05\n",
      "train loss:0.00018872772589204694\n",
      "train loss:2.3043106522117735e-05\n",
      "train loss:3.2120379018599794e-05\n",
      "train loss:4.721618411435223e-06\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9923007246376812\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## simple convolutional network(cnn)(chap07)\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.img_oxt import load_oxt\n",
    "from common.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_oxt(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=3, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=120,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0798191848380816\n",
      "=== epoch:1, train acc:0.359, test acc:0.361 ===\n",
      "train loss:1.111490909916366\n",
      "train loss:1.07919547718434\n",
      "train loss:1.071870844607949\n",
      "train loss:1.0529894145018006\n",
      "train loss:1.0586883634023079\n",
      "train loss:1.0054977772278424\n",
      "train loss:1.0278231871923007\n",
      "train loss:0.9905931323116974\n",
      "train loss:1.012972001847353\n",
      "train loss:0.9839848658003808\n",
      "train loss:0.9927358047428538\n",
      "train loss:0.9431157334374897\n",
      "train loss:0.9315779569974606\n",
      "train loss:0.9468026650283458\n",
      "train loss:0.906094211607014\n",
      "train loss:0.9317285111735292\n",
      "train loss:0.8981912118414307\n",
      "train loss:0.8322493191973357\n",
      "train loss:0.8729625411266857\n",
      "train loss:0.9599173330716574\n",
      "train loss:0.9046085764387336\n",
      "train loss:0.8316572868001095\n",
      "train loss:0.8240966024255842\n",
      "train loss:0.8321243006041216\n",
      "train loss:0.7699369378026512\n",
      "train loss:0.7543783525378475\n",
      "train loss:0.7788278873274979\n",
      "train loss:0.6983189699535849\n",
      "train loss:0.8490332876246051\n",
      "train loss:0.6869788735777699\n",
      "train loss:0.8369612058416755\n",
      "train loss:0.7446588728291275\n",
      "train loss:0.7294636026284294\n",
      "train loss:0.7535048913006058\n",
      "train loss:0.7238121206102569\n",
      "train loss:0.7001165061388396\n",
      "train loss:0.7348749976309047\n",
      "train loss:0.6954213892199078\n",
      "train loss:0.8464022625972478\n",
      "train loss:0.6484664215455673\n",
      "train loss:0.6747313261044839\n",
      "train loss:0.6796508907437471\n",
      "train loss:0.6984666884102967\n",
      "train loss:0.7096340303550174\n",
      "train loss:0.7752364773140987\n",
      "train loss:0.708673870234687\n",
      "train loss:0.662702505552443\n",
      "train loss:0.6372385867924317\n",
      "train loss:0.7015151774348892\n",
      "train loss:0.7243594589172456\n",
      "train loss:0.6468797813284524\n",
      "train loss:0.6369989847369584\n",
      "train loss:0.5365563222982066\n",
      "train loss:0.6536449823798354\n",
      "train loss:0.6610933792978336\n",
      "train loss:0.5837930235107635\n",
      "train loss:0.6547526637834811\n",
      "train loss:0.5647310438859737\n",
      "train loss:0.6399564731723141\n",
      "train loss:0.6605883350286573\n",
      "train loss:0.6780217351225762\n",
      "train loss:0.5950231517758836\n",
      "train loss:0.6279590438571252\n",
      "train loss:0.5225078914272949\n",
      "train loss:0.5626016666429131\n",
      "train loss:0.5996199778469503\n",
      "train loss:0.5012084148165282\n",
      "train loss:0.599134890090731\n",
      "train loss:0.5470768716711282\n",
      "train loss:0.5522317066267323\n",
      "train loss:0.587467295208505\n",
      "train loss:0.5697609646413284\n",
      "train loss:0.5119137811430216\n",
      "train loss:0.623223629265644\n",
      "train loss:0.6219239113905389\n",
      "train loss:0.6163918357374786\n",
      "train loss:0.6350713168168951\n",
      "train loss:0.6184642593733116\n",
      "train loss:0.49333834013142047\n",
      "train loss:0.5492694235284025\n",
      "train loss:0.5492096244798178\n",
      "train loss:0.6235840299980567\n",
      "train loss:0.504546020379238\n",
      "train loss:0.4697066915639561\n",
      "train loss:0.48123595223250365\n",
      "train loss:0.5253268145881919\n",
      "train loss:0.5692712555753426\n",
      "train loss:0.5931266155624212\n",
      "train loss:0.6479527025796931\n",
      "train loss:0.4913827819834032\n",
      "train loss:0.509644193058341\n",
      "train loss:0.42873965108788087\n",
      "train loss:0.5467307933019945\n",
      "train loss:0.5537642329584045\n",
      "train loss:0.4394668347313408\n",
      "train loss:0.5031412335621461\n",
      "train loss:0.5610172019120223\n",
      "train loss:0.46795190806879233\n",
      "train loss:0.4244592557974593\n",
      "train loss:0.4018202547007046\n",
      "train loss:0.47308879975886475\n",
      "train loss:0.5077800787427643\n",
      "train loss:0.4783369793913518\n",
      "train loss:0.5204914807877234\n",
      "train loss:0.5316099101244129\n",
      "train loss:0.5965629688485028\n",
      "train loss:0.47921813124384605\n",
      "train loss:0.4733955032505237\n",
      "train loss:0.4907559933898908\n",
      "train loss:0.37724314349663646\n",
      "train loss:0.5341837469279426\n",
      "train loss:0.4841144345588239\n",
      "train loss:0.4779115656723549\n",
      "train loss:0.4115584081898739\n",
      "train loss:0.4603595694591757\n",
      "train loss:0.5287226702591663\n",
      "train loss:0.6073461103953943\n",
      "train loss:0.45353533688626846\n",
      "train loss:0.5286273209705208\n",
      "train loss:0.48788814218342513\n",
      "train loss:0.4566701159279271\n",
      "train loss:0.4567793707783301\n",
      "train loss:0.5038427673153194\n",
      "train loss:0.43386386037413144\n",
      "train loss:0.47645312541799634\n",
      "train loss:0.50648373369392\n",
      "train loss:0.5087210379683239\n",
      "train loss:0.5669209834763836\n",
      "train loss:0.5088533301966951\n",
      "train loss:0.42915235074702446\n",
      "train loss:0.4156480070705891\n",
      "train loss:0.44327985663998165\n",
      "train loss:0.4629959810083214\n",
      "train loss:0.3892622852147352\n",
      "train loss:0.4374366108909124\n",
      "train loss:0.44168719445018617\n",
      "train loss:0.4718824289304332\n",
      "train loss:0.4789989019698945\n",
      "train loss:0.4478962119233357\n",
      "train loss:0.4359584445523942\n",
      "train loss:0.35928353536758795\n",
      "train loss:0.382504385506137\n",
      "train loss:0.45755212110179394\n",
      "train loss:0.37406112139206915\n",
      "train loss:0.44070669864507067\n",
      "train loss:0.4984065922457058\n",
      "train loss:0.5077696074993389\n",
      "train loss:0.40512580173738927\n",
      "train loss:0.38906742715156056\n",
      "train loss:0.43581550431540045\n",
      "train loss:0.4732700871571495\n",
      "train loss:0.5084874196727714\n",
      "train loss:0.42871131628779563\n",
      "train loss:0.41560234875427293\n",
      "train loss:0.4076616826019509\n",
      "train loss:0.32800022083323377\n",
      "train loss:0.4840016118267084\n",
      "train loss:0.4748363858664522\n",
      "train loss:0.3826989329472405\n",
      "train loss:0.36865012464843755\n",
      "train loss:0.4999877787805809\n",
      "train loss:0.3427710869113138\n",
      "train loss:0.37472216811753234\n",
      "train loss:0.3594512392559704\n",
      "train loss:0.3863292023055011\n",
      "train loss:0.3962165664018089\n",
      "train loss:0.4197659639982569\n",
      "train loss:0.38858374653081457\n",
      "train loss:0.40634271991566473\n",
      "train loss:0.37498028724496185\n",
      "train loss:0.37992118064999686\n",
      "train loss:0.37768607657490183\n",
      "train loss:0.41596064270893746\n",
      "train loss:0.5443248621720197\n",
      "train loss:0.4477154820081312\n",
      "train loss:0.3299509574240531\n",
      "train loss:0.45747425382067075\n",
      "train loss:0.4468570168613076\n",
      "train loss:0.454907033081991\n",
      "train loss:0.4561072292966345\n",
      "train loss:0.31676279996924184\n",
      "train loss:0.3645408668674481\n",
      "train loss:0.3853055257002651\n",
      "train loss:0.35927630859862136\n",
      "train loss:0.3293124639297175\n",
      "train loss:0.452654751908074\n",
      "train loss:0.502638015094729\n",
      "train loss:0.47688278694172287\n",
      "train loss:0.475035158321958\n",
      "train loss:0.3704342408370646\n",
      "train loss:0.41154167929759905\n",
      "train loss:0.33321300126411446\n",
      "train loss:0.3702711785078755\n",
      "train loss:0.4131931226703334\n",
      "train loss:0.46255600489231663\n",
      "train loss:0.42564187072837784\n",
      "train loss:0.3458826867714971\n",
      "train loss:0.41903563638756414\n",
      "train loss:0.44176099164621807\n",
      "train loss:0.3349098329139405\n",
      "train loss:0.4717631036774366\n",
      "train loss:0.36042234874187395\n",
      "train loss:0.3291220348675104\n",
      "train loss:0.41356222684124594\n",
      "train loss:0.396381598255476\n",
      "train loss:0.452221057973192\n",
      "train loss:0.36173936318008454\n",
      "train loss:0.4122770261310423\n",
      "train loss:0.43355045017085897\n",
      "train loss:0.3777130682729382\n",
      "train loss:0.528242578321531\n",
      "train loss:0.3709660176358454\n",
      "train loss:0.3736396691147045\n",
      "train loss:0.4812645023875612\n",
      "train loss:0.3014715197889217\n",
      "train loss:0.41847777022505805\n",
      "train loss:0.3612634105221458\n",
      "train loss:0.3305120210448943\n",
      "train loss:0.34262810285442424\n",
      "train loss:0.38052178822077276\n",
      "train loss:0.3426813853738286\n",
      "train loss:0.4044576408310403\n",
      "train loss:0.3783245352784846\n",
      "train loss:0.32708101899946546\n",
      "train loss:0.36917584100879697\n",
      "train loss:0.3663845870729883\n",
      "train loss:0.4214414448841912\n",
      "train loss:0.42608575722224995\n",
      "train loss:0.3331118065470585\n",
      "train loss:0.40732196546479404\n",
      "train loss:0.4062180250648462\n",
      "train loss:0.3812863695721717\n",
      "train loss:0.440969782412734\n",
      "train loss:0.3172150158878393\n",
      "train loss:0.361786911177193\n",
      "train loss:0.414649103231513\n",
      "train loss:0.34404064644999743\n",
      "train loss:0.35112219663019684\n",
      "train loss:0.3574112768121066\n",
      "train loss:0.3913946982052808\n",
      "train loss:0.41451576310034305\n",
      "train loss:0.44873997654931136\n",
      "train loss:0.3738440157794921\n",
      "train loss:0.35621991564035393\n",
      "train loss:0.3730332358747374\n",
      "train loss:0.3815436558131177\n",
      "train loss:0.36407778882047964\n",
      "train loss:0.42639474322135557\n",
      "train loss:0.3590993904143648\n",
      "train loss:0.37615507727721975\n",
      "train loss:0.4521305410253029\n",
      "train loss:0.406934931598494\n",
      "train loss:0.45832077755881345\n",
      "train loss:0.4016118599199841\n",
      "train loss:0.3178556179918137\n",
      "train loss:0.3506309675558096\n",
      "train loss:0.48828812720867193\n",
      "train loss:0.3917855816007673\n",
      "train loss:0.39037503821820124\n",
      "train loss:0.3009159574897564\n",
      "train loss:0.41242050500556454\n",
      "train loss:0.36311154424899345\n",
      "train loss:0.38995048754025663\n",
      "train loss:0.32998075633017526\n",
      "train loss:0.4167518252373421\n",
      "train loss:0.3464929759708717\n",
      "train loss:0.3535609588218287\n",
      "train loss:0.31933969991957445\n",
      "train loss:0.37936165522428733\n",
      "train loss:0.4234556999416066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.37306867175759767\n",
      "train loss:0.3033900371696974\n",
      "train loss:0.4193090326677654\n",
      "train loss:0.3032542612428833\n",
      "train loss:0.39471945988579754\n",
      "train loss:0.4064137457554365\n",
      "train loss:0.3175722622118981\n",
      "train loss:0.3123230158253662\n",
      "train loss:0.4223871543239312\n",
      "train loss:0.39107656881109704\n",
      "train loss:0.3126280988191846\n",
      "train loss:0.42637634797220475\n",
      "train loss:0.3998444026194445\n",
      "train loss:0.40363354797696843\n",
      "train loss:0.43917964096933265\n",
      "train loss:0.4379317590017762\n",
      "train loss:0.4281118387551485\n",
      "train loss:0.34200715205537713\n",
      "train loss:0.28825337468446155\n",
      "train loss:0.3352875152097559\n",
      "train loss:0.3480716358899161\n",
      "train loss:0.34045602520574403\n",
      "train loss:0.3629042892697631\n",
      "train loss:0.4258997321552686\n",
      "train loss:0.42822994325985714\n",
      "train loss:0.4054331527682449\n",
      "train loss:0.39583788088163224\n",
      "train loss:0.335708681421036\n",
      "train loss:0.36089978719868354\n",
      "train loss:0.3226947450018009\n",
      "train loss:0.33298280980041534\n",
      "train loss:0.410160979361872\n",
      "train loss:0.3966472810397684\n",
      "train loss:0.39380146937330096\n",
      "train loss:0.2677293021418381\n",
      "train loss:0.36015292290881196\n",
      "train loss:0.3108065449565275\n",
      "train loss:0.3559030195164303\n",
      "train loss:0.3354376531001722\n",
      "train loss:0.3752609065573507\n",
      "train loss:0.3154666635967546\n",
      "train loss:0.39603898492953454\n",
      "train loss:0.3738225051215235\n",
      "train loss:0.3170246123899692\n",
      "train loss:0.2859928316598516\n",
      "train loss:0.382372082811352\n",
      "train loss:0.3060169862081844\n",
      "train loss:0.37656132392252084\n",
      "train loss:0.3898239826098518\n",
      "train loss:0.40494411831439575\n",
      "train loss:0.3432276393642934\n",
      "train loss:0.34288766562758527\n",
      "train loss:0.31681157328737336\n",
      "train loss:0.34379639215979707\n",
      "train loss:0.3807372335805381\n",
      "train loss:0.478987576763617\n",
      "train loss:0.3956964529998332\n",
      "train loss:0.35315585284078654\n",
      "train loss:0.31628993258813304\n",
      "train loss:0.32790568875655174\n",
      "train loss:0.2710725703887545\n",
      "train loss:0.3991025304068102\n",
      "train loss:0.37536764679067264\n",
      "train loss:0.3764066046936051\n",
      "train loss:0.28503005865518966\n",
      "train loss:0.3123187402705925\n",
      "train loss:0.3391313256051267\n",
      "train loss:0.35927357457966214\n",
      "train loss:0.4143441412102709\n",
      "train loss:0.34796553059343815\n",
      "train loss:0.40467262811870947\n",
      "train loss:0.2938894009402485\n",
      "train loss:0.3593035524428105\n",
      "train loss:0.42266600919296915\n",
      "train loss:0.34620733280911026\n",
      "train loss:0.32037220824075036\n",
      "train loss:0.3977498961990324\n",
      "train loss:0.3878996116937052\n",
      "train loss:0.3488168805065813\n",
      "train loss:0.3489452523805458\n",
      "train loss:0.3495397784950368\n",
      "train loss:0.3644320239876684\n",
      "train loss:0.35332675568986727\n",
      "train loss:0.44590216534033494\n",
      "train loss:0.42953240809583115\n",
      "train loss:0.3204656967725088\n",
      "train loss:0.2918464528404165\n",
      "train loss:0.35648958293523625\n",
      "train loss:0.5442215852873186\n",
      "train loss:0.28455237734216443\n",
      "train loss:0.4042405605024498\n",
      "train loss:0.3408118449440826\n",
      "train loss:0.29123773103513517\n",
      "train loss:0.47669648579737883\n",
      "train loss:0.3394019980478565\n",
      "train loss:0.3519870528275107\n",
      "train loss:0.33040468756520947\n",
      "train loss:0.4064879743000163\n",
      "=== epoch:2, train acc:0.988, test acc:0.992 ===\n",
      "train loss:0.32946305461786335\n",
      "train loss:0.35698028733059395\n",
      "train loss:0.3274386679327087\n",
      "train loss:0.4309576620243157\n",
      "train loss:0.3804302624799218\n",
      "train loss:0.36417739429067275\n",
      "train loss:0.340379519191546\n",
      "train loss:0.3473545098761716\n",
      "train loss:0.32244014239390484\n",
      "train loss:0.2955125858875325\n",
      "train loss:0.31977184014780197\n",
      "train loss:0.4074157593318958\n",
      "train loss:0.3406180692173614\n",
      "train loss:0.2858694413176549\n",
      "train loss:0.5166563983088353\n",
      "train loss:0.3449570795930388\n",
      "train loss:0.3521894781894765\n",
      "train loss:0.40409460466955205\n",
      "train loss:0.4134521575794394\n",
      "train loss:0.42175771515518046\n",
      "train loss:0.36271853170791196\n",
      "train loss:0.471711947551218\n",
      "train loss:0.29770772989438243\n",
      "train loss:0.3244440022713647\n",
      "train loss:0.34225291146611064\n",
      "train loss:0.3482226115825538\n",
      "train loss:0.39234232151782433\n",
      "train loss:0.3164226170215604\n",
      "train loss:0.3367926160786044\n",
      "train loss:0.350300050046157\n",
      "train loss:0.3716665936900749\n",
      "train loss:0.3253207617972178\n",
      "train loss:0.43754363046149947\n",
      "train loss:0.3289016898165497\n",
      "train loss:0.3644519412821842\n",
      "train loss:0.3306659278579517\n",
      "train loss:0.358113993002724\n",
      "train loss:0.4369014632359634\n",
      "train loss:0.3658742903207373\n",
      "train loss:0.29897056986196574\n",
      "train loss:0.41688068811463597\n",
      "train loss:0.3337719588861661\n",
      "train loss:0.45427169090570246\n",
      "train loss:0.34201022204768444\n",
      "train loss:0.3274532654772083\n",
      "train loss:0.37911957087587406\n",
      "train loss:0.36167169614726263\n",
      "train loss:0.43246389151194536\n",
      "train loss:0.35152992218601553\n",
      "train loss:0.40104505043864797\n",
      "train loss:0.3198659496901829\n",
      "train loss:0.3457971739415318\n",
      "train loss:0.34282992007775875\n",
      "train loss:0.36258061871689357\n",
      "train loss:0.3116209374931858\n",
      "train loss:0.4077414271184547\n",
      "train loss:0.3385652234970074\n",
      "train loss:0.37132100803368373\n",
      "train loss:0.295602769942559\n",
      "train loss:0.38139166510293354\n",
      "train loss:0.3605398172206511\n",
      "train loss:0.3462232663462102\n",
      "train loss:0.4464112975384728\n",
      "train loss:0.3170962282622742\n",
      "train loss:0.34481631372522764\n",
      "train loss:0.3888372830371449\n",
      "train loss:0.3539436720947367\n",
      "train loss:0.3604710844492246\n",
      "train loss:0.31649279707114264\n",
      "train loss:0.393167649900075\n",
      "train loss:0.3527764715344734\n",
      "train loss:0.32676841970107995\n",
      "train loss:0.41336796661336533\n",
      "train loss:0.3874658990584604\n",
      "train loss:0.33865046324421316\n",
      "train loss:0.32434560157929937\n",
      "train loss:0.3240550346895714\n",
      "train loss:0.2968300390801997\n",
      "train loss:0.38450430183157314\n",
      "train loss:0.4013909671093833\n",
      "train loss:0.34579300368238425\n",
      "train loss:0.33683850302318713\n",
      "train loss:0.35367283821037554\n",
      "train loss:0.3344289176081163\n",
      "train loss:0.2938730580039436\n",
      "train loss:0.3014986404703508\n",
      "train loss:0.35270768235245264\n",
      "train loss:0.3741930123252845\n",
      "train loss:0.3342088904685409\n",
      "train loss:0.3598916205750309\n",
      "train loss:0.36069591251634\n",
      "train loss:0.3148963511599139\n",
      "train loss:0.292866623666896\n",
      "train loss:0.3197816733009876\n",
      "train loss:0.35090053905648105\n",
      "train loss:0.3294288309765177\n",
      "train loss:0.3107838912154541\n",
      "train loss:0.3492513302736635\n",
      "train loss:0.38942674582102127\n",
      "train loss:0.3526304368391423\n",
      "train loss:0.32547683411027795\n",
      "train loss:0.29639289952115405\n",
      "train loss:0.2755682531495648\n",
      "train loss:0.30682362781923156\n",
      "train loss:0.3272625122091179\n",
      "train loss:0.36061491659004347\n",
      "train loss:0.25287509927281365\n",
      "train loss:0.33595517745685205\n",
      "train loss:0.32152877274168434\n",
      "train loss:0.3943171877096525\n",
      "train loss:0.3279022420647637\n",
      "train loss:0.39341599851431597\n",
      "train loss:0.3700925851918763\n",
      "train loss:0.34513707205136573\n",
      "train loss:0.3859352429872903\n",
      "train loss:0.3694854808276833\n",
      "train loss:0.272156827998802\n",
      "train loss:0.32015622142844574\n",
      "train loss:0.39564123191159467\n",
      "train loss:0.3700305031317359\n",
      "train loss:0.2898092905537365\n",
      "train loss:0.3038455983347284\n",
      "train loss:0.38125808439914277\n",
      "train loss:0.3464100864272106\n",
      "train loss:0.33049298632587065\n",
      "train loss:0.3783409146167511\n",
      "train loss:0.3688405031815237\n",
      "train loss:0.30473700388982794\n",
      "train loss:0.42735665345130086\n",
      "train loss:0.4183038106577771\n",
      "train loss:0.30194415169283106\n",
      "train loss:0.3039228954770784\n",
      "train loss:0.4246324431821391\n",
      "train loss:0.33481662102574555\n",
      "train loss:0.3563186118311179\n",
      "train loss:0.4241842871242009\n",
      "train loss:0.43452775070959837\n",
      "train loss:0.3549420459243761\n",
      "train loss:0.4362962075395094\n",
      "train loss:0.3844057343648893\n",
      "train loss:0.3397710679786054\n",
      "train loss:0.39485253472974974\n",
      "train loss:0.3614480900829129\n",
      "train loss:0.3516544632010312\n",
      "train loss:0.4844280626037899\n",
      "train loss:0.39532719963596125\n",
      "train loss:0.37382859564979315\n",
      "train loss:0.34586064041496306\n",
      "train loss:0.3482412163576056\n",
      "train loss:0.37373289390132103\n",
      "train loss:0.3645150233304188\n",
      "train loss:0.2970657301585529\n",
      "train loss:0.37935211142375613\n",
      "train loss:0.3838066592953991\n",
      "train loss:0.28661131541361595\n",
      "train loss:0.326836407896783\n",
      "train loss:0.3375069728394539\n",
      "train loss:0.37693501698115645\n",
      "train loss:0.3258520151747774\n",
      "train loss:0.3771942179504166\n",
      "train loss:0.3458045301865933\n",
      "train loss:0.37025801197475716\n",
      "train loss:0.3385148036873739\n",
      "train loss:0.40621173866835236\n",
      "train loss:0.3469351791999703\n",
      "train loss:0.29293407900702545\n",
      "train loss:0.3710189229108381\n",
      "train loss:0.32735378368217544\n",
      "train loss:0.33337307757800816\n",
      "train loss:0.2720175745179512\n",
      "train loss:0.4356267675899617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3632060902505918\n",
      "train loss:0.30067253837356717\n",
      "train loss:0.34168171983466994\n",
      "train loss:0.38082286981209623\n",
      "train loss:0.32475078783012007\n",
      "train loss:0.3205394460372328\n",
      "train loss:0.32565948179744364\n",
      "train loss:0.3588641908795759\n",
      "train loss:0.379460868346461\n",
      "train loss:0.31061997037531186\n",
      "train loss:0.34900938470776666\n",
      "train loss:0.3730768729634633\n",
      "train loss:0.3716291259090016\n",
      "train loss:0.3946536841731766\n",
      "train loss:0.35592608019377925\n",
      "train loss:0.45400482020521754\n",
      "train loss:0.31693115370679276\n",
      "train loss:0.35386490035824186\n",
      "train loss:0.3181880943187153\n",
      "train loss:0.30178134071306345\n",
      "train loss:0.4363925843575359\n",
      "train loss:0.38886933443061894\n",
      "train loss:0.32960403721047626\n",
      "train loss:0.3912526556113355\n",
      "train loss:0.3226890988175752\n",
      "train loss:0.3499284942162325\n",
      "train loss:0.30555837868656754\n",
      "train loss:0.3131729882034176\n",
      "train loss:0.3266044847335845\n",
      "train loss:0.38320296890841876\n",
      "train loss:0.2911216898534461\n",
      "train loss:0.4173438459730129\n",
      "train loss:0.3762937315481054\n",
      "train loss:0.4331253766388368\n",
      "train loss:0.37760195506136146\n",
      "train loss:0.39436187967951114\n",
      "train loss:0.3462815044227257\n",
      "train loss:0.3466399331599985\n",
      "train loss:0.3396639964077977\n",
      "train loss:0.30920470766410246\n",
      "train loss:0.3588874444530286\n",
      "train loss:0.42393247135214657\n",
      "train loss:0.2800672735053144\n",
      "train loss:0.31789593966283625\n",
      "train loss:0.4093945164099069\n",
      "train loss:0.3491245819612548\n",
      "train loss:0.3093036555972951\n",
      "train loss:0.3304348349775025\n",
      "train loss:0.35401986784964673\n",
      "train loss:0.2980738157586637\n",
      "train loss:0.3735248084673871\n",
      "train loss:0.37867138319155097\n",
      "train loss:0.37838226024971566\n",
      "train loss:0.3744589001981144\n",
      "train loss:0.37121377933462957\n",
      "train loss:0.3807445473900422\n",
      "train loss:0.37790483658880375\n",
      "train loss:0.3056935382014224\n",
      "train loss:0.33012218011358757\n",
      "train loss:0.37118942313033\n",
      "train loss:0.32289913229660433\n",
      "train loss:0.37380990165979056\n",
      "train loss:0.28739684811088606\n",
      "train loss:0.3560750402650124\n",
      "train loss:0.2922155945907145\n",
      "train loss:0.388026781695611\n",
      "train loss:0.3158590868953504\n",
      "train loss:0.31752110968288394\n",
      "train loss:0.3457269197394608\n",
      "train loss:0.36500522796663026\n",
      "train loss:0.3512706460256972\n",
      "train loss:0.3302192299895763\n",
      "train loss:0.35200520060849516\n",
      "train loss:0.3840689976669168\n",
      "train loss:0.4712727259436887\n",
      "train loss:0.31822628992279417\n",
      "train loss:0.32914421744056005\n",
      "train loss:0.32442538332477483\n",
      "train loss:0.34098323869085795\n",
      "train loss:0.41375783783211806\n",
      "train loss:0.27700677640045746\n",
      "train loss:0.3463882689179246\n",
      "train loss:0.3426972435248563\n",
      "train loss:0.2834581030563517\n",
      "train loss:0.44211405871485426\n",
      "train loss:0.2961162189157088\n",
      "train loss:0.387312549064808\n",
      "train loss:0.3074488402113482\n",
      "train loss:0.3471154393123734\n",
      "train loss:0.3495853595104789\n",
      "train loss:0.31085395321448506\n",
      "train loss:0.30095524822260356\n",
      "train loss:0.3773041645849731\n",
      "train loss:0.3687106569955811\n",
      "train loss:0.273262362222983\n",
      "train loss:0.2802175652335672\n",
      "train loss:0.34684059656632354\n",
      "train loss:0.2724524861983515\n",
      "train loss:0.3061993633354069\n",
      "train loss:0.36513902010542043\n",
      "train loss:0.32772039565773764\n",
      "train loss:0.34244075889233777\n",
      "train loss:0.30651065301733116\n",
      "train loss:0.32287679214160353\n",
      "train loss:0.3910337144668662\n",
      "train loss:0.32967800369266637\n",
      "train loss:0.3928520207803048\n",
      "train loss:0.30800778954518815\n",
      "train loss:0.3492223159310932\n",
      "train loss:0.32888615869957744\n",
      "train loss:0.3879692850896395\n",
      "train loss:0.3599540128733093\n",
      "train loss:0.3625470433129923\n",
      "train loss:0.3384860318132967\n",
      "train loss:0.2825115822176412\n",
      "train loss:0.31178798348055903\n",
      "train loss:0.40054340524041016\n",
      "train loss:0.3659077921769475\n",
      "train loss:0.31690400408587777\n",
      "train loss:0.3650531946375491\n",
      "train loss:0.2524276359344477\n",
      "train loss:0.32853417713896416\n",
      "train loss:0.2826252026017531\n",
      "train loss:0.3289095225798265\n",
      "train loss:0.3783483570412534\n",
      "train loss:0.2898271721293477\n",
      "train loss:0.4085852923461703\n",
      "train loss:0.4040160388326525\n",
      "train loss:0.3230081461615335\n",
      "train loss:0.24240720057314505\n",
      "train loss:0.3249774080121381\n",
      "train loss:0.35025763321850895\n",
      "train loss:0.32882206958675025\n",
      "train loss:0.40358861841527266\n",
      "train loss:0.3091066004096044\n",
      "train loss:0.3140836941254856\n",
      "train loss:0.3730903272427444\n",
      "train loss:0.3033944468173792\n",
      "train loss:0.3680877061253087\n",
      "train loss:0.34640442366680535\n",
      "train loss:0.408925703241558\n",
      "train loss:0.3350875720891992\n",
      "train loss:0.35335732120926716\n",
      "train loss:0.40389148698925365\n",
      "train loss:0.3581311770853084\n",
      "train loss:0.33399412033333026\n",
      "train loss:0.3025393822494834\n",
      "train loss:0.3295622465023756\n",
      "train loss:0.4100744975337291\n",
      "train loss:0.33607043437228495\n",
      "train loss:0.34496142047511086\n",
      "train loss:0.35936120022672874\n",
      "train loss:0.40162730921493905\n",
      "train loss:0.28983252600273773\n",
      "train loss:0.3752337034575174\n",
      "train loss:0.3456785643870558\n",
      "train loss:0.3662348786968843\n",
      "train loss:0.3247353523115527\n",
      "train loss:0.3551270694872516\n",
      "train loss:0.3378892204899556\n",
      "train loss:0.32768650116975784\n",
      "train loss:0.33225058723376727\n",
      "train loss:0.24481871851649667\n",
      "train loss:0.3249000817263952\n",
      "train loss:0.2936785270256328\n",
      "train loss:0.31260467005980447\n",
      "train loss:0.27995438008505713\n",
      "train loss:0.40629254162451456\n",
      "train loss:0.31704361317766255\n",
      "train loss:0.3357499560469498\n",
      "train loss:0.37967789926629264\n",
      "train loss:0.3003126620296382\n",
      "train loss:0.33753471655015943\n",
      "train loss:0.3367161502526963\n",
      "train loss:0.3064187199182727\n",
      "train loss:0.3651154710690148\n",
      "train loss:0.3200656969366833\n",
      "train loss:0.3601722311489918\n",
      "train loss:0.38013027506847674\n",
      "train loss:0.3883708219079033\n",
      "train loss:0.36709802656573876\n",
      "train loss:0.30634467295564255\n",
      "train loss:0.3478247276429766\n",
      "train loss:0.3203538958252256\n",
      "train loss:0.3890093191879302\n",
      "train loss:0.31521804363910405\n",
      "train loss:0.49735123729560515\n",
      "train loss:0.3558506992746835\n",
      "train loss:0.27792837051383684\n",
      "train loss:0.29108448115228003\n",
      "train loss:0.385502307904575\n",
      "train loss:0.32305496536853295\n",
      "train loss:0.34947882291198407\n",
      "train loss:0.3186860439255509\n",
      "train loss:0.36922993931748216\n",
      "train loss:0.34547165556685333\n",
      "train loss:0.3523481062215692\n",
      "=== epoch:3, train acc:0.99, test acc:0.987 ===\n",
      "train loss:0.2886173738616922\n",
      "train loss:0.4850411182055578\n",
      "train loss:0.3932673203076451\n",
      "train loss:0.3102816310034272\n",
      "train loss:0.3965874222267079\n",
      "train loss:0.30084101162787735\n",
      "train loss:0.39051306809854\n",
      "train loss:0.3697566674888019\n",
      "train loss:0.2884661782631285\n",
      "train loss:0.4855153339874581\n",
      "train loss:0.33005000057974526\n",
      "train loss:0.30329489005103966\n",
      "train loss:0.35730145355708987\n",
      "train loss:0.3449297906353602\n",
      "train loss:0.28289581144881626\n",
      "train loss:0.2769917606221231\n",
      "train loss:0.3095466780138094\n",
      "train loss:0.41676828323368487\n",
      "train loss:0.3536543839827416\n",
      "train loss:0.3396892589278568\n",
      "train loss:0.33374402715147605\n",
      "train loss:0.3042903786166728\n",
      "train loss:0.2702205566855359\n",
      "train loss:0.44865752495612743\n",
      "train loss:0.28187968726298973\n",
      "train loss:0.3633913611499177\n",
      "train loss:0.2720425209950192\n",
      "train loss:0.28388188541481224\n",
      "train loss:0.2859432006704514\n",
      "train loss:0.32226411594867355\n",
      "train loss:0.344658494183004\n",
      "train loss:0.28163537661933447\n",
      "train loss:0.38264652777129576\n",
      "train loss:0.37540909803939326\n",
      "train loss:0.2610109544912919\n",
      "train loss:0.2965003112107851\n",
      "train loss:0.3135898441050005\n",
      "train loss:0.3980788070596977\n",
      "train loss:0.38705927117083233\n",
      "train loss:0.3367740029025184\n",
      "train loss:0.3153198877247864\n",
      "train loss:0.26734498322571404\n",
      "train loss:0.30840495565133375\n",
      "train loss:0.34479014863213303\n",
      "train loss:0.32717360508787185\n",
      "train loss:0.3584508720675936\n",
      "train loss:0.3477327311905697\n",
      "train loss:0.3310973237982518\n",
      "train loss:0.3356082414306639\n",
      "train loss:0.29225015675709487\n",
      "train loss:0.36872979366249053\n",
      "train loss:0.3879983189321025\n",
      "train loss:0.3788555124502967\n",
      "train loss:0.3083379555472778\n",
      "train loss:0.4031708435865062\n",
      "train loss:0.3226279048840059\n",
      "train loss:0.3963265291418315\n",
      "train loss:0.24216512962355605\n",
      "train loss:0.3623778402864868\n",
      "train loss:0.3191549685988858\n",
      "train loss:0.34091926324242683\n",
      "train loss:0.34687673523693546\n",
      "train loss:0.3483449650256978\n",
      "train loss:0.29921299581873967\n",
      "train loss:0.317518725297251\n",
      "train loss:0.3635623606762748\n",
      "train loss:0.3535933566705535\n",
      "train loss:0.3427239839048085\n",
      "train loss:0.32059323708418286\n",
      "train loss:0.3125935452767118\n",
      "train loss:0.2932433284681407\n",
      "train loss:0.3647822906832367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2941892494839364\n",
      "train loss:0.3139531002239638\n",
      "train loss:0.31166320876435966\n",
      "train loss:0.2542764256057019\n",
      "train loss:0.3089335540019415\n",
      "train loss:0.3290774401756748\n",
      "train loss:0.3474165628181808\n",
      "train loss:0.26667430307659795\n",
      "train loss:0.3347394615022318\n",
      "train loss:0.4167335348909998\n",
      "train loss:0.33426848391903713\n",
      "train loss:0.34831706723185507\n",
      "train loss:0.2944191183123319\n",
      "train loss:0.3073429359234204\n",
      "train loss:0.33053676856464914\n",
      "train loss:0.24470590459045868\n",
      "train loss:0.309456993079639\n",
      "train loss:0.36430620324733926\n",
      "train loss:0.3161084176101657\n",
      "train loss:0.3285077271479334\n",
      "train loss:0.3801476986030251\n",
      "train loss:0.30639470956469955\n",
      "train loss:0.31032118476123544\n",
      "train loss:0.3934292093173094\n",
      "train loss:0.3415976653836103\n",
      "train loss:0.3616260426041424\n",
      "train loss:0.3321480025950508\n",
      "train loss:0.3017336319745088\n",
      "train loss:0.35869239077411297\n",
      "train loss:0.3472931452133143\n",
      "train loss:0.4886650701103448\n",
      "train loss:0.34836885517857374\n",
      "train loss:0.29533455960863986\n",
      "train loss:0.3486996933018419\n",
      "train loss:0.25609119572242\n",
      "train loss:0.33492314581893284\n",
      "train loss:0.3548590859680111\n",
      "train loss:0.3649850523315394\n",
      "train loss:0.29410758892867117\n",
      "train loss:0.3396537608560815\n",
      "train loss:0.34318129329080305\n",
      "train loss:0.374005512343185\n",
      "train loss:0.3719430242197177\n",
      "train loss:0.3148100267947243\n",
      "train loss:0.2602025917467982\n",
      "train loss:0.33865501824718297\n",
      "train loss:0.2531330858372968\n",
      "train loss:0.3068759405845075\n",
      "train loss:0.3277041588381191\n",
      "train loss:0.3806901578549491\n",
      "train loss:0.3787460155914463\n",
      "train loss:0.3326695860169077\n",
      "train loss:0.30145289990854124\n",
      "train loss:0.38345163227674184\n",
      "train loss:0.353475677959068\n",
      "train loss:0.32544827689153705\n",
      "train loss:0.3013660209165438\n",
      "train loss:0.3814336254978752\n",
      "train loss:0.37237229359459884\n",
      "train loss:0.355656279559592\n",
      "train loss:0.35032830412591015\n",
      "train loss:0.29634263002365463\n",
      "train loss:0.33616267686421514\n",
      "train loss:0.2918220785473346\n",
      "train loss:0.3740336404664292\n",
      "train loss:0.39405344549412874\n",
      "train loss:0.4173599229357136\n",
      "train loss:0.35254137619609277\n",
      "train loss:0.4323462913121195\n",
      "train loss:0.31764450292230156\n",
      "train loss:0.3320922796915064\n",
      "train loss:0.3816676727149106\n",
      "train loss:0.35138256454234695\n",
      "train loss:0.29455880501145976\n",
      "train loss:0.3381065290964526\n",
      "train loss:0.3791296156539529\n",
      "train loss:0.36308149207497326\n",
      "train loss:0.3265098493884366\n",
      "train loss:0.36343177811991023\n",
      "train loss:0.366615769414606\n",
      "train loss:0.28985414248329705\n",
      "train loss:0.33674256766932814\n",
      "train loss:0.29019456498056967\n",
      "train loss:0.3580756192573195\n",
      "train loss:0.3639814479383762\n",
      "train loss:0.3794314988512049\n",
      "train loss:0.33162771804002233\n",
      "train loss:0.31023653750429175\n",
      "train loss:0.40779330769432875\n",
      "train loss:0.33822619822353933\n",
      "train loss:0.40180248037155525\n",
      "train loss:0.36027471651175563\n",
      "train loss:0.3643278516887816\n",
      "train loss:0.294861598833342\n",
      "train loss:0.3107496237465331\n",
      "train loss:0.3327805196921473\n",
      "train loss:0.29723662220080616\n",
      "train loss:0.3683949412449363\n",
      "train loss:0.47163061495322134\n",
      "train loss:0.31185330314593995\n",
      "train loss:0.3494996402249713\n",
      "train loss:0.33564706312290016\n",
      "train loss:0.3603412099932458\n",
      "train loss:0.3774423349871478\n",
      "train loss:0.30849436095986876\n",
      "train loss:0.33060974342168004\n",
      "train loss:0.39415934914030115\n",
      "train loss:0.3336115353119544\n",
      "train loss:0.2796821194739857\n",
      "train loss:0.2697215719237812\n",
      "train loss:0.3273373801854405\n",
      "train loss:0.2677151073751933\n",
      "train loss:0.31521181030522843\n",
      "train loss:0.2934864844563549\n",
      "train loss:0.3067819102885122\n",
      "train loss:0.33555453982427913\n",
      "train loss:0.3386547547533884\n",
      "train loss:0.2808397568501687\n",
      "train loss:0.31059387753482404\n",
      "train loss:0.38494735446926076\n",
      "train loss:0.3348628804096837\n",
      "train loss:0.3350467171739819\n",
      "train loss:0.33573058775556014\n",
      "train loss:0.34564081166961447\n",
      "train loss:0.3597365390742556\n",
      "train loss:0.3563910673156181\n",
      "train loss:0.4191354884683141\n",
      "train loss:0.27701222344464704\n",
      "train loss:0.34989592147493387\n",
      "train loss:0.3563875300420694\n",
      "train loss:0.36529281036867306\n",
      "train loss:0.34715388879510706\n",
      "train loss:0.3241871017383107\n",
      "train loss:0.2918253680551023\n",
      "train loss:0.3368742960817496\n",
      "train loss:0.306424668576036\n",
      "train loss:0.366790889528187\n",
      "train loss:0.2851264938671484\n",
      "train loss:0.34388725619311056\n",
      "train loss:0.2704968910025046\n",
      "train loss:0.3626296863946648\n",
      "train loss:0.3226438630887936\n",
      "train loss:0.42490913279717013\n",
      "train loss:0.3374741282875096\n",
      "train loss:0.3197083105710217\n",
      "train loss:0.2970428721548925\n",
      "train loss:0.33282384556875994\n",
      "train loss:0.3636287456235608\n",
      "train loss:0.34797340093225154\n",
      "train loss:0.3653625183077606\n",
      "train loss:0.253470734367741\n",
      "train loss:0.31748986401617346\n",
      "train loss:0.2707858390783595\n",
      "train loss:0.4340364927437588\n",
      "train loss:0.3334717323191384\n",
      "train loss:0.299790180228438\n",
      "train loss:0.32073277450697296\n",
      "train loss:0.36611311396071605\n",
      "train loss:0.356007464413684\n",
      "train loss:0.30299896325991593\n",
      "train loss:0.35805457939429186\n",
      "train loss:0.36372399369306513\n",
      "train loss:0.3512648654672139\n",
      "train loss:0.35570563130655625\n",
      "train loss:0.314845636131702\n",
      "train loss:0.30873432899280157\n",
      "train loss:0.3646620257835148\n",
      "train loss:0.3116288997176697\n",
      "train loss:0.3438938825009849\n",
      "train loss:0.2789168494964463\n",
      "train loss:0.3218056570206874\n",
      "train loss:0.35626515440596845\n",
      "train loss:0.2823947461808948\n",
      "train loss:0.27711995543472445\n",
      "train loss:0.24890230724947274\n",
      "train loss:0.34488389203485376\n",
      "train loss:0.24194843428273133\n",
      "train loss:0.2748503871657253\n",
      "train loss:0.3254299761439583\n",
      "train loss:0.36392197789229347\n",
      "train loss:0.34317679209229596\n",
      "train loss:0.31251352291417656\n",
      "train loss:0.34754344556516065\n",
      "train loss:0.3370651044082783\n",
      "train loss:0.34782463277261877\n",
      "train loss:0.3667303064661304\n",
      "train loss:0.3418386634722044\n",
      "train loss:0.2847005236957953\n",
      "train loss:0.27261121792655507\n",
      "train loss:0.3222263289336148\n",
      "train loss:0.3269758675902722\n",
      "train loss:0.365854026672417\n",
      "train loss:0.31439108156486156\n",
      "train loss:0.28801486497021356\n",
      "train loss:0.26430930245658124\n",
      "train loss:0.34129203278359194\n",
      "train loss:0.3082534944486914\n",
      "train loss:0.2778860798361161\n",
      "train loss:0.25876777927297284\n",
      "train loss:0.29271297576150085\n",
      "train loss:0.3219854193520405\n",
      "train loss:0.4774167839664964\n",
      "train loss:0.317125980073685\n",
      "train loss:0.3332334181211348\n",
      "train loss:0.42343532995735805\n",
      "train loss:0.3774493296696806\n",
      "train loss:0.32915676979992026\n",
      "train loss:0.25624862684129907\n",
      "train loss:0.2755846967448145\n",
      "train loss:0.29652194750546185\n",
      "train loss:0.3062730061723485\n",
      "train loss:0.3257169294189083\n",
      "train loss:0.34243439443273677\n",
      "train loss:0.33676757586059325\n",
      "train loss:0.2705875621127846\n",
      "train loss:0.36341874274019914\n",
      "train loss:0.282552790114088\n",
      "train loss:0.33396367446932834\n",
      "train loss:0.28917629809915435\n",
      "train loss:0.3578490303413667\n",
      "train loss:0.3862771008550624\n",
      "train loss:0.2764788762637425\n",
      "train loss:0.3199539414444592\n",
      "train loss:0.37621921904235206\n",
      "train loss:0.31794774920166685\n",
      "train loss:0.278114209040499\n",
      "train loss:0.2987319904060988\n",
      "train loss:0.3453092122352786\n",
      "train loss:0.4284564718116512\n",
      "train loss:0.28642198139538605\n",
      "train loss:0.3552677190997373\n",
      "train loss:0.3705637648609907\n",
      "train loss:0.2989549952970764\n",
      "train loss:0.26165318454014636\n",
      "train loss:0.3767009096149855\n",
      "train loss:0.3348232083776369\n",
      "train loss:0.29310264299851585\n",
      "train loss:0.33888694274962006\n",
      "train loss:0.332861282799047\n",
      "train loss:0.3183941293709836\n",
      "train loss:0.30420977072913297\n",
      "train loss:0.29499494556708755\n",
      "train loss:0.38527674250217375\n",
      "train loss:0.3201742619344981\n",
      "train loss:0.32186674601104664\n",
      "train loss:0.32840773085920516\n",
      "train loss:0.30279091709309125\n",
      "train loss:0.3380537312260517\n",
      "train loss:0.3690218926139945\n",
      "train loss:0.3678316522261682\n",
      "train loss:0.2817687729733424\n",
      "train loss:0.3643634668620513\n",
      "train loss:0.3429082003351252\n",
      "train loss:0.31568923981996233\n",
      "train loss:0.361706354761626\n",
      "train loss:0.34483664212420634\n",
      "train loss:0.2885034602644802\n",
      "train loss:0.4243401858004553\n",
      "train loss:0.3836113412889221\n",
      "train loss:0.32809953721355556\n",
      "train loss:0.3723905687310759\n",
      "train loss:0.31795091082124877\n",
      "train loss:0.37906485808972995\n",
      "train loss:0.32472569263509937\n",
      "train loss:0.3866433487801261\n",
      "train loss:0.34658774544387033\n",
      "train loss:0.327344538163358\n",
      "train loss:0.4123468014528682\n",
      "train loss:0.33808539416082606\n",
      "train loss:0.40245566702592356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.29193518111980554\n",
      "train loss:0.39188972915687625\n",
      "train loss:0.3194943963179239\n",
      "train loss:0.37322256358173056\n",
      "train loss:0.2680102917530001\n",
      "train loss:0.40428974823213343\n",
      "train loss:0.3796735363498165\n",
      "train loss:0.35930387402598585\n",
      "train loss:0.2898609848619934\n",
      "train loss:0.44292452838761076\n",
      "train loss:0.39485323565644276\n",
      "train loss:0.26779423676448316\n",
      "train loss:0.3336832035714778\n",
      "train loss:0.33334714032784624\n",
      "train loss:0.35154358660721197\n",
      "train loss:0.3017427013590058\n",
      "train loss:0.3536721544048832\n",
      "train loss:0.30970716995384145\n",
      "train loss:0.3076273372014777\n",
      "train loss:0.31069920497969555\n",
      "train loss:0.33650077222445834\n",
      "train loss:0.31234349686318175\n",
      "train loss:0.37574469039651465\n",
      "train loss:0.32154945651310346\n",
      "train loss:0.24343620871093685\n",
      "train loss:0.449514970934098\n",
      "=== epoch:4, train acc:0.988, test acc:0.985 ===\n",
      "train loss:0.42058024421513446\n",
      "train loss:0.3846044058864038\n",
      "train loss:0.3780972980019675\n",
      "train loss:0.2733288190484501\n",
      "train loss:0.3887930264780957\n",
      "train loss:0.3614251754571267\n",
      "train loss:0.36151270093822685\n",
      "train loss:0.310727501189754\n",
      "train loss:0.2936083034225669\n",
      "train loss:0.35203789556292525\n",
      "train loss:0.40732016985839375\n",
      "train loss:0.30907749213524144\n",
      "train loss:0.3200594119789267\n",
      "train loss:0.34592862916935124\n",
      "train loss:0.39120497535313725\n",
      "train loss:0.3311767199113234\n",
      "train loss:0.3327456823787339\n",
      "train loss:0.27553594661999375\n",
      "train loss:0.24649907787667935\n",
      "train loss:0.3060391764406277\n",
      "train loss:0.33278411916004624\n",
      "train loss:0.3637878387803789\n",
      "train loss:0.39445005080668677\n",
      "train loss:0.3071665279589302\n",
      "train loss:0.2887647878201679\n",
      "train loss:0.33384416237000575\n",
      "train loss:0.3505986145027872\n",
      "train loss:0.2622581456973231\n",
      "train loss:0.3079830633379836\n",
      "train loss:0.33515574774146384\n",
      "train loss:0.33825979412227425\n",
      "train loss:0.3151570633322879\n",
      "train loss:0.3477310298794386\n",
      "train loss:0.2897066021607237\n",
      "train loss:0.33984391992024926\n",
      "train loss:0.33884294312399016\n",
      "train loss:0.26021252383796434\n",
      "train loss:0.29430970600007644\n",
      "train loss:0.38970001586728775\n",
      "train loss:0.2750227504054464\n",
      "train loss:0.35585971449007586\n",
      "train loss:0.44020225370379745\n",
      "train loss:0.3423195724704818\n",
      "train loss:0.304308406484177\n",
      "train loss:0.3067348323783877\n",
      "train loss:0.34595349197049075\n",
      "train loss:0.3523454768191095\n",
      "train loss:0.32835411896935784\n",
      "train loss:0.3651517429601363\n",
      "train loss:0.34059824333248373\n",
      "train loss:0.3713858048561172\n",
      "train loss:0.2825050252457635\n",
      "train loss:0.3250633410838333\n",
      "train loss:0.26531579370562897\n",
      "train loss:0.28416683025427353\n",
      "train loss:0.25997395429584225\n",
      "train loss:0.3949774427143683\n",
      "train loss:0.3021735623782328\n",
      "train loss:0.3104475929421888\n",
      "train loss:0.3326728715636735\n",
      "train loss:0.3338312935793951\n",
      "train loss:0.31210172143464326\n",
      "train loss:0.31554513103981385\n",
      "train loss:0.32398638346283526\n",
      "train loss:0.36352095906264364\n",
      "train loss:0.27991570356602663\n",
      "train loss:0.35531330842395875\n",
      "train loss:0.33510009596341855\n",
      "train loss:0.3286016770395907\n",
      "train loss:0.3999055698940501\n",
      "train loss:0.35276210091309\n",
      "train loss:0.30836459623678436\n",
      "train loss:0.3445023645602435\n",
      "train loss:0.31016477518283797\n",
      "train loss:0.36461419732852024\n",
      "train loss:0.2561413058118777\n",
      "train loss:0.3472573280466076\n",
      "train loss:0.3129842012610167\n",
      "train loss:0.3237167660109786\n",
      "train loss:0.3514866095428516\n",
      "train loss:0.3364019508246342\n",
      "train loss:0.316992935842993\n",
      "train loss:0.3551802399298973\n",
      "train loss:0.3467987979524553\n",
      "train loss:0.3146822470194029\n",
      "train loss:0.2676867780224784\n",
      "train loss:0.30958589473764747\n",
      "train loss:0.37500561579353614\n",
      "train loss:0.3737434030480282\n",
      "train loss:0.2999973564076796\n",
      "train loss:0.35257415640138307\n",
      "train loss:0.3750795802413061\n",
      "train loss:0.3429687603818588\n",
      "train loss:0.34690193691594345\n",
      "train loss:0.42754552656753564\n",
      "train loss:0.33938893900905415\n",
      "train loss:0.32654373974879847\n",
      "train loss:0.3372470977451566\n",
      "train loss:0.37763348992902124\n",
      "train loss:0.3262800644658199\n",
      "train loss:0.30044316732010934\n",
      "train loss:0.2950943560535053\n",
      "train loss:0.28920260690818933\n",
      "train loss:0.2790914497935924\n",
      "train loss:0.3429022104361236\n",
      "train loss:0.24883543717274964\n",
      "train loss:0.26957386501503394\n",
      "train loss:0.36188305372896007\n",
      "train loss:0.3099372451281308\n",
      "train loss:0.33758719131753273\n",
      "train loss:0.3446158838153129\n",
      "train loss:0.3633968123885764\n",
      "train loss:0.3071281241248173\n",
      "train loss:0.2715222339911539\n",
      "train loss:0.39110030867926326\n",
      "train loss:0.2632308261181471\n",
      "train loss:0.2956810825350896\n",
      "train loss:0.2744677877756995\n",
      "train loss:0.31703558519340985\n",
      "train loss:0.34931149278881635\n",
      "train loss:0.37391760168204285\n",
      "train loss:0.28365725110149015\n",
      "train loss:0.3335391594922125\n",
      "train loss:0.23838679069557572\n",
      "train loss:0.2618890146748416\n",
      "train loss:0.3252105475944065\n",
      "train loss:0.35129466238858986\n",
      "train loss:0.27441994977123774\n",
      "train loss:0.30878158432644565\n",
      "train loss:0.27270270627941284\n",
      "train loss:0.29165381961678066\n",
      "train loss:0.44077097183549196\n",
      "train loss:0.3270013227668632\n",
      "train loss:0.3886252865104461\n",
      "train loss:0.2907926070050752\n",
      "train loss:0.26369649173661236\n",
      "train loss:0.3752073810787491\n",
      "train loss:0.37932224116645114\n",
      "train loss:0.3486550282275798\n",
      "train loss:0.30018305747027013\n",
      "train loss:0.3572667492539084\n",
      "train loss:0.35914566272004883\n",
      "train loss:0.3206087255674994\n",
      "train loss:0.2750107877689904\n",
      "train loss:0.40772682924439996\n",
      "train loss:0.3253255732632065\n",
      "train loss:0.33700576646222474\n",
      "train loss:0.3371744683488329\n",
      "train loss:0.33134741536657714\n",
      "train loss:0.308453942847738\n",
      "train loss:0.2851420569570195\n",
      "train loss:0.311983176499785\n",
      "train loss:0.34647355568792715\n",
      "train loss:0.3073060752883257\n",
      "train loss:0.3000806225260729\n",
      "train loss:0.2918313473521891\n",
      "train loss:0.35396553969903943\n",
      "train loss:0.3490410411996552\n",
      "train loss:0.3333293698030373\n",
      "train loss:0.26914084224813867\n",
      "train loss:0.27849446700574415\n",
      "train loss:0.3187650472175894\n",
      "train loss:0.4135380764139201\n",
      "train loss:0.3137120576495923\n",
      "train loss:0.3466402515573558\n",
      "train loss:0.3121447402486347\n",
      "train loss:0.2759463727300612\n",
      "train loss:0.26064406162829784\n",
      "train loss:0.35614804317770815\n",
      "train loss:0.34686457494800443\n",
      "train loss:0.3292950802568664\n",
      "train loss:0.3227514378543959\n",
      "train loss:0.3683383786086136\n",
      "train loss:0.25905781909340353\n",
      "train loss:0.27180582430620254\n",
      "train loss:0.2380435402986605\n",
      "train loss:0.2999648926836251\n",
      "train loss:0.3288103841265304\n",
      "train loss:0.40490009855562004\n",
      "train loss:0.355889044648556\n",
      "train loss:0.33233510289925594\n",
      "train loss:0.3033567276703136\n",
      "train loss:0.32573756625895894\n",
      "train loss:0.3113175721194806\n",
      "train loss:0.37024192637445197\n",
      "train loss:0.29926054053500395\n",
      "train loss:0.2878341185121568\n",
      "train loss:0.41419899996020326\n",
      "train loss:0.29439429785001253\n",
      "train loss:0.30112697049681475\n",
      "train loss:0.27630309965052396\n",
      "train loss:0.36440730416163125\n",
      "train loss:0.3025153954358499\n",
      "train loss:0.39222345198579023\n",
      "train loss:0.31921043161064994\n",
      "train loss:0.2722099446806502\n",
      "train loss:0.3258223493450385\n",
      "train loss:0.3352209773337404\n",
      "train loss:0.307895288960181\n",
      "train loss:0.3759968153356214\n",
      "train loss:0.2661710508018059\n",
      "train loss:0.3514364903120848\n",
      "train loss:0.3663991848322053\n",
      "train loss:0.280904125584849\n",
      "train loss:0.30762857638146823\n",
      "train loss:0.3015078618221559\n",
      "train loss:0.3338327964237082\n",
      "train loss:0.38223319081744983\n",
      "train loss:0.34885710230404904\n",
      "train loss:0.32778669106418945\n",
      "train loss:0.3564168118694214\n",
      "train loss:0.3002297786577865\n",
      "train loss:0.2797844795869427\n",
      "train loss:0.32118571351544023\n",
      "train loss:0.34953637582296726\n",
      "train loss:0.30156232917277576\n",
      "train loss:0.2852436485752989\n",
      "train loss:0.2752905910453316\n",
      "train loss:0.3034342426676113\n",
      "train loss:0.367425800174782\n",
      "train loss:0.32504794861962416\n",
      "train loss:0.35773864641982495\n",
      "train loss:0.2538524640359684\n",
      "train loss:0.23605435230276559\n",
      "train loss:0.3539980123420519\n",
      "train loss:0.29987518016182846\n",
      "train loss:0.3441981372604071\n",
      "train loss:0.3461300028127415\n",
      "train loss:0.263277352361619\n",
      "train loss:0.357422038301987\n",
      "train loss:0.2769518173770104\n",
      "train loss:0.373045387966292\n",
      "train loss:0.37338096591604825\n",
      "train loss:0.2684899467250287\n",
      "train loss:0.30636317825228415\n",
      "train loss:0.36966053750829186\n",
      "train loss:0.29393223340797425\n",
      "train loss:0.33229116216555477\n",
      "train loss:0.33941623632455986\n",
      "train loss:0.2890687869638415\n",
      "train loss:0.4083593036747203\n",
      "train loss:0.28196979855194904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.29606133315208244\n",
      "train loss:0.3265671532563567\n",
      "train loss:0.3755392284861972\n",
      "train loss:0.3433400663136311\n",
      "train loss:0.31978649447199126\n",
      "train loss:0.2775126413861545\n",
      "train loss:0.32623301365751955\n",
      "train loss:0.2774473570623342\n",
      "train loss:0.36983719745311144\n",
      "train loss:0.3572375370598499\n",
      "train loss:0.30593002876599357\n",
      "train loss:0.3110473469573877\n",
      "train loss:0.32789754067082\n",
      "train loss:0.3596012253711514\n",
      "train loss:0.3324695606168991\n",
      "train loss:0.3003070264678577\n",
      "train loss:0.24057238061499694\n",
      "train loss:0.32196232467335784\n",
      "train loss:0.3822447582230743\n",
      "train loss:0.31220444517814994\n",
      "train loss:0.25997666123158875\n",
      "train loss:0.3881123022263019\n",
      "train loss:0.3315301493923072\n",
      "train loss:0.37929155031214584\n",
      "train loss:0.3509503732769486\n",
      "train loss:0.34447058698297267\n",
      "train loss:0.33283613488735125\n",
      "train loss:0.3022071454258427\n",
      "train loss:0.29980318756678914\n",
      "train loss:0.35887159169705524\n",
      "train loss:0.31670388660064575\n",
      "train loss:0.3628953408526614\n",
      "train loss:0.2822014246954149\n",
      "train loss:0.3325832386855365\n",
      "train loss:0.334387517831231\n",
      "train loss:0.3006671463430007\n",
      "train loss:0.30420297331940965\n",
      "train loss:0.2993793491321045\n",
      "train loss:0.3324153626425848\n",
      "train loss:0.3011916941087704\n",
      "train loss:0.3216322798918821\n",
      "train loss:0.3424710527640235\n",
      "train loss:0.2652508880891414\n",
      "train loss:0.3687697016527677\n",
      "train loss:0.31187132580545884\n",
      "train loss:0.38299416744349274\n",
      "train loss:0.34081234535319793\n",
      "train loss:0.326229579850783\n",
      "train loss:0.2907414500210826\n",
      "train loss:0.3286803539026514\n",
      "train loss:0.35022349780024\n",
      "train loss:0.2978182638069652\n",
      "train loss:0.25738251178607663\n",
      "train loss:0.37307563952327943\n",
      "train loss:0.2764071273835506\n",
      "train loss:0.3229851057009342\n",
      "train loss:0.3386648971782211\n",
      "train loss:0.3320070127800279\n",
      "train loss:0.2610211117132217\n",
      "train loss:0.31165088984028416\n",
      "train loss:0.2884860678679878\n",
      "train loss:0.3260747701548608\n",
      "train loss:0.32372079247033236\n",
      "train loss:0.3075167208198223\n",
      "train loss:0.3432304772050176\n",
      "train loss:0.313850758938407\n",
      "train loss:0.282613455369304\n",
      "train loss:0.25379925071691223\n",
      "train loss:0.3441411125213886\n",
      "train loss:0.3394220756508799\n",
      "train loss:0.3167609202759947\n",
      "train loss:0.2729151751719996\n",
      "train loss:0.3448340041446129\n",
      "train loss:0.19014549975309594\n",
      "train loss:0.3019752265064522\n",
      "train loss:0.31482726374462555\n",
      "train loss:0.3306907655830516\n",
      "train loss:0.3538577473170328\n",
      "train loss:0.3022503581551779\n",
      "train loss:0.33528844390954615\n",
      "train loss:0.2644826467467535\n",
      "train loss:0.30664313425146617\n",
      "train loss:0.3479734664434933\n",
      "train loss:0.2873723345726838\n",
      "train loss:0.34552739609200145\n",
      "train loss:0.2916113278472126\n",
      "train loss:0.3434152752063004\n",
      "train loss:0.31085395320885045\n",
      "train loss:0.34251349614521587\n",
      "train loss:0.3142506847392482\n",
      "train loss:0.33151002805321766\n",
      "train loss:0.28926116277840513\n",
      "train loss:0.3067659643031558\n",
      "train loss:0.3517783338455095\n",
      "train loss:0.3595115801295465\n",
      "train loss:0.35720392207694956\n",
      "train loss:0.38697871840835496\n",
      "train loss:0.30057468315901625\n",
      "train loss:0.3732593875824965\n",
      "train loss:0.32212047906339597\n",
      "train loss:0.29313880062121905\n",
      "train loss:0.3023322304778173\n",
      "train loss:0.3409611551262365\n",
      "train loss:0.3582661363280961\n",
      "train loss:0.3262273437097632\n",
      "train loss:0.31234040361417037\n",
      "train loss:0.33691422675130256\n",
      "train loss:0.35845905503192105\n",
      "train loss:0.3229534818441054\n",
      "train loss:0.41289058292920067\n",
      "train loss:0.3514225637451426\n",
      "train loss:0.2752796947622934\n",
      "train loss:0.3751676666131446\n",
      "train loss:0.3746428313286362\n",
      "train loss:0.37310218586562666\n",
      "train loss:0.2969853807851995\n",
      "train loss:0.37623170308207726\n",
      "train loss:0.3508307925775154\n",
      "train loss:0.27278522771107055\n",
      "train loss:0.3120139495484953\n",
      "train loss:0.2925876765575938\n",
      "train loss:0.3659891799053547\n",
      "train loss:0.2676791671255857\n",
      "train loss:0.3812736843332247\n",
      "train loss:0.29017994249115525\n",
      "train loss:0.3385931108677255\n",
      "=== epoch:5, train acc:0.993, test acc:0.995 ===\n",
      "train loss:0.3269985188520463\n",
      "train loss:0.3193019321333624\n",
      "train loss:0.28211386105672615\n",
      "train loss:0.3335495244217968\n",
      "train loss:0.34717432036247664\n",
      "train loss:0.3007609850173004\n",
      "train loss:0.415796494105118\n",
      "train loss:0.3778687808672877\n",
      "train loss:0.26493906050511673\n",
      "train loss:0.32787464202011285\n",
      "train loss:0.29813506348072233\n",
      "train loss:0.3905680686387984\n",
      "train loss:0.3217825495796666\n",
      "train loss:0.3195194140962489\n",
      "train loss:0.2834995271647229\n",
      "train loss:0.2708243708502909\n",
      "train loss:0.44576688698882\n",
      "train loss:0.28961127749966703\n",
      "train loss:0.2633389152986695\n",
      "train loss:0.3191869155101906\n",
      "train loss:0.36833798602638873\n",
      "train loss:0.33026036415131005\n",
      "train loss:0.35889241337848155\n",
      "train loss:0.37141870688464423\n",
      "train loss:0.24232403576444456\n",
      "train loss:0.2674836206455239\n",
      "train loss:0.23789113471084083\n",
      "train loss:0.3288130374790368\n",
      "train loss:0.3217754440265884\n",
      "train loss:0.30613453657491324\n",
      "train loss:0.2903915569901395\n",
      "train loss:0.32910677852331066\n",
      "train loss:0.3187602931932067\n",
      "train loss:0.3416882180247119\n",
      "train loss:0.32303824558832667\n",
      "train loss:0.29857684998049766\n",
      "train loss:0.3590966076475535\n",
      "train loss:0.32556901721742987\n",
      "train loss:0.3218394371379111\n",
      "train loss:0.26367141349955736\n",
      "train loss:0.24837804909226222\n",
      "train loss:0.39677294166959726\n",
      "train loss:0.3054878018666043\n",
      "train loss:0.39805869699970237\n",
      "train loss:0.297447435766198\n",
      "train loss:0.35948922692999924\n",
      "train loss:0.2956006564681792\n",
      "train loss:0.25688281119223955\n",
      "train loss:0.354576168726697\n",
      "train loss:0.30253846140708657\n",
      "train loss:0.44915491069515967\n",
      "train loss:0.3576554564492104\n",
      "train loss:0.29183120378511074\n",
      "train loss:0.3506722005637261\n",
      "train loss:0.25226123357407876\n",
      "train loss:0.31556620462533247\n",
      "train loss:0.380570330969238\n",
      "train loss:0.3499170631477654\n",
      "train loss:0.30620150854546924\n",
      "train loss:0.39376472549076197\n",
      "train loss:0.3985270867117958\n",
      "train loss:0.3314771760448014\n",
      "train loss:0.3211316946763476\n",
      "train loss:0.3974654006374712\n",
      "train loss:0.31500413958148105\n",
      "train loss:0.37967871616259713\n",
      "train loss:0.3463345730013022\n",
      "train loss:0.3060078085066398\n",
      "train loss:0.302923000515439\n",
      "train loss:0.2667334439336084\n",
      "train loss:0.39075247983112066\n",
      "train loss:0.38788791633580944\n",
      "train loss:0.3483783626140459\n",
      "train loss:0.37061633967259516\n",
      "train loss:0.48378616734707036\n",
      "train loss:0.3291037322287006\n",
      "train loss:0.3449345499584241\n",
      "train loss:0.2884614128135017\n",
      "train loss:0.2586164275414007\n",
      "train loss:0.3719848660499231\n",
      "train loss:0.31649319183498\n",
      "train loss:0.29960339738655883\n",
      "train loss:0.28102266023403505\n",
      "train loss:0.39742550398632054\n",
      "train loss:0.3912123974566365\n",
      "train loss:0.3585621156230089\n",
      "train loss:0.32549576647393236\n",
      "train loss:0.27325839660453244\n",
      "train loss:0.35362032852213177\n",
      "train loss:0.3207825897539818\n",
      "train loss:0.30757429073959486\n",
      "train loss:0.25107622777800587\n",
      "train loss:0.3178436268435191\n",
      "train loss:0.35953700698671603\n",
      "train loss:0.2796927820783521\n",
      "train loss:0.26981269435713534\n",
      "train loss:0.3230561562802889\n",
      "train loss:0.3191412593226744\n",
      "train loss:0.3265977786667527\n",
      "train loss:0.3147020903928723\n",
      "train loss:0.40858635959786654\n",
      "train loss:0.3112552534395366\n",
      "train loss:0.2915754638898326\n",
      "train loss:0.32450227986728797\n",
      "train loss:0.3124307966976288\n",
      "train loss:0.34899306503780303\n",
      "train loss:0.3080388632676062\n",
      "train loss:0.3212173423670894\n",
      "train loss:0.3272353503801316\n",
      "train loss:0.3390788624485019\n",
      "train loss:0.3588806142062214\n",
      "train loss:0.3232883660387349\n",
      "train loss:0.312703158746238\n",
      "train loss:0.40404566396292085\n",
      "train loss:0.3042397755228224\n",
      "train loss:0.2921735704907937\n",
      "train loss:0.35141730947420496\n",
      "train loss:0.24291146665974417\n",
      "train loss:0.3431125052184469\n",
      "train loss:0.29562066708012824\n",
      "train loss:0.34984521474440167\n",
      "train loss:0.29789920530591957\n",
      "train loss:0.34081435970614066\n",
      "train loss:0.3416783805340714\n",
      "train loss:0.3052773488453106\n",
      "train loss:0.27998897448184945\n",
      "train loss:0.3295251956679729\n",
      "train loss:0.4029733060103809\n",
      "train loss:0.3313404975221605\n",
      "train loss:0.3099575730625032\n",
      "train loss:0.32811681066249526\n",
      "train loss:0.25809629639029646\n",
      "train loss:0.3109795725529204\n",
      "train loss:0.3514660896723168\n",
      "train loss:0.4065883984790039\n",
      "train loss:0.4058806262996181\n",
      "train loss:0.3419841515885088\n",
      "train loss:0.301922734012748\n",
      "train loss:0.30079965251894614\n",
      "train loss:0.2651999929348236\n",
      "train loss:0.4014005828411548\n",
      "train loss:0.31997193611532115\n",
      "train loss:0.3397552828643524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.333752539382455\n",
      "train loss:0.31165066074558206\n",
      "train loss:0.3281523441790167\n",
      "train loss:0.37923350242000414\n",
      "train loss:0.3473570537195831\n",
      "train loss:0.3049103796357533\n",
      "train loss:0.351975152183264\n",
      "train loss:0.3153703041223802\n",
      "train loss:0.2606801468611804\n",
      "train loss:0.30913019479112835\n",
      "train loss:0.36244531786871087\n",
      "train loss:0.3285377943500197\n",
      "train loss:0.3208625025691995\n",
      "train loss:0.25663597037065505\n",
      "train loss:0.24418957359091367\n",
      "train loss:0.3238674327281498\n",
      "train loss:0.31326401247610686\n",
      "train loss:0.3489630341196976\n",
      "train loss:0.2746752903150263\n",
      "train loss:0.3582129239296453\n",
      "train loss:0.3912027923055652\n",
      "train loss:0.34693493308076845\n",
      "train loss:0.37036416981149745\n",
      "train loss:0.2855370603656608\n",
      "train loss:0.40447666173539504\n",
      "train loss:0.34840128795583664\n",
      "train loss:0.3326111003464091\n",
      "train loss:0.41918784590184205\n",
      "train loss:0.4528907779988038\n",
      "train loss:0.34262840683399104\n",
      "train loss:0.3082117658828597\n",
      "train loss:0.34796313576283694\n",
      "train loss:0.2975092168594215\n",
      "train loss:0.31622527104699927\n",
      "train loss:0.32861147918960576\n",
      "train loss:0.33974483144489037\n",
      "train loss:0.32152133978629005\n",
      "train loss:0.38941778473414546\n",
      "train loss:0.364953274419436\n",
      "train loss:0.3423317514037457\n",
      "train loss:0.314427069293713\n",
      "train loss:0.3126250460365775\n",
      "train loss:0.3390755867825671\n",
      "train loss:0.37665485534152704\n",
      "train loss:0.3185519525089686\n",
      "train loss:0.37030348133211\n",
      "train loss:0.2839191602766103\n",
      "train loss:0.33077667221535284\n",
      "train loss:0.36249652533636667\n",
      "train loss:0.3593850135039638\n",
      "train loss:0.3691630868496452\n",
      "train loss:0.3380540021017726\n",
      "train loss:0.28553603432646274\n",
      "train loss:0.3556169422048588\n",
      "train loss:0.37940537115764666\n",
      "train loss:0.2848563011943061\n",
      "train loss:0.2939750751773985\n",
      "train loss:0.34939100257801375\n",
      "train loss:0.30999774206344266\n",
      "train loss:0.35105902897734503\n",
      "train loss:0.32476635706411716\n",
      "train loss:0.27640566968970914\n",
      "train loss:0.269109309531221\n",
      "train loss:0.31646384145223083\n",
      "train loss:0.3154156827106657\n",
      "train loss:0.3263158390741377\n",
      "train loss:0.3034488376200225\n",
      "train loss:0.3588374596708084\n",
      "train loss:0.3320142094180703\n",
      "train loss:0.26779247202149864\n",
      "train loss:0.33119628008517155\n",
      "train loss:0.250590452783943\n",
      "train loss:0.415966867407705\n",
      "train loss:0.2963143370737226\n",
      "train loss:0.2906268124316317\n",
      "train loss:0.1957475905398657\n",
      "train loss:0.397709237253104\n",
      "train loss:0.361918741116191\n",
      "train loss:0.24703213487323192\n",
      "train loss:0.3302477026043425\n",
      "train loss:0.25682629520212036\n",
      "train loss:0.2889963435349118\n",
      "train loss:0.31212939872705403\n",
      "train loss:0.33128635142417706\n",
      "train loss:0.2932530044938628\n",
      "train loss:0.3131154789234723\n",
      "train loss:0.3002101545786695\n",
      "train loss:0.3163625264734225\n",
      "train loss:0.34957699171323064\n",
      "train loss:0.3442100854134213\n",
      "train loss:0.3154273358641152\n",
      "train loss:0.3284555118916232\n",
      "train loss:0.23520078463932256\n",
      "train loss:0.3348678439064586\n",
      "train loss:0.33038073817797764\n",
      "train loss:0.3874883326699269\n",
      "train loss:0.24764565054194526\n",
      "train loss:0.32999949805390744\n",
      "train loss:0.2857534397359276\n",
      "train loss:0.3807502111885722\n",
      "train loss:0.38758538100502\n",
      "train loss:0.30220164647926023\n",
      "train loss:0.266722975756023\n",
      "train loss:0.2712625426014449\n",
      "train loss:0.3196450630437289\n",
      "train loss:0.27807476872813697\n",
      "train loss:0.30916179512173947\n",
      "train loss:0.3673060994603708\n",
      "train loss:0.3366344938947957\n",
      "train loss:0.35793997357878843\n",
      "train loss:0.39239821899602123\n",
      "train loss:0.30589022582971453\n",
      "train loss:0.31247409437936474\n",
      "train loss:0.29414907329729245\n",
      "train loss:0.3965649915925805\n",
      "train loss:0.2661903084245774\n",
      "train loss:0.3305344473471465\n",
      "train loss:0.27053561562438744\n",
      "train loss:0.30680475911405064\n",
      "train loss:0.3284969632828993\n",
      "train loss:0.3414986827406504\n",
      "train loss:0.28208818849642225\n",
      "train loss:0.4279895819605987\n",
      "train loss:0.2732956886605476\n",
      "train loss:0.36834179598873823\n",
      "train loss:0.41396469016568843\n",
      "train loss:0.29378007222482105\n",
      "train loss:0.32018492953770816\n",
      "train loss:0.3065738162210279\n",
      "train loss:0.2611780011312541\n",
      "train loss:0.2645792982608714\n",
      "train loss:0.3689475907094203\n",
      "train loss:0.31631442798313486\n",
      "train loss:0.29923200553193197\n",
      "train loss:0.30787560568797545\n",
      "train loss:0.2834349172633999\n",
      "train loss:0.30309311233969727\n",
      "train loss:0.30829451385617707\n",
      "train loss:0.32742516177165987\n",
      "train loss:0.33892052359774316\n",
      "train loss:0.35686831968574995\n",
      "train loss:0.31505948097607367\n",
      "train loss:0.3248731083422359\n",
      "train loss:0.34954069944181765\n",
      "train loss:0.33858793368928647\n",
      "train loss:0.21134906307758655\n",
      "train loss:0.29159287052381216\n",
      "train loss:0.32811201073710283\n",
      "train loss:0.262071323611385\n",
      "train loss:0.2903650350639386\n",
      "train loss:0.35846465966762203\n",
      "train loss:0.390542948080876\n",
      "train loss:0.29526294686003923\n",
      "train loss:0.2923778813119055\n",
      "train loss:0.32676627161434413\n",
      "train loss:0.2944396559427834\n",
      "train loss:0.34488335070024273\n",
      "train loss:0.29430045788481524\n",
      "train loss:0.2725602075449411\n",
      "train loss:0.38567918827703035\n",
      "train loss:0.3169049931547175\n",
      "train loss:0.320090848753675\n",
      "train loss:0.28635624826275335\n",
      "train loss:0.32070951440932327\n",
      "train loss:0.34943121057729487\n",
      "train loss:0.2862853778999252\n",
      "train loss:0.2533412913674357\n",
      "train loss:0.30856965225395855\n",
      "train loss:0.19383163837675296\n",
      "train loss:0.3650126147293743\n",
      "train loss:0.2832990707692937\n",
      "train loss:0.2841499293721778\n",
      "train loss:0.30815195037573656\n",
      "train loss:0.33350258433643715\n",
      "train loss:0.2558410531115517\n",
      "train loss:0.2590081976870684\n",
      "train loss:0.3628294008424441\n",
      "train loss:0.3516815323490164\n",
      "train loss:0.33503170716617864\n",
      "train loss:0.32839528009518243\n",
      "train loss:0.28722960139284237\n",
      "train loss:0.29935357756092035\n",
      "train loss:0.2819669429287667\n",
      "train loss:0.28850880931356726\n",
      "train loss:0.30496869936412246\n",
      "train loss:0.3460979219142489\n",
      "train loss:0.28902700112472934\n",
      "train loss:0.2917279779846451\n",
      "train loss:0.3098463055340556\n",
      "train loss:0.2962364018263156\n",
      "train loss:0.3935169338253115\n",
      "train loss:0.29044785376522486\n",
      "train loss:0.3076660417863657\n",
      "train loss:0.28475891530930625\n",
      "train loss:0.25151571441947407\n",
      "train loss:0.2724283658963864\n",
      "train loss:0.3534481834336297\n",
      "train loss:0.3301492846237514\n",
      "train loss:0.3523365014747373\n",
      "train loss:0.33833028879128096\n",
      "train loss:0.3198200231411431\n",
      "train loss:0.2976092259658633\n",
      "train loss:0.31520874685426853\n",
      "train loss:0.2759928383985852\n",
      "train loss:0.37424555763045014\n",
      "train loss:0.3888020368383015\n",
      "train loss:0.2845664967178921\n",
      "train loss:0.26216021765231473\n",
      "train loss:0.30259340692018116\n",
      "train loss:0.34087821152013403\n",
      "train loss:0.33056482329054027\n",
      "train loss:0.3639056670848136\n",
      "train loss:0.37722712837885425\n",
      "train loss:0.30223556706716354\n",
      "train loss:0.3876017372565726\n",
      "train loss:0.3512955097938412\n",
      "train loss:0.34127469017394974\n",
      "train loss:0.3862797741853086\n",
      "train loss:0.3112502735111207\n",
      "train loss:0.34476955875530024\n",
      "train loss:0.2688182744354763\n",
      "train loss:0.3249327262830706\n",
      "train loss:0.2888483824545688\n",
      "train loss:0.33914501148505516\n",
      "train loss:0.27257592609677345\n",
      "=== epoch:6, train acc:0.995, test acc:0.999 ===\n",
      "train loss:0.2998453030010059\n",
      "train loss:0.3249604149628054\n",
      "train loss:0.3222948443208382\n",
      "train loss:0.35303068804945875\n",
      "train loss:0.2992289411908167\n",
      "train loss:0.27898326778485616\n",
      "train loss:0.31813189745640974\n",
      "train loss:0.3518211247672747\n",
      "train loss:0.350503916485305\n",
      "train loss:0.2616081788495875\n",
      "train loss:0.24908385703338268\n",
      "train loss:0.33907094763109524\n",
      "train loss:0.27624540053738816\n",
      "train loss:0.3480866261551316\n",
      "train loss:0.3000885129247425\n",
      "train loss:0.4170877509681581\n",
      "train loss:0.31161179318496296\n",
      "train loss:0.26504979407967466\n",
      "train loss:0.341977962885128\n",
      "train loss:0.30039514491741465\n",
      "train loss:0.3006664991191443\n",
      "train loss:0.3413905988486654\n",
      "train loss:0.372931391272478\n",
      "train loss:0.3156747597636438\n",
      "train loss:0.4025899057547336\n",
      "train loss:0.34560533138598054\n",
      "train loss:0.36568062408966356\n",
      "train loss:0.3119115449284106\n",
      "train loss:0.3792695354082804\n",
      "train loss:0.24790983149567927\n",
      "train loss:0.3282768729858199\n",
      "train loss:0.23844261054849897\n",
      "train loss:0.26252598508981884\n",
      "train loss:0.3593995938523429\n",
      "train loss:0.3582140653793358\n",
      "train loss:0.25591768514692326\n",
      "train loss:0.34412950488880306\n",
      "train loss:0.30479045419530565\n",
      "train loss:0.309235810834983\n",
      "train loss:0.2799612065696758\n",
      "train loss:0.3717312342295854\n",
      "train loss:0.31218276653207927\n",
      "train loss:0.3550455026206587\n",
      "train loss:0.3394213904804071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.31619298169553756\n",
      "train loss:0.3425702513977882\n",
      "train loss:0.384335182505832\n",
      "train loss:0.3439404221484708\n",
      "train loss:0.3306439394611383\n",
      "train loss:0.372158698610372\n",
      "train loss:0.3038513450479451\n",
      "train loss:0.301056283437671\n",
      "train loss:0.3575248739478738\n",
      "train loss:0.30206298786771474\n",
      "train loss:0.25814805497431276\n",
      "train loss:0.3147607714256144\n",
      "train loss:0.4978417339819991\n",
      "train loss:0.3035515615612517\n",
      "train loss:0.3218703347393648\n",
      "train loss:0.34723191939086223\n",
      "train loss:0.41582337151510484\n",
      "train loss:0.3808723752725925\n",
      "train loss:0.33290820758308104\n",
      "train loss:0.3848330312071767\n",
      "train loss:0.3368417616058999\n",
      "train loss:0.2758964936879804\n",
      "train loss:0.3367875449113566\n",
      "train loss:0.2595150486858959\n",
      "train loss:0.33403386634335086\n",
      "train loss:0.40170116085341584\n",
      "train loss:0.3972573702085845\n",
      "train loss:0.4299702843911979\n",
      "train loss:0.2563738507121185\n",
      "train loss:0.41621578181117547\n",
      "train loss:0.34597907781828996\n",
      "train loss:0.34120669755115657\n",
      "train loss:0.35413980427112673\n",
      "train loss:0.2632410854571502\n",
      "train loss:0.3213678876259556\n",
      "train loss:0.30630092640234036\n",
      "train loss:0.3229573379399646\n",
      "train loss:0.35189425984646683\n",
      "train loss:0.29592149938524687\n",
      "train loss:0.3611366387056561\n",
      "train loss:0.27989889240487237\n",
      "train loss:0.3341372096048275\n",
      "train loss:0.3295038178828039\n",
      "train loss:0.3750423211718506\n",
      "train loss:0.34887440966735883\n",
      "train loss:0.30570744535002325\n",
      "train loss:0.3009900944299873\n",
      "train loss:0.28717909688080745\n",
      "train loss:0.3277648922659936\n",
      "train loss:0.3563801314839395\n",
      "train loss:0.2624895735232838\n",
      "train loss:0.3349347915637626\n",
      "train loss:0.32306223774308906\n",
      "train loss:0.3753304894871929\n",
      "train loss:0.30940133663550834\n",
      "train loss:0.3698566058753277\n",
      "train loss:0.30740578645528405\n",
      "train loss:0.34942472007043796\n",
      "train loss:0.34168309102191363\n",
      "train loss:0.29795998771482946\n",
      "train loss:0.3290134471185036\n",
      "train loss:0.28849860116649784\n",
      "train loss:0.3126519898412378\n",
      "train loss:0.3419298402603213\n",
      "train loss:0.30593840532299577\n",
      "train loss:0.2923595048858368\n",
      "train loss:0.3548745461335602\n",
      "train loss:0.31125804347163155\n",
      "train loss:0.32947837429994614\n",
      "train loss:0.24791998539823362\n",
      "train loss:0.34425706854970767\n",
      "train loss:0.35628619656568394\n",
      "train loss:0.33404084057442335\n",
      "train loss:0.342920095214074\n",
      "train loss:0.3309247732191087\n",
      "train loss:0.32361152132502724\n",
      "train loss:0.3042044056316593\n",
      "train loss:0.33229902490552565\n",
      "train loss:0.36414440985363955\n",
      "train loss:0.3802396203853816\n",
      "train loss:0.29065599367013756\n",
      "train loss:0.3383950228332459\n",
      "train loss:0.3599648000926343\n",
      "train loss:0.31947774986478855\n",
      "train loss:0.3514231032676263\n",
      "train loss:0.36600525269923645\n",
      "train loss:0.2885860850152355\n",
      "train loss:0.35645786011496106\n",
      "train loss:0.37069031460120955\n",
      "train loss:0.27536995313386947\n",
      "train loss:0.29517337549818934\n",
      "train loss:0.3595670585018697\n",
      "train loss:0.28170705360662657\n",
      "train loss:0.3754825224002358\n",
      "train loss:0.31148577492541374\n",
      "train loss:0.3073966024292379\n",
      "train loss:0.32986095127437315\n",
      "train loss:0.303047658719449\n",
      "train loss:0.3329235937759428\n",
      "train loss:0.3127472354589029\n",
      "train loss:0.2530380808210869\n",
      "train loss:0.3069875356756302\n",
      "train loss:0.3366167418613952\n",
      "train loss:0.3389776315155257\n",
      "train loss:0.32680291843821185\n",
      "train loss:0.3998131707660915\n",
      "train loss:0.3238648564366064\n",
      "train loss:0.3043181350796787\n",
      "train loss:0.3299468531544654\n",
      "train loss:0.33273328052707074\n",
      "train loss:0.3534020227313983\n",
      "train loss:0.3371866574965488\n",
      "train loss:0.30218694011404684\n",
      "train loss:0.2560942803551175\n",
      "train loss:0.32651165692661793\n",
      "train loss:0.2602206369599182\n",
      "train loss:0.40287231987426075\n",
      "train loss:0.3232550180815141\n",
      "train loss:0.2917860954510193\n",
      "train loss:0.30353618766343515\n",
      "train loss:0.30785623625594916\n",
      "train loss:0.3772365041590291\n",
      "train loss:0.3342788152891552\n",
      "train loss:0.34561586381827436\n",
      "train loss:0.36435472399489277\n",
      "train loss:0.32916363000350324\n",
      "train loss:0.29748173063422617\n",
      "train loss:0.31735720013509133\n",
      "train loss:0.28898575651253894\n",
      "train loss:0.3327630431418971\n",
      "train loss:0.22994636273956273\n",
      "train loss:0.31947633571825496\n",
      "train loss:0.28317982430233063\n",
      "train loss:0.30883969441339076\n",
      "train loss:0.3307608600112831\n",
      "train loss:0.3280467014694353\n",
      "train loss:0.3619465981739138\n",
      "train loss:0.29868254992973203\n",
      "train loss:0.3357959769197422\n",
      "train loss:0.3115783446910092\n",
      "train loss:0.35742281984469415\n",
      "train loss:0.30294965672351765\n",
      "train loss:0.3128930214323717\n",
      "train loss:0.3671289754802653\n",
      "train loss:0.29627365426900254\n",
      "train loss:0.34857245723700286\n",
      "train loss:0.29731857662944916\n",
      "train loss:0.2943798231723784\n",
      "train loss:0.349002350039955\n",
      "train loss:0.30293932602341267\n",
      "train loss:0.2838130030590536\n",
      "train loss:0.3518610417563161\n",
      "train loss:0.294753806590433\n",
      "train loss:0.35361522071278356\n",
      "train loss:0.28476398857365587\n",
      "train loss:0.363135178475659\n",
      "train loss:0.31049330971752453\n",
      "train loss:0.336125331103647\n",
      "train loss:0.30992145679126126\n",
      "train loss:0.31918587061226644\n",
      "train loss:0.32502214737842583\n",
      "train loss:0.2529127524144558\n",
      "train loss:0.3880312218101596\n",
      "train loss:0.3178585557733067\n",
      "train loss:0.3258132546889619\n",
      "train loss:0.31073549147884183\n",
      "train loss:0.3191553010184479\n",
      "train loss:0.34192420572818577\n",
      "train loss:0.3141733552227683\n",
      "train loss:0.35386179089056247\n",
      "train loss:0.3628863885054076\n",
      "train loss:0.35938859517660476\n",
      "train loss:0.3306331100832146\n",
      "train loss:0.34928982463358965\n",
      "train loss:0.2924401907581811\n",
      "train loss:0.3001164573590166\n",
      "train loss:0.30524737843119454\n",
      "train loss:0.2667108937440789\n",
      "train loss:0.3377649803698434\n",
      "train loss:0.3256989960201858\n",
      "train loss:0.28123516282174243\n",
      "train loss:0.2513993385778286\n",
      "train loss:0.27100772011022806\n",
      "train loss:0.2744989725881564\n",
      "train loss:0.3202366934456595\n",
      "train loss:0.3550519586806399\n",
      "train loss:0.267981236003079\n",
      "train loss:0.3248763316116264\n",
      "train loss:0.35955407048057425\n",
      "train loss:0.3134350976317248\n",
      "train loss:0.3564669700229837\n",
      "train loss:0.3063549941800789\n",
      "train loss:0.30869841397874515\n",
      "train loss:0.2799506544872573\n",
      "train loss:0.32330693195718785\n",
      "train loss:0.3074584979328428\n",
      "train loss:0.2716974004505532\n",
      "train loss:0.3042965087632402\n",
      "train loss:0.4129766944421253\n",
      "train loss:0.29787782497694143\n",
      "train loss:0.32135409540981663\n",
      "train loss:0.30036319146211904\n",
      "train loss:0.2744056479584776\n",
      "train loss:0.30497646166427167\n",
      "train loss:0.356612924400496\n",
      "train loss:0.2412083585568219\n",
      "train loss:0.2733006200021008\n",
      "train loss:0.3176636825319399\n",
      "train loss:0.34254555264573494\n",
      "train loss:0.32757012774548666\n",
      "train loss:0.35685644780526904\n",
      "train loss:0.2888391896135619\n",
      "train loss:0.32626734275869923\n",
      "train loss:0.38484577642686496\n",
      "train loss:0.28869483091704623\n",
      "train loss:0.25415951312944446\n",
      "train loss:0.27392217272456804\n",
      "train loss:0.3502056703097207\n",
      "train loss:0.369844783075839\n",
      "train loss:0.510257971630389\n",
      "train loss:0.3487545918822576\n",
      "train loss:0.29674944482753446\n",
      "train loss:0.3903905868801598\n",
      "train loss:0.317674115789243\n",
      "train loss:0.3347928526649361\n",
      "train loss:0.3103618570124417\n",
      "train loss:0.3602086651333342\n",
      "train loss:0.29547903665582814\n",
      "train loss:0.32507734644813546\n",
      "train loss:0.3275357587480942\n",
      "train loss:0.25971996628550464\n",
      "train loss:0.29127533659142346\n",
      "train loss:0.32809529113335484\n",
      "train loss:0.38922418944793724\n",
      "train loss:0.3441950607720037\n",
      "train loss:0.250927522822608\n",
      "train loss:0.293253497947652\n",
      "train loss:0.3200067721042986\n",
      "train loss:0.27258428960546344\n",
      "train loss:0.2977725389968913\n",
      "train loss:0.353762413988934\n",
      "train loss:0.2878022783083549\n",
      "train loss:0.3425416179491986\n",
      "train loss:0.35358097892691587\n",
      "train loss:0.3157723921420285\n",
      "train loss:0.33371396021411404\n",
      "train loss:0.29950996586329065\n",
      "train loss:0.27037186260688106\n",
      "train loss:0.26937958443393284\n",
      "train loss:0.23149820409858546\n",
      "train loss:0.28612559354138395\n",
      "train loss:0.3442762008621854\n",
      "train loss:0.3332930709054522\n",
      "train loss:0.2718433428636169\n",
      "train loss:0.3062995788613095\n",
      "train loss:0.35729998547268876\n",
      "train loss:0.347737380387275\n",
      "train loss:0.3038255179399805\n",
      "train loss:0.32563638300623954\n",
      "train loss:0.32384948865645513\n",
      "train loss:0.37266490675755437\n",
      "train loss:0.3537578796047256\n",
      "train loss:0.36433112876669294\n",
      "train loss:0.26334820451559016\n",
      "train loss:0.2629555757288229\n",
      "train loss:0.29633703518230126\n",
      "train loss:0.3625101866997824\n",
      "train loss:0.3141041673124042\n",
      "train loss:0.2678345872139385\n",
      "train loss:0.3625642952556722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2872255954115594\n",
      "train loss:0.31378423229477276\n",
      "train loss:0.29211625797134083\n",
      "train loss:0.2918387562423694\n",
      "train loss:0.3367095193169562\n",
      "train loss:0.2961863726217581\n",
      "train loss:0.34992963507641756\n",
      "train loss:0.34458340050058656\n",
      "train loss:0.3365283946349637\n",
      "train loss:0.3115986115613115\n",
      "train loss:0.3070713493770871\n",
      "train loss:0.3579227413675682\n",
      "train loss:0.36125603704101433\n",
      "train loss:0.3293901101603188\n",
      "train loss:0.35376360486196046\n",
      "train loss:0.28983337052955893\n",
      "train loss:0.3490194240476518\n",
      "train loss:0.32330088622199715\n",
      "train loss:0.27628547005637116\n",
      "train loss:0.332549560073926\n",
      "train loss:0.3177257977678896\n",
      "train loss:0.3136627797237834\n",
      "train loss:0.2703658932918169\n",
      "train loss:0.3414992254029483\n",
      "train loss:0.34508442726622846\n",
      "train loss:0.3134580813165255\n",
      "train loss:0.28228787245271164\n",
      "train loss:0.31340650541595283\n",
      "train loss:0.3348223033146925\n",
      "train loss:0.35317844275856924\n",
      "train loss:0.33208469818895664\n",
      "train loss:0.34930715561153514\n",
      "train loss:0.3477889129171429\n",
      "train loss:0.310544430689015\n",
      "train loss:0.2640490912183101\n",
      "train loss:0.3352229964033407\n",
      "train loss:0.3099507239420707\n",
      "train loss:0.29164149312921317\n",
      "train loss:0.28719870858707797\n",
      "train loss:0.35670541470130446\n",
      "train loss:0.36410262868991977\n",
      "train loss:0.3381918365096369\n",
      "train loss:0.3421127489902568\n",
      "train loss:0.27310914603411\n",
      "train loss:0.25463897734809116\n",
      "train loss:0.355810484431816\n",
      "train loss:0.32780141160981763\n",
      "train loss:0.2555529400497765\n",
      "train loss:0.3534100810532494\n",
      "train loss:0.24480720241626053\n",
      "train loss:0.27248636569526136\n",
      "train loss:0.3129522706287661\n",
      "train loss:0.3465318094734979\n",
      "train loss:0.32414756879219053\n",
      "=== epoch:7, train acc:0.997, test acc:0.999 ===\n",
      "train loss:0.375607345854514\n",
      "train loss:0.33397866330715203\n",
      "train loss:0.3140409019906823\n",
      "train loss:0.36439320322675994\n",
      "train loss:0.3165803502958845\n",
      "train loss:0.3548792642596345\n",
      "train loss:0.2628245976206515\n",
      "train loss:0.30763313753615845\n",
      "train loss:0.268057397328811\n",
      "train loss:0.3473107774894917\n",
      "train loss:0.35191703439110983\n",
      "train loss:0.34811527373617046\n",
      "train loss:0.3192120017528809\n",
      "train loss:0.35555484626601225\n",
      "train loss:0.3321350980606871\n",
      "train loss:0.3230380646925467\n",
      "train loss:0.3436583029104397\n",
      "train loss:0.33173328062873075\n",
      "train loss:0.37078705360888026\n",
      "train loss:0.31933982207015416\n",
      "train loss:0.230117846053652\n",
      "train loss:0.2995638157908875\n",
      "train loss:0.285171563202035\n",
      "train loss:0.3362150867953391\n",
      "train loss:0.2708036827282446\n",
      "train loss:0.304970121850951\n",
      "train loss:0.2872771464682903\n",
      "train loss:0.3439191566448118\n",
      "train loss:0.36947714790370484\n",
      "train loss:0.3300524023543306\n",
      "train loss:0.24857457569125468\n",
      "train loss:0.2902935431146884\n",
      "train loss:0.2937843087846583\n",
      "train loss:0.28939010965775946\n",
      "train loss:0.31451243897362036\n",
      "train loss:0.4042213390980299\n",
      "train loss:0.3621742155972116\n",
      "train loss:0.27920491957669336\n",
      "train loss:0.3157745829702725\n",
      "train loss:0.30679227960321875\n",
      "train loss:0.2816753730684823\n",
      "train loss:0.25137814442387163\n",
      "train loss:0.32925722946963704\n",
      "train loss:0.40674968039496556\n",
      "train loss:0.39279342222292046\n",
      "train loss:0.31329364868192855\n",
      "train loss:0.28337317502759396\n",
      "train loss:0.3182531237560303\n",
      "train loss:0.3210848052872109\n",
      "train loss:0.3364732371272752\n",
      "train loss:0.3510533739037579\n",
      "train loss:0.30594970558738904\n",
      "train loss:0.30463684505799954\n",
      "train loss:0.3039789143043355\n",
      "train loss:0.2780140633800741\n",
      "train loss:0.3589659133090526\n",
      "train loss:0.2985516634251036\n",
      "train loss:0.2364356175199685\n",
      "train loss:0.37008706261220975\n",
      "train loss:0.3287860395384231\n",
      "train loss:0.3004040850605921\n",
      "train loss:0.2959564043568612\n",
      "train loss:0.3474859026008334\n",
      "train loss:0.3133735582794292\n",
      "train loss:0.33868713673509715\n",
      "train loss:0.42053237539829963\n",
      "train loss:0.29949318852791595\n",
      "train loss:0.2211828116688182\n",
      "train loss:0.45071994386088104\n",
      "train loss:0.39571082320848966\n",
      "train loss:0.31760686763045587\n",
      "train loss:0.27697020825537205\n",
      "train loss:0.3184421964982653\n",
      "train loss:0.2860706046377565\n",
      "train loss:0.33696966647300647\n",
      "train loss:0.31314351031607174\n",
      "train loss:0.3092463324198336\n",
      "train loss:0.3551362635717555\n",
      "train loss:0.3295340536818848\n",
      "train loss:0.3439664246296521\n",
      "train loss:0.36365315603143183\n",
      "train loss:0.24605371611660662\n",
      "train loss:0.2931741654686296\n",
      "train loss:0.36689612903059426\n",
      "train loss:0.3210358333804645\n",
      "train loss:0.38902490933967554\n",
      "train loss:0.2680892161557446\n",
      "train loss:0.2864694296015314\n",
      "train loss:0.28778961870150926\n",
      "train loss:0.3226126577370195\n",
      "train loss:0.3707999456428612\n",
      "train loss:0.38147332191151545\n",
      "train loss:0.27914582169757174\n",
      "train loss:0.3828100291791887\n",
      "train loss:0.3515051383145851\n",
      "train loss:0.33673408896010115\n",
      "train loss:0.36936071524361874\n",
      "train loss:0.34446835879351656\n",
      "train loss:0.37595270440248973\n",
      "train loss:0.30584920048171926\n",
      "train loss:0.3082107084766068\n",
      "train loss:0.3347731367182851\n",
      "train loss:0.3276437648057381\n",
      "train loss:0.24611169903286303\n",
      "train loss:0.34853551846847997\n",
      "train loss:0.3787651993745351\n",
      "train loss:0.3818070990189652\n",
      "train loss:0.3494704336596789\n",
      "train loss:0.3499464688894545\n",
      "train loss:0.39624637549968683\n",
      "train loss:0.3817234178096061\n",
      "train loss:0.259368081833143\n",
      "train loss:0.32804408597113616\n",
      "train loss:0.3380506418118968\n",
      "train loss:0.29363509023046724\n",
      "train loss:0.33922002603782747\n",
      "train loss:0.33608490931574914\n",
      "train loss:0.3304667286770624\n",
      "train loss:0.3087643774024469\n",
      "train loss:0.31949971102871433\n",
      "train loss:0.3977903441106568\n",
      "train loss:0.27198865339810396\n",
      "train loss:0.32435817356713775\n",
      "train loss:0.40420599054060735\n",
      "train loss:0.31487311124160283\n",
      "train loss:0.3486900492684505\n",
      "train loss:0.2948639298067589\n",
      "train loss:0.36489298836760553\n",
      "train loss:0.27089705734900704\n",
      "train loss:0.3531587015248205\n",
      "train loss:0.36908331859189564\n",
      "train loss:0.407125300041975\n",
      "train loss:0.31063484068276764\n",
      "train loss:0.31979591471317464\n",
      "train loss:0.3010071137285257\n",
      "train loss:0.310204429155417\n",
      "train loss:0.4108212726801932\n",
      "train loss:0.33963966598642276\n",
      "train loss:0.38318978355170696\n",
      "train loss:0.30023029659773987\n",
      "train loss:0.35697989505073024\n",
      "train loss:0.3308345584672409\n",
      "train loss:0.38244151572412716\n",
      "train loss:0.25465263284092976\n",
      "train loss:0.30829352511210206\n",
      "train loss:0.33628714668923704\n",
      "train loss:0.3563426485853279\n",
      "train loss:0.3015188272462867\n",
      "train loss:0.33205498006773804\n",
      "train loss:0.33259045858442965\n",
      "train loss:0.3198581007595311\n",
      "train loss:0.39523911821888336\n",
      "train loss:0.2622048813055055\n",
      "train loss:0.31449834412121286\n",
      "train loss:0.38941280208996537\n",
      "train loss:0.3491606232725249\n",
      "train loss:0.3312449662661934\n",
      "train loss:0.26862482961810025\n",
      "train loss:0.3108736403544279\n",
      "train loss:0.2887051414308464\n",
      "train loss:0.2908196803026645\n",
      "train loss:0.26671633400834716\n",
      "train loss:0.3459265129464644\n",
      "train loss:0.3615985426316586\n",
      "train loss:0.38680863156236195\n",
      "train loss:0.31141872745203386\n",
      "train loss:0.28050428219966894\n",
      "train loss:0.2770645578839838\n",
      "train loss:0.3738355741145996\n",
      "train loss:0.34886933771906853\n",
      "train loss:0.2671754719734088\n",
      "train loss:0.250823545971909\n",
      "train loss:0.3727901952206355\n",
      "train loss:0.25395701449507907\n",
      "train loss:0.34702380839932967\n",
      "train loss:0.27352205191892753\n",
      "train loss:0.32365093891081026\n",
      "train loss:0.30387729181869566\n",
      "train loss:0.3137900546251659\n",
      "train loss:0.27895022839420514\n",
      "train loss:0.2571798563323821\n",
      "train loss:0.3296339460741899\n",
      "train loss:0.3088568259436493\n",
      "train loss:0.29916927312488506\n",
      "train loss:0.275477202542521\n",
      "train loss:0.34608413854916686\n",
      "train loss:0.30520082243523466\n",
      "train loss:0.3507003551376522\n",
      "train loss:0.2489352507651705\n",
      "train loss:0.25934024792929805\n",
      "train loss:0.2903351397559605\n",
      "train loss:0.3798945762671331\n",
      "train loss:0.3149175014374614\n",
      "train loss:0.29139397438912307\n",
      "train loss:0.4011264216706181\n",
      "train loss:0.3102003072989963\n",
      "train loss:0.33130073132910665\n",
      "train loss:0.3464274678178619\n",
      "train loss:0.3121973255576925\n",
      "train loss:0.28047333931419\n",
      "train loss:0.3312773343965986\n",
      "train loss:0.3593118768584959\n",
      "train loss:0.29551744243835226\n",
      "train loss:0.3851808213022854\n",
      "train loss:0.3040969738750117\n",
      "train loss:0.334049021811776\n",
      "train loss:0.30878796764830774\n",
      "train loss:0.3927580902109289\n",
      "train loss:0.3364956519718257\n",
      "train loss:0.2987234180820203\n",
      "train loss:0.2693911695259198\n",
      "train loss:0.32467776217650024\n",
      "train loss:0.31475737109108776\n",
      "train loss:0.3976690906423697\n",
      "train loss:0.2991591203245437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3056496236752639\n",
      "train loss:0.29422646820206205\n",
      "train loss:0.32047475524648356\n",
      "train loss:0.3015189819435903\n",
      "train loss:0.3889561058526028\n",
      "train loss:0.3196709699051597\n",
      "train loss:0.3454190516586255\n",
      "train loss:0.30737130073819124\n",
      "train loss:0.2933947786866496\n",
      "train loss:0.3629913962897337\n",
      "train loss:0.2618064472906764\n",
      "train loss:0.38004687957008537\n",
      "train loss:0.2686503599073509\n",
      "train loss:0.2537114056981413\n",
      "train loss:0.29459647998926475\n",
      "train loss:0.28348299354026973\n",
      "train loss:0.31981869056800655\n",
      "train loss:0.2768938221269996\n",
      "train loss:0.26379501922089527\n",
      "train loss:0.33988335401145875\n",
      "train loss:0.32317997893009737\n",
      "train loss:0.5841695820732906\n",
      "train loss:0.39367315157025307\n",
      "train loss:0.2961861416647273\n",
      "train loss:0.36414982511942184\n",
      "train loss:0.2945600526245404\n",
      "train loss:0.2643841030369385\n",
      "train loss:0.284988232281018\n",
      "train loss:0.33450847651654136\n",
      "train loss:0.3107381266263246\n",
      "train loss:0.26181618340594337\n",
      "train loss:0.3856295625761275\n",
      "train loss:0.28592153395486813\n",
      "train loss:0.41452826884659816\n",
      "train loss:0.29992552210362544\n",
      "train loss:0.2906474976675622\n",
      "train loss:0.33263094074019955\n",
      "train loss:0.3016737814234092\n",
      "train loss:0.26874788445430625\n",
      "train loss:0.3314956257495323\n",
      "train loss:0.27686565379613626\n",
      "train loss:0.3819143972859659\n",
      "train loss:0.2928218953569015\n",
      "train loss:0.35447595453877817\n",
      "train loss:0.3165348858887695\n",
      "train loss:0.3084415088761844\n",
      "train loss:0.31796780526197355\n",
      "train loss:0.3716392107652847\n",
      "train loss:0.31092283308311575\n",
      "train loss:0.3716109255287757\n",
      "train loss:0.23641733117392635\n",
      "train loss:0.3518513551704332\n",
      "train loss:0.3807848377103241\n",
      "train loss:0.3411268891265671\n",
      "train loss:0.29771925672765537\n",
      "train loss:0.2827398555749157\n",
      "train loss:0.30550391120580983\n",
      "train loss:0.2584912431956302\n",
      "train loss:0.4166521935090091\n",
      "train loss:0.28640951916299556\n",
      "train loss:0.25936222395226916\n",
      "train loss:0.39777268703561625\n",
      "train loss:0.37943289950365205\n",
      "train loss:0.3124454389901788\n",
      "train loss:0.3225778141451812\n",
      "train loss:0.3290594548389666\n",
      "train loss:0.3440326245837226\n",
      "train loss:0.3245714190296853\n",
      "train loss:0.3766525999703883\n",
      "train loss:0.31031161951788416\n",
      "train loss:0.23433218842968268\n",
      "train loss:0.3695294045807724\n",
      "train loss:0.35778304632180374\n",
      "train loss:0.335723932235584\n",
      "train loss:0.33822228958433675\n",
      "train loss:0.2807550210052074\n",
      "train loss:0.37152322130620424\n",
      "train loss:0.2989939595000833\n",
      "train loss:0.3317804564434308\n",
      "train loss:0.32014627470022344\n",
      "train loss:0.4064443159129103\n",
      "train loss:0.30414972334019197\n",
      "train loss:0.3731307209637584\n",
      "train loss:0.3280865171504844\n",
      "train loss:0.3113574580127631\n",
      "train loss:0.3206756046706073\n",
      "train loss:0.3447316594457927\n",
      "train loss:0.3230617292262498\n",
      "train loss:0.2702515838407962\n",
      "train loss:0.3487204826049609\n",
      "train loss:0.3979699175889048\n",
      "train loss:0.3416077285853511\n",
      "train loss:0.34298364217067706\n",
      "train loss:0.23601485616129073\n",
      "train loss:0.32423728861470535\n",
      "train loss:0.2888404106450668\n",
      "train loss:0.29052727162748887\n",
      "train loss:0.31060758187030435\n",
      "train loss:0.3265942099258049\n",
      "train loss:0.35536930539222455\n",
      "train loss:0.3913092398904742\n",
      "train loss:0.3249512248519564\n",
      "train loss:0.30833133584546046\n",
      "train loss:0.32670982873133914\n",
      "train loss:0.2874924032566811\n",
      "train loss:0.28058789560411257\n",
      "train loss:0.3117455992716336\n",
      "train loss:0.3286894265222601\n",
      "train loss:0.34888510507531584\n",
      "train loss:0.35838983888425957\n",
      "train loss:0.38000308502944985\n",
      "train loss:0.3614903125172887\n",
      "train loss:0.34038228726587183\n",
      "train loss:0.335087383051806\n",
      "train loss:0.2729180598954412\n",
      "train loss:0.3084136265928471\n",
      "train loss:0.3673046583501099\n",
      "train loss:0.4263508030373675\n",
      "train loss:0.31048945088145624\n",
      "train loss:0.36943646716657147\n",
      "train loss:0.2697965708209548\n",
      "train loss:0.2930538371051333\n",
      "train loss:0.34015309356802137\n",
      "train loss:0.2853715229413952\n",
      "train loss:0.28528804320383444\n",
      "train loss:0.29581604836978087\n",
      "train loss:0.279841426216876\n",
      "train loss:0.288122114270774\n",
      "train loss:0.36469485723464884\n",
      "train loss:0.3406428379671542\n",
      "train loss:0.39228178439519973\n",
      "train loss:0.2599742748300988\n",
      "train loss:0.33592348452887627\n",
      "train loss:0.30087990731354936\n",
      "train loss:0.29526195311848497\n",
      "train loss:0.3845565022932451\n",
      "train loss:0.42112665859173265\n",
      "train loss:0.3203321426858258\n",
      "train loss:0.2992870848445421\n",
      "train loss:0.29210697056647855\n",
      "train loss:0.3554617662114694\n",
      "train loss:0.28083450091028245\n",
      "train loss:0.3111055449565363\n",
      "train loss:0.2883100681709116\n",
      "train loss:0.3458533152944772\n",
      "train loss:0.2705732288655123\n",
      "train loss:0.2997436425746288\n",
      "train loss:0.38043546244186444\n",
      "train loss:0.23958315634340052\n",
      "train loss:0.36873893421131626\n",
      "train loss:0.3291643723303105\n",
      "train loss:0.3046504946456846\n",
      "train loss:0.3188454307663041\n",
      "=== epoch:8, train acc:1.0, test acc:0.997 ===\n",
      "train loss:0.25473259555215605\n",
      "train loss:0.32752047084346386\n",
      "train loss:0.26219198753393913\n",
      "train loss:0.27671444051196553\n",
      "train loss:0.30204917156901845\n",
      "train loss:0.28007955628217013\n",
      "train loss:0.23717495389633864\n",
      "train loss:0.3348356154133111\n",
      "train loss:0.3778434240240497\n",
      "train loss:0.2734349368939343\n",
      "train loss:0.39189222532527845\n",
      "train loss:0.3767037515410695\n",
      "train loss:0.31594541682364174\n",
      "train loss:0.3079738261950054\n",
      "train loss:0.32088293605624674\n",
      "train loss:0.31349126561989565\n",
      "train loss:0.2902253314769344\n",
      "train loss:0.3434330844405719\n",
      "train loss:0.3274833227917416\n",
      "train loss:0.33378452838566386\n",
      "train loss:0.3427747199048358\n",
      "train loss:0.3172004733263802\n",
      "train loss:0.3109662603441549\n",
      "train loss:0.31215894461338384\n",
      "train loss:0.36113670878118925\n",
      "train loss:0.24826282140606318\n",
      "train loss:0.2686973547066599\n",
      "train loss:0.3115005834570538\n",
      "train loss:0.33932730974817743\n",
      "train loss:0.3322264020559215\n",
      "train loss:0.2610351566702179\n",
      "train loss:0.25439667452603026\n",
      "train loss:0.35983454983211277\n",
      "train loss:0.3058444985228711\n",
      "train loss:0.37701670515274394\n",
      "train loss:0.28562882371397547\n",
      "train loss:0.34752551556192496\n",
      "train loss:0.3572357132845551\n",
      "train loss:0.352442810639679\n",
      "train loss:0.30671666087864324\n",
      "train loss:0.34752806267222325\n",
      "train loss:0.2991936297690051\n",
      "train loss:0.26189476466786615\n",
      "train loss:0.3215253223587407\n",
      "train loss:0.27757897136419296\n",
      "train loss:0.3560778554474758\n",
      "train loss:0.2588744569377645\n",
      "train loss:0.32595145623128186\n",
      "train loss:0.36272054372063295\n",
      "train loss:0.3178101185120915\n",
      "train loss:0.30533229478748136\n",
      "train loss:0.3360989278767154\n",
      "train loss:0.31686561406243136\n",
      "train loss:0.37968460881678673\n",
      "train loss:0.4038989343335923\n",
      "train loss:0.3389345312347972\n",
      "train loss:0.22231735505042607\n",
      "train loss:0.29441649297436245\n",
      "train loss:0.3051660874956205\n",
      "train loss:0.3211829088980262\n",
      "train loss:0.33291011903468465\n",
      "train loss:0.2710496300833417\n",
      "train loss:0.27221256508654507\n",
      "train loss:0.34512360993849295\n",
      "train loss:0.4097405626147797\n",
      "train loss:0.26745916813621645\n",
      "train loss:0.28574795497837496\n",
      "train loss:0.33937993433302666\n",
      "train loss:0.36323538570221103\n",
      "train loss:0.3037316744191728\n",
      "train loss:0.34490585812367125\n",
      "train loss:0.3126137543098372\n",
      "train loss:0.29895943415100346\n",
      "train loss:0.2857116269091048\n",
      "train loss:0.30510521734325236\n",
      "train loss:0.3640239912808386\n",
      "train loss:0.3169724073877439\n",
      "train loss:0.3483873898706733\n",
      "train loss:0.39463725531660454\n",
      "train loss:0.3198759042483935\n",
      "train loss:0.30650957890752883\n",
      "train loss:0.32512022355296577\n",
      "train loss:0.2705785308999815\n",
      "train loss:0.3029649455460778\n",
      "train loss:0.33823852204791\n",
      "train loss:0.258275716855456\n",
      "train loss:0.28148036775583224\n",
      "train loss:0.2612713240270568\n",
      "train loss:0.39306621881052345\n",
      "train loss:0.29773325551965046\n",
      "train loss:0.40424290044279154\n",
      "train loss:0.3026154385142116\n",
      "train loss:0.31537230747649214\n",
      "train loss:0.2464576457603244\n",
      "train loss:0.2983119998667382\n",
      "train loss:0.2836207078360424\n",
      "train loss:0.3451100135502076\n",
      "train loss:0.32176694824457847\n",
      "train loss:0.3307088973186189\n",
      "train loss:0.3613671866127711\n",
      "train loss:0.337665701676136\n",
      "train loss:0.3307865739692501\n",
      "train loss:0.28134502707607706\n",
      "train loss:0.3292326830438925\n",
      "train loss:0.29012229961257874\n",
      "train loss:0.3294939783836907\n",
      "train loss:0.3729213821876062\n",
      "train loss:0.3328885063397048\n",
      "train loss:0.3485197836257615\n",
      "train loss:0.32033020982516713\n",
      "train loss:0.36758609726023955\n",
      "train loss:0.27912065215459936\n",
      "train loss:0.3294004634644019\n",
      "train loss:0.28622515026131173\n",
      "train loss:0.28548883966875727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.31707445931029377\n",
      "train loss:0.2877193867232981\n",
      "train loss:0.34706420870459287\n",
      "train loss:0.3636728816355924\n",
      "train loss:0.3041582337033652\n",
      "train loss:0.30768712877719234\n",
      "train loss:0.26767603102002385\n",
      "train loss:0.3053911831656887\n",
      "train loss:0.25349114457497496\n",
      "train loss:0.2949471089674507\n",
      "train loss:0.287642243830956\n",
      "train loss:0.26438789390463724\n",
      "train loss:0.3100723651777662\n",
      "train loss:0.30248231034958517\n",
      "train loss:0.31391840083737976\n",
      "train loss:0.3169417552558074\n",
      "train loss:0.29358100283518784\n",
      "train loss:0.28485128164448503\n",
      "train loss:0.3098996876588901\n",
      "train loss:0.2823842630101639\n",
      "train loss:0.29321042846992135\n",
      "train loss:0.26763418316379967\n",
      "train loss:0.29837475238127276\n",
      "train loss:0.3405010614549495\n",
      "train loss:0.27885097683235177\n",
      "train loss:0.2972855147395374\n",
      "train loss:0.4477461878556428\n",
      "train loss:0.31561374161769795\n",
      "train loss:0.2329570102732714\n",
      "train loss:0.27887581220141644\n",
      "train loss:0.32383411650478267\n",
      "train loss:0.334918336011481\n",
      "train loss:0.330009217799523\n",
      "train loss:0.24294872842239412\n",
      "train loss:0.2713700960256782\n",
      "train loss:0.31097106294848825\n",
      "train loss:0.32585695576046814\n",
      "train loss:0.34830844406170064\n",
      "train loss:0.31604006179530225\n",
      "train loss:0.3624048623996193\n",
      "train loss:0.311798024863959\n",
      "train loss:0.36016039854778487\n",
      "train loss:0.2760067856843972\n",
      "train loss:0.2658951072353463\n",
      "train loss:0.3626642932589016\n",
      "train loss:0.23091164798062153\n",
      "train loss:0.3484989470343084\n",
      "train loss:0.3060732264198105\n",
      "train loss:0.271362050676501\n",
      "train loss:0.3253529153311041\n",
      "train loss:0.32852697062066555\n",
      "train loss:0.2924309530751046\n",
      "train loss:0.26278115033775384\n",
      "train loss:0.33015811868870126\n",
      "train loss:0.32384878124394106\n",
      "train loss:0.34639102892408513\n",
      "train loss:0.2717485148974936\n",
      "train loss:0.326790797375978\n",
      "train loss:0.31951781989160666\n",
      "train loss:0.3739691667002347\n",
      "train loss:0.3125443983673183\n",
      "train loss:0.26064702750581736\n",
      "train loss:0.32664412272857446\n",
      "train loss:0.29266256421705467\n",
      "train loss:0.3012278644201115\n",
      "train loss:0.295948438091927\n",
      "train loss:0.33141770043573404\n",
      "train loss:0.32143945702833626\n",
      "train loss:0.3316268329804571\n",
      "train loss:0.3036161187657667\n",
      "train loss:0.338024366076896\n",
      "train loss:0.2562040048371549\n",
      "train loss:0.29434127134293303\n",
      "train loss:0.24985062200575253\n",
      "train loss:0.3035710092495165\n",
      "train loss:0.3629631203680847\n",
      "train loss:0.2750481820006559\n",
      "train loss:0.35664447119406845\n",
      "train loss:0.2909538551124244\n",
      "train loss:0.34778179982572544\n",
      "train loss:0.33660293774760425\n",
      "train loss:0.36496060367823163\n",
      "train loss:0.2516658461210747\n",
      "train loss:0.37018002511179043\n",
      "train loss:0.26725763835539\n",
      "train loss:0.255373248253617\n",
      "train loss:0.3304173212119052\n",
      "train loss:0.3377363112781595\n",
      "train loss:0.30639517790953097\n",
      "train loss:0.3646422620823864\n",
      "train loss:0.34935819484260927\n",
      "train loss:0.33146602564868444\n",
      "train loss:0.35506453023430284\n",
      "train loss:0.3118945862277396\n",
      "train loss:0.2940355194499976\n",
      "train loss:0.3481999873507768\n",
      "train loss:0.2945488498097417\n",
      "train loss:0.3412403851623107\n",
      "train loss:0.3378528788729531\n",
      "train loss:0.3695328274410335\n",
      "train loss:0.2964174165085827\n",
      "train loss:0.4107179769082751\n",
      "train loss:0.3061461266064898\n",
      "train loss:0.3059432093284928\n",
      "train loss:0.32059482662888633\n",
      "train loss:0.31248239941229544\n",
      "train loss:0.3408758462576066\n",
      "train loss:0.2934759591443787\n",
      "train loss:0.3370583235455439\n",
      "train loss:0.3256982364408181\n",
      "train loss:0.26920767163738607\n",
      "train loss:0.291077789615258\n",
      "train loss:0.3607596598915626\n",
      "train loss:0.32771489919276464\n",
      "train loss:0.36317080526350126\n",
      "train loss:0.2822022681553777\n",
      "train loss:0.3531126989197694\n",
      "train loss:0.29046337694259566\n",
      "train loss:0.33646767122468524\n",
      "train loss:0.248366637295424\n",
      "train loss:0.318673772873595\n",
      "train loss:0.27016282028546\n",
      "train loss:0.36516927438125735\n",
      "train loss:0.2763316756865039\n",
      "train loss:0.2344477758418945\n",
      "train loss:0.28299806944432376\n",
      "train loss:0.3481211288872204\n",
      "train loss:0.20764295981757305\n",
      "train loss:0.32005652908918003\n",
      "train loss:0.2543024307185849\n",
      "train loss:0.4074712628183707\n",
      "train loss:0.29428319898735905\n",
      "train loss:0.35328321992750555\n",
      "train loss:0.34168809190254723\n",
      "train loss:0.3096838189323846\n",
      "train loss:0.29386232258616735\n",
      "train loss:0.297158604445965\n",
      "train loss:0.25365493523222127\n",
      "train loss:0.26433171741135486\n",
      "train loss:0.2531604501339519\n",
      "train loss:0.3274453852731941\n",
      "train loss:0.41154851101883433\n",
      "train loss:0.3953438506371297\n",
      "train loss:0.3546505788158941\n",
      "train loss:0.3052051351098785\n",
      "train loss:0.259551156398259\n",
      "train loss:0.35560574545759815\n",
      "train loss:0.30381782115467004\n",
      "train loss:0.3664566554994954\n",
      "train loss:0.2665573966556715\n",
      "train loss:0.3443031343779681\n",
      "train loss:0.31175997995423255\n",
      "train loss:0.3213043130130078\n",
      "train loss:0.34666192811452456\n",
      "train loss:0.3495396373336253\n",
      "train loss:0.283249765023812\n",
      "train loss:0.33720703708918126\n",
      "train loss:0.3952914878483477\n",
      "train loss:0.32347957500101276\n",
      "train loss:0.3069279307022965\n",
      "train loss:0.2671059526722368\n",
      "train loss:0.2773822957314567\n",
      "train loss:0.23859122403507504\n",
      "train loss:0.2948088834295179\n",
      "train loss:0.33173535285382594\n",
      "train loss:0.33234365406941774\n",
      "train loss:0.30303376233095386\n",
      "train loss:0.3726769356514292\n",
      "train loss:0.34228500114655486\n",
      "train loss:0.3164767003032473\n",
      "train loss:0.30626219929979986\n",
      "train loss:0.3650077219371714\n",
      "train loss:0.3418426728295465\n",
      "train loss:0.33225710056447044\n",
      "train loss:0.28993937100534123\n",
      "train loss:0.3085611899131038\n",
      "train loss:0.3615517524408613\n",
      "train loss:0.3026410431324359\n",
      "train loss:0.42420962196956186\n",
      "train loss:0.2949013804641259\n",
      "train loss:0.2665329092904967\n",
      "train loss:0.32252924551211576\n",
      "train loss:0.35042916879791763\n",
      "train loss:0.33158948120535114\n",
      "train loss:0.36247439723440417\n",
      "train loss:0.30500484483817814\n",
      "train loss:0.2594670374250614\n",
      "train loss:0.2880187683319594\n",
      "train loss:0.25667342663898335\n",
      "train loss:0.2662464826704408\n",
      "train loss:0.3201947514065121\n",
      "train loss:0.27706904699008467\n",
      "train loss:0.32938704787399403\n",
      "train loss:0.3032634201885274\n",
      "train loss:0.2891914200178387\n",
      "train loss:0.27840634290106475\n",
      "train loss:0.23487584736867137\n",
      "train loss:0.3117609307787919\n",
      "train loss:0.33399161405616407\n",
      "train loss:0.3142864291278424\n",
      "train loss:0.35843872998307647\n",
      "train loss:0.3590034139162011\n",
      "train loss:0.34685326029242514\n",
      "train loss:0.23960267196852988\n",
      "train loss:0.3397416183361796\n",
      "train loss:0.3012123598258252\n",
      "train loss:0.37945355391382163\n",
      "train loss:0.3425314118740308\n",
      "train loss:0.3260071618806961\n",
      "train loss:0.3136291487387267\n",
      "train loss:0.34313471304588333\n",
      "train loss:0.3513103674695401\n",
      "train loss:0.2977014127313023\n",
      "train loss:0.2567696746186201\n",
      "train loss:0.27757613258725444\n",
      "train loss:0.3654444256718265\n",
      "train loss:0.33693333345922505\n",
      "train loss:0.33206408615979066\n",
      "train loss:0.2942641980187399\n",
      "train loss:0.3307557014245776\n",
      "train loss:0.2738258746307473\n",
      "train loss:0.3409588540273444\n",
      "train loss:0.22234735384175852\n",
      "train loss:0.24798283935199522\n",
      "train loss:0.2704046781198615\n",
      "train loss:0.23449517446753174\n",
      "train loss:0.2898598373834593\n",
      "train loss:0.36314039132895526\n",
      "train loss:0.3072442037153897\n",
      "train loss:0.3993643928406211\n",
      "train loss:0.2988876648722723\n",
      "train loss:0.3079160664638021\n",
      "train loss:0.3173535829153003\n",
      "train loss:0.3043334046995023\n",
      "train loss:0.325515198786799\n",
      "train loss:0.2684590394092647\n",
      "train loss:0.2705702628085922\n",
      "train loss:0.34476121459450293\n",
      "train loss:0.3064104009766871\n",
      "train loss:0.321907393104166\n",
      "train loss:0.3181654480751054\n",
      "train loss:0.3578350508466056\n",
      "train loss:0.25893825839215234\n",
      "train loss:0.43503441092891365\n",
      "train loss:0.27509049552229914\n",
      "train loss:0.3277958699775827\n",
      "train loss:0.30017914894358416\n",
      "train loss:0.30225000090403037\n",
      "train loss:0.32648337817216694\n",
      "train loss:0.23511504135242076\n",
      "train loss:0.2650424349857381\n",
      "train loss:0.34133017408781513\n",
      "train loss:0.40782324749415333\n",
      "=== epoch:9, train acc:0.998, test acc:0.997 ===\n",
      "train loss:0.3518516374453815\n",
      "train loss:0.31320919216984305\n",
      "train loss:0.34406674254680164\n",
      "train loss:0.38985447840382753\n",
      "train loss:0.35739998435385717\n",
      "train loss:0.3105773213526876\n",
      "train loss:0.32713133431509384\n",
      "train loss:0.3200522711626281\n",
      "train loss:0.27504821506078597\n",
      "train loss:0.2874280046626759\n",
      "train loss:0.32160271650213695\n",
      "train loss:0.34770448165482176\n",
      "train loss:0.42931649486431656\n",
      "train loss:0.29037942667410593\n",
      "train loss:0.34646998994122424\n",
      "train loss:0.3595886082440509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3273821527376562\n",
      "train loss:0.26434530278023843\n",
      "train loss:0.28260522930742393\n",
      "train loss:0.2902576398897295\n",
      "train loss:0.26827248864248604\n",
      "train loss:0.34900531346318303\n",
      "train loss:0.31471903362230336\n",
      "train loss:0.31605067616312266\n",
      "train loss:0.3376623983805177\n",
      "train loss:0.31427308304061635\n",
      "train loss:0.34829394139436826\n",
      "train loss:0.36214644940093677\n",
      "train loss:0.2823261813499984\n",
      "train loss:0.3012776605794792\n",
      "train loss:0.318053210087629\n",
      "train loss:0.32641367669165455\n",
      "train loss:0.2682728393385101\n",
      "train loss:0.297089352076733\n",
      "train loss:0.3318070727791416\n",
      "train loss:0.32768227123974236\n",
      "train loss:0.29053380224332864\n",
      "train loss:0.29525275726366323\n",
      "train loss:0.33714836004502485\n",
      "train loss:0.2973604914445694\n",
      "train loss:0.3370694198153463\n",
      "train loss:0.23717676096355544\n",
      "train loss:0.2797915096938327\n",
      "train loss:0.2789025489964294\n",
      "train loss:0.2868293601520938\n",
      "train loss:0.32145094998361035\n",
      "train loss:0.32384174757165834\n",
      "train loss:0.3348335058566266\n",
      "train loss:0.3245805395710388\n",
      "train loss:0.3572205020949231\n",
      "train loss:0.3910914850276914\n",
      "train loss:0.3133432818151883\n",
      "train loss:0.33162868159108816\n",
      "train loss:0.38824898859440393\n",
      "train loss:0.33646593872125813\n",
      "train loss:0.31879330905064157\n",
      "train loss:0.2805764010881585\n",
      "train loss:0.3482742685629647\n",
      "train loss:0.3332687842360373\n",
      "train loss:0.2892915882433664\n",
      "train loss:0.3049101012496881\n",
      "train loss:0.2605869103536883\n",
      "train loss:0.35450959527970544\n",
      "train loss:0.32477067572803464\n",
      "train loss:0.2639870937514722\n",
      "train loss:0.3050019312682681\n",
      "train loss:0.27209076132844523\n",
      "train loss:0.36062445678379773\n",
      "train loss:0.33819112847413024\n",
      "train loss:0.3232576878918181\n",
      "train loss:0.26210601234275666\n",
      "train loss:0.46754525222093324\n",
      "train loss:0.2655102863877058\n",
      "train loss:0.3548911784071146\n",
      "train loss:0.2942953456740061\n",
      "train loss:0.3110933012131393\n",
      "train loss:0.32345648079004957\n",
      "train loss:0.34699982493112885\n",
      "train loss:0.37660993428763156\n",
      "train loss:0.3306349305867313\n",
      "train loss:0.33463162872620467\n",
      "train loss:0.2981536855910517\n",
      "train loss:0.36430753729469034\n",
      "train loss:0.25453624289319515\n",
      "train loss:0.2973710037439609\n",
      "train loss:0.3030550767655006\n",
      "train loss:0.3040313874210199\n",
      "train loss:0.25234967922179513\n",
      "train loss:0.3213644108205379\n",
      "train loss:0.3241745873977164\n",
      "train loss:0.2552602222247381\n",
      "train loss:0.3233070953298937\n",
      "train loss:0.28321452409805115\n",
      "train loss:0.3280527210854185\n",
      "train loss:0.3010844763246439\n",
      "train loss:0.4064127798578847\n",
      "train loss:0.33016479558404266\n",
      "train loss:0.3219577122978798\n",
      "train loss:0.3219704421702863\n",
      "train loss:0.31509518527357194\n",
      "train loss:0.4033962101217964\n",
      "train loss:0.3790703548618292\n",
      "train loss:0.31999156631453624\n",
      "train loss:0.3193159375052847\n",
      "train loss:0.2947394121846071\n",
      "train loss:0.364401108260243\n",
      "train loss:0.38908974089349624\n",
      "train loss:0.3466436227310904\n",
      "train loss:0.3706143539091868\n",
      "train loss:0.2777867268679229\n",
      "train loss:0.2737221085141553\n",
      "train loss:0.285141779706422\n",
      "train loss:0.26558290230255494\n",
      "train loss:0.33298179664835387\n",
      "train loss:0.29233644895047173\n",
      "train loss:0.2600873848228547\n",
      "train loss:0.2906139832056167\n",
      "train loss:0.32302677823158527\n",
      "train loss:0.316576028317823\n",
      "train loss:0.364237928267782\n",
      "train loss:0.31748054681061766\n",
      "train loss:0.24417962891463324\n",
      "train loss:0.3439020509065249\n",
      "train loss:0.3096565778505541\n",
      "train loss:0.2660105510449625\n",
      "train loss:0.33448126172886533\n",
      "train loss:0.32318314983665114\n",
      "train loss:0.34189893452616765\n",
      "train loss:0.29780481451330754\n",
      "train loss:0.2937844068758543\n",
      "train loss:0.3077537745427465\n",
      "train loss:0.3503209885546524\n",
      "train loss:0.32179649453612735\n",
      "train loss:0.30114483450568613\n",
      "train loss:0.37213086245607935\n",
      "train loss:0.31819972078668984\n",
      "train loss:0.30734514682477054\n",
      "train loss:0.31479175586709585\n",
      "train loss:0.3557418107789638\n",
      "train loss:0.34476686794790584\n",
      "train loss:0.40929266785532814\n",
      "train loss:0.34041005619135783\n",
      "train loss:0.33502355538200906\n",
      "train loss:0.28455391298216726\n",
      "train loss:0.2889516472604523\n",
      "train loss:0.28260052569554905\n",
      "train loss:0.3617200264625985\n",
      "train loss:0.2703822559273312\n",
      "train loss:0.2961065100099945\n",
      "train loss:0.4151942667606689\n",
      "train loss:0.3554831508896164\n",
      "train loss:0.3714459548514307\n",
      "train loss:0.2879234368651448\n",
      "train loss:0.32190863223265576\n",
      "train loss:0.29011902522644806\n",
      "train loss:0.3749729754130481\n",
      "train loss:0.26140202763082715\n",
      "train loss:0.26999203433249686\n",
      "train loss:0.3592740439534196\n",
      "train loss:0.2962788899447535\n",
      "train loss:0.3058147105606672\n",
      "train loss:0.29630943068984816\n",
      "train loss:0.3540885148299451\n",
      "train loss:0.2755051556100722\n",
      "train loss:0.3422000721339033\n",
      "train loss:0.3525664893312191\n",
      "train loss:0.3752454215630776\n",
      "train loss:0.326703027710893\n",
      "train loss:0.3086562259838433\n",
      "train loss:0.280277904637825\n",
      "train loss:0.2808510587760425\n",
      "train loss:0.3248469847842764\n",
      "train loss:0.2896130089376427\n",
      "train loss:0.3001255428480907\n",
      "train loss:0.2507210225706182\n",
      "train loss:0.3420875031726658\n",
      "train loss:0.2851384343795627\n",
      "train loss:0.3557314924396388\n",
      "train loss:0.30697408863438214\n",
      "train loss:0.2809814670178887\n",
      "train loss:0.24197410706284916\n",
      "train loss:0.2619736075815703\n",
      "train loss:0.3610864303854033\n",
      "train loss:0.3060950899313744\n",
      "train loss:0.2770119589132394\n",
      "train loss:0.3036506892915105\n",
      "train loss:0.29927011780608304\n",
      "train loss:0.3324476869587246\n",
      "train loss:0.2967415898989436\n",
      "train loss:0.315668923934359\n",
      "train loss:0.356471963703549\n",
      "train loss:0.26976581644223485\n",
      "train loss:0.29876511686728774\n",
      "train loss:0.35767670827697307\n",
      "train loss:0.273094665987243\n",
      "train loss:0.2982216657404079\n",
      "train loss:0.3170204020340893\n",
      "train loss:0.34834120899756726\n",
      "train loss:0.253281477174912\n",
      "train loss:0.2591582515375238\n",
      "train loss:0.3905824881797313\n",
      "train loss:0.40077629327282055\n",
      "train loss:0.29764671822123506\n",
      "train loss:0.3346832938734365\n",
      "train loss:0.25907131226938745\n",
      "train loss:0.3479175352253565\n",
      "train loss:0.29589517382524116\n",
      "train loss:0.34497228795396595\n",
      "train loss:0.3280571226338787\n",
      "train loss:0.36345136616652574\n",
      "train loss:0.3469565689894394\n",
      "train loss:0.30599319579713924\n",
      "train loss:0.32123066528596694\n",
      "train loss:0.3279714653429427\n",
      "train loss:0.34301746771527225\n",
      "train loss:0.25850532250750374\n",
      "train loss:0.26564907446770436\n",
      "train loss:0.31960756021403813\n",
      "train loss:0.29852909382834897\n",
      "train loss:0.38787654218500445\n",
      "train loss:0.28262167371556485\n",
      "train loss:0.33145622164119054\n",
      "train loss:0.3304407739576322\n",
      "train loss:0.3161678328034286\n",
      "train loss:0.36072427006842245\n",
      "train loss:0.30362165930530677\n",
      "train loss:0.3620520295188765\n",
      "train loss:0.29892624893052094\n",
      "train loss:0.3218521941036254\n",
      "train loss:0.36645102557079406\n",
      "train loss:0.3211402476317679\n",
      "train loss:0.3525462106202392\n",
      "train loss:0.37449976604022583\n",
      "train loss:0.3467488643216733\n",
      "train loss:0.299401041625033\n",
      "train loss:0.3076165729652679\n",
      "train loss:0.29754610834296347\n",
      "train loss:0.3187651171043203\n",
      "train loss:0.2759535006485087\n",
      "train loss:0.30451509630032897\n",
      "train loss:0.30519704010974885\n",
      "train loss:0.28897555160894545\n",
      "train loss:0.2764817873511009\n",
      "train loss:0.3692566925291364\n",
      "train loss:0.348002495791781\n",
      "train loss:0.41503002211365303\n",
      "train loss:0.3804763258787605\n",
      "train loss:0.2622456497313442\n",
      "train loss:0.3114770228078125\n",
      "train loss:0.2792475934480264\n",
      "train loss:0.322081353366516\n",
      "train loss:0.30481560193166307\n",
      "train loss:0.3140035130663461\n",
      "train loss:0.36418223018828055\n",
      "train loss:0.3428869206098337\n",
      "train loss:0.3010578127736586\n",
      "train loss:0.2668266341433128\n",
      "train loss:0.38564797560094155\n",
      "train loss:0.29246382813055305\n",
      "train loss:0.29102551946003263\n",
      "train loss:0.28613912614209114\n",
      "train loss:0.261827884186694\n",
      "train loss:0.3004510255197839\n",
      "train loss:0.22353057664394083\n",
      "train loss:0.3142954118367923\n",
      "train loss:0.3713096033265728\n",
      "train loss:0.3167625617242991\n",
      "train loss:0.34384337555412736\n",
      "train loss:0.2856064640585732\n",
      "train loss:0.3020158981836711\n",
      "train loss:0.2657081364392386\n",
      "train loss:0.30054506630051203\n",
      "train loss:0.30232645947873943\n",
      "train loss:0.3544273623833778\n",
      "train loss:0.284286034264466\n",
      "train loss:0.3005091206050473\n",
      "train loss:0.2866334099756759\n",
      "train loss:0.3133171701768733\n",
      "train loss:0.23061077646471836\n",
      "train loss:0.32140515421691346\n",
      "train loss:0.406286584578505\n",
      "train loss:0.3511986727741431\n",
      "train loss:0.34600726522891406\n",
      "train loss:0.3979705192694747\n",
      "train loss:0.33303779088192736\n",
      "train loss:0.2795205792511532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.27160698674180506\n",
      "train loss:0.3027272408416105\n",
      "train loss:0.2426667695940042\n",
      "train loss:0.3960016120214233\n",
      "train loss:0.3979955167422578\n",
      "train loss:0.32586654995160713\n",
      "train loss:0.4145214962179838\n",
      "train loss:0.24398476238761663\n",
      "train loss:0.3096212471970967\n",
      "train loss:0.3033450451018346\n",
      "train loss:0.305715966810986\n",
      "train loss:0.3052265260058727\n",
      "train loss:0.3656697898729734\n",
      "train loss:0.2552802512530691\n",
      "train loss:0.26104779271948064\n",
      "train loss:0.2518272831981238\n",
      "train loss:0.26990043004134884\n",
      "train loss:0.3118946419183129\n",
      "train loss:0.30967809917244354\n",
      "train loss:0.32083135324248163\n",
      "train loss:0.33636807053434153\n",
      "train loss:0.36602694935287067\n",
      "train loss:0.28934895781515346\n",
      "train loss:0.33405057672002936\n",
      "train loss:0.2842399182795866\n",
      "train loss:0.3507560255667698\n",
      "train loss:0.29918657539300625\n",
      "train loss:0.30691964869671\n",
      "train loss:0.31401885084962683\n",
      "train loss:0.24337485137094247\n",
      "train loss:0.3063144486031805\n",
      "train loss:0.324008740784051\n",
      "train loss:0.38452599185797803\n",
      "train loss:0.3407111930991457\n",
      "train loss:0.2936457376035888\n",
      "train loss:0.3166332930844048\n",
      "train loss:0.27903977361688465\n",
      "train loss:0.31672458814646715\n",
      "train loss:0.316426441750025\n",
      "train loss:0.3070199164811059\n",
      "train loss:0.26997897950858313\n",
      "train loss:0.41032047430321866\n",
      "train loss:0.26715666006734484\n",
      "train loss:0.3226840199557264\n",
      "train loss:0.35465880163387936\n",
      "train loss:0.29849473223813944\n",
      "train loss:0.29070700129131577\n",
      "train loss:0.3635266511234902\n",
      "train loss:0.32444935170776434\n",
      "train loss:0.2957859434808918\n",
      "train loss:0.3381343586292968\n",
      "train loss:0.32634938845552747\n",
      "train loss:0.36297876632890375\n",
      "train loss:0.2961739423211123\n",
      "train loss:0.5755635729528871\n",
      "train loss:0.33758640807852774\n",
      "train loss:0.252886494358527\n",
      "train loss:0.2845794769991604\n",
      "train loss:0.34692771036322334\n",
      "train loss:0.3516434713221187\n",
      "train loss:0.2970510402681723\n",
      "train loss:0.36284181425610046\n",
      "train loss:0.38278358549908104\n",
      "train loss:0.30960929244356733\n",
      "train loss:0.3422390001228449\n",
      "train loss:0.27241505483564993\n",
      "train loss:0.3205302612609406\n",
      "train loss:0.31324102774761226\n",
      "train loss:0.26116520959702727\n",
      "train loss:0.3529138063956239\n",
      "train loss:0.36361865976188845\n",
      "train loss:0.33524634854899393\n",
      "train loss:0.33094062624447623\n",
      "train loss:0.25399017241123517\n",
      "train loss:0.32070582990302826\n",
      "train loss:0.3604373636738764\n",
      "train loss:0.3707960662322614\n",
      "train loss:0.3658285066620424\n",
      "train loss:0.33249221004415763\n",
      "train loss:0.31001841025732496\n",
      "train loss:0.44236728411177645\n",
      "train loss:0.30373514538339824\n",
      "=== epoch:10, train acc:0.998, test acc:0.997 ===\n",
      "train loss:0.32735049845605296\n",
      "train loss:0.3738151905620196\n",
      "train loss:0.34973737105708463\n",
      "train loss:0.3229401266690413\n",
      "train loss:0.3039567051547717\n",
      "train loss:0.3445335812756698\n",
      "train loss:0.2677077865376148\n",
      "train loss:0.2629218275861166\n",
      "train loss:0.3592761247297505\n",
      "train loss:0.4448915375311689\n",
      "train loss:0.3840111957860753\n",
      "train loss:0.3227429062032708\n",
      "train loss:0.24729636104396882\n",
      "train loss:0.3203703254449045\n",
      "train loss:0.3440257149513903\n",
      "train loss:0.3306026366988437\n",
      "train loss:0.3210240114072849\n",
      "train loss:0.27969841353767294\n",
      "train loss:0.3375094532037725\n",
      "train loss:0.3156691551662963\n",
      "train loss:0.36480431886006176\n",
      "train loss:0.3156760600219862\n",
      "train loss:0.33018849177839715\n",
      "train loss:0.29495290757743514\n",
      "train loss:0.29865942333731244\n",
      "train loss:0.39708799605214723\n",
      "train loss:0.3147384775488607\n",
      "train loss:0.3739288837181143\n",
      "train loss:0.35547915816704145\n",
      "train loss:0.269324130227891\n",
      "train loss:0.3347546945256671\n",
      "train loss:0.3426727553992934\n",
      "train loss:0.40101649077672413\n",
      "train loss:0.29707487809124883\n",
      "train loss:0.3117979023791418\n",
      "train loss:0.3806645868504743\n",
      "train loss:0.38861350963806723\n",
      "train loss:0.28243451975553185\n",
      "train loss:0.3320957681744563\n",
      "train loss:0.31939115613769575\n",
      "train loss:0.32479786524015164\n",
      "train loss:0.3465429657163618\n",
      "train loss:0.2775639821200133\n",
      "train loss:0.3015786840866629\n",
      "train loss:0.2664473345900687\n",
      "train loss:0.3085932820300786\n",
      "train loss:0.34664049509045647\n",
      "train loss:0.309947275197282\n",
      "train loss:0.29842842640714873\n",
      "train loss:0.32443898210075783\n",
      "train loss:0.29667397409535784\n",
      "train loss:0.32557587746998834\n",
      "train loss:0.284161366473201\n",
      "train loss:0.298287703588283\n",
      "train loss:0.3622360965172252\n",
      "train loss:0.3003133761643378\n",
      "train loss:0.28580472374721594\n",
      "train loss:0.31865612539959104\n",
      "train loss:0.38378810943603603\n",
      "train loss:0.34311582572239624\n",
      "train loss:0.27084278161979036\n",
      "train loss:0.30111971890458233\n",
      "train loss:0.2766083031440658\n",
      "train loss:0.34222530847532273\n",
      "train loss:0.29678034581094626\n",
      "train loss:0.3943956242458559\n",
      "train loss:0.31227502396530427\n",
      "train loss:0.38113682877941024\n",
      "train loss:0.3256135781875708\n",
      "train loss:0.3030054828820147\n",
      "train loss:0.3049435712503301\n",
      "train loss:0.2828443126194247\n",
      "train loss:0.3438751041586837\n",
      "train loss:0.3481164185664166\n",
      "train loss:0.2943723685438601\n",
      "train loss:0.3523196364716364\n",
      "train loss:0.32336423760128497\n",
      "train loss:0.349917098281085\n",
      "train loss:0.3157813268770879\n",
      "train loss:0.3176339116708602\n",
      "train loss:0.32760791250738813\n",
      "train loss:0.30756319517369773\n",
      "train loss:0.27132757099819493\n",
      "train loss:0.2639021671847766\n",
      "train loss:0.3170084369912923\n",
      "train loss:0.2731065872017336\n",
      "train loss:0.27478956681131117\n",
      "train loss:0.34056740134684266\n",
      "train loss:0.33665596965207967\n",
      "train loss:0.34857217079775277\n",
      "train loss:0.3023811269782165\n",
      "train loss:0.32465816872404646\n",
      "train loss:0.27327498494058794\n",
      "train loss:0.32176362338005576\n",
      "train loss:0.2867188469815957\n",
      "train loss:0.31311428881866454\n",
      "train loss:0.438386075158099\n",
      "train loss:0.3022196976051505\n",
      "train loss:0.4028848878544809\n",
      "train loss:0.34517266236762006\n",
      "train loss:0.2616644402838329\n",
      "train loss:0.30770931674616475\n",
      "train loss:0.34937087708186765\n",
      "train loss:0.3129313637886657\n",
      "train loss:0.2938721550318261\n",
      "train loss:0.2775846279148633\n",
      "train loss:0.31703279845563337\n",
      "train loss:0.3422504610687269\n",
      "train loss:0.30837872132169475\n",
      "train loss:0.26010173370921147\n",
      "train loss:0.2683737064481313\n",
      "train loss:0.33237856106589175\n",
      "train loss:0.32462822467120217\n",
      "train loss:0.2542171789890534\n",
      "train loss:0.28266063615841713\n",
      "train loss:0.26019560327719615\n",
      "train loss:0.31880717478570025\n",
      "train loss:0.32553264012261507\n",
      "train loss:0.3013025253237715\n",
      "train loss:0.3294061988742269\n",
      "train loss:0.3381950870962233\n",
      "train loss:0.29224727594258587\n",
      "train loss:0.34147486581959435\n",
      "train loss:0.330445106122356\n",
      "train loss:0.26846975514730514\n",
      "train loss:0.3002225427725236\n",
      "train loss:0.35493324484970784\n",
      "train loss:0.3062069911563938\n",
      "train loss:0.3305483387216292\n",
      "train loss:0.38415540777744045\n",
      "train loss:0.28675964676814636\n",
      "train loss:0.30365454089026517\n",
      "train loss:0.29067943460892265\n",
      "train loss:0.3395934013151423\n",
      "train loss:0.32722101824080646\n",
      "train loss:0.28343970279233954\n",
      "train loss:0.2584635911997999\n",
      "train loss:0.3129928049341365\n",
      "train loss:0.3536403949949309\n",
      "train loss:0.3117438856228894\n",
      "train loss:0.30927807396289886\n",
      "train loss:0.30091981313180705\n",
      "train loss:0.3806809688247275\n",
      "train loss:0.2912855579915847\n",
      "train loss:0.3541402957088398\n",
      "train loss:0.252160583165375\n",
      "train loss:0.26947244974294926\n",
      "train loss:0.32007640134950766\n",
      "train loss:0.3169727486975766\n",
      "train loss:0.3232190822448289\n",
      "train loss:0.22712648730724108\n",
      "train loss:0.2630800610291197\n",
      "train loss:0.25201456281138135\n",
      "train loss:0.3719091181801579\n",
      "train loss:0.353307713895996\n",
      "train loss:0.2858205215345798\n",
      "train loss:0.3264548622072397\n",
      "train loss:0.38599228202683983\n",
      "train loss:0.23994715217115886\n",
      "train loss:0.32261009457813544\n",
      "train loss:0.326939389102065\n",
      "train loss:0.2997823735906307\n",
      "train loss:0.3071126060190448\n",
      "train loss:0.37872087323398534\n",
      "train loss:0.3812466236562839\n",
      "train loss:0.32364413433176914\n",
      "train loss:0.2856401822589933\n",
      "train loss:0.29141097251978537\n",
      "train loss:0.36367811285861634\n",
      "train loss:0.23065551537352888\n",
      "train loss:0.34221146303010086\n",
      "train loss:0.2910661357981071\n",
      "train loss:0.3286265081224035\n",
      "train loss:0.36535419768691024\n",
      "train loss:0.3633524653123021\n",
      "train loss:0.4388325360986485\n",
      "train loss:0.35293520397329453\n",
      "train loss:0.34065954115695174\n",
      "train loss:0.2595608455226402\n",
      "train loss:0.2492386118160609\n",
      "train loss:0.2262508604710351\n",
      "train loss:0.29370848542380906\n",
      "train loss:0.3254606597481858\n",
      "train loss:0.26279566226913575\n",
      "train loss:0.36801918802250444\n",
      "train loss:0.3290715328395462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.28992928880115953\n",
      "train loss:0.2501406266484708\n",
      "train loss:0.3731283335314064\n",
      "train loss:0.30197822614615727\n",
      "train loss:0.30022504672769884\n",
      "train loss:0.32697969183622533\n",
      "train loss:0.3378911154735943\n",
      "train loss:0.3190241956186274\n",
      "train loss:0.3053900535660512\n",
      "train loss:0.24582423012886553\n",
      "train loss:0.26595351825339913\n",
      "train loss:0.32417967695120437\n",
      "train loss:0.31469982423183146\n",
      "train loss:0.3076214661556602\n",
      "train loss:0.3926342093780069\n",
      "train loss:0.375266641675994\n",
      "train loss:0.3311526534784355\n",
      "train loss:0.3022324006764761\n",
      "train loss:0.33225438271639807\n",
      "train loss:0.36640101952467563\n",
      "train loss:0.27365738480678165\n",
      "train loss:0.3222025527969524\n",
      "train loss:0.24206928050279866\n",
      "train loss:0.2582772769494613\n",
      "train loss:0.30227866468508646\n",
      "train loss:0.31564934799615385\n",
      "train loss:0.29182484358321353\n",
      "train loss:0.32464455072047166\n",
      "train loss:0.2659084387164148\n",
      "train loss:0.3291901350778542\n",
      "train loss:0.3585085272815867\n",
      "train loss:0.3962729896829142\n",
      "train loss:0.30278027036169014\n",
      "train loss:0.3553488326919459\n",
      "train loss:0.29245218002228895\n",
      "train loss:0.3423155641401561\n",
      "train loss:0.26815770338037637\n",
      "train loss:0.2684872536867987\n",
      "train loss:0.2708977251854266\n",
      "train loss:0.3339287224066418\n",
      "train loss:0.32369931795581347\n",
      "train loss:0.34165144738874564\n",
      "train loss:0.37996168131993335\n",
      "train loss:0.343799849009444\n",
      "train loss:0.34404454670211526\n",
      "train loss:0.3786058063551897\n",
      "train loss:0.3553470926701267\n",
      "train loss:0.33683288993060095\n",
      "train loss:0.3441216434758144\n",
      "train loss:0.31579729442022647\n",
      "train loss:0.30070707479493325\n",
      "train loss:0.36994192055280795\n",
      "train loss:0.30483722785935385\n",
      "train loss:0.29808784999897403\n",
      "train loss:0.28208046211821425\n",
      "train loss:0.26317924599199144\n",
      "train loss:0.33500651025677314\n",
      "train loss:0.30454910869316654\n",
      "train loss:0.28224691414333586\n",
      "train loss:0.27882380352804254\n",
      "train loss:0.28668357404882644\n",
      "train loss:0.3135512328180885\n",
      "train loss:0.3236754856986335\n",
      "train loss:0.28427069900489965\n",
      "train loss:0.29770432841260625\n",
      "train loss:0.3324517793401333\n",
      "train loss:0.29818629636670424\n",
      "train loss:0.3581778185033137\n",
      "train loss:0.2995371779812853\n",
      "train loss:0.28142951550881357\n",
      "train loss:0.3007269534061047\n",
      "train loss:0.3596561785369922\n",
      "train loss:0.3454968183910407\n",
      "train loss:0.24669824658876266\n",
      "train loss:0.24756285121038749\n",
      "train loss:0.3696234083568102\n",
      "train loss:0.27754704344403514\n",
      "train loss:0.35208105323846606\n",
      "train loss:0.31705668756830807\n",
      "train loss:0.3260133962910666\n",
      "train loss:0.3304440375335088\n",
      "train loss:0.27079966290716706\n",
      "train loss:0.2901773700734578\n",
      "train loss:0.35756729537331894\n",
      "train loss:0.3474211827316386\n",
      "train loss:0.3884525116196051\n",
      "train loss:0.3602028633694355\n",
      "train loss:0.31193382816881265\n",
      "train loss:0.34832765379556196\n",
      "train loss:0.2650670895289623\n",
      "train loss:0.3568553249183368\n",
      "train loss:0.330301842577392\n",
      "train loss:0.32220661976132176\n",
      "train loss:0.3270556372113262\n",
      "train loss:0.35014412838976827\n",
      "train loss:0.37257084370152993\n",
      "train loss:0.37271137187739384\n",
      "train loss:0.30260916850064784\n",
      "train loss:0.31706041772428756\n",
      "train loss:0.30777578313100307\n",
      "train loss:0.34764480354008404\n",
      "train loss:0.3138281684973791\n",
      "train loss:0.2973186265745207\n",
      "train loss:0.3391146885077519\n",
      "train loss:0.32660988867293717\n",
      "train loss:0.3278192878427478\n",
      "train loss:0.31025723578364267\n",
      "train loss:0.2829896379270261\n",
      "train loss:0.3259955381928473\n",
      "train loss:0.3195682014849621\n",
      "train loss:0.32553569126620474\n",
      "train loss:0.24100869978627026\n",
      "train loss:0.2967485205013001\n",
      "train loss:0.32663027598195654\n",
      "train loss:0.35340774873862063\n",
      "train loss:0.31094356844626947\n",
      "train loss:0.3284886412538076\n",
      "train loss:0.33706995134533624\n",
      "train loss:0.3188298276315953\n",
      "train loss:0.29716950202032927\n",
      "train loss:0.3487565842900256\n",
      "train loss:0.2997675863230362\n",
      "train loss:0.28929481695788345\n",
      "train loss:0.32854639078486475\n",
      "train loss:0.3087179205705228\n",
      "train loss:0.29909575339398725\n",
      "train loss:0.3694800758955354\n",
      "train loss:0.26896783764681137\n",
      "train loss:0.27161652811373016\n",
      "train loss:0.3815233745211321\n",
      "train loss:0.3857681504682015\n",
      "train loss:0.3343915207434142\n",
      "train loss:0.34399356447683965\n",
      "train loss:0.3683908375626496\n",
      "train loss:0.30027216246365757\n",
      "train loss:0.30516865181314257\n",
      "train loss:0.3749525507551572\n",
      "train loss:0.34893122154880735\n",
      "train loss:0.30595168622924157\n",
      "train loss:0.3247260157431545\n",
      "train loss:0.2591376921416268\n",
      "train loss:0.28635453965576907\n",
      "train loss:0.30800258187979507\n",
      "train loss:0.3085539334758806\n",
      "train loss:0.38024469743108763\n",
      "train loss:0.33613398744519796\n",
      "train loss:0.3589564066506352\n",
      "train loss:0.39944160064315487\n",
      "train loss:0.3247192295354381\n",
      "train loss:0.30101680594951324\n",
      "train loss:0.2866247499852719\n",
      "train loss:0.26880477267006486\n",
      "train loss:0.3208717249570878\n",
      "train loss:0.37962429733641206\n",
      "train loss:0.27497659795143786\n",
      "train loss:0.31341525944284643\n",
      "train loss:0.30848983823974796\n",
      "train loss:0.34223097800655083\n",
      "train loss:0.35170813715496985\n",
      "train loss:0.4029551068356829\n",
      "train loss:0.36412186158029053\n",
      "train loss:0.28282567028631705\n",
      "train loss:0.31335519190095873\n",
      "train loss:0.34915643464087215\n",
      "train loss:0.2592137266623328\n",
      "train loss:0.3285312334910243\n",
      "train loss:0.370138789480688\n",
      "train loss:0.3670551621017703\n",
      "train loss:0.35695066856081775\n",
      "train loss:0.3194748679442244\n",
      "train loss:0.28898616975357455\n",
      "train loss:0.3356419104160538\n",
      "train loss:0.28233140052643946\n",
      "train loss:0.27966208095757766\n",
      "train loss:0.35259779926252055\n",
      "train loss:0.3118812964139307\n",
      "train loss:0.38131045081459813\n",
      "train loss:0.3291650931017536\n",
      "train loss:0.2537082567760621\n",
      "train loss:0.35223531238791833\n",
      "train loss:0.36102084997542444\n",
      "train loss:0.3499997540331556\n",
      "=== epoch:11, train acc:0.997, test acc:0.998 ===\n",
      "train loss:0.3626090802625754\n",
      "train loss:0.33041120362830134\n",
      "train loss:0.30515660389217925\n",
      "train loss:0.3060041179615821\n",
      "train loss:0.28734655454937\n",
      "train loss:0.36145302998535567\n",
      "train loss:0.2702494961329375\n",
      "train loss:0.2675781301958397\n",
      "train loss:0.3293764324113708\n",
      "train loss:0.313351922325302\n",
      "train loss:0.30570746390817455\n",
      "train loss:0.27533584186485105\n",
      "train loss:0.3240883129326183\n",
      "train loss:0.3170108766370936\n",
      "train loss:0.3975717053834991\n",
      "train loss:0.3127861213573612\n",
      "train loss:0.30138820558093504\n",
      "train loss:0.3091730588261118\n",
      "train loss:0.3699657676066837\n",
      "train loss:0.29450203038719514\n",
      "train loss:0.32074490444262566\n",
      "train loss:0.3283211699508096\n",
      "train loss:0.29506463981289244\n",
      "train loss:0.2951985712332268\n",
      "train loss:0.301972841276339\n",
      "train loss:0.25962135585714563\n",
      "train loss:0.33578865044955275\n",
      "train loss:0.30958883119056574\n",
      "train loss:0.2500370545855474\n",
      "train loss:0.30743424708581063\n",
      "train loss:0.30913505303476946\n",
      "train loss:0.31738647639857187\n",
      "train loss:0.26227093392820533\n",
      "train loss:0.2892989827488101\n",
      "train loss:0.38199716532537487\n",
      "train loss:0.31477676248212844\n",
      "train loss:0.2762328743867463\n",
      "train loss:0.33537490000638814\n",
      "train loss:0.35774080969723615\n",
      "train loss:0.28146589772553887\n",
      "train loss:0.2534100187576927\n",
      "train loss:0.31537763342955394\n",
      "train loss:0.3130272799455646\n",
      "train loss:0.27322037514009434\n",
      "train loss:0.29427088113100447\n",
      "train loss:0.33249124857609486\n",
      "train loss:0.26583551038633935\n",
      "train loss:0.2930048083326177\n",
      "train loss:0.3149049040042471\n",
      "train loss:0.2967483315623482\n",
      "train loss:0.3410370308110392\n",
      "train loss:0.2800874534470445\n",
      "train loss:0.2557411187014892\n",
      "train loss:0.31210747320252685\n",
      "train loss:0.3554493338058614\n",
      "train loss:0.26823681525411885\n",
      "train loss:0.35660537758783595\n",
      "train loss:0.31064908013410986\n",
      "train loss:0.33587107725637005\n",
      "train loss:0.2846426769826184\n",
      "train loss:0.3128294887314869\n",
      "train loss:0.2915186302978923\n",
      "train loss:0.33761913076099376\n",
      "train loss:0.33282675890543817\n",
      "train loss:0.3117681420197773\n",
      "train loss:0.3574227924730032\n",
      "train loss:0.30125813981143434\n",
      "train loss:0.3581128119524651\n",
      "train loss:0.35486613428610203\n",
      "train loss:0.31304229260325594\n",
      "train loss:0.3198324598331388\n",
      "train loss:0.3388083529859542\n",
      "train loss:0.3039342717562326\n",
      "train loss:0.348739568267758\n",
      "train loss:0.25589541504247293\n",
      "train loss:0.30059324310712754\n",
      "train loss:0.33678367080379085\n",
      "train loss:0.36336868630491753\n",
      "train loss:0.30095393447930185\n",
      "train loss:0.29152452350230246\n",
      "train loss:0.3205977086608956\n",
      "train loss:0.3155482799758674\n",
      "train loss:0.28416155709598445\n",
      "train loss:0.30974365652935526\n",
      "train loss:0.3285628459675499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.25328836354300316\n",
      "train loss:0.3245995753222663\n",
      "train loss:0.3231056054915413\n",
      "train loss:0.40696748451268383\n",
      "train loss:0.3758908083642435\n",
      "train loss:0.3471617099082606\n",
      "train loss:0.3222080708462247\n",
      "train loss:0.3067149817469662\n",
      "train loss:0.2749053348849536\n",
      "train loss:0.29330082297787263\n",
      "train loss:0.30296163520163594\n",
      "train loss:0.28818813462730286\n",
      "train loss:0.31585241100994155\n",
      "train loss:0.3173779530133327\n",
      "train loss:0.3704183561914064\n",
      "train loss:0.2440270774815167\n",
      "train loss:0.2842345575764081\n",
      "train loss:0.3602667374704396\n",
      "train loss:0.3762673437046915\n",
      "train loss:0.43190274839096693\n",
      "train loss:0.31435329316902677\n",
      "train loss:0.3160679498550942\n",
      "train loss:0.3197979479537954\n",
      "train loss:0.2721382104542978\n",
      "train loss:0.34321974709060155\n",
      "train loss:0.29512008167999837\n",
      "train loss:0.3279455431589752\n",
      "train loss:0.3632183912750782\n",
      "train loss:0.3107296655509818\n",
      "train loss:0.2641664222980227\n",
      "train loss:0.3809223339730938\n",
      "train loss:0.3066999398950196\n",
      "train loss:0.353079340301466\n",
      "train loss:0.3092687191496007\n",
      "train loss:0.23670517699516944\n",
      "train loss:0.34092084900270253\n",
      "train loss:0.2726193003131803\n",
      "train loss:0.3105127429160786\n",
      "train loss:0.2784677874676971\n",
      "train loss:0.31580131882552265\n",
      "train loss:0.3785536844402184\n",
      "train loss:0.4042513679788066\n",
      "train loss:0.27524593842345946\n",
      "train loss:0.3417537016896926\n",
      "train loss:0.3811651107070728\n",
      "train loss:0.34363601940378163\n",
      "train loss:0.33604474334703177\n",
      "train loss:0.2802010421598445\n",
      "train loss:0.28298614110637144\n",
      "train loss:0.2632448143377661\n",
      "train loss:0.32316831602879315\n",
      "train loss:0.34340123309593734\n",
      "train loss:0.3506275182672451\n",
      "train loss:0.3065357486644503\n",
      "train loss:0.36170392994808803\n",
      "train loss:0.28791332062472935\n",
      "train loss:0.21040265552585194\n",
      "train loss:0.31883105445225274\n",
      "train loss:0.31943095298456353\n",
      "train loss:0.2832107885936771\n",
      "train loss:0.2830381228068906\n",
      "train loss:0.25190849146170685\n",
      "train loss:0.29909219705691364\n",
      "train loss:0.286021302694971\n",
      "train loss:0.28856178782836245\n",
      "train loss:0.2772940502908848\n",
      "train loss:0.26164641972435854\n",
      "train loss:0.2607380347228842\n",
      "train loss:0.33249184194587955\n",
      "train loss:0.31099218498808906\n",
      "train loss:0.2895181640341657\n",
      "train loss:0.275068810634738\n",
      "train loss:0.3089724527031603\n",
      "train loss:0.305173763239747\n",
      "train loss:0.3098057268462348\n",
      "train loss:0.27259395566650124\n",
      "train loss:0.2838687557430343\n",
      "train loss:0.34689088202681795\n",
      "train loss:0.3812457037916691\n",
      "train loss:0.3072877498457119\n",
      "train loss:0.33457274119312624\n",
      "train loss:0.2750973028361238\n",
      "train loss:0.3352830296339885\n",
      "train loss:0.38020096453329233\n",
      "train loss:0.36299726065605736\n",
      "train loss:0.312297358285629\n",
      "train loss:0.332620503102313\n",
      "train loss:0.34159913559823185\n",
      "train loss:0.30041340229188235\n",
      "train loss:0.29336094224535963\n",
      "train loss:0.31575851750372086\n",
      "train loss:0.29174554093072963\n",
      "train loss:0.2603013474792667\n",
      "train loss:0.295697210330006\n",
      "train loss:0.3266258593177502\n",
      "train loss:0.30251285492590535\n",
      "train loss:0.2809294966450741\n",
      "train loss:0.3486504765405319\n",
      "train loss:0.27107418833957037\n",
      "train loss:0.27878066404218804\n",
      "train loss:0.3113174273678097\n",
      "train loss:0.28560118647533794\n",
      "train loss:0.342903068952453\n",
      "train loss:0.32421980891224594\n",
      "train loss:0.3484190685796452\n",
      "train loss:0.30786631569110434\n",
      "train loss:0.3116100678745898\n",
      "train loss:0.36610576758379587\n",
      "train loss:0.31251784010107386\n",
      "train loss:0.3064454360316041\n",
      "train loss:0.3374410749517446\n",
      "train loss:0.28270213549021606\n",
      "train loss:0.35106899526620955\n",
      "train loss:0.2962530076083591\n",
      "train loss:0.3387114178398145\n",
      "train loss:0.298648050779659\n",
      "train loss:0.2647795409701563\n",
      "train loss:0.34797558436433057\n",
      "train loss:0.27292867857587866\n",
      "train loss:0.3211636224548656\n",
      "train loss:0.34841544472377123\n",
      "train loss:0.31182293142878365\n",
      "train loss:0.37588719254281694\n",
      "train loss:0.36253434016456804\n",
      "train loss:0.3452362827017555\n",
      "train loss:0.2364897311283012\n",
      "train loss:0.30137597198030625\n",
      "train loss:0.2997791992001917\n",
      "train loss:0.3427187916665501\n",
      "train loss:0.3349231439837887\n",
      "train loss:0.3287371395752727\n",
      "train loss:0.3042866114395211\n",
      "train loss:0.3535166408749849\n",
      "train loss:0.4002849623993804\n",
      "train loss:0.34226442890074077\n",
      "train loss:0.306120860338797\n",
      "train loss:0.2729025331879196\n",
      "train loss:0.32488838456562924\n",
      "train loss:0.33631717215254825\n",
      "train loss:0.3805367137300609\n",
      "train loss:0.3541703548798369\n",
      "train loss:0.34757834979355345\n",
      "train loss:0.31489477038011154\n",
      "train loss:0.36867472813782914\n",
      "train loss:0.2890856811915545\n",
      "train loss:0.2870178854500684\n",
      "train loss:0.38122440203689706\n",
      "train loss:0.33733481696574447\n",
      "train loss:0.31426911678120373\n",
      "train loss:0.30610271727309396\n",
      "train loss:0.36820707831025934\n",
      "train loss:0.3822389902194132\n",
      "train loss:0.3441173083673775\n",
      "train loss:0.2897650849759236\n",
      "train loss:0.3006014248543784\n",
      "train loss:0.3445406473093558\n",
      "train loss:0.39286760894055933\n",
      "train loss:0.36592168021129673\n",
      "train loss:0.36235447324764064\n",
      "train loss:0.3395107236802112\n",
      "train loss:0.2571069927333218\n",
      "train loss:0.35829881655878176\n",
      "train loss:0.33883387702878653\n",
      "train loss:0.38590815599396877\n",
      "train loss:0.32994007653544827\n",
      "train loss:0.29328848756010106\n",
      "train loss:0.3153354451130854\n",
      "train loss:0.3747509296926696\n",
      "train loss:0.24139271336430898\n",
      "train loss:0.3057978327715882\n",
      "train loss:0.3242998880340871\n",
      "train loss:0.35019233597536203\n",
      "train loss:0.2565277816187624\n",
      "train loss:0.35505310616864383\n",
      "train loss:0.32523436409085094\n",
      "train loss:0.3181514595553265\n",
      "train loss:0.3057761046808199\n",
      "train loss:0.3246382270449453\n",
      "train loss:0.2334558785131326\n",
      "train loss:0.3147554748174061\n",
      "train loss:0.307686831553302\n",
      "train loss:0.4097606409847832\n",
      "train loss:0.2988533312524511\n",
      "train loss:0.2878491949389405\n",
      "train loss:0.28041248925624\n",
      "train loss:0.3014814056939978\n",
      "train loss:0.3003599565307788\n",
      "train loss:0.2852177049245244\n",
      "train loss:0.3570533412131722\n",
      "train loss:0.29433599990848397\n",
      "train loss:0.27609510656945474\n",
      "train loss:0.31647344506471864\n",
      "train loss:0.2831549422772584\n",
      "train loss:0.3353643277691223\n",
      "train loss:0.35952067077168454\n",
      "train loss:0.29306626343451825\n",
      "train loss:0.2935474519113233\n",
      "train loss:0.2785158551529308\n",
      "train loss:0.35420415143378214\n",
      "train loss:0.31325908972132005\n",
      "train loss:0.3228278847310617\n",
      "train loss:0.31819782462153123\n",
      "train loss:0.3325404015657777\n",
      "train loss:0.32564062564147883\n",
      "train loss:0.2788319534103713\n",
      "train loss:0.32825613289793526\n",
      "train loss:0.32310217834636223\n",
      "train loss:0.3414674473328307\n",
      "train loss:0.2832484247644634\n",
      "train loss:0.20442863907105335\n",
      "train loss:0.3006932589051155\n",
      "train loss:0.34179685673804083\n",
      "train loss:0.33581845033861296\n",
      "train loss:0.2570458493788071\n",
      "train loss:0.27689590434554157\n",
      "train loss:0.28976092734875664\n",
      "train loss:0.29848652983505325\n",
      "train loss:0.357610412207089\n",
      "train loss:0.3424845109321556\n",
      "train loss:0.30232003265001\n",
      "train loss:0.28088358953683484\n",
      "train loss:0.2811181399563802\n",
      "train loss:0.3008971117259049\n",
      "train loss:0.2897203309047827\n",
      "train loss:0.2489130795913385\n",
      "train loss:0.3392849400025942\n",
      "train loss:0.2628012581984936\n",
      "train loss:0.28445276224237676\n",
      "train loss:0.3059763623079546\n",
      "train loss:0.32752072636626844\n",
      "train loss:0.3192093550173748\n",
      "train loss:0.27991632373049274\n",
      "train loss:0.3940019164151811\n",
      "train loss:0.31680083851080404\n",
      "train loss:0.33228156324027913\n",
      "train loss:0.3429051777677967\n",
      "train loss:0.3281120273159776\n",
      "train loss:0.2657887413198935\n",
      "train loss:0.2807901296291893\n",
      "train loss:0.30159592715627903\n",
      "train loss:0.2913228587468569\n",
      "train loss:0.30430261419828486\n",
      "train loss:0.26502468292223624\n",
      "train loss:0.3015569066252012\n",
      "train loss:0.3357843645353574\n",
      "train loss:0.27656360475904873\n",
      "train loss:0.23440537632648445\n",
      "train loss:0.35366097378358397\n",
      "train loss:0.26355260650175416\n",
      "train loss:0.2899503255813179\n",
      "train loss:0.2560460781156005\n",
      "train loss:0.2873118139787277\n",
      "train loss:0.3894829677503445\n",
      "train loss:0.3304405220336325\n",
      "train loss:0.27656597268133926\n",
      "train loss:0.2649772073493218\n",
      "train loss:0.3372028884220537\n",
      "train loss:0.27958407355216397\n",
      "train loss:0.33550789162712097\n",
      "train loss:0.3234014933116178\n",
      "train loss:0.3101213205390376\n",
      "train loss:0.29276494122413327\n",
      "train loss:0.2793029384765393\n",
      "train loss:0.32345443851456834\n",
      "train loss:0.29778710251899226\n",
      "train loss:0.28602016595832025\n",
      "train loss:0.3690668723942263\n",
      "train loss:0.35538359067971487\n",
      "train loss:0.3727903754499241\n",
      "train loss:0.31576151614671605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.20898290723552887\n",
      "train loss:0.3156437930855843\n",
      "train loss:0.27378139634391824\n",
      "train loss:0.2818482734504915\n",
      "train loss:0.2985799184420768\n",
      "train loss:0.30039346930434685\n",
      "train loss:0.3098090804438349\n",
      "train loss:0.26860594375764574\n",
      "train loss:0.3165953628188481\n",
      "train loss:0.3180326321391705\n",
      "train loss:0.3169413490343415\n",
      "train loss:0.32435227285846635\n",
      "train loss:0.2751142112506985\n",
      "=== epoch:12, train acc:0.999, test acc:1.0 ===\n",
      "train loss:0.27006230574850554\n",
      "train loss:0.3094815628710766\n",
      "train loss:0.3375375748630761\n",
      "train loss:0.3392580971378997\n",
      "train loss:0.26577569260409295\n",
      "train loss:0.27003555820012487\n",
      "train loss:0.33799621448450584\n",
      "train loss:0.33211741391270844\n",
      "train loss:0.3532006698799303\n",
      "train loss:0.3216889321814795\n",
      "train loss:0.32342289345543956\n",
      "train loss:0.287923138590805\n",
      "train loss:0.2881261843492486\n",
      "train loss:0.39436892778754046\n",
      "train loss:0.3249749684941058\n",
      "train loss:0.3657110088407413\n",
      "train loss:0.2925225761989387\n",
      "train loss:0.3220495937998991\n",
      "train loss:0.3135530406404882\n",
      "train loss:0.3119080483825442\n",
      "train loss:0.2681851170676702\n",
      "train loss:0.2951621209362429\n",
      "train loss:0.33193635328935484\n",
      "train loss:0.2727830279968096\n",
      "train loss:0.2885765237814499\n",
      "train loss:0.29222111330173406\n",
      "train loss:0.2829793618387224\n",
      "train loss:0.3120821536302847\n",
      "train loss:0.30829182664860466\n",
      "train loss:0.3425153627783537\n",
      "train loss:0.29100704510356784\n",
      "train loss:0.3184079731688007\n",
      "train loss:0.37059731156266673\n",
      "train loss:0.3661039746439699\n",
      "train loss:0.3230881594973069\n",
      "train loss:0.2893115335993535\n",
      "train loss:0.2939672761774801\n",
      "train loss:0.2717868485219058\n",
      "train loss:0.34225023133802224\n",
      "train loss:0.3540865760608709\n",
      "train loss:0.3155907350083596\n",
      "train loss:0.3390781840335468\n",
      "train loss:0.3710315175930825\n",
      "train loss:0.34741506412858586\n",
      "train loss:0.34254461145571397\n",
      "train loss:0.24439212797385904\n",
      "train loss:0.3166325072922532\n",
      "train loss:0.3126035854447557\n",
      "train loss:0.27172315927998636\n",
      "train loss:0.3511706043498565\n",
      "train loss:0.3930135536861304\n",
      "train loss:0.3110070815376436\n",
      "train loss:0.3081235902861579\n",
      "train loss:0.26302941920349626\n",
      "train loss:0.35935612289875096\n",
      "train loss:0.3083827834982602\n",
      "train loss:0.2863171179976222\n",
      "train loss:0.3648815289767961\n",
      "train loss:0.3136982599555777\n",
      "train loss:0.28519020143431906\n",
      "train loss:0.24717483720259187\n",
      "train loss:0.3226646296088935\n",
      "train loss:0.30583003050747404\n",
      "train loss:0.29428967250582666\n",
      "train loss:0.3243662079696804\n",
      "train loss:0.33164912938219293\n",
      "train loss:0.39826987334027564\n",
      "train loss:0.3516363052600804\n",
      "train loss:0.2997847184527181\n",
      "train loss:0.35312388183873916\n",
      "train loss:0.33782054142899126\n",
      "train loss:0.3449876849928607\n",
      "train loss:0.33883126096631777\n",
      "train loss:0.4085952677362073\n",
      "train loss:0.3736481656230483\n",
      "train loss:0.3308046433296908\n",
      "train loss:0.36262585545374687\n",
      "train loss:0.3323740875705828\n",
      "train loss:0.34839462175347863\n",
      "train loss:0.206114763283215\n",
      "train loss:0.23127226122287575\n",
      "train loss:0.3186357014934896\n",
      "train loss:0.2743777794233552\n",
      "train loss:0.27634124918804787\n",
      "train loss:0.33654219331295226\n",
      "train loss:0.26431427340154046\n",
      "train loss:0.2683517085361556\n",
      "train loss:0.3163125945762227\n",
      "train loss:0.29129465386121184\n",
      "train loss:0.29118129014701216\n",
      "train loss:0.2837218958150301\n",
      "train loss:0.31413429129496584\n",
      "train loss:0.31955147211537643\n",
      "train loss:0.21529139426186486\n",
      "train loss:0.3926312511773444\n",
      "train loss:0.30598472071470617\n",
      "train loss:0.252138357764789\n",
      "train loss:0.3057236422238937\n",
      "train loss:0.2917813090339776\n",
      "train loss:0.32075737542802496\n",
      "train loss:0.28092941772053936\n",
      "train loss:0.3815690221956079\n",
      "train loss:0.3618486201161934\n",
      "train loss:0.2834062458347109\n",
      "train loss:0.27875079519580626\n",
      "train loss:0.2823661229001792\n",
      "train loss:0.30113731994227944\n",
      "train loss:0.2571864980859775\n",
      "train loss:0.3141103251779758\n",
      "train loss:0.3471454107518552\n",
      "train loss:0.297203395059181\n",
      "train loss:0.32941557773558916\n",
      "train loss:0.3692897021237152\n",
      "train loss:0.30261623853179315\n",
      "train loss:0.29714842764399346\n",
      "train loss:0.32431714461953226\n",
      "train loss:0.2658007979232988\n",
      "train loss:0.35060969369444006\n",
      "train loss:0.32348376577513477\n",
      "train loss:0.2972803947845371\n",
      "train loss:0.30877029173465115\n",
      "train loss:0.33440851007279043\n",
      "train loss:0.263448790159355\n",
      "train loss:0.34758172547014854\n",
      "train loss:0.2694572447184929\n",
      "train loss:0.36716959836147584\n",
      "train loss:0.2920808763143576\n",
      "train loss:0.32284836264562494\n",
      "train loss:0.28228244851754847\n",
      "train loss:0.28648840975728146\n",
      "train loss:0.29605221822546995\n",
      "train loss:0.3029910575043552\n",
      "train loss:0.32019889572003696\n",
      "train loss:0.2712686034312772\n",
      "train loss:0.39225464535393856\n",
      "train loss:0.3230758635456607\n",
      "train loss:0.3154184303887027\n",
      "train loss:0.26247308060755015\n",
      "train loss:0.2882872214263979\n",
      "train loss:0.28098454319251726\n",
      "train loss:0.35449176608115757\n",
      "train loss:0.25568435500999936\n",
      "train loss:0.3547762428647269\n",
      "train loss:0.3590889536618848\n",
      "train loss:0.296433034122849\n",
      "train loss:0.20247716930200693\n",
      "train loss:0.2911909766150093\n",
      "train loss:0.3136756155534451\n",
      "train loss:0.343211800448519\n",
      "train loss:0.3127828751051779\n",
      "train loss:0.2865252809284605\n",
      "train loss:0.36092835685216756\n",
      "train loss:0.35228637826121495\n",
      "train loss:0.38781314418672286\n",
      "train loss:0.3924429271172401\n",
      "train loss:0.26017924558112004\n",
      "train loss:0.35661151561199056\n",
      "train loss:0.25967424123701977\n",
      "train loss:0.3047157641196848\n",
      "train loss:0.37052472021081984\n",
      "train loss:0.2757150397022334\n",
      "train loss:0.3107023571276433\n",
      "train loss:0.25947578175959135\n",
      "train loss:0.32412494193260294\n",
      "train loss:0.3381179699364009\n",
      "train loss:0.2925267720249902\n",
      "train loss:0.3623180270672842\n",
      "train loss:0.3145699289263305\n",
      "train loss:0.34109508609854206\n",
      "train loss:0.32879496276689574\n",
      "train loss:0.31250707135673594\n",
      "train loss:0.31949685287201796\n",
      "train loss:0.3626163079761315\n",
      "train loss:0.2746231343443389\n",
      "train loss:0.28342341656996617\n",
      "train loss:0.4058087941643755\n",
      "train loss:0.35757068127143454\n",
      "train loss:0.2418806678873331\n",
      "train loss:0.3287663800435782\n",
      "train loss:0.3554346203184009\n",
      "train loss:0.3440566610657823\n",
      "train loss:0.2703196423086606\n",
      "train loss:0.27926826883419387\n",
      "train loss:0.2900194540227676\n",
      "train loss:0.3124724832177719\n",
      "train loss:0.3378813967476899\n",
      "train loss:0.36651573423587996\n",
      "train loss:0.3198772806080764\n",
      "train loss:0.4649675879361967\n",
      "train loss:0.375661950957298\n",
      "train loss:0.32934739118302353\n",
      "train loss:0.24599474013029507\n",
      "train loss:0.23568916720109961\n",
      "train loss:0.31669029234724155\n",
      "train loss:0.34684919504028217\n",
      "train loss:0.3176147209224272\n",
      "train loss:0.2804063502827688\n",
      "train loss:0.27968878932848756\n",
      "train loss:0.27638924009050925\n",
      "train loss:0.3738277988078966\n",
      "train loss:0.3117707597909585\n",
      "train loss:0.29614675807195284\n",
      "train loss:0.29522774052236644\n",
      "train loss:0.2659989072482647\n",
      "train loss:0.26852842363841756\n",
      "train loss:0.3066348094934352\n",
      "train loss:0.30131502852159264\n",
      "train loss:0.2770069324617558\n",
      "train loss:0.26680525568939845\n",
      "train loss:0.3236725919048773\n",
      "train loss:0.28257562132446346\n",
      "train loss:0.2839232052983723\n",
      "train loss:0.3023740050990914\n",
      "train loss:0.3123966009550979\n",
      "train loss:0.2968718748589118\n",
      "train loss:0.31896803114993316\n",
      "train loss:0.3265848809075654\n",
      "train loss:0.28200226504801357\n",
      "train loss:0.2837961822374287\n",
      "train loss:0.4199527358118579\n",
      "train loss:0.34964524744793196\n",
      "train loss:0.2736623884158303\n",
      "train loss:0.2959264845482096\n",
      "train loss:0.3290281800384707\n",
      "train loss:0.3261977792093941\n",
      "train loss:0.2672294689513048\n",
      "train loss:0.3323959603958932\n",
      "train loss:0.30213527952552494\n",
      "train loss:0.30186154762839196\n",
      "train loss:0.30246027208746246\n",
      "train loss:0.38317063622370706\n",
      "train loss:0.3123729621715674\n",
      "train loss:0.3814000509985697\n",
      "train loss:0.2750300781868452\n",
      "train loss:0.3028038944195975\n",
      "train loss:0.333120402055292\n",
      "train loss:0.35692752571894004\n",
      "train loss:0.29816423319588525\n",
      "train loss:0.29199388573408674\n",
      "train loss:0.34523338423763844\n",
      "train loss:0.3701176712568034\n",
      "train loss:0.34084796966894887\n",
      "train loss:0.22724239423754994\n",
      "train loss:0.31462026911473473\n",
      "train loss:0.331561558034677\n",
      "train loss:0.27402770045159985\n",
      "train loss:0.38596691036360664\n",
      "train loss:0.22829030935990932\n",
      "train loss:0.25612684248877465\n",
      "train loss:0.3119839768097557\n",
      "train loss:0.31238969798005767\n",
      "train loss:0.2971919505289805\n",
      "train loss:0.35848215301987824\n",
      "train loss:0.3469650168506089\n",
      "train loss:0.3515100780209855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3111886698519835\n",
      "train loss:0.32992674232840097\n",
      "train loss:0.288362463821476\n",
      "train loss:0.2951785420317037\n",
      "train loss:0.3560936145662366\n",
      "train loss:0.24312671560940347\n",
      "train loss:0.28767124140783434\n",
      "train loss:0.34999847809401174\n",
      "train loss:0.3335371372977954\n",
      "train loss:0.27631904829391674\n",
      "train loss:0.3371125162574521\n",
      "train loss:0.31190567798528707\n",
      "train loss:0.34979918474720173\n",
      "train loss:0.34635827747205133\n",
      "train loss:0.2755018077467498\n",
      "train loss:0.26495585000723976\n",
      "train loss:0.30321582795919094\n",
      "train loss:0.22746645036789487\n",
      "train loss:0.3529648045927784\n",
      "train loss:0.3320955723498294\n",
      "train loss:0.3156983519035385\n",
      "train loss:0.26983428754824285\n",
      "train loss:0.30433898618658356\n",
      "train loss:0.34355930289718467\n",
      "train loss:0.36117922768124733\n",
      "train loss:0.3542092522151982\n",
      "train loss:0.29254020337405134\n",
      "train loss:0.35580902034986034\n",
      "train loss:0.2951871244031208\n",
      "train loss:0.3693681417138179\n",
      "train loss:0.30726960033755646\n",
      "train loss:0.25251675426907955\n",
      "train loss:0.3052009984291457\n",
      "train loss:0.322834477494518\n",
      "train loss:0.26626115983134135\n",
      "train loss:0.3807943483638985\n",
      "train loss:0.35261291301503467\n",
      "train loss:0.3210219047647215\n",
      "train loss:0.282925937815016\n",
      "train loss:0.28036871085668774\n",
      "train loss:0.3427829127508231\n",
      "train loss:0.34896239951454366\n",
      "train loss:0.3065688540004898\n",
      "train loss:0.3117010973223449\n",
      "train loss:0.3042190891656379\n",
      "train loss:0.2719502101043994\n",
      "train loss:0.29006370145214805\n",
      "train loss:0.322388952277578\n",
      "train loss:0.35566172322941486\n",
      "train loss:0.3729922337984269\n",
      "train loss:0.4234115249209188\n",
      "train loss:0.39642082815343627\n",
      "train loss:0.259967619518744\n",
      "train loss:0.3115766724211499\n",
      "train loss:0.32504696955720347\n",
      "train loss:0.2871298261891146\n",
      "train loss:0.2993731439169564\n",
      "train loss:0.27428093342090587\n",
      "train loss:0.2939307527607413\n",
      "train loss:0.334530050907687\n",
      "train loss:0.2868490190106408\n",
      "train loss:0.3583540230318936\n",
      "train loss:0.2967928566506475\n",
      "train loss:0.2468404874444424\n",
      "train loss:0.332029132053535\n",
      "train loss:0.28083188338208165\n",
      "train loss:0.22937711961928545\n",
      "train loss:0.362100987128155\n",
      "train loss:0.29017295921039776\n",
      "train loss:0.27937607751092414\n",
      "train loss:0.2859447429765742\n",
      "train loss:0.31293916772744634\n",
      "train loss:0.33996816753473275\n",
      "train loss:0.2918683204957625\n",
      "train loss:0.30077938637239077\n",
      "train loss:0.4768000982031932\n",
      "train loss:0.30616579202789423\n",
      "train loss:0.34355687001172514\n",
      "train loss:0.3477390921413081\n",
      "train loss:0.32319517245004004\n",
      "train loss:0.3112408543962692\n",
      "train loss:0.3545386271019985\n",
      "train loss:0.39089133837643286\n",
      "train loss:0.3574280273487088\n",
      "train loss:0.40565429201401315\n",
      "train loss:0.33961064653118606\n",
      "train loss:0.3183702538689513\n",
      "train loss:0.29860112112391396\n",
      "train loss:0.29200047795312306\n",
      "train loss:0.3101209802576516\n",
      "train loss:0.2415113420361044\n",
      "train loss:0.35752293748851016\n",
      "train loss:0.2612959542760083\n",
      "train loss:0.27859513391969004\n",
      "train loss:0.3204139321185007\n",
      "train loss:0.2986837460779151\n",
      "train loss:0.33655158609138136\n",
      "train loss:0.3651522818759098\n",
      "train loss:0.36041803245232346\n",
      "train loss:0.33677349782786975\n",
      "train loss:0.3290964782391085\n",
      "train loss:0.3205999938174166\n",
      "train loss:0.33105054210609125\n",
      "train loss:0.3310541927910242\n",
      "train loss:0.317595425464634\n",
      "train loss:0.3897041907735526\n",
      "train loss:0.3066382445805985\n",
      "train loss:0.31673712036981494\n",
      "train loss:0.23611099873886968\n",
      "train loss:0.2964106202521209\n",
      "train loss:0.258731380537661\n",
      "train loss:0.31609831979116687\n",
      "train loss:0.28406723312290355\n",
      "=== epoch:13, train acc:1.0, test acc:0.998 ===\n",
      "train loss:0.3049505026017855\n",
      "train loss:0.26700186896674494\n",
      "train loss:0.35664760253918004\n",
      "train loss:0.3187963539972048\n",
      "train loss:0.3902449553598478\n",
      "train loss:0.2770253104002662\n",
      "train loss:0.335176788547558\n",
      "train loss:0.30775750973539384\n",
      "train loss:0.28882333341892086\n",
      "train loss:0.2907063303323438\n",
      "train loss:0.3747585880262824\n",
      "train loss:0.2867448028587473\n",
      "train loss:0.2881573716094099\n",
      "train loss:0.3743652247734389\n",
      "train loss:0.31087417582912774\n",
      "train loss:0.31051621454418676\n",
      "train loss:0.389411852665332\n",
      "train loss:0.2725822434074413\n",
      "train loss:0.29456400387099146\n",
      "train loss:0.27673405699375475\n",
      "train loss:0.41664624099165243\n",
      "train loss:0.301432924842587\n",
      "train loss:0.3225497886600002\n",
      "train loss:0.42739209708990844\n",
      "train loss:0.3046485994723694\n",
      "train loss:0.3340702231302401\n",
      "train loss:0.40706927579096214\n",
      "train loss:0.25108597091061147\n",
      "train loss:0.2931895766047435\n",
      "train loss:0.2493381099907507\n",
      "train loss:0.30202727778954286\n",
      "train loss:0.3030241510410747\n",
      "train loss:0.3555744780498694\n",
      "train loss:0.278313471487864\n",
      "train loss:0.31043299838713345\n",
      "train loss:0.30479153052934127\n",
      "train loss:0.2936006061346786\n",
      "train loss:0.38037531678529296\n",
      "train loss:0.28838439842569147\n",
      "train loss:0.3226232606031012\n",
      "train loss:0.28836532413009236\n",
      "train loss:0.34804014508404996\n",
      "train loss:0.3303975845357661\n",
      "train loss:0.3133917976832333\n",
      "train loss:0.3616604726478074\n",
      "train loss:0.31946802746398634\n",
      "train loss:0.2913885254676476\n",
      "train loss:0.2929585956389133\n",
      "train loss:0.2865082927483505\n",
      "train loss:0.37253055961091813\n",
      "train loss:0.3617919847977281\n",
      "train loss:0.3084177512848534\n",
      "train loss:0.2750344034543808\n",
      "train loss:0.3081576178477932\n",
      "train loss:0.3012235198271355\n",
      "train loss:0.27951306968343553\n",
      "train loss:0.3825176369081428\n",
      "train loss:0.35326324645479146\n",
      "train loss:0.33960389547591835\n",
      "train loss:0.3658799633199082\n",
      "train loss:0.28049691100665136\n",
      "train loss:0.34794417767519675\n",
      "train loss:0.25747176895815344\n",
      "train loss:0.29909972297337384\n",
      "train loss:0.29828959418756423\n",
      "train loss:0.3329165466070462\n",
      "train loss:0.26846850853070225\n",
      "train loss:0.29498482298082146\n",
      "train loss:0.2994121628936941\n",
      "train loss:0.2717709402524791\n",
      "train loss:0.30111536777239206\n",
      "train loss:0.33528667585019595\n",
      "train loss:0.30399427173939186\n",
      "train loss:0.23815922536681847\n",
      "train loss:0.3182171381926539\n",
      "train loss:0.32670670255914963\n",
      "train loss:0.31695299109116964\n",
      "train loss:0.35813308884045675\n",
      "train loss:0.33482423295901864\n",
      "train loss:0.3254918072047674\n",
      "train loss:0.3256922559123062\n",
      "train loss:0.3129166282561258\n",
      "train loss:0.313546413067287\n",
      "train loss:0.2768770296782525\n",
      "train loss:0.34657169603270455\n",
      "train loss:0.35587968362956074\n",
      "train loss:0.3112476831572449\n",
      "train loss:0.3815702396683246\n",
      "train loss:0.2910723020566283\n",
      "train loss:0.41602703014105136\n",
      "train loss:0.3472470018118136\n",
      "train loss:0.3279247459382828\n",
      "train loss:0.41732598470724525\n",
      "train loss:0.32668056870007567\n",
      "train loss:0.32830672062648375\n",
      "train loss:0.32294874303195964\n",
      "train loss:0.3138947162159835\n",
      "train loss:0.354875195651368\n",
      "train loss:0.3497910846652682\n",
      "train loss:0.3124476952413264\n",
      "train loss:0.32803827718520506\n",
      "train loss:0.4245149779117617\n",
      "train loss:0.34654573237858216\n",
      "train loss:0.32293007748769836\n",
      "train loss:0.38449249145620357\n",
      "train loss:0.354740279287266\n",
      "train loss:0.3223754436724175\n",
      "train loss:0.3169958303825962\n",
      "train loss:0.3913533977448189\n",
      "train loss:0.29485748887310614\n",
      "train loss:0.3113791427241439\n",
      "train loss:0.3437350591161357\n",
      "train loss:0.366209024090546\n",
      "train loss:0.28805276360880033\n",
      "train loss:0.26700055098180653\n",
      "train loss:0.3763241681260848\n",
      "train loss:0.2837274017002548\n",
      "train loss:0.3848799904296181\n",
      "train loss:0.34694386868402827\n",
      "train loss:0.27309634485677886\n",
      "train loss:0.30017846570874795\n",
      "train loss:0.29925535496289324\n",
      "train loss:0.2995107279928236\n",
      "train loss:0.33384187172830015\n",
      "train loss:0.24649028699041056\n",
      "train loss:0.3540669620575094\n",
      "train loss:0.2926256396869572\n",
      "train loss:0.3852955172890746\n",
      "train loss:0.34397683388540007\n",
      "train loss:0.29395399460127647\n",
      "train loss:0.34773051657573834\n",
      "train loss:0.2839947995546199\n",
      "train loss:0.34413822339316874\n",
      "train loss:0.33376026047984236\n",
      "train loss:0.35575100018385497\n",
      "train loss:0.28863055822399164\n",
      "train loss:0.29848086232260773\n",
      "train loss:0.2542768757108677\n",
      "train loss:0.38332054592023396\n",
      "train loss:0.30865282359583107\n",
      "train loss:0.29722142587422223\n",
      "train loss:0.28579080539652696\n",
      "train loss:0.284500548019701\n",
      "train loss:0.32660378624538366\n",
      "train loss:0.3042391770582214\n",
      "train loss:0.2477254793416212\n",
      "train loss:0.3314631290488735\n",
      "train loss:0.35888244822571796\n",
      "train loss:0.3083732874070664\n",
      "train loss:0.3021399059259559\n",
      "train loss:0.35079632976908826\n",
      "train loss:0.2957221695561314\n",
      "train loss:0.3637165231495357\n",
      "train loss:0.3260625775887017\n",
      "train loss:0.32710029143100966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3980971551801611\n",
      "train loss:0.31468682516947194\n",
      "train loss:0.292727157671935\n",
      "train loss:0.3313945852391211\n",
      "train loss:0.29490147137378836\n",
      "train loss:0.24097282453651156\n",
      "train loss:0.2847876362771405\n",
      "train loss:0.29780103099999783\n",
      "train loss:0.3744784745813338\n",
      "train loss:0.2910876192396007\n",
      "train loss:0.36958339850607036\n",
      "train loss:0.2716426230171629\n",
      "train loss:0.32896142631157116\n",
      "train loss:0.2920456984882624\n",
      "train loss:0.3371075088480504\n",
      "train loss:0.3214151501201213\n",
      "train loss:0.28573890360706466\n",
      "train loss:0.31851969034585537\n",
      "train loss:0.2353064049428006\n",
      "train loss:0.3175938141521654\n",
      "train loss:0.2927931659250938\n",
      "train loss:0.29757613616380024\n",
      "train loss:0.3005613629394318\n",
      "train loss:0.30792417234905867\n",
      "train loss:0.3159083728375209\n",
      "train loss:0.2785721850680384\n",
      "train loss:0.23886357289484128\n",
      "train loss:0.33095383338064427\n",
      "train loss:0.26263911128234646\n",
      "train loss:0.2911231160696442\n",
      "train loss:0.3081181307394831\n",
      "train loss:0.29681452967886024\n",
      "train loss:0.3073213358511377\n",
      "train loss:0.3417801084469544\n",
      "train loss:0.321153132782262\n",
      "train loss:0.3014955456133582\n",
      "train loss:0.3415218160957796\n",
      "train loss:0.3699461603284534\n",
      "train loss:0.31408497019671455\n",
      "train loss:0.2536222552275158\n",
      "train loss:0.30105137467947063\n",
      "train loss:0.30520261192056886\n",
      "train loss:0.26865801846234055\n",
      "train loss:0.31127831524483074\n",
      "train loss:0.27977528577364524\n",
      "train loss:0.323274017422258\n",
      "train loss:0.31759746580456466\n",
      "train loss:0.3033684433419283\n",
      "train loss:0.3545543666192286\n",
      "train loss:0.3179239593738173\n",
      "train loss:0.32173669197216626\n",
      "train loss:0.31886321244002297\n",
      "train loss:0.33381418283790215\n",
      "train loss:0.2921105078398811\n",
      "train loss:0.3024453355757744\n",
      "train loss:0.3773319107748241\n",
      "train loss:0.3449851102904576\n",
      "train loss:0.33395424772438354\n",
      "train loss:0.28997712807385173\n",
      "train loss:0.2936955691500896\n",
      "train loss:0.3395330113480786\n",
      "train loss:0.3260457050837683\n",
      "train loss:0.32992213091276423\n",
      "train loss:0.30002117357024216\n",
      "train loss:0.27532166245051937\n",
      "train loss:0.2574060671440977\n",
      "train loss:0.31829065589864336\n",
      "train loss:0.3280503896067793\n",
      "train loss:0.3476937713946516\n",
      "train loss:0.2867568671164688\n",
      "train loss:0.3272470633306235\n",
      "train loss:0.24767661082635808\n",
      "train loss:0.31413564317518733\n",
      "train loss:0.3130546079775424\n",
      "train loss:0.3056955269214898\n",
      "train loss:0.34976850549318667\n",
      "train loss:0.3840875687545961\n",
      "train loss:0.2798328239429504\n",
      "train loss:0.38745878301850106\n",
      "train loss:0.3174805645531331\n",
      "train loss:0.32456072451478607\n",
      "train loss:0.2546117577496621\n",
      "train loss:0.3286686222562079\n",
      "train loss:0.3457665825338251\n",
      "train loss:0.3428479017955668\n",
      "train loss:0.2855829107635696\n",
      "train loss:0.31019527451984363\n",
      "train loss:0.34399843306860006\n",
      "train loss:0.27316483803736435\n",
      "train loss:0.2654242860232473\n",
      "train loss:0.25284279132942594\n",
      "train loss:0.3741326543324551\n",
      "train loss:0.30038289793727496\n",
      "train loss:0.39188912111193897\n",
      "train loss:0.30800940859576353\n",
      "train loss:0.3137432167229369\n",
      "train loss:0.31073471651871976\n",
      "train loss:0.321933951587469\n",
      "train loss:0.3786724123148\n",
      "train loss:0.331463746770039\n",
      "train loss:0.3143983017924938\n",
      "train loss:0.29404869147315543\n",
      "train loss:0.3733217485329103\n",
      "train loss:0.34741452157401104\n",
      "train loss:0.35000714861848714\n",
      "train loss:0.2970470035808203\n",
      "train loss:0.392686100535566\n",
      "train loss:0.3155922495347669\n",
      "train loss:0.3566116033483309\n",
      "train loss:0.2716809152417478\n",
      "train loss:0.3386182047315128\n",
      "train loss:0.2933583171407375\n",
      "train loss:0.30741962615230395\n",
      "train loss:0.3506428536396505\n",
      "train loss:0.23284446936684605\n",
      "train loss:0.34230968585257976\n",
      "train loss:0.3310284616673428\n",
      "train loss:0.32093211881375877\n",
      "train loss:0.32800347490605475\n",
      "train loss:0.32351737270365516\n",
      "train loss:0.28949183631729686\n",
      "train loss:0.27503209951194896\n",
      "train loss:0.3187641768654657\n",
      "train loss:0.2828686908674972\n",
      "train loss:0.2648895636063584\n",
      "train loss:0.32059114524377347\n",
      "train loss:0.3102647794768991\n",
      "train loss:0.31193939718106695\n",
      "train loss:0.3279645006343641\n",
      "train loss:0.3848533216993452\n",
      "train loss:0.2613989003649476\n",
      "train loss:0.32996345118599846\n",
      "train loss:0.27497717329573595\n",
      "train loss:0.3633094727202659\n",
      "train loss:0.36275171527485145\n",
      "train loss:0.3374105476064321\n",
      "train loss:0.31172802587747456\n",
      "train loss:0.2890243258679476\n",
      "train loss:0.31241621007557685\n",
      "train loss:0.3869104106038287\n",
      "train loss:0.4041856770958136\n",
      "train loss:0.38572201548990565\n",
      "train loss:0.29976667062926265\n",
      "train loss:0.3231783400186368\n",
      "train loss:0.35675400435264315\n",
      "train loss:0.27129900968730064\n",
      "train loss:0.3591825042497072\n",
      "train loss:0.26348275179716557\n",
      "train loss:0.32734270076399813\n",
      "train loss:0.3395117059439412\n",
      "train loss:0.28708480788743196\n",
      "train loss:0.337828629721031\n",
      "train loss:0.34305197548061356\n",
      "train loss:0.3319140539599977\n",
      "train loss:0.37283545141922203\n",
      "train loss:0.2683833597914275\n",
      "train loss:0.28922378166850155\n",
      "train loss:0.3727976090244205\n",
      "train loss:0.3372308001717202\n",
      "train loss:0.3338879567044798\n",
      "train loss:0.33812448403162165\n",
      "train loss:0.389225893109515\n",
      "train loss:0.2754489278507284\n",
      "train loss:0.3798986242895797\n",
      "train loss:0.26565359234017166\n",
      "train loss:0.3143841975516994\n",
      "train loss:0.336852077010542\n",
      "train loss:0.34986482025072557\n",
      "train loss:0.3640316393515054\n",
      "train loss:0.3400670507631237\n",
      "train loss:0.34294472287068867\n",
      "train loss:0.3522317480356551\n",
      "train loss:0.26717171362869613\n",
      "train loss:0.26742708429547013\n",
      "train loss:0.2962518053751373\n",
      "train loss:0.28261361701624726\n",
      "train loss:0.33591470101754933\n",
      "train loss:0.3815530630028298\n",
      "train loss:0.342465538218926\n",
      "train loss:0.3336541375133126\n",
      "train loss:0.36578490463305047\n",
      "train loss:0.31528153085453\n",
      "train loss:0.2825891316480277\n",
      "train loss:0.28606738015915517\n",
      "train loss:0.3676163109016616\n",
      "train loss:0.3112536178562484\n",
      "train loss:0.3262581053311332\n",
      "train loss:0.23813544213851143\n",
      "train loss:0.2879100943588163\n",
      "train loss:0.3282978016387387\n",
      "train loss:0.3005079850910713\n",
      "train loss:0.328991736698836\n",
      "train loss:0.2598319261296719\n",
      "train loss:0.3357255042119845\n",
      "train loss:0.28193732708198577\n",
      "train loss:0.2534822705745207\n",
      "train loss:0.312216104384942\n",
      "train loss:0.2923879999145356\n",
      "train loss:0.32554758301276965\n",
      "train loss:0.2968140281263649\n",
      "train loss:0.3037549989023711\n",
      "train loss:0.28546046040885875\n",
      "train loss:0.2971752096580925\n",
      "train loss:0.2671963639470349\n",
      "train loss:0.2646691961265257\n",
      "train loss:0.3137067806314374\n",
      "train loss:0.31644299240944895\n",
      "train loss:0.2851312896570542\n",
      "train loss:0.38195279822070244\n",
      "train loss:0.34618326176539715\n",
      "train loss:0.2543210093989484\n",
      "train loss:0.23665396964865237\n",
      "train loss:0.3398127849437208\n",
      "=== epoch:14, train acc:0.999, test acc:1.0 ===\n",
      "train loss:0.3846374198316439\n",
      "train loss:0.2778636287121585\n",
      "train loss:0.22776492605174806\n",
      "train loss:0.2784578352235832\n",
      "train loss:0.29018790462540334\n",
      "train loss:0.40958823265314354\n",
      "train loss:0.29976306444339046\n",
      "train loss:0.3609133152979464\n",
      "train loss:0.30751556659676793\n",
      "train loss:0.323634191304996\n",
      "train loss:0.401083297951495\n",
      "train loss:0.367552300419861\n",
      "train loss:0.2969983355620747\n",
      "train loss:0.33172377827096255\n",
      "train loss:0.31329869009420647\n",
      "train loss:0.3198106303643037\n",
      "train loss:0.2759847075571437\n",
      "train loss:0.31845256234761016\n",
      "train loss:0.3679549790509299\n",
      "train loss:0.20155322804397707\n",
      "train loss:0.353998805767255\n",
      "train loss:0.34512067347454606\n",
      "train loss:0.2981198078137217\n",
      "train loss:0.3082177671139059\n",
      "train loss:0.3079535307543739\n",
      "train loss:0.3621696763991228\n",
      "train loss:0.3744214021133388\n",
      "train loss:0.31885203759622177\n",
      "train loss:0.2827562767291879\n",
      "train loss:0.31859146752630496\n",
      "train loss:0.3292300812425856\n",
      "train loss:0.3173844713014712\n",
      "train loss:0.3172083171533012\n",
      "train loss:0.32041088832243303\n",
      "train loss:0.3100694856720408\n",
      "train loss:0.3095530275157911\n",
      "train loss:0.37059991524208685\n",
      "train loss:0.38770134323658056\n",
      "train loss:0.2683421239220984\n",
      "train loss:0.3177241429052587\n",
      "train loss:0.31659882974415793\n",
      "train loss:0.26772555943908977\n",
      "train loss:0.2855743259542237\n",
      "train loss:0.42100284575141383\n",
      "train loss:0.3698162507696215\n",
      "train loss:0.33474860565001424\n",
      "train loss:0.37694959722172555\n",
      "train loss:0.3090612838639672\n",
      "train loss:0.3015167445576258\n",
      "train loss:0.348573849629601\n",
      "train loss:0.3200250099241713\n",
      "train loss:0.3114270514194651\n",
      "train loss:0.3709082030511631\n",
      "train loss:0.38824084084673155\n",
      "train loss:0.31270966759569735\n",
      "train loss:0.2864114154928334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.24518184104962357\n",
      "train loss:0.34183933754002377\n",
      "train loss:0.30698853839196194\n",
      "train loss:0.3338230965142665\n",
      "train loss:0.3164707596565103\n",
      "train loss:0.3721045279274223\n",
      "train loss:0.29380297594118615\n",
      "train loss:0.3677052116972292\n",
      "train loss:0.3907854939066665\n",
      "train loss:0.3930598606057217\n",
      "train loss:0.26305061654391126\n",
      "train loss:0.24628514574881913\n",
      "train loss:0.38118928175097416\n",
      "train loss:0.275545829540604\n",
      "train loss:0.32133324966269844\n",
      "train loss:0.3075423833428971\n",
      "train loss:0.3639469384062513\n",
      "train loss:0.2598782386101765\n",
      "train loss:0.2971296167836305\n",
      "train loss:0.3020336772347521\n",
      "train loss:0.35351145384579485\n",
      "train loss:0.2838659560363746\n",
      "train loss:0.30080071346148\n",
      "train loss:0.2951007069560268\n",
      "train loss:0.3021115357264739\n",
      "train loss:0.29628814247931606\n",
      "train loss:0.3078977965313328\n",
      "train loss:0.2875957140072754\n",
      "train loss:0.32087115391172805\n",
      "train loss:0.4091994178429305\n",
      "train loss:0.3155285066016944\n",
      "train loss:0.3377955041174134\n",
      "train loss:0.3351868601893168\n",
      "train loss:0.35489457256566426\n",
      "train loss:0.2582194081234246\n",
      "train loss:0.3292972559282975\n",
      "train loss:0.3132161993445845\n",
      "train loss:0.24427470634855547\n",
      "train loss:0.2793932361280625\n",
      "train loss:0.2671485446322855\n",
      "train loss:0.3547669716229087\n",
      "train loss:0.23435153061671474\n",
      "train loss:0.3117877221306781\n",
      "train loss:0.3165477070162292\n",
      "train loss:0.3544739593368094\n",
      "train loss:0.2834401288252143\n",
      "train loss:0.3346117209200522\n",
      "train loss:0.31619676055150076\n",
      "train loss:0.279343688560242\n",
      "train loss:0.30620741495916964\n",
      "train loss:0.38140964077987694\n",
      "train loss:0.3401271733118149\n",
      "train loss:0.28470653820310704\n",
      "train loss:0.32382287340338833\n",
      "train loss:0.2872735264514116\n",
      "train loss:0.2764765552714631\n",
      "train loss:0.2377217568243143\n",
      "train loss:0.3092731004295699\n",
      "train loss:0.31784849860535264\n",
      "train loss:0.30398550258618745\n",
      "train loss:0.31197332828268515\n",
      "train loss:0.22794228036559486\n",
      "train loss:0.30512692993809515\n",
      "train loss:0.41575795111682357\n",
      "train loss:0.3158929679041931\n",
      "train loss:0.317729861096406\n",
      "train loss:0.33514222745157035\n",
      "train loss:0.2746510394968461\n",
      "train loss:0.35086736382787687\n",
      "train loss:0.3107833353401746\n",
      "train loss:0.29696093955978903\n",
      "train loss:0.29642162579031023\n",
      "train loss:0.321118746662315\n",
      "train loss:0.3306653302307253\n",
      "train loss:0.3199088021392027\n",
      "train loss:0.36294908665876946\n",
      "train loss:0.28730310068516224\n",
      "train loss:0.31744185463096275\n",
      "train loss:0.31946704201537635\n",
      "train loss:0.31765931606304226\n",
      "train loss:0.25272157032280224\n",
      "train loss:0.25621328391891846\n",
      "train loss:0.34798057072610156\n",
      "train loss:0.3234717040991843\n",
      "train loss:0.27978568199593096\n",
      "train loss:0.2423917885676527\n",
      "train loss:0.29639158768714435\n",
      "train loss:0.3454711868452926\n",
      "train loss:0.32753588616378054\n",
      "train loss:0.279150483122839\n",
      "train loss:0.2880904168251578\n",
      "train loss:0.2763357241838444\n",
      "train loss:0.313417167462393\n",
      "train loss:0.35448533354307454\n",
      "train loss:0.3095675634737573\n",
      "train loss:0.2930658110802179\n",
      "train loss:0.3345185365744991\n",
      "train loss:0.30872305377569514\n",
      "train loss:0.31975393222888776\n",
      "train loss:0.3226390379777795\n",
      "train loss:0.26692636985976853\n",
      "train loss:0.3809314160330659\n",
      "train loss:0.34670735864523117\n",
      "train loss:0.33243790473778545\n",
      "train loss:0.3540023596205065\n",
      "train loss:0.3586939566282185\n",
      "train loss:0.3163468206309164\n",
      "train loss:0.38993727985626525\n",
      "train loss:0.2755433124201566\n",
      "train loss:0.29550223100568945\n",
      "train loss:0.32977145615100356\n",
      "train loss:0.3086626489364521\n",
      "train loss:0.35868360306644015\n",
      "train loss:0.2957058681251293\n",
      "train loss:0.33249773587440834\n",
      "train loss:0.2604587398353441\n",
      "train loss:0.3127484080683486\n",
      "train loss:0.3228986347842227\n",
      "train loss:0.257857170142027\n",
      "train loss:0.3428213428498791\n",
      "train loss:0.4369008648455272\n",
      "train loss:0.271318018918367\n",
      "train loss:0.25185236304163516\n",
      "train loss:0.259513569494294\n",
      "train loss:0.28193420465180535\n",
      "train loss:0.312084333061494\n",
      "train loss:0.33326268164757583\n",
      "train loss:0.3420462137120486\n",
      "train loss:0.3370692040879517\n",
      "train loss:0.3415124813968473\n",
      "train loss:0.34704849515165387\n",
      "train loss:0.2914259995455744\n",
      "train loss:0.23300833970732485\n",
      "train loss:0.368284557484184\n",
      "train loss:0.31873793904362047\n",
      "train loss:0.2676474888956683\n",
      "train loss:0.2645308166717209\n",
      "train loss:0.3067820113895407\n",
      "train loss:0.32350084832665993\n",
      "train loss:0.38185799425424527\n",
      "train loss:0.398169778066367\n",
      "train loss:0.3290354069179237\n",
      "train loss:0.2754580084383684\n",
      "train loss:0.2477161278246105\n",
      "train loss:0.33379601952906035\n",
      "train loss:0.3462630929336779\n",
      "train loss:0.28296635919797664\n",
      "train loss:0.33001489864062383\n",
      "train loss:0.38745905261080626\n",
      "train loss:0.3004582153848529\n",
      "train loss:0.30706953467298653\n",
      "train loss:0.3253368373313788\n",
      "train loss:0.2558574801495182\n",
      "train loss:0.4117582695001537\n",
      "train loss:0.3496592892799815\n",
      "train loss:0.2927465254058198\n",
      "train loss:0.3253356541472662\n",
      "train loss:0.32715804131152587\n",
      "train loss:0.3546204545782651\n",
      "train loss:0.35718266009287325\n",
      "train loss:0.3041976368863712\n",
      "train loss:0.3382347305551684\n",
      "train loss:0.34706406640088544\n",
      "train loss:0.3130239394542059\n",
      "train loss:0.24834710867278004\n",
      "train loss:0.35600493925168436\n",
      "train loss:0.31180543713595377\n",
      "train loss:0.31078736050485106\n",
      "train loss:0.33620605078601334\n",
      "train loss:0.3014905350319162\n",
      "train loss:0.36120943682778067\n",
      "train loss:0.49388355710953336\n",
      "train loss:0.3388700429380152\n",
      "train loss:0.28082895519789114\n",
      "train loss:0.24607639280412444\n",
      "train loss:0.3016327388991696\n",
      "train loss:0.308125037262057\n",
      "train loss:0.367385582065544\n",
      "train loss:0.2583860704804727\n",
      "train loss:0.3455991084216798\n",
      "train loss:0.28898702837719387\n",
      "train loss:0.2641688372793106\n",
      "train loss:0.3361673757754114\n",
      "train loss:0.3229447600874751\n",
      "train loss:0.2949365402819655\n",
      "train loss:0.2996296367460374\n",
      "train loss:0.35101007812647683\n",
      "train loss:0.27121534199891734\n",
      "train loss:0.31987429424264324\n",
      "train loss:0.2266113881318267\n",
      "train loss:0.3111709013873624\n",
      "train loss:0.38203199439190744\n",
      "train loss:0.33201275167327454\n",
      "train loss:0.2921037510718503\n",
      "train loss:0.3316560643359996\n",
      "train loss:0.28128502796434723\n",
      "train loss:0.2907062182306201\n",
      "train loss:0.3026227088222107\n",
      "train loss:0.2798246904760928\n",
      "train loss:0.26380591785103125\n",
      "train loss:0.32398346960499097\n",
      "train loss:0.3417566623158465\n",
      "train loss:0.2545791789897711\n",
      "train loss:0.33811862342282584\n",
      "train loss:0.36703387879149024\n",
      "train loss:0.2901381416853578\n",
      "train loss:0.311194099978457\n",
      "train loss:0.38940757506336215\n",
      "train loss:0.33101358693541505\n",
      "train loss:0.37913039923148456\n",
      "train loss:0.34640611699648716\n",
      "train loss:0.312603606327655\n",
      "train loss:0.32767349964559134\n",
      "train loss:0.26425568738432537\n",
      "train loss:0.29760860222694563\n",
      "train loss:0.3359392709474898\n",
      "train loss:0.2533354794980232\n",
      "train loss:0.3484320709607604\n",
      "train loss:0.27707455160224276\n",
      "train loss:0.33191428021175634\n",
      "train loss:0.32966650350952303\n",
      "train loss:0.27559438718810014\n",
      "train loss:0.239229355483672\n",
      "train loss:0.3186989035227897\n",
      "train loss:0.33387731693730915\n",
      "train loss:0.33262471328380244\n",
      "train loss:0.3089034035463963\n",
      "train loss:0.23876688027028015\n",
      "train loss:0.3121445537470123\n",
      "train loss:0.2776554733249713\n",
      "train loss:0.36860892944289436\n",
      "train loss:0.27254414543308936\n",
      "train loss:0.3387062792732376\n",
      "train loss:0.3884162412596878\n",
      "train loss:0.33734358775963247\n",
      "train loss:0.3429861748693707\n",
      "train loss:0.3023221065533062\n",
      "train loss:0.20611900603137442\n",
      "train loss:0.3228311433752059\n",
      "train loss:0.3034456839403958\n",
      "train loss:0.3176094682626894\n",
      "train loss:0.38727125726060124\n",
      "train loss:0.3253486561769304\n",
      "train loss:0.2759732464043258\n",
      "train loss:0.34181450170038213\n",
      "train loss:0.2890094810977811\n",
      "train loss:0.28783833238366924\n",
      "train loss:0.24357641981919673\n",
      "train loss:0.2573925722809202\n",
      "train loss:0.29017438557820757\n",
      "train loss:0.3097202993606705\n",
      "train loss:0.3593878080620409\n",
      "train loss:0.32222814567106894\n",
      "train loss:0.2754095510263771\n",
      "train loss:0.3135884356910726\n",
      "train loss:0.28901212767425644\n",
      "train loss:0.3370599605196181\n",
      "train loss:0.2544171306628391\n",
      "train loss:0.21542470169246736\n",
      "train loss:0.24179247659031955\n",
      "train loss:0.3294487528691827\n",
      "train loss:0.2691308208794345\n",
      "train loss:0.214690526917512\n",
      "train loss:0.3579501307836155\n",
      "train loss:0.28954319593405925\n",
      "train loss:0.2904336046826985\n",
      "train loss:0.2953964866338248\n",
      "train loss:0.39215103553542635\n",
      "train loss:0.3629621208454031\n",
      "train loss:0.2558784394831441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.32030778954215505\n",
      "train loss:0.3348962429960348\n",
      "train loss:0.39585721169103777\n",
      "train loss:0.41661136655051234\n",
      "train loss:0.3576028761509704\n",
      "train loss:0.3498396021143808\n",
      "train loss:0.3290854132618935\n",
      "train loss:0.3441614617087388\n",
      "train loss:0.24192945320933212\n",
      "train loss:0.3361518749121846\n",
      "train loss:0.3334398346025656\n",
      "train loss:0.22343053576388697\n",
      "train loss:0.32843742510822743\n",
      "train loss:0.3477395664671142\n",
      "train loss:0.32323350172873094\n",
      "train loss:0.3107034124300242\n",
      "train loss:0.3661320871150617\n",
      "train loss:0.3039625964909099\n",
      "train loss:0.28081868390843184\n",
      "train loss:0.33811413460210626\n",
      "train loss:0.31037269535273176\n",
      "train loss:0.2729759393260843\n",
      "train loss:0.32494041396802786\n",
      "train loss:0.28555017360498863\n",
      "train loss:0.2732329446623128\n",
      "train loss:0.31352711651357235\n",
      "train loss:0.32558258447661986\n",
      "train loss:0.2740926491841058\n",
      "train loss:0.3142437894184252\n",
      "train loss:0.2537238152327325\n",
      "train loss:0.3270041853120253\n",
      "train loss:0.40722229675632876\n",
      "train loss:0.29931932498772656\n",
      "train loss:0.31621738509456127\n",
      "train loss:0.3327022361255209\n",
      "train loss:0.36160499784071193\n",
      "train loss:0.36742716233813666\n",
      "train loss:0.291346361896485\n",
      "train loss:0.29097876637763803\n",
      "train loss:0.2843152788861406\n",
      "train loss:0.27411967801250275\n",
      "train loss:0.3246091905259256\n",
      "=== epoch:15, train acc:1.0, test acc:0.997 ===\n",
      "train loss:0.30354414292230325\n",
      "train loss:0.283504589897216\n",
      "train loss:0.341483135845671\n",
      "train loss:0.2553510263929581\n",
      "train loss:0.36752478642625647\n",
      "train loss:0.2971380530929757\n",
      "train loss:0.3665355866824426\n",
      "train loss:0.3924921655636943\n",
      "train loss:0.30003255202319257\n",
      "train loss:0.289936925667396\n",
      "train loss:0.357805260772509\n",
      "train loss:0.3189438978966182\n",
      "train loss:0.29073830751281865\n",
      "train loss:0.32385068432884384\n",
      "train loss:0.3035347861460726\n",
      "train loss:0.26662273959235816\n",
      "train loss:0.2829836111173228\n",
      "train loss:0.36224446856506576\n",
      "train loss:0.34643038325008035\n",
      "train loss:0.3024494090018649\n",
      "train loss:0.3077227260722708\n",
      "train loss:0.48339503069183076\n",
      "train loss:0.30901876200537115\n",
      "train loss:0.32893470699443983\n",
      "train loss:0.32903537858742854\n",
      "train loss:0.32007084686484044\n",
      "train loss:0.2939783928514396\n",
      "train loss:0.31746087430342507\n",
      "train loss:0.33054890159946937\n",
      "train loss:0.3174970987969293\n",
      "train loss:0.3231562662219748\n",
      "train loss:0.2766792482031046\n",
      "train loss:0.2798288728348094\n",
      "train loss:0.26592105778479264\n",
      "train loss:0.2733496046885252\n",
      "train loss:0.3193373802036523\n",
      "train loss:0.2890265084235445\n",
      "train loss:0.3504461662302204\n",
      "train loss:0.34694061030351137\n",
      "train loss:0.33055279624542366\n",
      "train loss:0.3256514056615361\n",
      "train loss:0.32084341361513197\n",
      "train loss:0.2809015607323562\n",
      "train loss:0.31479944617181616\n",
      "train loss:0.2757259341682232\n",
      "train loss:0.3189376923348359\n",
      "train loss:0.27189338198537766\n",
      "train loss:0.2900017993419831\n",
      "train loss:0.26362367396876185\n",
      "train loss:0.2727751647476116\n",
      "train loss:0.32378859343139926\n",
      "train loss:0.2956348683931644\n",
      "train loss:0.26467760553305975\n",
      "train loss:0.32959688619102395\n",
      "train loss:0.367628937269841\n",
      "train loss:0.34899606798783933\n",
      "train loss:0.2672854740415119\n",
      "train loss:0.2703194071391971\n",
      "train loss:0.30647410848199946\n",
      "train loss:0.3267729516210947\n",
      "train loss:0.3313074754360888\n",
      "train loss:0.3602967145978271\n",
      "train loss:0.34288109306797837\n",
      "train loss:0.33373201209259223\n",
      "train loss:0.32941599463829413\n",
      "train loss:0.3573388756365831\n",
      "train loss:0.36599241440469765\n",
      "train loss:0.35001709833335576\n",
      "train loss:0.32030668903361215\n",
      "train loss:0.29146052210535095\n",
      "train loss:0.32398278064334785\n",
      "train loss:0.28515104738037894\n",
      "train loss:0.29104091844679564\n",
      "train loss:0.3689947494189203\n",
      "train loss:0.32006979006517083\n",
      "train loss:0.2768978793336146\n",
      "train loss:0.2511749621882235\n",
      "train loss:0.29367340642130774\n",
      "train loss:0.29691474672433904\n",
      "train loss:0.29935531575173485\n",
      "train loss:0.3532414244426086\n",
      "train loss:0.36794740563115563\n",
      "train loss:0.35303606970628654\n",
      "train loss:0.30736439566406326\n",
      "train loss:0.28236714256330553\n",
      "train loss:0.31308114215277544\n",
      "train loss:0.32171475063410726\n",
      "train loss:0.3480349409359388\n",
      "train loss:0.3426422565251675\n",
      "train loss:0.303594706300996\n",
      "train loss:0.26585501237651804\n",
      "train loss:0.3059699205430242\n",
      "train loss:0.2292508035306315\n",
      "train loss:0.3108681267654923\n",
      "train loss:0.285903915102784\n",
      "train loss:0.27728372222385217\n",
      "train loss:0.30138126108125907\n",
      "train loss:0.3727594968276415\n",
      "train loss:0.29162694636634623\n",
      "train loss:0.3668788368136036\n",
      "train loss:0.40134387844399505\n",
      "train loss:0.31938099483967725\n",
      "train loss:0.25824785467321226\n",
      "train loss:0.27514730627115147\n",
      "train loss:0.2462980270060535\n",
      "train loss:0.273059868409279\n",
      "train loss:0.3723261844376991\n",
      "train loss:0.2999546605727932\n",
      "train loss:0.26332835220162726\n",
      "train loss:0.33036857025903527\n",
      "train loss:0.33124057939513996\n",
      "train loss:0.28414341889789946\n",
      "train loss:0.296305705476922\n",
      "train loss:0.29074682195561485\n",
      "train loss:0.4050081666638649\n",
      "train loss:0.24335900679261446\n",
      "train loss:0.3667489132420176\n",
      "train loss:0.2544605473095196\n",
      "train loss:0.21355697235349722\n",
      "train loss:0.2861350805224425\n",
      "train loss:0.3513604398644887\n",
      "train loss:0.34854957165949296\n",
      "train loss:0.3291053416248941\n",
      "train loss:0.32825342781092587\n",
      "train loss:0.33995223170909306\n",
      "train loss:0.3745520402363878\n",
      "train loss:0.3547357853147635\n",
      "train loss:0.32413474994526703\n",
      "train loss:0.3314685892487031\n",
      "train loss:0.28791650510309985\n",
      "train loss:0.3479860611726859\n",
      "train loss:0.32556766164411094\n",
      "train loss:0.29245796282814013\n",
      "train loss:0.3299866928311194\n",
      "train loss:0.30764986050291404\n",
      "train loss:0.3342577163000377\n",
      "train loss:0.29983852831219976\n",
      "train loss:0.2771780733441902\n",
      "train loss:0.2716181697253632\n",
      "train loss:0.2947420144316537\n",
      "train loss:0.3016417297971112\n",
      "train loss:0.2855696842463538\n",
      "train loss:0.3233405896587864\n",
      "train loss:0.3385719448057006\n",
      "train loss:0.34727410385017354\n",
      "train loss:0.30834856163545105\n",
      "train loss:0.31870674020630324\n",
      "train loss:0.3181960685550601\n",
      "train loss:0.3014600009764314\n",
      "train loss:0.31925351875251073\n",
      "train loss:0.2875204097347427\n",
      "train loss:0.2697510059545179\n",
      "train loss:0.2936753296720912\n",
      "train loss:0.34745039895643703\n",
      "train loss:0.3425353503354092\n",
      "train loss:0.27641886962654555\n",
      "train loss:0.3140989766348076\n",
      "train loss:0.31796593375155846\n",
      "train loss:0.31087090819890134\n",
      "train loss:0.35645967417687413\n",
      "train loss:0.3512410575235272\n",
      "train loss:0.25096458969049285\n",
      "train loss:0.3269966521579535\n",
      "train loss:0.28662647366580224\n",
      "train loss:0.3487050202667538\n",
      "train loss:0.33638374433930124\n",
      "train loss:0.3003316622854195\n",
      "train loss:0.26826570208230127\n",
      "train loss:0.33133067886456885\n",
      "train loss:0.3178550376902924\n",
      "train loss:0.2798569736695934\n",
      "train loss:0.32548344024489306\n",
      "train loss:0.3463157574040035\n",
      "train loss:0.3484425976926166\n",
      "train loss:0.3082606668075588\n",
      "train loss:0.33394867456456934\n",
      "train loss:0.2148564347379556\n",
      "train loss:0.41575592406172296\n",
      "train loss:0.2658310720024273\n",
      "train loss:0.28654621538997205\n",
      "train loss:0.2769749948267293\n",
      "train loss:0.2981539478742802\n",
      "train loss:0.37417377823045206\n",
      "train loss:0.32218141737943545\n",
      "train loss:0.4107566814782174\n",
      "train loss:0.2634598883596163\n",
      "train loss:0.37954225593886176\n",
      "train loss:0.4046546522469095\n",
      "train loss:0.30499482688720436\n",
      "train loss:0.303894173128266\n",
      "train loss:0.32492287568880834\n",
      "train loss:0.28687487284121344\n",
      "train loss:0.2675731443062515\n",
      "train loss:0.2731573920437729\n",
      "train loss:0.25777850849325845\n",
      "train loss:0.32915492356371256\n",
      "train loss:0.2961829198088657\n",
      "train loss:0.2879919259916074\n",
      "train loss:0.3371670868869308\n",
      "train loss:0.3181653796521852\n",
      "train loss:0.35487082068053066\n",
      "train loss:0.3025006821406361\n",
      "train loss:0.297145152519131\n",
      "train loss:0.3106624331395266\n",
      "train loss:0.30102636169705016\n",
      "train loss:0.2818208967520201\n",
      "train loss:0.2418025384585095\n",
      "train loss:0.3364310137611595\n",
      "train loss:0.2741776766752227\n",
      "train loss:0.31599322132307156\n",
      "train loss:0.3030054156360704\n",
      "train loss:0.2709415257042675\n",
      "train loss:0.2936345971212744\n",
      "train loss:0.34326220910151134\n",
      "train loss:0.29387839600096616\n",
      "train loss:0.29242974159914664\n",
      "train loss:0.2933423438137416\n",
      "train loss:0.31303611456839925\n",
      "train loss:0.32315175190378015\n",
      "train loss:0.2817768319190641\n",
      "train loss:0.2774039045983185\n",
      "train loss:0.3238296506307583\n",
      "train loss:0.3362017126454749\n",
      "train loss:0.3177245846912889\n",
      "train loss:0.3025586463521269\n",
      "train loss:0.22802439134543787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3347813325262693\n",
      "train loss:0.30220124796551195\n",
      "train loss:0.3456787224490533\n",
      "train loss:0.23273911174106038\n",
      "train loss:0.3265594622125496\n",
      "train loss:0.30511211835666463\n",
      "train loss:0.3433578583054614\n",
      "train loss:0.2865737802368108\n",
      "train loss:0.2765198361776337\n",
      "train loss:0.35312239896673947\n",
      "train loss:0.30418483266983193\n",
      "train loss:0.27178673286890564\n",
      "train loss:0.29471058890991186\n",
      "train loss:0.2808582332175598\n",
      "train loss:0.2992828581356935\n",
      "train loss:0.27934474555293015\n",
      "train loss:0.33499826387950143\n",
      "train loss:0.2131413879223913\n",
      "train loss:0.3564842587613248\n",
      "train loss:0.33373921503364173\n",
      "train loss:0.32220094740545563\n",
      "train loss:0.24303830863795728\n",
      "train loss:0.3601589189358104\n",
      "train loss:0.2624647776149862\n",
      "train loss:0.38336481629525915\n",
      "train loss:0.25433252820978963\n",
      "train loss:0.27148056283601096\n",
      "train loss:0.2130637084264358\n",
      "train loss:0.28787232615138314\n",
      "train loss:0.26037891118288137\n",
      "train loss:0.26973693349068323\n",
      "train loss:0.34555985378145215\n",
      "train loss:0.3795940915171345\n",
      "train loss:0.3179009423212913\n",
      "train loss:0.29470041570456734\n",
      "train loss:0.21528614545284036\n",
      "train loss:0.33276054451827675\n",
      "train loss:0.33079646382717887\n",
      "train loss:0.2486661837794495\n",
      "train loss:0.2837282108286588\n",
      "train loss:0.287383471164009\n",
      "train loss:0.33800444140035346\n",
      "train loss:0.3100830829848886\n",
      "train loss:0.2687832088018181\n",
      "train loss:0.3856127042065444\n",
      "train loss:0.3480540679735988\n",
      "train loss:0.37428590430389513\n",
      "train loss:0.35158858793786957\n",
      "train loss:0.30672213210415195\n",
      "train loss:0.32115397718567895\n",
      "train loss:0.40883656261751705\n",
      "train loss:0.31547624309503414\n",
      "train loss:0.2914565306740703\n",
      "train loss:0.31090686750760654\n",
      "train loss:0.32754451468333534\n",
      "train loss:0.32676257831321665\n",
      "train loss:0.3010653389734317\n",
      "train loss:0.34122042890690985\n",
      "train loss:0.3463445602247328\n",
      "train loss:0.3563527178110758\n",
      "train loss:0.38507113832145673\n",
      "train loss:0.2875517439753248\n",
      "train loss:0.41970646861496236\n",
      "train loss:0.30874074884745895\n",
      "train loss:0.39533486665072043\n",
      "train loss:0.3470491945054262\n",
      "train loss:0.3034826248553981\n",
      "train loss:0.2749099146325239\n",
      "train loss:0.2828000459978606\n",
      "train loss:0.27773428356372304\n",
      "train loss:0.33642323293346305\n",
      "train loss:0.30545022671389505\n",
      "train loss:0.2660995581591892\n",
      "train loss:0.3367415458061455\n",
      "train loss:0.32808538208785654\n",
      "train loss:0.26752536886517225\n",
      "train loss:0.3557154259784396\n",
      "train loss:0.2549659662180127\n",
      "train loss:0.35554210087198485\n",
      "train loss:0.3321228384966258\n",
      "train loss:0.39663471802166966\n",
      "train loss:0.3084875608642583\n",
      "train loss:0.34254148021779207\n",
      "train loss:0.26441938402977955\n",
      "train loss:0.3389026063688495\n",
      "train loss:0.31211149469083915\n",
      "train loss:0.3346895803853851\n",
      "train loss:0.26106862846147366\n",
      "train loss:0.318549953909545\n",
      "train loss:0.35317623575529367\n",
      "train loss:0.2514626276957078\n",
      "train loss:0.3238885605467228\n",
      "train loss:0.32894114310809724\n",
      "train loss:0.287569770416523\n",
      "train loss:0.3069405884925642\n",
      "train loss:0.3494451867282003\n",
      "train loss:0.36955828904108934\n",
      "train loss:0.3066276902793187\n",
      "train loss:0.2804250464213728\n",
      "train loss:0.3736339848228885\n",
      "train loss:0.2904254046499186\n",
      "train loss:0.32406936586406954\n",
      "train loss:0.31383733298150235\n",
      "train loss:0.3136324345198369\n",
      "train loss:0.38767201751306607\n",
      "train loss:0.38195601036816\n",
      "train loss:0.2104649395044754\n",
      "train loss:0.37749112263411294\n",
      "train loss:0.3029518569135821\n",
      "train loss:0.29051179076580724\n",
      "train loss:0.3671516041992804\n",
      "train loss:0.2271651810612717\n",
      "train loss:0.2690938950237696\n",
      "train loss:0.27832003734128796\n",
      "train loss:0.28219776018705406\n",
      "train loss:0.31857757737361003\n",
      "train loss:0.3774077097625377\n",
      "train loss:0.2947933393542941\n",
      "train loss:0.3040666370265459\n",
      "train loss:0.32339937462492807\n",
      "train loss:0.3347645786451494\n",
      "train loss:0.30746383992259835\n",
      "train loss:0.3192168484054993\n",
      "train loss:0.33614701032487293\n",
      "train loss:0.2662516832456267\n",
      "train loss:0.33524170654870045\n",
      "train loss:0.35697635645518433\n",
      "train loss:0.34052898256805053\n",
      "train loss:0.29065191994904943\n",
      "train loss:0.32956892245655267\n",
      "train loss:0.2776020901408875\n",
      "train loss:0.32316087366334956\n",
      "train loss:0.36339742888667825\n",
      "train loss:0.2902311766652782\n",
      "train loss:0.27364250461928713\n",
      "train loss:0.3084902045198653\n",
      "train loss:0.2692421768069655\n",
      "train loss:0.3118537157193348\n",
      "train loss:0.34835565044613653\n",
      "train loss:0.2787563986303451\n",
      "train loss:0.3328219993206207\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9948369565217391\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (15,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m markers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(max_epochs)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_acc_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkevery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x, trainer\u001b[38;5;241m.\u001b[39mtest_acc_list, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, markevery\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py:2767\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2768\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2769\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1635\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1635\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (15,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deep convolutional Network(chap08)\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.img_oxt import load_oxt\n",
    "from common.deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_oxt(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=15, mini_batch_size=120,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보관\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep convolutional Network(chap08)\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.img_oxt import load_oxt\n",
    "from common.deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_oxt(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "window = Tk()\n",
    "window.title('oxt 예측하기')\n",
    "    \n",
    "oldx = oldy = -1\n",
    "\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global oldx, oldy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x, y\n",
    "        # print('EVENT_LBUTTONDOWN: %d, %d' % (x, y))\n",
    "\n",
    "    # elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # print('EVENT_LBUTTONUP: %d, %d' % (x, y))\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx, oldy), (x, y), 0, 5, cv2.LINE_AA)\n",
    "            cv2.imshow('image', img)\n",
    "            oldx, oldy = x, y\n",
    "\n",
    "def crt():\n",
    "    global img, tmp_img\n",
    "    img = np.ones((280, 280), dtype=np.uint8) * 255\n",
    "\n",
    "    cv2.namedWindow('image')\n",
    "    cv2.setMouseCallback('image', on_mouse, img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(3000)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    img = cv2.resize(img, (28,28), interpolation=cv2.INTER_AREA)     # 28*28 resize\n",
    "    cv2.imwrite('tmp.png', img)\n",
    "    img = ~img  # invert\n",
    "    img=img.reshape(-1,1,28,28)\n",
    "    \n",
    "    labels_view=['o', 'x', '△']\n",
    "\n",
    "    y=network.predict(img)\n",
    "    pred_num=np.argmax(y)\n",
    "    result = \"my predict is %s\"%(labels_view[pred_num])\n",
    "    \n",
    "    tmp_img=Image.open('tmp.png')\n",
    "    tmp_img=ImageTk.PhotoImage(tmp_img)\n",
    "    \n",
    "    Label(window, text=\"파일경로: new\").grid(row=2) # 파일경로 view\n",
    "    Label(window, image=tmp_img).grid(row=3) #사진 view\n",
    "    Label(window, text=result).grid(row=4) # 예측 결과 출력    \n",
    "\n",
    "def open():\n",
    "    global my_image # 함수에서 이미지를 기억하도록 전역변수 선언 (안하면 사진이 안보임)\n",
    "    window.filename = filedialog.askopenfilename(initialdir='', title='파일선택', filetypes=(\n",
    "    ('png files', '*.png'), ('jpg files', '*.jpg'), ('all files', '*.*')))\n",
    " \n",
    "    Label(window, text=\"파일경로: \"+window.filename).grid(row=2) # 파일경로 view\n",
    "    \n",
    "    img = Image.open(window.filename)\n",
    "    my_image = ImageTk.PhotoImage(img)\n",
    "    \n",
    "    img=img.convert(\"L\")                         # gray 저장\n",
    "    img=np.invert(img)                           # 흑백을 반전\n",
    "    \n",
    "    # print(img.shape)                           # img의 shape 확인\n",
    "    img=img.reshape(-1, 1, 28, 28)\n",
    "    \n",
    "    Label(window, image=my_image).grid(row=3) #사진 view\n",
    "    \n",
    "    labels_view=['o', 'x', '△']\n",
    "\n",
    "    y=network.predict(img)\n",
    "    pred_num=np.argmax(y)\n",
    "    result = \"my predict is %s\"%(labels_view[pred_num])\n",
    "    Label(window, text=result).grid(row=4) # 예측 결과 출력\n",
    "    \n",
    "\n",
    "b_create=Button(window, text='그리기(아무키나 누르면 닫기)', command=crt).grid(row=0)\n",
    "b_open = Button(window, text='파일열기', command=open).grid(row=1)\n",
    "Label(window, text=\"파일 경로\").grid(row=2)\n",
    "Label(window).grid(row=3)\n",
    "Label(window, text=\"예측 결과\").grid(row=4)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
